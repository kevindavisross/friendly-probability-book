# The Language of Simulation {#sec-language-simulation}

{{< include _r_setup.qmd >}}

{{< include _python_setup.qmd >}}

::: {.content-hidden}
$$
{{< include _macros.tex >}}
$$
:::


A probability model of a random phenomenon consists of a sample space of possible outcomes, associated events and random variables, and a probability measure which encapsulates the model assumptions and determines probabilities of events and distributions of random variables.
We will study strategies for computing probabilities, distributions, expected values, and more, but in many situations explicit computation is difficult.
Simulation provides a powerful tool for working with probability models and solving complex problems.

**Simulation** involves using a probability model to artificially recreate a random phenomenon, usually using a computer.
Given a probability model, we can simulate outcomes, occurrences of events, and values of random variables.
Simulation can be used to approximate probabilities of events, distributions of random variables, expected values, and more.





Recall that the probability of an event can be interpreted as a long run relative frequency.
Therefore the probability of an event can be approximated by simulating---according to the assumptions of the probability model---the random phenomenon a large number of times and computing the relative frequency of repetitions on which the event occurs.

Likewise, the expected value of a random variable can be interpreted as its long run average value, and can be approximated by simulating---according to the assumptions of the probability model---the random phenomenon a large number of times and computing the average value of the random variable over the simulated repetitions.


In general, a simulation involves the following steps.

1.  **Set up.**
Define[^simulation-11] a probability space, and related random variables and events.
The probability measure encodes all the assumptions of the model, but the probability measure is often only specified indirectly.
2.  **Simulate.**
Simulate outcomes, occurrences of events, and values of random variables.
3.  **Summarize.**
Summarize simulation output in plots and summary statistics (e.g., relative frequencies, averages, standard deviations, correlations) to describe and approximate probabilities, distributions, expected values, and more.
4.  **Sensitivity analysis.**
Investigate how results respond to changes in assumptions or parameters of the simulation.

[^simulation-11]: In most situations we'll encounter in this book, the "set up" step requires the most work and the most computer programming, while the "simulate" and "summarize" steps are usually straightforward.
    In many other cases, these steps can be challenging.
    Complex set ups often require sophisticated methods, such MCMC (Markov Chain Monte Carlo) algorithms, to efficiently simulate realizations.
    Effectively summarizing high dimensional simulation output often requires the use of multivariate statistics and visualizations.

You might ask: if we have access to the probability measure, then why do we need simulation to approximate probabilities?
Can't we just compute them?
Remember that the probability measure is often only specified indirectly, e.g. "flip a fair coin ten times and count the number of heads".
In most situations the probability measure does not provide an explicit formula for computing the probability of any particular event.
And in many cases, it is impossible to enumerate all possible outcomes.

For example, a probabilistic model of a particular Atlantic Hurricane does not provide a mathematical formula for computing the probability that the hurricane makes landfall in the U.S.
Nor does the model provide a comprehensive list of the uncountably many possible paths of the hurricane.
Rather, the model reflects a set of assumptions under which possible paths can be simulated to approximate probabilities of events of interest like those depicted in @fig-hurricane-cone.

![Picture of a "hurricane cone of uncertainty" from the [August 28, 2019 *Washington Post* article "How the hurricane cone of uncertainty can be a cone of confusion, and what to do about it."](https://www.washingtonpost.com/weather/2019/08/28/how-hurricane-cone-uncertainty-can-be-cone-confusion-what-do-about-it/)](_graphics/hurricane-cone.png){#fig-hurricane-cone}



In this chapter we will use simulation to investigate some of the problems introduced in the previous chapter.
We can solve many of these problems without simulation.
But we like to introduce simulation via simple examples where we know the answers so we can get comfortable with the simulation process and easily check that it works.

## Tactile simulation: Boxes and spinners {#sec-tactile}

While we generally use technology to conduct large scale simulations, it is helpful to first consider how to conduct a simulation by hand using physical objects like coins, dice, cards, or spinners.

Many random phenomena can be represented in terms of a **"box model**[^simulation-12]"

[^simulation-12]: Our use of "box models" is inspired by [@FPP].

-   Imagine a box containing "tickets" with labels. Examples include:
    -   Fair coin flip. 2 tickets: 1 labeled H and 1 labeled T
    -   Free throw attempt of a 90% free throw shooter. 10 tickets: 9 labeled "make" and 1 labeled "miss"
    -   Card shuffling. 52 cards: each card with a pair of labels (face value, suit).
-   The tickets are shuffled in the box and some number are drawn out, either *with replacement or without replacement* of the tickets before the next draw[^simulation-13].
-   In some cases, the order in which the tickets are drawn matters; in other cases the order is irrelevant. For example,
    -   Dealing a 5 card poker hand: Select 5 cards without replacement, order does not matter
    -   Random digit dialing: Select 4 cards with replacement from a box with tickets labeled 0 through 9 to represent the last 4 digits of a randomly selected phone number with a particular area code and exchange; order matters, e.g., 805-555-1212 is a different outcome than 805-555-2121.
-   Then something is done with the tickets to determine which events of interest  have occurred or to measure random variables.
For example, you might flip a coin 10 times (by drawing from the H/T box 10 times with replacement) and check if there were at least 3 H in a row or count the number of H.

[^simulation-13]: "With replacement" always implies replacement at a uniformly random point in the box.
    Think of "with replacement" as "with replacement and reshuffling" before the next draw.

If the draws are made with replacement from a single box, we can think of a single circular "spinner" instead of a box, spun multiple times.
For example:

-   Fair coin flip. Spinner with half of the area corresponding to H and half T
-   Free throw attempt of a 90% free throw shooter. Spinner with 90% of the area corresponding to "make" and 10% "miss". <!-- - Random digit dialing.  Spinner marked with digits 0-9, possibly with some digits more likely than others.  spun multiple times.  Depending on what regions you are trying to sample, you might have three spinners: one to generate area code, one to generate the next three digits, and one to generate the last four digits. -->

:::: {.callout-note appearance="simple"}
::: {#exm-dice-sim}
Consider a box model for rolling a four-sided die.


1.  Set up a box model for simulating a roll of each of the following dice.
    a.  a fair four-sided die
    a.  the weighted die in @exm-die-weighted
    a.  the weighted die in @exm-dice-normalize.
1.  Roll a die from the previous part twice and let $X$ be the sum of two rolls and let $Y$ be the larger of the two rolls (or the common value if a tie).
Explain how you would use the box models from the previous part to simulate a realization of $(X, Y)$.
1.  Let $A$ be the event that the sum is 3, and let $\ind_A$ be the indicator random variable.
Explain how you would use the box models to simulate a realization of $A$ and $I_A$.
1.  In the previous parts, could you use spinners instead?
1.  Use a *fair* four-sided die (or a box or a spinner) to simulate 10 repetitions.
(Yes, really do it.)
For each repetition, record the results of the first and second rolls (or draws or spins) and the simulated values of $X$, $Y$, $A$, and $I_A$.

:::
::::

:::: {.callout-tip collapse=true}
::: {#sol-dice-sim}



1.  Each box would have the numbers 1, 2, 3, 4 written on some number of tickets.
    a.  4 tickets: labeled 1, 2, 3, 4
    a.  10 tickets: 1 labeled 1, 2 labeled 2, 3 labeled 3, 4 labeled 4
    a.  15 tickets: 4 labeled 1, 6 labeled 2, 3 labeled 3, 2 labeled 4
1.  Use the appropriate box for the die of interest.
Draw two tickets *with replacement* (that is, put the first ticket back in the box and reshuffle before drawing the second ticket).
Let $X$ be the sum of the two numbers drawn and $Y$ the larger of the two numbers drawn.
1.  Similar to the previous part, but event $A$ either happens or not, so a realization of it is true or false instead of a number.
If the first roll is 3 then $A$ is true; otherwise $A$ is false.
The indicator random variable $\ind_A$ just translates true to 1 and false to 0.
1.  We could replace the boxes in part 1 with the spinners in @fig-die-three-spinners.
Spin the appropriate spinner twice and let $X$ be the sum of the two numbers spun and $Y$ the larger of the two numbers spun, etc.
1.  See @tbl-dice-sim-tactile-results.
Results vary naturally so your simulation results will be different, but the same ideas apply.

:::
::::


```{r}
#| echo: false

u1 = c(2, 1, 3, 4, 3, 3, 2, 2, 1, 3)
u2 = c(1, 1, 3, 3, 2, 4, 3, 4, 2, 4)
x = u1 + u2
y = pmax(u1, u2)
A = ifelse(u1 == 3, "True", "False")
IA = as.numeric(u1 == 3)

die_df = data.frame(1:10, u1, u2, x, y, A, IA)


```





```{r}
#| label: tbl-dice-sim-tactile-results
#| echo: false
#| tbl-cap: "Results of 10 repetitions of two rolls of a fair four-sided die. X is the sum of the two rolls, Y is the maximum, and A is the event that the first roll is a 3."


knitr::kable(
  die_df, booktabs = TRUE,
  col.names = c("Repetition", "First roll", "Second roll", "X", "Y", "Event A occurs?", expression(I[A]))
)

```


::: {.callout-warning appearance="default"}
The tables of outcomes in this chapter are a different type than those in @sec-language-probability.
Many tables in @sec-language-probability, such as @tbl-dice-rv-sol-table, represent the sample space: there is one and only one row for each distinct possible outcome, and each outcome (row) has a corresponding theoretical probability.
On the other hand, tables of simulation output---like @tbl-dice-sim-tactile-results and many tables in this chapter---contain one row for each *repetition* of the simulation.
A particular outcome might be repeated several times in a simulation and thus might appear in several rows of the table of simulation output.
For example, the outcome (3, 4) appears only once in @tbl-dice-rv-sol-table, but twice in @tbl-dice-sim-tactile-results (in repetitions 6 and 10).
We will discuss how to approximate the theoretical probability of a particular outcome using the relative frequency of repetitions of that outcome in the simulation.
:::

Note that we are able to simulate outcomes of the rolls and values of $X$ and $Y$ without defining the probability space in detail.
That is, we do not need to list all the possible outcomes and events and their probabilities.
Instead, the probability space is defined implicitly via the specification to "roll a fair four-sided die twice" or "draw two tickets with replacement from a box with four tickets labeled 1, 2, 3, 4" or "spin the spinner on the left of @fig-die-three-spinners twice".
The random variables are defined by what is being measured for each outcome, the sum ($X$) and the max ($Y$) of the two draws or spins.

A simulation usually involves many repetitions.
When conducting a simulation^[If we're repeating something many times, do we perform "a simulation" or "many simulations"? Throughout, "a simulation" refers to the collection of results corresponding to repeatedly artificially recreating the random process. "A repetition" refers to a single artificial recreation resulting in a single simulated outcome. We perform a simulation which consists of many repetitions.] it is important to distinguish between what entails (1) one repetition of the simulation and its output, and (2) the simulation itself and output from many repetitions.
When describing a simulation, refrain from making vague statements like "repeat this" or "do it again", because "this" or "it" could refer to different elements of the simulation.
In the dice example, (1) rolling a die is repeated to generate a single $(X, Y)$ pair, and (2) the process of generating $(X, Y)$ pairs is repeated to obtain the simulation results.
That is, a single repetition involves an ordered pair of die rolls, resulting in an outcome $\omega$, and the values of the sum $X(\omega)$ and max $Y(\omega)$ are computed for the outcome $\omega$.
The process described in the previous sentence is repeated many times to generate many outcomes and $(X, Y)$ pairs according to the probability model.



Think of simulation results being organized in a table like @tbl-dice-sim-tactile-results, where each row corresponds to a repetition of the simulation, resulting in a possible outcome of the random phenomenon, and each column corresponds to a different random variable or event.
Remember that indicators are the bridge between events and random variables.
On each repetition of the simulation an event either occurs or not; we could record the occurrence of an event as "true" or "false", or we could record the value of the corresponding indicator random variable, 1 or 0.

@fig-dice-sim-tactile-results-plot displays two plots summarizing the results in @tbl-dice-sim-tactile-results.
Each dot represents the results of one repetition.
@fig-dice-sim-tactile-results-plot-1 displays the simulated $(X, Y)$ pairs, @fig-dice-sim-tactile-results-plot-2 displays the simulated values of $X$ alon along with their frequencies.
While this simulation only consists of 10 repetitions, a larger scale simulation would follow the same process.




```{r}
#| label: fig-dice-sim-tactile-results-plot
#| echo: false
#| fig-cap: "Dot plots of the simulation results in @tbl-dice-sim-tactile-results of 10 repetitions of two rolls of a fair four-sided die, where $X$ is the sum and $Y$ is the larger (or common value if a tie) of the two rolls."
#| fig-subcap: 
#|   - "Simulated $(X, Y)$ pairs"
#|   - "Simulated values of $X$"
#| layout-ncol: 2

plot(x + c(0, 0, 0, 0, 0, 0.1, 0.1, 0, 0.1, -0.1), y,
     xlab = "X", ylab = "Y", xaxt = 'n', yaxt = 'n',
     xlim = c(1.5, 8.5), ylim = c(0.5, 4.5), xaxs = "i", yaxs = "i")
segments(x0 = 2.5:7.5, y0 = 0, x1 = 2.5:7.5, y1 = 5, lty = 3)
segments(x0 = 1.5, y0 = 0.5:4.5, x1 = 8.5, y1 = 0.5:4.5, lty = 3)
axis(1, at = 2:8, tck = 0)
axis(2, at = 1:4, tck = 0)


stripchart(x, method = "stack",
           xaxt = 'n', xlim = c(2, 8),
           offset = .5, at = .15, pch = 1, 
           xlab = "X", ylab = "Number of repetitions")
axis(1, at = 2:8)


```


:::: {.callout-note appearance="simple"}
::: {#exm-matching-box-sim}
Recall @exm-matching-outcome.
Consider the matching problem with $n=4$.
Label the objects 1, 2, 3, 4, and the spots 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. 
Let $X$ be the number of objects that are placed in the correct spot,
and let $C$ be the event that at least one object is placed in the correct spot.
Describe how you would use a box model to simulate a single realization of $X$ and of $C$.
Could you use a spinner instead?

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-matching-box-sim}



Use a box with 4 tickets, labeled 1, 2, 3, 4.
Shuffle the tickets and draw all 4 *without* replacement and record the tickets drawn *in order*.
Let $X$ be the number of tickets that match their spot in order.
For example, if the tickets are drawn in the order 2431 then the realized value of $X$ is 1 since only ticket 3 matches its spot in the order.
Since $C=\{X \ge 1\}$, event $C$ occurs if $X\ge 1$ and does not occur if $X=0$.
We could record the realization of event $C$ as "true" or "false".
We could also record the realization of $\ind_C$, the indicator random variable for event $C$, as 1 if $C$ occurs and 0 if $C$ does not occur.

Since the tickets are drawn *without* replacement, we could not simply spin a single spinner, like the one in @fig-die-three-spinners-1, four times.
If we really wanted to use the spinner in @fig-die-three-spinners-1, we couldn't just spin it four times; we would sometimes have to discard spins and try again.
For example, suppose the first spin results in 2; then if the second spin results in 2 we would need to discard it and try again.
So we would usually need more than four spins to obtain a valid outcome.
If we wanted to guarantee a valid outcome in only four spins, we would need a collection of spinners, and which one we use would depend on the results of previous spins.
For example, if the first spin results in 2, then we would need to spin a spinner that only lands on 1, 3, 4; if the second spin results in 3, then we would need to spin a spinner that lands only on 1 and 4.

:::
::::

### Exercises

::: {#exr-tactile-birthday}
Recall the birthday problem of @exm-birthday.
Let $B$ be the event that at least two people in a group of $n$ share a birthday.

Describe in detail you could use physical objects (coins, cards, spinners, etc) to simulate by hand a single realization of $B$ (that is, simulate whether or not $B$ occurs). 
:::


::: {#exr-tactile-geometric}

Maya is a basketball player who makes 40% of her three point field goal attempts.
Suppose that at the end of every practice session, she attempts three pointers until she makes one and then stops.
Let $X$ be the total number of shots she attempts in a practice session.
Assume shot attempts are independent, each with probability of 0.4 of being successful.
Describe in detail you could use physical objects (coins, cards, spinners, etc) to simulate by hand a single value of $X$.
:::

::: {#exr-tactile-collector}
The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3).
Each package contains a single unknown prize.
Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3).
For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.
Let $X$ be the number of distinct prizes obtained in these 3 packages.
Let $Y$ be the number of these 3 packages that contain prize 1.

Describe in detail you could use physical objects (coins, cards, spinners, etc) to simulate by hand a single $(X, Y)$ pair.
:::



## Tactile simulation: Meeting problem {#sec-language-simulation-tactile-meeting}

Now we'll consider tactile simulation for a continuous sample space.
Throughout this section we'll consider the two-person meeting problem.
We'll continue to measure arrival times in minutes after noon, including fractions of a minute, so that arrival times take values on a continuous scale.

### A uniform distribution

:::: {.callout-note appearance="simple"}
::: {#exm-meeting-box-sim}
Assume that Regina and Cady each arrive at a time uniformly at random in the continuous time interval between noon and 1, independently of each other.



1.  Explain how you could construct a circular spinner to simulate Regina's arrival time.
In particular, what values go at the "3 o'clock", "6 o'clock", and "9 o'clock" points on the spinner's axis?
(Here "3 o'clock" refers to the direction on the "clock" (spinner), and not arrival time.)
1.  Explain how you could use the spinner from the previous part to simulate an outcome, that is, a pair of arrival times for Regina and Cady.
1.  Why could we not simulate this situation with a box model?

:::
::::

:::: {.callout-tip collapse=true}
::: {#sol-meeting-box-sim}


1.  Imagine a circular spinner with an infinitely fine needle that after being spun well points to a value on the spinner's axis uniformly at random.
We could label the axis like the spinner like the one in @fig-uniform-spinner, but ranging from 0 to 60 instead of 0 to 1; see @fig-meeting-uniform-spinner, which we'll call the "Uniform(0, 60)" spinner.
(Or we could just use the spinner in @fig-uniform-spinner to get the arrival time as a fraction of the hour, then multiply the result of a spin by 60.)
Only selected rounded values are displayed on the circular axis, but in the idealized model the spinner is infinitely precise so that any real number between 0 and 60 is a possible outcome.
Assuming the arrival time is uniformly distributed, Regina should have a probability of $15/60=0.25$ of arriving in each of the 15-minutes intervals $[0, 15]$, $[15, 30]$, $[30, 45]$, and $[45, 60]$.
Therefore, 15 should go at "3 o'clock", 30 at "6 o'clock", and 45 at "9 o'clock", just like the minutes on a regular clock.
1.  Since the arrival times are independent and follow the same uniform pattern, we can spin the spinner in @fig-meeting-uniform-spinner  twice to simulate an outcome; the first spin represents Regina's arrival time, the second Cady's.
The order of the spins matters; for example, the pair (34.89, 12.56) represents Regina arriving at 34.89 minutes after noon, while the pair (12.56, 34.89) represents Regina arriving at 12.56 minutes after noon (and vice versa for Cady).
1.  An outcome consists of a pair of values from the continuous interval [0, 60].
Since this interval is uncountable, it's not possible to write every real number in the interval [0, 60] on a ticket to place in a box.
To use a box model, we would have to round arrival times to some desired degree of precision---nearest minute, second, millisecond, etc---and put the rounded values on the tickets.
Which is probably fine for practical purposes!
But if we really want to create a tactile representation of continuous outcomes, a box model won't work; we tend to use spinners instead.

:::
::::


```{r}
#| label: fig-meeting-uniform-spinner
#| echo: false
#| fig-cap: "A continuous *Uniform(0, 60)* spinner. Only selected rounded values are displayed, but in the idealized model the spinner is infinitely precise so that any real number between 0 and 60 is a possible outcome."
#| fig-subcap: 
#|   - "Values at 1 o'clock, 2 o'clock, etc"
#|   - "Spinner axis marked at 10 minute intervals"
#| layout-ncol: 2

n = 12

xp <- data.frame(
  x = (0:(n-1))/n,
  p = rep(1/n, n)
  )

cdf = c(0, cumsum(xp$p))

plotp = (cdf[-1] + cdf[-length(cdf)]) / 2
  
spinner1 <- ggplot(xp, aes(x="", y=p, fill=x))+
  geom_bar(width = 1, stat = "identity", color="black", fill="white") + 
  coord_polar("y", start=0) +
  theme_void() +
  # plot the possible values on the outside
  scale_y_continuous(breaks = xp$x, minor_breaks = (0:99)/100, labels=c("60|0", 60 * xp$x[-1])) +
  theme(axis.text.x=element_text(size=14, face="bold")) +
      annotate(geom="segment", y=(0:99)/100, yend = (0:99)/100,
             x=1.48, xend= 1.52)

spinner1

n = 6

xp <- data.frame(
  x = (0:(n-1))/n,
  p = rep(1/n, n)
  )

cdf = c(0, cumsum(xp$p))

plotp = (cdf[-1] + cdf[-length(cdf)]) / 2
  
spinner2 <- ggplot(xp, aes(x="", y=p, fill=x))+
  geom_bar(width = 1, stat = "identity", color="black", fill="white") + 
  coord_polar("y", start=0) +
  theme_void() +
  # plot the possible values on the outside
  scale_y_continuous(breaks = xp$x, minor_breaks = (0:99)/100, labels=c("60|0", 60 * xp$x[-1])) +
  theme(axis.text.x=element_text(size=14, face="bold")) +
      annotate(geom="segment", y=(0:99)/100, yend = (0:99)/100,
             x=1.48, xend= 1.52) +
  # plot the probabilities as percents inside
      geom_text(aes(y = plotp,
                label = percent(p, accuracy = 0.1)), size=4, color=c("black",rep("black",4), rep("black",1)))

spinner2

```

Notice that the values on the circular axis in @fig-meeting-uniform-spinner are evenly spaced.
For example, the intervals [0, 15], [15, 30], [30, 45], and [45, 60], all of length 15, each represent 25% of the spinner area.
If we spin the idealized spinner represented by @fig-meeting-uniform-spinner 10 times, our results might look like those in @tbl-meeting-tactile-uniform-sim-table.

```{r}
#| label: tbl-meeting-tactile-uniform-sim-table
#| echo: false



n = 10
x = 60 * runif(n)

kbl(data.frame(1:n, x),
    digits = 13,
    col.names = c("Spin", "Result"),
    caption = 'Results of 10 spins of the Uniform(0, 60) spinner.') |>
  kable_styling(fixed_thead = TRUE)

```



Notice the number of decimal places.
If the sample space is [0, 60], any value in the continuous interval between 0 and 60 is a distinct possible value: 10.25000000000... is different from 10.25000000001... which is different from 10.2500000000000000000001... and so on.

@fig-meeting-tactile-uniform-sim-table displays the 10 values in @tbl-meeting-tactile-uniform-sim-table plotted along a number line.
The values are roughly evenly spaced, but there is some natural variability.
(Though it's hard to discern any pattern with only 10 values.)


```{r}
#| label: fig-meeting-tactile-uniform-sim-table
#| echo: false
#| fig-cap: "Plot of the 10 values simulated from a Uniform(0, 60) model, recorded in @tbl-meeting-tactile-uniform-sim-table"


ggplot(data.frame(x),
       aes(x = x,
           y = 0)) +
  geom_point(shape = "|", size = 10) +
  scale_y_continuous(limits = c(0, 5), expand = c(0, 0)) +
  scale_x_continuous(breaks = seq(0, 60, 10), limits = c(-0.5, 60.5), expand = c(0, 0)) +
  theme_classic() +
  coord_fixed() +
  labs(x = "Simulated arrival time (minutes after noon)") +
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y = element_blank(),
        plot.margin = margin(t = 0,  # Top margin
                             r = 0,  # Right margin
                             b = 0,  # Bottom margin
                             l = 0) # Left margin
  )

```

To simulate a (Regina, Cady) pair of arrival times, we would spin the Uniform(0, 60) spinner twice.
Let $R$ be the result of the first spin, representing Regina's arrival time, and $Y$ the second spin for Cady.
Also let $T=\min(R, Y)$ be the time (minutes after noon) at which the first person arrives, and $W=|R-Y|$ be the time (minutes) the first person to arrive waits for the second person to arrive.
@tbl-meeting-tactile-uniform-sim-table-pair displays the values of $R$, $Y$, $T$, $W$ for 10 simulated repetitions, each repetition consisting of a pair of spins of the Uniform(0, 60) spinner.

```{r}
#| label: tbl-meeting-tactile-uniform-sim-table-pair
#| echo: false

n = 10
R = 60 * runif(n)
Y = 60 * runif(n)
T = pmin(R, Y)
W = abs(R - Y)



meeting_tactile_sim <- data.frame(1:n, R, Y, T, W)

meeting_tactile_sim |>
  kbl(digits = 10,
      col.names = c("Repetition", "R", "Y", "T", "W"),
      caption = 'Results of 10 repetitions of a simulation of the independent Uniform model in the two-person meeting problem.'
  ) |>
  kable_styling(fixed_thead = TRUE)

```

@fig-meeting-tactile-uniform-sim-table-pair plots the 10 simulated $(R, Y)$ pairs in @tbl-meeting-tactile-uniform-sim-table-pair



```{r}
#| label: fig-meeting-tactile-uniform-sim-table-pair
#| echo: false
#| fig-cap: "Plot of 10 pairs of values, each pair simulated independently from a Uniform(0, 60) model, recorded in @tbl-meeting-tactile-uniform-sim-table-pair. Each dot represents a pair. The components of each pair are marked on the horizontal and vertical axes."


ggplot(meeting_tactile_sim,
       aes(x = R, y = Y)) +
  geom_point(shape = 1) +
  geom_rug(length = unit(0.02, "snpc")) +
  theme_classic() +
  scale_x_continuous(limits = c(0, 60), expand = c(0, 0)) +
    scale_y_continuous(limits = c(0, 60), expand = c(0, 0)) +
  labs(x = "Regina's arrival time (minutes after noon)",
       y = "Cady's arrival time (minutes after noon)")  
```

Now suppose we keep repeating the process, resulting in many simulated (Regina, Cady) pairs of arrival times.
@fig-meeting-tactile-uniform-sim-pair displays 1000 simulated pairs of arrival times, resulting from 1000 pairs of spins of the Uniform(0, 60) spinner.



```{r}
#| label: fig-meeting-tactile-uniform-sim-pair
#| echo: false
#| fig-cap: "Plot of 1000 pairs of values, each pair simulated independently from a Uniform(0, 60) model. Each dot represents a pair. The components of each pair are marked on the horizontal and vertical axes."


ggplot(data.frame(x = 60 * runif(1000), y = 60 * runif(1000)),
       aes(x = x, y = y)) +
  geom_point(alpha = 0.75, shape = 1) +
  geom_rug(length = unit(0.02, "snpc")) +
  theme_classic() +
  scale_x_continuous(limits = c(0, 60), expand = c(0, 0)) +
    scale_y_continuous(limits = c(0, 60), expand = c(0, 0)) +
  labs(x = "Regina's arrival time (minutes after noon)",
       y = "Cady's arrival time (minutes after noon)")
```

We see that the pairs are fairly evenly distributed throughout the square with sides [0, 60] representing the sample space (though there is some "clumping" due to natural variability).
If we simulated more values and summarized them in an appropriate plot, we would expect to see something like @fig-meeting-probmeasure1.

### A non-uniform distribution {#sec-language-simulation-tactile-meeting-normal}

:::: {.callout-note appearance="simple"}
::: {#exm-meeting-tactile-sim-normal}
Imagine we have an unlabeled circular spinner with an infinitely fine needle that after being spun well lands on a point on the spinner's axis uniformly at random.
But now suppose that Regina's arrival time is not uniformly distributed.
How should we label the spinner's circular axis to reflect assumptions about Regina's arrival time?


1.  In particular, suppose that Regina has a probability of 0.25 of arriving in each of the intervals $[0, 23]$, $[23, 30]$, $[30, 37]$, $[37, 60]$.
Start to label the spinner for simulating Regina's arrival time; what values should go at the "3 o'clock", "6 o'clock", and "9 o'clock" positions on the spinner's circular axis?
1.  Also assume that Regina has a probability of (roughly):

    -   0.025 of arriving in the interval $[0, 10]$
    -   0.135 of arriving in the interval $[10, 20]$
    -   0.135 of arriving in the interval $[40, 50]$
    -   0.025 of arriving in the interval $[50, 60]$

    At what points on the spinner's circular axis should the values 10, 20, 40, and 50 go?
    What is the probability that Regina arrives in the interval $[20, 30]$?
    $[30, 40]$?
1.  What does this spinner say about Regina's arrival time: is she most likely to arrive near noon, near 12:30, or near 1:00?

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-meeting-tactile-sim-normal}


1.  We can split the spinner into four equal sectors representing the four intervals.
Therefore, 23 should go at 3 o'clock, 30 at 6 o'clock, and 37 at 9 o'clock.
See @fig-meeting-normal-spinner-1.
This part only provides enough information to label 3, 6, and 9 o'clock; we'll discuss where the other values come from below.
(Also, we have rounded values in this example.)
1.  Starting from 0 and moving clockwise around the spinner
    -   10 goes 2.5% of the way around
    -   20 goes 16% of the way around, at roughly 2 o'clock (2.5% to get from 0 to 10 then another 13.5% to get from 10 to 20)
    -   30 goes at 6 o'clock like before
    -   40 goes 84% of the way around, at roughly 10 o'clock ($1 - 0.025 - 0.135 = 0.84$)
    -   50 goes 97.5% of the way around ($1 - 0.025 = 0.975$)
    Since the probability of arriving in $[0, 30]$ is 0.5, the probability of arriving in $[20, 30]$ is $0.5 - 0.16 = 0.34$.
    Similarly, the probability of arriving in $[30, 40]$ is 0.34.
    See @fig-meeting-normal-spinner-2
    (We have rounded values a little differently for this example.)
1.  Part 1 shows that Regina is as likely as not to arrive between 12:23 and 12:37.
Part 2 shows that Regina has a probability of about 0.68 of arriving withing 10 minutes of 12:30, but only a probability of about 0.05 of arriving within 10 minutes of either noon or 1:00.
So under these assumptions she is more likely to arrive near 12:30 than near noon or 1:00.

:::
::::



```{r}
#| label: fig-meeting-normal-spinner
#| echo: false
#| fig-cap: "A continuous *Normal(30, 10)* spinner. The same spinner is displayed on both sides, with different features highlighted on the left and right. Only selected rounded values are displayed, but in the idealized model the spinner is infinitely precise so that any real number is a possible outcome. Notice that the values on the axis are *not* evenly spaced."
#| fig-subcap: 
#|   - "Values at 1 o'clock, 2 o'clock, etc"
#|   - "Spinner axis marked at 10 minute intervals"
#| layout-ncol: 2

n = 12

xp <- data.frame(
  x = (0:(n-1))/n,
  p = rep(1/n, n)
  )

cdf = c(0, cumsum(xp$p))

plotp = (cdf[-1] + cdf[-length(cdf)]) / 2
  
spinner1 <- ggplot(xp, aes(x="", y=p, fill=x))+
  geom_bar(width = 1, stat = "identity", color="black", fill="white") + 
  coord_polar("y", start=0) +
  theme_void() +
  # plot the possible values on the outside
  scale_y_continuous(breaks = xp$x, minor_breaks = (0:99)/100, labels=c("60|0", round(30 + 10 * qnorm(xp$x[-1]), 2))) +
  theme(axis.text.x=element_text(size=12, face="bold"))

spinner1


x = c("","<-2",-1, 0, 1, ">2")
p = c(pnorm(-2), pnorm(-1:2) - pnorm(-2:1), 1-pnorm(2))

xp <- data.frame(x, p)

cdf = c(0, cumsum(xp$p))



plotp = (cdf[-1] + cdf[-length(cdf)]) / 2
  
spinner2 <- ggplot(xp, aes(x="", y=p, fill=x))+
  geom_bar(width = 1, stat = "identity", color="black", fill="white", linetype=1) + 
  # coord_polar("y", start=0) +
  coord_curvedpolar("y", start = 0) +
  theme_void() +
  # plot the possible values on the outside
  scale_y_continuous(breaks = cdf[-c(1, length(cdf))], labels=c(10, 20, 30, 40, 50)) +
  # theme(axis.text.x=element_text(angle=c(90-180/50*(0:49), -90-180/50*(50:99)), size=8)) +
  theme(axis.text.x=element_text(angle = 0, size=12)) +
  # annotate(geom="segment", y=(0:19)/20+0.000, yend = (0:19)/20+0.000,
  #          x=1.48, xend= 1.52) +
  # plot the probabilities as percents inside
    geom_text(aes(y = plotp,
                label = percent(p, accuracy = 0.1)), size=4, color=c(NA, rep("black",4), rep(NA, 1)))

spinner2
```


Imagine we have an unlabeled circular spinner with an infinitely fine needle that after being spun well lands on a point on the spinner's axis uniformly at random.
Even though the needle lands uniformly, we can use the spinner to represent non-uniform probability measures by labeling the spinner's circular axis appropriately.
We can "stretch" intervals with higher probability, and "shrink" intervals with lower probability.
We have already done this intuitively with discrete spinners; see @fig-worldseries-spinner and @fig-die-three-spinners.
But the same idea applies to continuous spinners.


@fig-meeting-normal-spinner displays a "Normal(30, 10)" spinner.
Only selected rounded values are displayed, but the needle can land---uniformly at random---at any point on the continuous circular axis.
*But pay close attention to the circular axis; the values are not equally spaced.*
For example, the bottom half of the spinner corresponds to the interval [23.26, 36.74], with length 13.48 minutes, while the upper half of the spinner corresponds to the intervals [0, 23.26] and [36.74, 60], with total length 46.52 minutes.
Compared with the Uniform(0, 60) spinner, in the Normal(30, 10) spinner intervals near 30 are "stretched out" to reflect a higher probability of arriving near 12:30, while intervals near 0 and 60 are "shrunk" to reflect a lower probability of arriving near 12:00 or 1:00.
The interval [20, 40] represents about 68% of the spinner area, so if we spin this spinner many times, about 68% of the spins will land in the interval [20, 40].
A person whose arrival time is represented by this spinner has a probability of about 0.68 of arriving within 10 minutes of 12:30 compared to $20/60 = 0.33$ for the Uniform(0, 60) model, and a probability of about 0.05 of arriving with 10 minutes of either noon or 1:00, compared to $20/60=0.33$ in the Uniform(0, 60) model.
(The spinner on the left is divided into 12 wedges of equal area, so each wedge represents 8.33% of the probability.
Not all values on the axis are labeled, but you can use the wedges to eyeball probabilities.)

The particular pattern represented by the spinner in @fig-meeting-normal-spinner is a *Normal(30, 10) distribution*; that is, a *Normal distribution with mean 30 and standard deviation 10*.
We will see Normal distributions in much more detail later.
For now, just know that a Normal(30, 10) model reflects one particular pattern of non-uniform probability^[Technically, a Normal(30, 10) distribution allows for values outside the [0, 60] interval, but the probability is small, roughly 0.003.]. 
@tbl-meeting-uniform-normal-compare compares probabilities of selected intervals under the Uniform(0, 60) and Normal(30, 10) models.

::: {.callout-warning appearance="default"}
The parameters in the uniform probability model are different from those in the Normal model. 
In the Uniform(0, 60) model, 0 is the minimum possible value; in the Normal(30, 10) model, 30 is the average value.
In the Uniform(0, 60) model, 60 is the maximum possible value; in the Normal(30, 10) model, 10 is the standard deviation.
:::


| Interval | Uniform(0, 60) probability | Normal(30, 10) probability |
|----------|---------------------------:|---------------------------:|
| [0, 10]  |                      0.167 |                      0.025 |
| [10, 20] |                      0.167 |                      0.136 |
| [20, 30] |                      0.167 |                      0.341 |
| [30, 40] |                      0.167 |                      0.341 |
| [40, 50] |                      0.167 |                      0.136 |
| [50, 60] |                      0.167 |                      0.025 |

: Comparison of probabilities for the Uniform(0, 60) and Normal(30, 10) models {#tbl-meeting-uniform-normal-compare}

If we spin the idealized spinner represented by @fig-meeting-normal-spinner 10 times, our results might look like those in @tbl-meeting-tactile-normal-sim-table.

```{r}
#| label: tbl-meeting-tactile-normal-sim-table
#| echo: false
#| tbl-cap: "Results of 10 spins of the Normal(30, 10) spinner."


n = 10
x_normal_10 = 30 + 10 * rnorm(n)
x_normal_10 = pmin(60, pmax(0, x_normal_10))
  
kbl(data.frame(1:n, x_normal_10),
    col.names = c("Spin", "Result")
) |>
  kable_styling(fixed_thead = TRUE)

```

@fig-meeting-tactile-normal-sim-table displays the 10 values in @tbl-meeting-tactile-normal-sim-table plotted along a number line.
We tend to see more values near 30 than near 0 or 60 (though it's hard to discern any pattern with only 10 values).





```{r}
#| label: fig-meeting-tactile-normal-sim-table
#| echo: false
#| fig-cap: "Plot of the 10 values simulated from a Normal(30, 10) model, recorded in @tbl-meeting-tactile-normal-sim-table."


ggplot(data.frame(x_normal_10),
       aes(x = x_normal_10,
           y = 0)) +
  geom_point(shape = "|", size = 10) +
  scale_y_continuous(limits = c(0, 5), expand = c(0, 0)) +
  scale_x_continuous(limits = c(0, 60), expan = c(0, 0)) +
  theme_classic() +
  coord_fixed() +
  labs(x = "Simulated arrival time (minutes after noon)") +
  theme(axis.text.y=element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y = element_blank()
  )

```

If we spin the spinner in @fig-meeting-normal-spinner many times, 

-   About half of the simulated values would be below 30 and half above
-   Because axis values near 30 are stretched out, values near 30 would occur with higher frequency than those near 0 or 60.
-   The shape of the distribution would be symmetric about 30 since the axis spacing of values below 30 mirrors that for values above 30. For example, about 34% of values would be between 20 and 30, and also 34% between 30 and 40.
-   About 68% of values would be between 20 and 40.
-   About 95% of values would be between 10 and 50.

And so on.
We could compute percentages for other intervals by measuring the areas of corresponding sectors on the spinner to complete the pattern of variability that values resulting from this spinner would follow.
This particular pattern is called a "Normal(30, 10)" distribution, which we will explore in much more detail later (in particular, see @sec-histogram-to-density). 



Now suppose Regina's and Cady's arrival times are each reasonably modeled by a Normal(30, 10) model, independently of each other.
To simulate a (Regina, Cady) pair of arrival times, we would spin the Normal(30, 10) spinner twice.
@tbl-meeting-tactile-normal-sim-table-pair  displays the results of 10 repetitions, each repetition resulting in a (Regina, Cady) pair.




```{r}
#| label: tbl-meeting-tactile-normal-sim-table-pair
#| echo: false
#| tbl-cap: "Results of 10 pairs of spins of the Normal(30, 10) spinner."


n = 10
x = 30 + 10 * rnorm(n)
y = 30 + 10 * rnorm(n)
x = pmin(60, pmax(0, x))
y = pmin(60, pmax(0, y))

kbl(data.frame(1:n, x, y),
    col.names = c("Repetition", "Regina's time", "Cady's time")
) |>
  kable_styling(fixed_thead = TRUE)

```

@fig-meeting-tactile-normal-sim-table-pair plots the 10 simulated pairs in @tbl-meeting-tactile-normal-sim-table-pair




```{r}
#| label: fig-meeting-tactile-normal-sim-table-pair
#| echo: false
#| fig-cap: "Plot of 10 pairs of values, each pair simulated from a Normal(30, 10) model, recorded in @tbl-meeting-tactile-normal-sim-table-pair. Each dot represents a pair. The components of each pair are marked on the horizontal and vertical axes."


ggplot(data.frame(x, y),
       aes(x = x, y = y)) +
  geom_point(shape = 1) +
  geom_rug(length = unit(0.02, "snpc")) +
  theme_classic() +
  scale_x_continuous(limits = c(0, 60), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 60), expand = c(0, 0)) +
  labs(x = "Regina's arrival time (minutes after noon)",
       y = "Cady's arrival time (minutes after noon)")
```

@fig-meeting-tactile-normal-sim-pair displays 1000 pairs of (Regina, Cady) arrival times, resulting from 1000 pairs of spins of the Normal(30, 10) spinner.
Compared with the simulated pairs from the Uniform(0, 60) spinner (in @fig-meeting-tactile-uniform-sim-pair), we see many more simulated pairs in the center of the plot (when both arrive near 12:30) than in the corners of the plot (where either arrives near 12:00 or 1:00).
If we simulated more values and summarized them in an appropriate plot, we would expect to see something like @fig-meeting-independent-normal.





```{r}
#| label: fig-meeting-tactile-normal-sim-pair
#| echo: false
#| warning: false
#| fig-cap: "Plot of 1000 pairs of values, each pair simulated from a Normal(30, 10) model. Each dot represents a pair. The components of each pair are marked on the horizontal and vertical axes."


ggplot(data.frame(x = 30 + 10 * rnorm(1000), y = 30 + 10 * rnorm(1000)),
       aes(x = x, y = y)) +
  geom_point(shape = 1, alpha = 0.75) +
  geom_rug(length = unit(0.02, "snpc")) +
  theme_classic() +
  scale_x_continuous(limits = c(0, 60), expand = c(0, 0)) +
    scale_y_continuous(limits = c(0, 60), expand = c(0, 0)) +
  labs(x = "Regina's arrival time (minutes after noon)",
       y = "Cady's arrival time (minutes after noon)")
```


@exm-meeting-box-sim and @exm-meeting-tactile-sim-normal assumed that Regina's and Cady's arrival times individually followed the same model, both Uniform(0, 60) or both Normal(30, 10), so we just spun the same spinner twice to simulate a pair of arrival times.
However, we could easily simulate from different models.
Suppose Regina's arrival time follows a Uniform(0, 60) model while Cady's follows a Normal(30, 10) model, independently of each other.
Then we could simulate a pair of arrival times by spinning the Uniform(0, 60) spinner for Regina and the Normal(30, 10) spinner for Cady.



So far we have assumed that Regina and Cady arrive independently, but what if they coordinate and their arrival times are related?
Recall that @fig-meeting-dependent-normal reflects a model where Regina and Cady each are more likely to arrive around 12:30 than noon or 1:00, and also more likely to arrive around the same time.
In such a situation, we could still use spinners to simulate pairs of arrival times, but it's more involved than just spinning a single spinner twice (or having just one spinner for each person).
We'll revisit using spinners to simulate dependent pairs later.


### Exercises

::: {#exr-tactile-dartboard}
Katniss throws a dart at a circular dartboard with radius 12 inches.
Suppose that the dart lands uniformly at random anywhere on the dartboard, and assume that Katniss's dart never misses the dartboard.
Suppose that the dartboard is on a coordinate plane, with the center of the dartboard at (0, 0) and the north, south, east, and west edges, respectively, at coordinates (0, 12), (0,-12), (12, 0), (-12, 0).
When the dart hits the board its $(X, Y)$ coordinates are recorded.
Let $R$ be the distance (inches) from the location of the dart to the center of the dartboard.

1.  Sketch a Uniform(0, 12) spinner.
1.  Describe how you could use a fair coin and the Uniform(0, 12) spinner to simulate the $(X, Y)$ coordinates of a single throw of the dart and the value of $R$.
Hint: you might need to flip the coin and spin the spinner multiple times.
What will you do if your simulated coordinates correspond to "off the board"?
1.  Suppose you want to simulate $R$ directly.
Could you just spin the Uniform(0, 12) spinner and record the value?
Explain.
Hint: see @exr-probspace-dartboard-b.

:::


::: {#exr-tactile-dartboard-b}
Continuing @exr-tactile-dartboard.
Computing like we did in @exr-probspace-dartboard-b, we can show

```{r}
#| echo: false

x1 = 0:11
x2 = 1:12

data.frame(paste(x1, "to", x2),
  (x2 / 12)^2 - (x1 / 12)^2) |>
kbl(digits = 4,
  booktabs = TRUE,
  col.names = c("Range", "Probability that $R$ is in range")
) |>
  kable_styling()
```


Sketch a spinner that could be used to simulate values of $R$.
You should label 12 sectors on the spinner.
Hint: the sectors won't be the same size and the values on the outside axis of the spinner won't be evenly spaced.

:::


## Computer simulation: Dice rolling {#sec-technology-intro}



We will perform computer simulations using the Python package Symbulate.
The syntax of Symbulate mirrors the language of probability in that the primary objects in Symbulate are the same as the primary components of a probability model: probability spaces, random variables, events.
Once these components are specified, Symbulate allows users to simulate many times from the probability model and summarize the results.

This section contains a brief introduction to Symbulate; more examples can be found throughout the text.
Symbulate can be installed with `pip`.

```{python}
#| eval: false

pip install git+https://github.com/kevindavisross/symbulate
```

Import Symbulate during a Python session using the following command.

```{python}
#| eval: false
from symbulate import *
```

We'll start with a dice rolling example.
Unless indicated otherwise, in this section $X$ represents the sum of two rolls of a *fair* four-sided die, and $Y$ represents the larger of the two rolls (or the common value if a tie).
We have already discussed a tactile simulation; now we'll carry out the process on a computer.

There aren't many examples for you to work in this section.
Instead, we encourage you to open a Python session and copy and run the code as you read.
In particular, you can run Python code using this [template Colab notebook](https://colab.research.google.com/drive/1YU0BaezMxInwCT5IP1TdSVJd9w2uYwim?usp=sharing) which includes the code needed to get started with Symbulate.

### Simulating outcomes

The following Symbulate code defines a probability space[^simulation-14] `P` for simulating the 16 equally likely ordered pairs of rolls via a box model.

[^simulation-14]: We primarily view a Symbulate probability space as a description of the probability model rather than an explicit specification of the sample space $\Omega$.
    For example, we define a `BoxModel` instead of creating a set with all possible outcomes.
    We tend to represent a probability space with `P`, even though this is a slight abuse of notation (since $\IP$ typically refers to a probability measure).

```{python}
#| label: dice-sym-boxmodel

P = BoxModel([1, 2, 3, 4], size = 2, replace = True)

```

The above code tells Symbulate to draw 2 tickets (`size = 2`), with replacement[^simulation-15], from a box with tickets labeled 1, 2, 3, and 4 (entered as the Python list `[1, 2, 3, 4]`).
Each simulated outcome consists of an ordered[^simulation-16] pair of rolls
.

[^simulation-15]: The default argument for `replace` is `True`, so we could have just written `BoxModel([1, 2, 3, 4], size = 2)`.

[^simulation-16]: There is an additional argument `order_matters` which defaults to `True`, but we could set it to `False` for unordered pairs.

The `sim(r)` command simulates `r` realizations of probability space outcomes (or events or random variables).
Here is the result of one repetition.

```{python}

P.sim(1)

```

And here are the results of 10 repetitions.
(We will typically run thousands of repetitions, or more, but in this section we just run a few repetitions for illustration.)

```{python}

P.sim(10)

```

::: {.callout-warning appearance="default"}
Every time `.sim()` is called, a new simulation is run.
**When running a simulation, the "simulate" step should be performed with a *single* call to `sim`** so that all analysis of results corresponds to the same simulated values.
We'll show how to do this below.
:::

### Simulating random variables

A Symbulate `RV` is specified by the probability space on which it is defined and the mapping function which defines it.
Recall that $X$ is the sum of the two dice rolls and $Y$ is the larger (max).

```{python}
#| label: dice-sym-rv
X = RV(P, sum)
Y = RV(P, max)

```

<!-- Since a random variable $X$ is a function, any `RV` can be called as a function^[The warning you get when you call a `RV` as a function just means that Symbulate is not going to check for you that the inputs to the function you used to define the `RV` actually match up with the outcomes of the probability space `P`.] to return its value $X(\omega)$ for a particular outcome $\omega$ in the probability space. -->

<!-- ```{python} -->

<!-- omega = (3, 2)  # a pair of rolls -->

<!-- X(omega), Y(omega) -->

<!-- ``` -->

The above code simply defines the random variables.
Again, we can simulate values with `.sim()`.
Since every call to `sim` runs a new simulation, we typically store the simulation results as an object.
The following commands simulate 100 values of the random variable `X` and store the results as `x`.
For consistency with standard probability notation[^simulation-17], the random variable itself is denoted with an uppercase letter `X`, while the realized values of it are denoted with a lowercase letter `x`.

[^simulation-17]: We generally use names in our code that mirror and reinforce standard probability notation, e.g., uppercase letters near the end of the alphabet for random variables, with corresponding lowercase letters for their realized values.
    Of course, these naming conventions are not necessary and you are welcome to use more descriptive names in your code.
    For example, we could have named the probability space `DiceRolls` and the random variables `DiceSum` and `DiceMax` rather than `P, X, Y`.
    Whatever you do, we encourage you to use names that distinguish the objects themselves from their simulated values, e.g. `Dice_Sum` for the random variable and `dice_sum_sim` for the simulated values.

```{python}
x = X.sim(100)

x # this just displays x; only the first few and last values will print

```

### Simulating multiple random variables

If we call `X.sim(10000)` and `Y.sim(10000)` we get two separate simulations of 10000 pairs of rolls, one which returns the sum of the rolls for each repetition, and the other the max.
If we want to study relationships between $X$ and $Y$ we need to compute both $X$ and $Y$ for each pair of rolls in the same simulation.

We can simulate $(X, Y)$ pairs using[^simulation-18] `&`. We store the simulation output as `x_and_y` to emphasize that `x_and_y` contains pairs of values.

[^simulation-18]: Technically `&` joins two `RV`s together to form a random *vector*.
    While we often interpret Symbulate `RV` as "random variable", it really functions as "random vector".

```{python}
x_and_y = (X & Y).sim(10)

x_and_y # this just displays x_and_y

```

Think of `x_and_y` as a table with two columns.
We can select columns using brackets `[]`.
Remember that Python uses zero-based indexing, so 0 corresponds to the first column, 1 to the second, etc.

```{python}
x = x_and_y[0]

x
```

```{python}
y = x_and_y[1]

y
```

We can also select multiple columns.

```{python}
x_and_y[0, 1]
```



### Simulating outcomes and random variables

When calling `X.sim(10)` or `(X & Y).sim(10)` the outcomes of the rolls are generated in the background but not saved.
We can create a `RV` which returns the outcomes of the probability space[^simulation-19].
The default mapping function for `RV` is the identity function, $g(u) = u$, so simulating values of `U = RV(P)` below returns the outcomes of the BoxModel `P` representing the outcome of the two rolls.

[^simulation-19]: You might try `(P & X).sim(10)`.
    But `P` is a probability space object, and `X` is an `RV` object, and `&` can only be used to join like objects together.
    Much like in probability theory in general, in Symbulate the probability space plays a background role, and it is usually random variables we are interested in.

```{python}
U = RV(P)

U.sim(10)

```

Now we can simulate and display the outcomes along with the values of $X$ and $Y$ using `&`.

```{python}
(U & X & Y).sim(10)
```

Because the probability space `P` returns pairs of values, `U = RV(P)` above defines a random vector.
The individual components[^simulation-20] of `U` can be "unpacked" as `U1, U2` in the following.
Here `U1` is an `RV` representing the result of the first roll and `U2` the second.

[^simulation-20]: The components of an `RV` can also be accessed using brackets.
    `U1, U2 = RV(P)` is shorthand for\
    `U = RV(P); U1 = U[0]; U2 = U[1]`.

```{python}
U1, U2 = RV(P)
(U1 & U2 & X & Y).sim(10)
```

### Simulating events

Events involving random variables can also be defined and simulated.
For programming reasons, events are enclosed in parentheses `()` rather than braces $\{\}$.
For example, we can define the event that the larger of the two rolls is less than 3, $A=\{Y<3\}$, as

```{python}
A = (Y < 3) # an event
```

We can use `sim` to simulate events.
A realization of an event is `True` if the event occurs for the simulated outcome, or `False` if not.

```{python}
A.sim(10)

```

For logical equality use a double equal sign `==`.
For example, `(Y == 3)` represents the event $\{Y=3\}$.

```{python}
(Y == 3).sim(10)

```

In most situations, events of interest involve random variables.
It is much more common to simulate random variables directly, rather than events; see @sec-symbulate-two-worlds for further discussion.
Events are primarily used in Symbulate for conditioning.

### Simulating transformations of random variables

Transformations of random variables (defined on the same probability space) are random variables.
If `X` is a Symbulate `RV` and `g` is a function, then `g(X)` is also a Symbulate `RV`.

For example, we can simulate values of $X^2$.
(In Python, exponentiation is represented by `**`; e.g., `2 ** 5 = 32`.)

```{python}
(X ** 2).sim(10)
```

For many common functions (e.g., `sqrt`, `log`, `cos`), the syntax `g(X)` is sufficient.
Here `sqrt(u)` is the square root function $g(u) = \sqrt{u}$.

```{python}
(X & sqrt(X)).sim(10)
```

For general functions, including user defined functions, the syntax for defining $g(X)$ is `X.apply(g)`.
Here we define the function $g(u) = (u-5)^2$ and then define^[We could have actually defined `Z = (X - 5) ** 2` here. We'll see examples where the `apply` syntax is necessary later.] the random variable $g(X) = (X - 5)^2$.

```{python}
# define a function g; u represents a generic input
def g(u):
  return (u - 5) ** 2

# define the RV g(X)  
Z = X.apply(g)

# simulate X and Z pairs
(X & Z).sim(10)

```



We can also apply transformations of multiple `RV`s *defined on the same probability space*.
(We will look more closely at how Symbulate treats this "same probability space" issue later.)

For example, we can simulate values of $XY$, the product of $X$ and $Y$.

```{python}
(X * Y).sim(10)
```

Recall that we defined $X$ via `X = RV(P, sum)`.
Defining random variables $U_1, U_2$ to represent the individual rolls, we can define $X=U_1 + U_2$.
Recall that we previously defined[^simulation-21] `U1, U2 = RV(P)`.

[^simulation-21]: We can also define `U = RV(P)` and then `X = U.apply(sum)`.

```{python}
X = U1 + U2

X.sim(10)

```

Unfortunately `max(U1, U2)` does not work, but we can use the `apply` syntax.
Since we want to apply `max` to $(U_1, U_2)$ pairs, we must[^simulation-22] first join them together with `&`.

[^simulation-22]: We can also define `U = RV(P)` and then `X = U.apply(max)`.

```{python}
Y  = (U1 & U2).apply(max)

Y.sim(10)

```


### Other probability spaces

So far we have assumed a *fair* four-sided die.
Now consider the weighted die in @exm-die-weighted: a single roll results in 1 with probability 0.1, 2 with probability 0.2, 3 with probability 0.3, and 4 with probability 0.4.
`BoxModel` assumes equally likely tickets by default, but we can specify non-equally likely tickets using the `probs` option.
The probability space `WeightedRoll` in the following code corresponds to a single roll of the weighted die; the default `size` option is 1.

```{python}

WeightedRoll = BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4])
WeightedRoll.sim(10)

```

We could add `size = 2` to the `BoxModel` to create a probability space corresponding to two rolls of the weighted die.
Alternatively, we can think of `BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4])` as defining the middle spinner in @fig-die-three-spinners that we want to spin two times, which we can do with `** 2`.

```{python}
Q = BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4]) ** 2
Q.sim(10)

```

You can interpret `BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4])` as defining the middle spinner in @fig-die-three-spinners and `** 2` as "spin the spinner two times".
In Python, `**` represents exponentiation; e.g., `2 ** 5 = 32`.
So `BoxModel([1, 2, 3, 4]) ** 2` is equivalent to `BoxModel([1, 2, 3, 4]) * BoxModel([1, 2, 3, 4])`.
In light of our discussion in @sec-independence, the product `*` notation should seem natural for *independent* spins.

We could use the product notation to define a probability space corresponding to a pair of rolls, one from a fair die and one from a weighted-die.

```{python}
MixedRolls = BoxModel([1, 2, 3, 4]) * BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4])
MixedRolls.sim(10)
```

Now consider the weighted die from @exm-dice-normalize, represented by the spinner in @fig-die-three-spinners-3.
We could use the `probs` option, but we can also imagine a box model with 15 tickets---four tickets labeled 1, six tickets labeled 2, three tickets labeled 3, and two tickets labeled 4---from which a single ticket is drawn.
A `BoxModel` can be specified in this way using the following `{label: number of tickets with the label}` formulation[^simulation-24].
This formulation is especially useful when multiple tickets are drawn from the box *without replacement*.

[^simulation-24]: Braces `{}` are used here because this defines a Python *dictionary*.
    But don't confuse this code with set notation.

```{python}

Q = BoxModel({1: 4, 2: 6, 3: 3, 4: 2})
Q.sim(10)

```

While many scenarios can be represented by box models, there are also many Symbulate probability spaces other than `BoxModel`.
When tickets are equally likely and sampled with replacement, a *Discrete Uniform* model can also be used.
Think of a `DiscreteUniform(a, b)` probability space corresponding to a spinner with sectors of *equal area* labeled with integer values from `a` to `b` (inclusive).
For example, the spinner in @fig-die-three-spinners-1 corresponds to the `DiscreteUniform(1, 4)` model.
This gives us another way to represent the probability space corresponding to two rolls of a fair-four sided die.

```{python}
P = DiscreteUniform(1, 4) ** 2
P.sim(10)
```

Note that `BoxModel` is the only probability space with the `size` argument.
For other probability spaces, the product `*` or exponentiation `**` notation must be used to simulate multiple spins.

This section has only introduced how to set up a probability model and simulate realizations.
We'll see how to summarize and use simulation output soon.

### Exercises

::: {#exr-computer-simulation-collector}
The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3).
Each package contains a single unknown prize.
Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3).
For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.
Let $X$ be the number of distinct prizes obtained in these 3 packages.
Let $Y$ be the number of these 3 packages that contain prize 1.

Write Symbulate code to define an appropriate probability space and random variables, and simulate a few repetitions.
Hint: you'll need to define a function to define $X$; try `len(unique(...))`
:::


::: {#exr-computer-simulation-collector-b}
Continuing @exr-computer-simulation-collector.
Now suppose that 10% of boxes contain prize 1, 30% contain prize 2, and 60% contain prize 3.
Write Symbulate code to define an appropriate probability space and random variables, and simulate a few repetitions.
:::


::: {#exr-computer-simulation-birthday}
Recall the birthday problem of @exm-birthday.
Let $B$ be the event that at least two people in a group of $n$ share a birthday.

Write Symbulate code to define an appropriate probability space, and simulate a few realizations of $B$ (that is, simulate whether or not $B$ occurs). 
:::


::: {#exr-computer-simulation-geometric}

Maya is a basketball player who makes 40% of her three point field goal attempts.
Suppose that at the end of every practice session, she attempts three pointers until she makes one and then stops.
Let $X$ be the total number of shots she attempts in a practice session.
Assume shot attempts are independent, each with probability of 0.4 of being successful.

Write Symbulate code to define an appropriate probability space and random variable, and simulate a few repetitions.

:::


## Computer simulation: Meeting problem {#sec-meeting-sim}

Now we'll introduce computer simulation of the continuous models in @sec-language-simulation-tactile-meeting.
Throughout this section we'll consider the two-person meeting problem.
Let $R$ be the random variable representing Regina's arrival time (minutes after noon, including fractions of a minute), and $Y$ for Cady.
Also let $T=\min(R, Y)$ be the time (minutes after noon) at which the first person arrives, and $W=|R-Y|$ be the time (minutes) the first person to arrive waits for the second person to arrive.


### Independent Uniform model

First consider the situation of @exm-meeting-box-sim where Regina and Cady each arrive at a time uniformly at random in [0, 60], independently of each other.
The following code defines a Uniform(0, 60) spinner^[Careful: don't confuse `Uniform(a, b)` with `DiscreteUniform(a, b)`. `Uniform(a, b)` corresponds to the continuous interval $[a, b]$.], like in @fig-meeting-uniform-spinner, which we spin twice to get the (Regina, Cady) pair of outcomes.








```{python}
P = Uniform(0, 60) ** 2
P.sim(10)

```

Notice (again) the number of decimal places; any value in the continuous interval between 0 and 60 is a distinct possible value

A probability space outcome is a (Regina, Cady) pair of arrival times.
We can define the random variables $R$ and $Y$, representing the individual arrival times, by "unpacking" the outcomes.

```{python}
R, Y = RV(P)

(R & Y).sim(10)

```

We can define $W = |R-Y|$ using the `abs` function.
In order to define $T = \min(R, Y)$ we need to use the `apply` syntax with `R & Y`.

```{python}
W = abs(R - Y)

T = (R & Y).apply(min)
```

Now we can simulate values of $R$, $Y$, $T$, and $W$ with a single call to `sim`.
Each row in the resulting @tbl-meeting-independent-uniform-sim corresponds to a single simulated outcome (pair of arrival times).

```{python}
#| label: tbl-meeting-independent-uniform-sim
(R & Y & T & W).sim(10)

```

We can simulate values of $R$ and plot them along a number line in a "rug" plot; compare to @fig-meeting-tactile-uniform-sim-table.
Notice how we have chained together the `sim` and `plot` commands.
(We'll see some more interesting and useful plots later.)



```{python}

plt.figure()
R.sim(100).plot('rug')
plt.show()
```

Calling `.plot()` (without `'rug'`) for simulated values of a *continuous* random variable produces a *histogram*, which we will discuss in much more detail in @sec-simulation-marginal-continuous.


```{python}

plt.figure()
R.sim(10000).plot()
plt.show()
```







We can simulate and plot many $(R, Y)$ pairs of arrival times; compare to @fig-meeting-tactile-uniform-sim-pair (without the rug).

```{python}
#| eval: false
(R & Y).sim(1000).plot()
```


```{python}
#| echo: false
plt.figure()
(R & Y).sim(1000).plot()
plt.show()
```

When plotting simulated pairs, the first component is plotted on the horizontal axis and the second component on the vertical axis.
In the following plots, we'll `import matplotlib.pyplot as plt` and use `plt.xlabel("x-axis text")` and `plt.ylabel("y-axis text")`to label axes.


We can also simulate and plot many $(T, W)$ pairs.
For purposes of illustration, first we simulate all four random variables, then we'll select the columns corresponding to $(T, W)$ and plot the simulated pairs.

```{python}
#| eval: false

import matplotlib.pyplot as plt

meeting_sim = (R & Y & T & W).sim(1000)

meeting_sim[2, 3].plot()
plt.xlabel("T")
plt.ylabel("W")
```

```{python}
#| echo: false
meeting_sim = (R & Y & T & W).sim(1000)

plt.figure()
meeting_sim[2, 3].plot()
plt.xlabel("T");
plt.ylabel("W");
plt.show()
```

### Independent Normal model


Now consider a `Normal(30, 10)` model, represented by the spinner in @fig-meeting-normal-spinner.

```{python}
Normal(mean = 30, sd = 10).sim(10)
```

We define a probability space corresponding to (Regina, Cady) pairs of arrival times, by assuming that their arrival times individually follow a Normal(30, 10) model, independently of each other.
That is, we spin the Normal(30, 10) spinner twice to simulate a pair of arrival times.

```{python}
P = Normal(30, 10) ** 2
P.sim(10)
```

We can unpack the individual $R$, $Y$ random variables and define $W$, $T$ as before.

```{python}
R, Y = RV(P)

W = abs(R - Y)

T = (R & Y).apply(min)
```


We can simulate values of $R$ and plot them along a number line in a rug plot; compare to @fig-meeting-tactile-normal-sim-table.
(Technically, the Normal(30, 10) assigns small but positive probability to values outside of [0, 60], so we might see some values outside of [0, 60].)



```{python}
plt.figure()
R.sim(100).plot('rug')
plt.show()
```

We can simulate many values and summarize them in a histogram.
We'll discuss histograms in more detail later, but notice that the histogram conveys that for a Normal(30, 10) distribution values near 30 are more likely than values near 0 or 60.

```{python}
plt.figure()
R.sim(10000).plot()
plt.show()
```



We can simulate and plot many $(R, Y)$ pairs of arrival times; compare to @fig-meeting-tactile-normal-sim-pair (without the rug).



```{python}
#| eval: false
(R & Y).sim(1000).plot()
plt.xlabel("R");
plt.ylabel("Y");
```

```{python}
#| echo: false
R, Y = RV(P)

plt.figure()
(R & Y).sim(1000).plot()
plt.xlabel("R");
plt.ylabel("Y");
plt.show()
```


We can also simulate and plot many $(T, W)$ pairs.
Notice that the plot looks quite different from the one for the independent Uniform(0, 60) model for arrival times.

```{python}
#| eval: false
meeting_sim = (R & Y & T & W).sim(1000)

meeting_sim[2, 3].plot()
plt.xlabel("T");
plt.ylabel("W");
```

```{python}
#| echo: false
meeting_sim = (R & Y & T & W).sim(1000)

plt.figure()
meeting_sim[2, 3].plot()
plt.xlabel("T");
plt.ylabel("W");
plt.show()
```

### Bivariate Normal model {#sec-language-simulation-computer-meeting-bvn}


Now assume that Regina and Cady tend to arrive around the same time.
We haven't yet seen how to construct spinners to reflect dependence, but we'll briefly introduce a particular model and some code.
One way to model pairs of values that have a relationship or *correlation* is with a `BivariateNormal` model, like in the following.

```{python}
P = BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7)
P.sim(10)
```

Note that a `BivariateNormal` probability space returns pairs directly.
We can unpack the pairs as before, and plot some simulated values.


```{python}
#| eval: false
R, Y = RV(P)

(R & Y).sim(1000).plot()
plt.xlabel("R");
plt.ylabel("Y");
```

```{python}
#| echo: false
R, Y = RV(P)

plt.figure()
(R & Y).sim(1000).plot()
plt.xlabel("R");
plt.ylabel("Y");
plt.show()
```

Now we see that Regina and Cady tend to arrive near the same time, similar to @fig-meeting-dependent-normal.

If we plot $(T, W)$ pairs, we expect values of the waiting time $W$ to tend to be closer to 0 than in the independent arrivals models.
Compare the scale on the vertical axis, corresponding to $W$, in each of the three plots of $(T, W)$ pairs in this section.

```{python}
#| eval: false

W = abs(R - Y)

T = (R & Y).apply(min)

meeting_sim = (R & Y & T & W).sim(1000)

meeting_sim[2, 3].plot()
plt.xlabel("T");
plt.ylabel("W");
```

```{python}
#| echo: false

W = abs(R - Y)

T = (R & Y).apply(min)

meeting_sim = (R & Y & T & W).sim(1000)

plt.figure()
meeting_sim[2, 3].plot()
plt.xlabel("T");
plt.ylabel("W");
plt.show()
```

A call to `sim` always simulates independent repetitions from the model, but be careful about what this means.
In the Bivariate Normal model, the $R$ and $Y$ values are dependent *within a repetition*.
However, the $(R, Y)$ pairs are independent *between repetitions*.
Thinking in terms of a table, the $R, Y$ columns are dependent, but the rows are independent.


We will study specific probability models like `Normal` and `BivariateNormal` in much more detail as we go.

### Exercises


::: {#exr-computer-simulation-dartboard}
Write Symbulate code to conduct the simulation in @exr-tactile-dartboard.
Caveat: don't worry about the code to discard repetitions where the dart lands off the board.
(We'll return to this later.)
:::

::: {#exr-computer-simulation-continuous-dice}
Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4).
Let $X$ be the sum of the two spins and let $Y$ be the larger of the two spins.
Write Symbulate code to define an appropriate probability space and random variables, and simulate a few repetitions.
:::



## Approximating probabilities: Relative frequencies {#sec-language-simulation-relative-frequency}


We can use simulation-based relative frequencies to approximate probabilities.
That is, the probability of event $A$ can be approximated by simulating---according to the assumptions encoded in the probability measure $\IP$---the random phenomenon a large number of times and computing the relative frequency of $A$.

$$
{\small
\IP(A) \approx \frac{\text{number of repetitions on which $A$ occurs}}{\text{number of repetitions}}, \quad \text{for a large number of repetitions simulated according to $\IP$}
}
$$

In practice, many repetitions of a simulation are performed on a computer to approximate what happens in the "long run".
However, we often start by carrying out a few repetitions by hand to help make the process more concrete.

:::: {.callout-note appearance="simple"}
::: {#exm-dice-sim-tactile}

Recall your simulation results from @exm-dice-sim; ours are in @tbl-dice-sim-tactile-results.
Based only on your 10 repetitions, how would you approximate the following?
(Don't worry if the approximations are any good yet.)


1.  $\IP(A)$, where $A$ is the event that the first roll is 3.
2.  $\IP(X=6)$
3.  $\IP(X \ge 6)$
4.  $\IP(Y = 3)$
5.  $\IP(Y \ge 3)$
6.  $\IP(X=6, Y=3)$
7.  $\IP(X\ge6, Y \ge 3)$

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-dice-sim-tactile}



See @tbl-dice-sim-tactile-results for the results of our simulation.

1. Approximate $\IP(A)$ by 4/10 = 0.4, the relative frequency of event $A$ in the simulation; that is, the proportion of repetitions where the first roll is 3.
1. Approximate $\IP(X=6)$ by 2/10 = 0.2, the proportion of repetitions where the sum is 6.
1. Approximate $\IP(X\ge 6)$ by 5/10 = 0.5, the proportion of repetitions where the sum is at least 6.
1. Approximate $\IP(Y=3)$ by 3/10 = 0.3, the proportion of repetitions where the max is 3.
1. Approximate $\IP(Y\ge 3)$ by 7/10 = 0.7, the proportion of repetitions where the max is at least 3.
1. Approximate $\IP(X=6, Y = 3)$ by 1/10 = 0.1, the proportion of repetitions where both the sum is 6 and the max is 3.
1. Approximate $\IP(X\ge 6, Y \ge 3)$ by 5/10 = 0.5, the proportion of repetitions where both the sum is at least 6 and the max is at least 3.
(Since $X\ge 6$ implies $Y\ge 3$, $\IP(X\ge 6, Y\ge 3) = \IP(X\ge 6)$.)


:::
::::


:::: {.callout-note appearance="simple"}
::: {#exm-dice-sim-tactile-dist}
Continuing @exm-dice-sim-tactile.

1. Construct a table of the simulated relative frequencies of each possible value $x$ of $X$.
1. Construct a table of the simulated relative frequencies of each possible value $(x, y)$ pair of $(X, Y)$.

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-dice-sim-tactile-dist}

For discrete random variables like these we can make tables or plots summarizing the observed values of the random variables and their corresponding relative frequencies.

Summarizing our simulation results from @tbl-dice-sim-tactile-results, the observed values of $X$ and corresponding relative frequencies are

| $x$ | Relative frequency |
|-----|-------------------:|
| 2   |               1/10 |
| 3   |               2/10 |
| 4   |                  0 |
| 5   |               2/10 |
| 6   |               2/10 |
| 7   |               3/10 |
| 8   |                  0 |
  
The above table^[We would typically only include the values observed in the simulation in the summary. However, we include 4 and 8 here because if we had performed more repetitions we would have observed these values.] represents an approximation of the distribution of $X$, albeit a bad approximation; compare with @tbl-dice-sum-dist-table.

We can summarize simulated $(X, Y)$ *pairs* and their relative frequencies, as in the following two-way table; compare with @tbl-dice-joint-dist-twoway.

| $x, y$ |    1 |    2 |    3 |    4 |
|--------|-----:|-----:|-----:|-----:|
| 2      | 1/10 |    0 |    0 |    0 |
| 3      |    0 | 2/10 |    0 |    0 |
| 4      |    0 |    0 |    0 |    0 |
| 5      |    0 |    0 | 2/10 |    0 |
| 6      |    0 |    0 | 1/10 | 1/10 |
| 7      |    0 |    0 |    0 | 3/10 |
| 8      |    0 |    0 |    0 |    0 |


:::
::::


You might have noticed that many of the simulated relative frequencies in @exm-dice-sim-tactile provide terrible estimates of the corresponding probabilities.
For example, the true probability that the first roll is a 3 is $\IP(A) = 0.25$ while the simulated relative frequency is 0.4.
The problem is that the simulation only consisted of 10 repetitions.
Probabilities can be approximated by *long run* relatively frequencies, but 10 repetitions certainly doesn't qualify as the long run!
The more repetitions we perform the better our estimates should be.
But how many repetitions is sufficient?
And how accurate are the estimates?
We will address these issues in @sec-moe.



### A few Symbulate commands for summarizing simulation output


We'll continue with the dice rolling example.
Recall the setup.

```{python}
P = DiscreteUniform(1, 4) ** 2

X = RV(P, sum)

Y = RV(P, max)
```

First we'll simulate and store 10 values of $X$.

```{python}
x = X.sim(10)
x # displays the simulated values
```

Suppose we want to find the relative frequency of 6. We can count the number of simulated values equal to 6 with `count_eq()`.

```{python}
x.count_eq(6)
```

The count is the frequency. To find the relative frequency we simply divide by the number of simulated values.

```{python}
x.count_eq(6) / 10
```

We can find frequencies of other events using the "count" functions:

-   `count_eq(u)`: count *equal to* ($=$) `u`
-   `count_neq(u)`: count *not equal to* ($\neq$) `u`
-   `count_leq(u)`: count *less than or equal to* ($\le$) `u`
-   `count_lt(u)`: count *less than* ($<$) `u`
-   `count_geq(u)`: count *greater than or equal to* ($\ge$) `u`
-   `count_gt(u)`: count *greater than* ($>$) `u`
-   `count`: count according to a custom True/False criteria (see examples below)

Using `count()` with no inputs to defaults to "count all", which provides a way to count the total number of simulated values.
(This is especially useful when conditioning.)


```{python}
x.count_eq(6) / x.count()
```



The `tabulate` method provides a quick summary of the individual simulated values and their frequencies.

```{python}
x.tabulate()

```

By default, `tabulate` returns frequencies (counts).
Adding the argument[^simulation-27] `normalize = True` returns relative frequencies (proportions).

[^simulation-27]: "Normalize" is used in the sense of @sec-consistency and refers to rescaling the values so that they add up to 1 but the ratios are preserved.

```{python}
x.tabulate(normalize = True)

```


We often initially simulate a small number of repetitions to see what the simulation is doing and check that it is working properly.
However, in order to accurately approximate probabilities or distribution we simulate a large number of repetitions (usually thousands for our purposes).
Now let's simulate many $X$ values and summarize the results.

```{python}
#| label: tbl-dice-sum-marginal-sim
#| tbl-cap: "Table representing simulation-based approximate distribution of $X$, the sum of two rolls of a fair four-sided die."


x = X.sim(10000)

x.tabulate(normalize = True)
```

Compare to @tbl-dice-sum-dist-table; with 10000 repetitions the simulation based approximations are pretty close to the theoretical probabilities. 

Graphical summaries play an important role in analyzing simulation output.
We have previously seen rug plots of individual simulated values.
Rug plot emphasize that realizations of a random variable  are numbers along a number line.
However, a rug plot does not adequately summarize relative frequencies.
Instead, calling `.plot()` for simulated values of a *discrete* random variable produces^[For discrete random variables `'impulse'` is the default plot type. Like `.tabulate()`, the `.plot()` method also has a `normalize` argument; the default is `normalize=True`.] an *impulse plot* which displays the simulated values and their relative frequencies; see @fig-dice-sum-marginal-sim and compare to @fig-dice-sum-dist-plot22.
Since we stored the simulated values as `x`, the same simulated values are used to produce @tbl-dice-sum-marginal-sim and @fig-dice-sum-marginal-sim.




```{python}
#| eval: false

x.plot()
```

```{python}
#| label: fig-dice-sum-marginal-sim
#| echo: false
#| fig-cap: "Impulse plot representing simulation-based approximate distribution of $X$, the sum of two rolls of a fair four-sided die."

plt.figure()
x.plot()
plt.show()

```





Now we simulate and summarize a few  $(X, Y)$ pairs.

```{python}
x_and_y = (X & Y).sim(10)
x_and_y 

```



Pairs of values can also be tabulated.

```{python}
x_and_y.tabulate()

```


```{python}
x_and_y.tabulate(normalize = True)

```

Individual pairs can be plotted in a scatter plot, which is a two-dimensional analog of a rug plot.

```{python}
#| eval: false
x_and_y.plot()

```

```{python}
#| echo: false
plt.figure()
x_and_y.plot()
plt.show()

```


The values can be "jittered" slightly, as below, so that points do not coincide.


```{python}
#| eval: false
x_and_y.plot(jitter = True)

```

```{python}
#| echo: false
plt.figure()
x_and_y.plot(jitter = True)
plt.show()

```

The two-dimensional analog of an impulse plot is a *tile plot*. For two discrete variables, the `'tile'` plot type produces a tile plot (a.k.a. heat map) where rectangles represent the simulated pairs with their relative frequencies visualized on a color scale.

```{python}
#| eval: false
x_and_y.plot('tile')

```

```{python}
#| echo: false
plt.figure()
x_and_y.plot('tile')
plt.show()

```



<!-- (ref:cap-dice-tile) Tile plot visualization of the simulation-based approximate joint distribution of the sum ($X$) and larger ($Y$) of two rolls of a fair four-sided die.  Color intensity represents relative frequencies of pairs. -->


<!-- ```{r, dice-tile, echo = FALSE, fig-cap = "(ref:cap-dice-tile)"} -->

<!-- knitr::include_graphics("_graphics/dice-tile.png") -->
<!-- ``` -->

<!-- We can add the impulse plot for each of $X$ and $Y$ in the margins of the tile plot using the `'marginal'` argument.   -->

<!-- ```{python, eval = FALSE} -->
<!-- xy.plot(['tile', 'marginal']) -->
<!-- plt.show() -->

<!-- ``` -->

<!-- (ref:cap-dice-tile-marginal) Tile and impulse plot visualization of the simulation-based approximate joint and marginal distributions of the sum ($X$) and larger ($Y$) of two rolls of a fair four-sided die. -->




<!-- ```{r, dice-tile-marginal, echo = FALSE, fig-cap = "(ref:cap-dice-tile-marginal)"} -->

<!-- knitr::include_graphics("_graphics/dice-tile-marginal.png") -->
<!-- ``` -->


Custom functions can be used with `count` to compute relative frequencies of events involving multiple random variables. Suppose we want to approximate $\IP(X<6, Y \ge 2)$.  We first define a Python function which takes as an input a pair `u = (u[0], u[1])` and returns `True` if `u[0] < 6` and `u[1] >= 2`.

```{python}

def is_x_lt_6_and_y_ge_2(u):
  if u[0] < 6 and u[1] >= 2:
    return True
  else:
    return False

```

Now we can use this function along with `count` to find the simulated relative frequency of the event $\{X <6, Y \ge 2\}$.
Remember that `x_and_y` stores $(X, Y)$ pairs of values, so the first coordinate `x_and_y[0]` represents values of $X$ and the second coordinate `x_and_y[1]` represents values of $Y$.

```{python}
x_and_y.count(is_x_lt_6_and_y_ge_2) / x_and_y.count()
```

We could also count use Boolean logic; basically using indicators and the property $\ind_{\{X<6,Y\ge 2\}}=\ind_{\{X<6\}}\ind_{\{Y\ge 2\}}$.

```{python}
((x_and_y[0] < 6) * (x_and_y[1] >= 2)).count_eq(True) / x_and_y.count()
```


Now we simulate many $(X, Y)$ pairs and summarize their frequencies.

```{python}
x_and_y = (X & Y).sim(10000)

x_and_y.tabulate()
```

Here are the relative frequencies; compare with @tbl-dice-joint-dist-flat.

```{python}
x_and_y.tabulate(normalize = True)
```

When there are thousands of simulated pairs, a scatter plot does not adequately display relative frequencies, even with jittering.

```{python}
#| eval: false
x_and_y.plot(jitter = True)

```

```{python}
#| echo: false
plt.figure()
x_and_y.plot(jitter = True)
plt.show()

```




 
The tile plot provides a better summary.
Notice how the colors represent the relative frequencies in the previous table.

```{python}
#| eval: false
x_and_y.plot('tile')

```

```{python}
#| echo: false
plt.figure()
x_and_y.plot('tile')
plt.show()

```



Finally, we find the simulated relative frequency of the event $\{X <6, Y \ge 2\}$.

```{python}
x_and_y.count(is_x_lt_6_and_y_ge_2) / x_and_y.count()
```


### Approximating probabilities in the meeting problem


:::: {.callout-note appearance="simple"}
::: {#exm-meeting-sim-independent-uniform-rel-freq}
Recall the independent Uniform(0, 60) model for arrival times of @exm-meeting-box-sim.
Use the simulation results in 
@tbl-meeting-tactile-uniform-sim-table-pair to approximate the following.
(Don't worry if the approximations are any good yet.)



1.  $\IP(T < 15)$
1.  $\IP(W < 15)$
1.  $\IP(T < 15, W < 15)$
1.  $\IP(R = 20)$
1.  $\IP(19.5 < R < 20.5)$

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-meeting-sim-independent-uniform-rel-freq}




1.  Approximate $\IP(T < 15)$ by 3/10 = 0.3, the proportion of repetitions where the first arrival time is less than 15 minutes.
1.  Approximate $\IP(W < 15)$ by 6/10 = 0.6, the proportion of repetitions where the waiting time is less than 15 minutes.
1.  Approximate $\IP(T < 15, W < 15)$ by 2/10 = 0.2, the proportion of repetitions where both the first arrival time and the waiting time are less than 15 minutes.
1.  Approximate $\IP(R=20)$ by 0, the proportion of repetitions where $R$ is equal to 20.
1.  Approximate $\IP(19.5 < R < 20.5)$ by 1/10 = 0.1, the proportion of repetitions where $R$, rounded to the nearest minute, is equal to 20.

:::
::::

An event either happens or not.
Regardless of whether an event involves a discrete or continuous random variable, the probability of the event is approximated in the same way.
However, the kinds of events we're interested in differ between those involving discrete and those involving continuous random variables.
The probability that a continuous random variable is equal to any particular value is 0, so we're not interested in approximating "equals to" probabilities for continuous random variables.
When dealing with continuous random variables in practice, "equals to" is really "close to", and we compute approximate "close to" probabilities with relative frequencies are usual.
(Later, we'll see what it means to *condition* on a continuous random variable being equal to some value.)

To get better approximations for the probabilities in @exm-meeting-box-sim we would need to simulate many more repetitions.
But the process of approximating probabilities with simulated relative frequencies is the same as in @exm-meeting-box-sim.

Simulation can also be used to investigate how sensitive (approximate) probabilities are to changes in assumptions.

:::: {.callout-note appearance="simple"}
::: {#exm-meeting-sim-intro}
Write Symbulate code to run simulations and use the results to approximate the probability that Regina and Cady arrive with 15 minutes of each other for each of the three models in @sec-meeting-sim. 


1.  Independent Uniform model
1.  Independent Normal model
1.  Bivariate Normal model

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-meeting-sim-intro}

There are a few ways to code this, but one way is to define the waiting time random variable $W=|R-Y|$ and find simulated relative frequencies of the event $\{W<15\}$.

First the independent Uniform model.

```{python}

P = Uniform(0, 60) ** 2
R, Y = RV(P)

W = abs(R - Y)

w = W.sim(10000)

w.count_lt(15) / w.count()

```


Next the independent Normal model.

```{python}

P = Normal(30, 10) ** 2
R, Y = RV(P)

W = abs(R - Y)

w = W.sim(10000)

w.count_lt(15) / w.count()

```

Finally, the Bivariate Normal model.

```{python}

P = BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7)
R, Y = RV(P)

W = abs(R - Y)

w = W.sim(10000)

w.count_lt(15) / w.count()

```

We see that these changes in assumptions have substantial influence on this probability.
The simulations shows that they are roughly 1.7 times more likely to arrive within 15 minutes of each other under the independent Normal model than under the independent Uniform model, and roughly 1.3 times more likely under the Bivariate Normal model than under the independent Normal model.

:::
::::

We have previously seen rug plots of individual simulated values.
Rug plot emphasize that realizations of a random variable  are numbers along a number line.
However, a rug plot does not adequately summarize the distribution of values.
Instead, calling `.plot()` for simulated values of a *continuous* random variable produces a *histogram*.

```{python}

plt.figure()
w.plot()
plt.show()
```

We will cover histograms and marginal distributions of continuous random variables in much more detail in @sec-simulation-marginal-continuous.

### Exercises


::: {#exr-approximate-probability-collector}
The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3).
Each package contains a single unknown prize.
Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3).
For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.
Let $X$ be the number of distinct prizes obtained in these 3 packages.
Let $Y$ be the number of these 3 packages that contain prize 1.

1.  Explain how you could, in principle, conduct a simulation by hand and use the results to approximate
    a.  $\IP(X = 2)$
    a.  $\IP(Y = 1)$
    a.  $\IP(X = 2, Y = 1)$
1.  Write Symbulate code to conduct a simulation and approximate the values in part 1.
1.  Write Sybulate code to conduct a simulation and approximate
    a.  Marginal distribution of $X$
    a.  Marginal distribution of $Y$
    a.  Joint distribution of $X$ and $Y$
:::


::: {#exr-approximate-probability-collector-b}
Repeat @exr-approximate-probability-collector, but now assuming that 10% of boxes contain prize 1, 30% contain prize 2, and 60% contain prize 3.
:::




::: {#exr-approximate-probability-geometric}

Maya is a basketball player who makes 40% of her three point field goal attempts.
Suppose that at the end of every practice session, she attempts three pointers until she makes one and then stops.
Let $X$ be the total number of shots she attempts in a practice session.
Assume shot attempts are independent, each with probability of 0.4 of being successful.

1.  Explain in words you could use simulation to approximate the distribution of $X$ and $\IP(X > 3)$.
1.  Write Symbulate code to approximate the distribution of $X$ and $\IP(X > 3)$.

:::

::: {#exr-approximate-probability-continuous-dice}
Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4).
Let $X$ be the sum of the two spins and let $Y$ be the larger of the two spins.


1.  Describe in words how you could use simulation to approximate
    a.  $\IP(X < 3.5)$
    a.  $\IP(Y > 2.7)$
    a.  $\IP(X < 3.5, Y > 2.7)$
1.  Write Symbulate code to conduct a simulation to approximate, via plots
    a.  the marginal distribution of $X$
    a.  the marginal distribution of $Y$
    a.  the joint distribution of $X$ and $Y$
    a.  The probabilities from part 1
:::




## Approximating probabilities: Simulation margin of error {#sec-moe}

The probability of an event can be approximated by simulating the random phenomenon a large number of times and computing the relative frequency of the event.
After enough repetitions we expect the simulated relative frequency to be *close to* the true probability, but there probably won't be an exact match.
Therefore, in addition to reporting the approximate probability, we should also provide a margin of error which indicates how close we think our simulated relative frequency is to the true probability.

@sec-rel-freq introduced the relative frequency interpretation in the context of flipping a fair coin.
After many flips of a fair coin, we expect the proportion of flips resulting in H to be close to 0.5.
But how many flips is enough?
And how "close" to 0.5?
We'll investigate these questions now.

```{r}
#| echo: false
#| cache: true
#| warning: false
#| message: false

N = 100
n = 10000
p = 0.5
ci = 0.95
z = 2


phat = data.frame(phat = rbinom(N, n, p) / n)

phat = phat |>
  mutate(ci_lb = phat - z * sqrt(p * (1 - p) / n),
         ci_ub = phat + z * sqrt(p * (1 - p) / n),
         good_ci = abs(phat - p) <= z * sqrt(p * (1 - p) / n))

plot_coin_phat_n1 <- ggplot(phat,
                            aes(x = phat,
                                color = good_ci,
                                fill = good_ci)) +
  geom_dotplot() +
  theme_classic() +
  theme(axis.line = element_line(color = "black"),
        legend.position = "none") +
  scale_color_manual(
    values = c("orange", "skyblue"),
    aesthetics = c("color", "fill")
  ) +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_x_continuous(breaks = p - seq(-3, 3, 0.5) * sqrt(p * (1 - p) / n)) +
  geom_vline(xintercept = p + c(-1, 1) * z * sqrt(p * (1 - p) / n),
             linetype = "dotted", color = "black", size = 1.5) +
  labs(x = "Proportion of heads")

num_good_ci_n1 <- phat |> select(good_ci) |> sum()

num_good_phat <- phat |> filter(phat == p) |> count()

```

Consider @fig-coin-sim1 below.
Each dot represents a set of 10,000 fair coin flips.
There are 100 dots displayed, representing 100 different sets of 10,000 coin flips each.
For each set of flips, the proportion of the 10,000 flips which landed on head is recorded.
For example, if in one set 4973 out of 10,000 flips landed on heads, the proportion of heads is 0.4973.
The plot displays 100 such proportions; similar values have been "binned" together for plotting.
We see that `r num_good_ci_n1` of these 100 proportions are between 0.49 and 0.51, represented by the blue dots.
So if "between 0.49 and 0.51" is considered "close to 0.5", then yes, in 10000 coin flips we would expect[^simulation-30] the proportion of heads to be close to 0.5.

[^simulation-30]: In 10000 flips, the probability of heads on between 49% and 51% of flips is 0.956, so `r num_good_ci_n1` out of 100 provides a rough estimate of this probability.
    We will see how to compute such a probability later.


::: {#fig-coin-sim1}

```{r}
#| echo: false
#| warning: false
#| message: false

print(plot_coin_phat_n1)

```

Proportion of flips which are heads in 100 sets of **10,000** fair coin flips. Each dot represents a set of **10,000** fair coin flips. In `r num_good_ci_n1` of these 100 sets the proportion of heads is between 0.49 and 0.51 (the blue dots).

:::




Our discussion of @fig-coin-sim1 suggests that 0.01 might be an appropriate margin of error for a simulation based on 10,000 flips.
Suppose we perform a simulation of 10000 flips with 4973 landing on heads.
We could say "we estimate that the probability that a coin land on heads is equal to 0.4973".
But such a precise estimate would almost certainly be incorrect, due to natural variability in the simulation.
In fact, only `r num_good_phat` sets[^simulation-31] resulted in a proportion of heads exactly equal to the true probability of 0.5.

[^simulation-31]: This is difficult to see in @fig-coin-sim1 due to the binning.
    But we can at least tell from @fig-coin-sim1 that at most a handful of the 100 sets resulted in a proportion of heads exactly equal to 0.5.

A better statement would be "we estimate that the probability that a coin land on heads is 0.4973 *with a margin of error*[^simulation-32] *of 0.01*".
This means that we estimate that the true probability of heads is within 0.01 of 0.4973.
In other words, we estimate that the true probability of heads is between 0.4873 and 0.5073, an interval whose endpoints are $0.4973 \pm 0.01$.
This interval estimate is "accurate" in the sense that the true probability of heads, 0.5, *is* between 0.4873 and 0.5073.
By providing a margin of error, we have sacrificed a little precision---"equal to 0.4973" versus "within 0.01 of 0.4973"---to achieve greater accuracy.

[^simulation-32]: Technically, we should say "a margin of error *for 95% confidence* of 0.01".
    We'll discuss "confidence" in a little more detail soon.

Let's explore this idea of "accuracy" further.
Recall that @fig-coin-sim1 displays the proportion of flips which landed on heads for 100 sets of 10000 flips each.
Suppose that for each of these sets we form an interval estimate of the probability that the coin lands on heads by adding/subtracting 0.01 from the simulated proportion, as we did for $0.4973 \pm 0.01$ in the previous paragraph.
@fig-coin-sim1-ci displays the results.
Even though the proportion of heads was equal to 0.5 in only `r num_good_phat` sets, in `r num_good_ci_n1` of these 100 sets (the blue intervals) the corresponding interval contains 0.5, the true probability of heads.
For almost all of the sets, the interval formed via "relative frequency $\pm$ margin of error" provides an accurate estimate of the true probability.
However, not all the intervals contain the true probability, which is why we often qualify that our margin of error is for "95% confidence" or "95% accuracy".
We will see more about "confidence" soon.
In any case, the discussion so far, and the results in @fig-coin-sim1 and @fig-coin-sim1-ci, suggest that 0.01 is a reasonable choice for margin of error when estimating the probability that a coin lands on heads based on 10000 flips.



::: {#fig-coin-sim1-ci}

```{r}
#| echo: false
#| warning: false
#| message: false

plot_coin_phat_n1_ci <- ggplot(phat |>
                                 arrange(phat) |>
                                 mutate(repetition = row_number()),
                               aes(x = phat,
                                   y = repetition,
                                   color = good_ci)) +
  geom_point() +
  geom_segment(aes(x = ci_lb, xend = ci_ub,
                   y = repetition, yend = repetition,
                   color = good_ci)) +
  scale_color_manual(
    values = c("orange", "skyblue"),
    aesthetics = c("color", "fill")
  ) +
    geom_vline(xintercept = p, color = "black", size = 1.0) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Proportion of heads, with margin of error",
       y = "Set")

print(plot_coin_phat_n1_ci)
```

Interval estimates of the probability of heads based on 100 sets of **10,000** fair coin flips. Each dot represents the proportion of heads in a set of **10,000** fair coin flips. (The sets have been sorted based on their proportion of heads.) For each set an interval is obtained by adding/subtracting the margin of error of 0.01 from the proportion of heads. In `r num_good_ci_n1` of these 100 sets (the blue dots/intervals) the corresponding interval contains the true probability of heads (0.5, represented by the vertical black line).

:::



```{r}
#| echo: false
#| cache: true
#| warning: false
#| message: false

N = 100
n = 1000000
p = 0.5
ci = 0.95
z = 2


phat = data.frame(phat = rbinom(N, n, p) / n)

phat = phat |>
  mutate(ci_lb = phat - z * sqrt(p * (1 - p) / n),
         ci_ub = phat + z * sqrt(p * (1 - p) / n),
         good_ci = abs(phat - p) <= z * sqrt(p * (1 - p) / n))

plot_coin_phat_n2 <- ggplot(phat,
                            aes(x = phat,
                                color = good_ci,
                                fill = good_ci)) +
  geom_dotplot() +
  theme_classic() +
  theme(axis.line = element_line(color = "black"),
        legend.position = "none") +
  scale_color_manual(
    values = c("orange", "skyblue"),
    aesthetics = c("color", "fill")
  ) +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_x_continuous(breaks = p - seq(-3, 3, 0.5) * sqrt(p * (1 - p) / n)) +
  geom_vline(xintercept = p + c(-1, 1) * z * sqrt(p * (1 - p) / n),
             linetype = "dotted", color = "black", size = 1.5) +
  labs(x = "Proportion of heads")

num_good_ci_n2 <- phat |> select(good_ci) |> sum()

```

What if we want to be stricter about what qualifies as "close to 0.5"?
That is, what if a margin of error of 0.01 isn't good enough?
You might suspect that with even more flips we would expect to observe heads on even closer to 50% of flips.
Indeed, this is the case.
@fig-coin-sim2 displays the results of 100 sets of *1,000,000* fair coin flips.
The pattern seems similar to @fig-coin-sim1 but pay close attention to the horizontal axis which covers a much shorter range of values than in the previous figure.
Now `r num_good_ci_n2` of the 100 proportions are between *0.499 and 0.501*.
So in 1,000,000 flips we would expect[^simulation-33] the proportion of heads to be between 0.499 and 0.501, pretty close to 0.5.
This suggests that 0.001 might be an appropriate margin of error for a simulation based on 1,000,000 flips.

[^simulation-33]: In 1,000,000 flips, the probability of heads on between 49.9% and 50.1% of flips is 0.955, and `r num_good_ci_n2` out of 100 sets provides a rough estimate of this probability.


::: {#fig-coin-sim2}


```{r}
#| echo: false
#| warning: false
#| message: false

print(plot_coin_phat_n2)

```

Proportion of flips which are heads in 100 sets of **1,000,000** fair coin flips. Each dot represents a set of **1,000,000** fair coin flips. In `r num_good_ci_n2` of these 100 sets the proportion of heads is between 0.499 and 0.501 (the blue dots).

:::

```{r}
#| echo: false
#| cache: true
#| warning: false
#| message: false

N = 100
n = 100000000
p = 0.5
ci = 0.95
z = 2


phat = data.frame(phat = rbinom(N, n, p) / n)

phat = phat |>
  mutate(ci_lb = phat - z * sqrt(p * (1 - p) / n),
         ci_ub = phat + z * sqrt(p * (1 - p) / n),
         good_ci = abs(phat - p) <= z * sqrt(p * (1 - p) / n))

plot_coin_phat_n3 <- ggplot(phat,
                            aes(x = phat,
                                color = good_ci,
                                fill = good_ci)) +
  geom_dotplot() +
  theme_classic() +
  theme(axis.line = element_line(color = "black"),
        legend.position = "none") +
  scale_color_manual(
    values = c("orange", "skyblue"),
    aesthetics = c("color", "fill")
  ) +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_x_continuous(breaks = p - seq(-3, 3, 0.5) * sqrt(p * (1 - p) / n)) +
  geom_vline(xintercept = p + c(-1, 1) * z * sqrt(p * (1 - p) / n),
             linetype = "dotted", color = "black", size = 1.5) +
  labs(x = "Proportion of heads")

num_good_ci_n3 <- phat |> select(good_ci) |> sum()

```

What about even more flips?
In @fig-coin-sim3 each dot represents a set of *100 million* flips.
The pattern seems similar to the previous figures, but again pay close attention the horizontal access which covers a smaller range of values.
Now `r num_good_ci_n3` of the 100 proportions are between *0.4999 and 0.5001*.
So in 100 million flips we would expect[^simulation-34] the proportion of heads to be between 0.4999 and 0.5001, pretty close to 0.5.
This suggests that 0.0001 might be an appropriate margin of error for a simulation based on 100,000,000 flips.

[^simulation-34]: In 100 million flips, the probability of heads on between 49.99% and 50.01% of flips is 0.977, and `r num_good_ci_n3` out of 100 sets provides a rough estimate of this probability.



::: {#fig-coin-sim3}

```{r}
#| echo: false
#| warning: false
#| message: false

print(plot_coin_phat_n3)

```

Proportion of flips which are heads in 100 sets of **100,000,000** fair coin flips. Each dot represents a set of **100,000,000** fair coin flips. In `r num_good_ci_n3` of these 100 sets the proportion of heads is between 0.4999 and 0.5001 (the blue dots).

:::

The previous figures illustrate that the more flips there are, the more likely it is that we observe a proportion of flips landing on heads close to 0.5.
We also see that with more flips we can refine our definition of "close to 0.5": increasing the number of flips by a factor of 100 (10,000 to 1,000,000 to 100,000,000) seems to give us an additional decimal place of precision ($0.5\pm0.01$ to $0.5\pm 0.001$ to $0.5\pm 0.0001$.)


### A closer look at margin of error {#sec-language-simulation-moe-formula}

We will now carry out an analysis similar to the one above to investigate simulation margin of error and how it is influenced by the number of simulated values used to compute the relative frequency.
Continuing the dice example, suppose we want to estimate $p=\IP(X=6)$, the probability that the sum of two rolls of a fair four-sided equals six.
Since there are 16 possible equally likely outcomes, 3 of which result in a sum of 3, the true probability is $p=3/16=0.1875$. 

We will perform a "meta-simulation". The process is as follows

1.  Simulate two rolls of a fair four-sided die.  Compute the sum ($X$) and see if it is equal to 6.
1.  Repeat step 1 to generate $N$ simulated values of the sum ($X$).
Compute the relative frequency of sixes: count the number of the $N$ simulated values equal to 6 and divide by $N$.
Denote this relative frequency $\hat{p}$ (read "p-hat").
1.  Repeat step 2 a large number of times, recording the relative frequency $\hat{p}$ for each set of $N$ values.

Be sure to distinguish between steps 2 and 3.
A simulation will typically involve just steps 1 and 2, resulting in a single relative frequency based on $N$ simulated values.
Step 3 is the "meta" step; we see how this relative frequency varies from simulation to simulation to help us in determing an appropriate margin of error.
The important quantity in this analysis is $N$, the *number of independently simulated values used to compute the relative frequency* in a single simulation.
We wish to see how $N$ impacts margin of error.
The number of simulations in step 3 just needs to be "large" enough to provide a clear picture of how the relative frequency varies from simulation to simulation.
The more the relative frequency varies from simulation to simulation, the larger the margin of error needs to be.

We can combine steps 1 and 2 of the meta-simulation to put it in the framework of the simulations from earlier in this chapter.
Namely, we can code the meta-simulation as a single simulation in which

-   A sample space outcome represents $N$ values of the sum of two fair-four sided dice
-   The main random variable of interest is the proportion of the $N$ values which are equal to 6.

Let's first consider $N=100$.
The following Symbulate code defines the probability space corresponding to 100 values of the sum of two-fair four sided dice.
Notice the use of `apply` which functions much in the same way^[One difference between `RV` and `apply`: `apply` preserves the type of the input object.  That is, if `apply` is applied to a `ProbabilitySpace` then the output will be a `ProbabilitySpace`; if `apply` is applied to an `RV` then the output will be an `RV`.  In contrast, `RV` always creates an `RV`.] as `RV`.


```{python}
#| label: metasim-p
N = 100
P = BoxModel([1, 2, 3, 4], size = 2).apply(sum) ** N
P.sim(5)

```

In the code above

-   `BoxModel([1, 2, 3, 4], size = 2)` simulates two rolls of a fair four-sided die
-   `.apply(sum)` computes the sum of the two rolls
-   `** N` repeats the process `N` times to generate a set of `N` independent values, each value representing the sum of two rolls of a fair four-sided die
-   `P.sim(5)` simulates 5 sets, each set consisting of `N` sums

Now we define the random variable which takes as an input a set of $N$ sums and returns the proportion of the $N$ sums which are equal to six.

```{python}
#| label: metasim-phat

phat = RV(P, count_eq(6)) / N
phat.sim(5)

```

In the code above

-   `phat` is an `RV` defined on the probability space `P`.
Recall that an outcome of `P` is a set of `N` sums (and each sum is the sum of two rolls of a fair four-sided die).
-   The function that defines the `RV` is `count.eq(6)`, which counts the number of values in the set that are equal to 6. We then^[Unfortunately, for techincal reasons, `RV(P, count_eq(6) / N)` will not work.  It is possible to divide by `N` within `RV` if we define a custom function `def rel_freq_six(x): return x.count_eq(6) / N`
and then define `RV(P, rel_freq_six)`.] divide by `N`, the total number of values in the set, to get the relative frequency.
(Remember that a transformation of a random variable is also a random variable.)
-   `phat.sim(5)` generates 5 simulated values of the relative frequency `phat`.
Each simulated value of `phat` is the relative frequency of sixes in `N` sums of two rolls of a fair four-sided die.


Now we simulate and summarize a large number of values of `phat`.
We'll simulate 100 values for illustration (as we did in @fig-coin-sim1, @fig-coin-sim2, and @fig-coin-sim3).
Be sure not to confuse 100 with `N`.
Remember, the important quantity is `N`, the number of simulated values used in computing each relative frequency.

```{python}
#| eval: true
#| echo: false
#| cache: true
plt.figure()
phat.sim(100).plot(type = "impulse", normalize = False)
plt.ylabel('Number of simulations');
plt.show()

```


```{python}
#| eval: false

phat.sim(100).plot(type = "impulse", normalize = False)
plt.ylabel('Number of simulations');

```


We see that the 100 relative frequencies are roughly centered around the true probability 0.1875, but there is variability in the relative frequencies from simulation to simulation.
From the range of values, we see that most relative frequencies are within about 0.08 or so from the true probability 0.1875.
So a value around 0.08 seems like a reasonable value of the margin of error, but the actual value depends on what we mean by "most".
We can get a clearer picture if we run more simulations.
The following plot displays the results of 10000 simulations, each resulting in a value of $\hat{p}$.
Remember that each relative frequency is based on $N=100$ sums of two rolls.

```{python}
#| eval: true
#| echo: false
#| cache: true
plt.figure()
phats = phat.sim(10000)
phats.plot(type = "impulse", normalize = False)
plt.ylabel('Number of simulations');
plt.show()
```

```{python}
#| eval: false

phats = phat.sim(10000)
phats.plot(type = "impulse", normalize = False)
plt.ylabel('Number of simulations');
```

Let's see how many of these 10000 simulated proportions are within 0.08 of the true probability 0.1875.




```{python}
#| eval: true
#| cache: true
1 - (phats.count_lt(0.1875 - 0.08) + phats.count_gt(0.1875 + 0.08)) / 10000

```

In roughly 95% or so of simulations, the simulated relative frequency was within 0.08 of the true probability.
So 0.08 seems like a reasonable margin of error for "95% confidence" or "95% accuracy".
However, a margin of error of 0.08 yields pretty imprecise estimates, ranging from about 0.10 to 0.27.
Can we keep the degree of accuracy at 95% but get a smaller margin of error, and hence a more precise estimate?
Yes, if we increase the number of repetitions used to compute the relative frequency.

Now we repeat the analysis, but with $N=10000$.
In this case, each relative frequency is computed based on 10000 independent values, each value representing a sum of two rolls of a fair four-sided die.
As before we start with 100 simulated relative frequencies.

```{python}
#| eval: true
#| echo: false
#| cache: true

N = 10000
P = BoxModel([1, 2, 3, 4], size = 2).apply(sum) ** N
phat = RV(P, count_eq(6)) / N

phats = phat.sim(100)
phats.plot(type = "impulse", normalize = False)
plt.ylabel('Number of simulations');
plt.show()

```


```{python}
#| eval: false

N = 10000
P = BoxModel([1, 2, 3, 4], size = 2).apply(sum) ** N
phat = RV(P, count_eq(6)) / N

phats = phat.sim(100)
phats.plot(type = "impulse", normalize = False)
plt.ylabel('Number of simulations');

```


Again we see that the 100 relative frequencies are roughly centered around the true probability 0.1875, but there is less variability in the relative frequencies from simulation to simulation for $N=10000$ than for $N=100$.
Pay close attention to the horizontal axis.
From the range of values, we see that most relative frequencies are now within about 0.008 of the true probability 0.1875.

```{python}
#| eval: true
#| cache: true
1 - (phats.count_lt(0.1875 - 0.008) + phats.count_gt(0.1875 + 0.008)) / 100

```

As with $N=100$, running more than 100 simulations would give a clearer picture of how much the relative frequency based on $N=10000$ simulated values varies from simulation to simulation. But even with just 100 simulations, we see that a margin of error of about 0.008 is required for roughly 95% accuracy when $N=10000$, as opposed to 0.08 when $N=100$.
As we observed in the coin flipping example earlier in this section, it appears that increasing $N$ by a factor of 100 yields an extra decimal place of precision.
That is, increasing $N$ by a factor of 100 decreases the margin of error by a factor of $\sqrt{100}$.
In general, the margin of error is inversely related to $\sqrt{N}$.



```{r}
#| label: tbl-moe-compare
#| echo: false
#| tbl-cap: "Comparison of margins of error for 95% confidence for the meta-simulations in this section."


ns = 100 ^ (1:3)

compare_df = data.frame(c("A fair coin flip lands H",
                          "Two rolls of a fair four-sided die sum to 6"),
                        c(0.5, 0.1875),
                    round(t(cbind(2 * 0.5 / sqrt(ns), 2 * sqrt(3 / 16 * (1 - 3 / 16)) / sqrt(ns))), 4))

kbl(
  compare_df,
  digits = 7,
  format.args = list(scientific = FALSE),
  booktabs = TRUE,
  col.names = c("Probability that", "True value",
                "95% m.o.e. (N = 100)", "95% m.o.e. (N = 10000)",
                "95% m.o.e. (N = 1000000)")
) |>
  kable_styling()

```


The two examples in this section illustrate that the margin of error also depends somewhat on the true probability.
The margin of error required for 95% accuracy is larger when the true probability is 0.5 than when it is 0.1875.
It can be shown that when estimating a probability $p$ with a relative frequency based on $N$ simulated repetitions, the margin of error required for 95% confidence^[We will see
    the rationale behind this formula later. The factor 2
    comes from the fact that for a Normal distribution, about 95% of values
    are within 2 standard deviations of the mean. Technically, the
    factor 2 corresponds to 95% confidence only when a single
    probability is estimated. If multiple probabilities are estimated
    simultaneously, then alternative methods should be used,
    e.g., increasing the factor 2 using a
    [Bonferroni
    correction](https://en.wikipedia.org/wiki/Bonferroni_correction).
    For example, a multiple of 4 rather than 2 produces very conservative error bounds for 95% confidence even when many probabilities are being estimated.] is
$$
2\frac{\sqrt{p(1-p)}}{\sqrt{N}}
$$
For a given $N$, the above quantity is maximized when $p$ is 0.5.
Since $p$ is usually unknown---the reason for performing the simulation is to approximate it---we plug in 0.5 for a somewhat conservative margin of error of $1/\sqrt{N}$.

For a fixed $N$, there is a tradeoff between accuracy and precision.
The factor 2 in the margin of error formula above corresponds to 95% accuracy.
Greater accuracy would require a larger factor, and a larger margin of error, resulting in a wider---that is, less precise---interval.
For example, 99% confidence requires a factor of roughly 2.6 instead of 2, resulting in an interval that is roughly 30 percent wider.
The confidence level does matter, but the primary influencer of margin of error is $N$, the number of independently simulated repetitions on which the relative frequency is based.
Regardless of confidence level, the margin of error is on the order of magnitude of $1/\sqrt{N}$.

In summary, **the margin of error when approximating a probability based on a simulated relative frequency is roughly on the order $1/\sqrt{N}$, where $N$ is the number of independently simulated repetitions used to calculate the relative frequency.**
Warning: alternative methods are necessary when the actual probability being estimated is very close to 0 or to 1.


A probability is a theoretical long run relative frequency.
A probability can be approximated by a relative frequency from a large number of simulated repetitions, but there is some simulation margin of error.
Likewise, the average value of $X$  after a large number of simulated repetitions is only an approximation to the theoretical long run average value of $X$, that is, the expected value of $X$.
The margin of error is also on the order of $1/\sqrt{N}$ where $N$ is the number of independently simulated values used to compute the average, but the degree of variability of the random variable also plays a role.
We will explore margins of error for long run averages  in more detail later.

Pay attention to what $N$ denotes: $N$ is the number of independently^[In all the situations in this book the repetitions will be simulated independently.  However, there are many simulation methods where this is not true, most notably MCMC (Markov Chain Monte Carlo) methods. The margin of error needs to be adjusted to reflect any dependence between simulated values.] simulated repetitions *used to calculate the relative frequency*.
This is not necessarily the number of simulated repetitions.
For example, suppose we use simulation to approximate the conditional probability that the larger of two rolls of a fair four-sided die is 4 *given that the sum is equal to 6.*
We might start by simulating 10000 pairs of rolls.
But the sum would be equal to 6 in only about 1875 pairs, and it is only these pairs that would be used to compute the relative frequency that the larger roll is 4 to approximate the probability of interest.
The appropriate margin of error is roughly $1/\sqrt{1875} \approx 0.023$.
Compared to 0.01 (based on the original 10000 repetitions), the margin of error of 0.023 for the conditional probability results in intervals that are 130 percent wider.
Carefully identifying the number of repetitions *used to calculate the relative frequency* is especially important when determining appropriate simulation margins of error for approximating *conditional probabilities*, which we'll discuss in more detail later.



### Approximating multiple probabilities {#sec-moe-multiple}

When using simulation to estimate a single probability, the primary influencer of margin of error is $N$, the number of repetitions on which the relative frequency is based.
It doesn't matter as much whether we use, say, 95% versus 99% confidence (either way, it's an "A").
That is, it doesn't matter too much whether we compute our margin of error using
$$
2\frac{\sqrt{p(1-p)}}{\sqrt{N}},
$$
with a multiple of 2 for 95% confidence, or if we replace 2 by 2.6 for 99% confidence.
(Remember, we can plug in 0.5 for the unknown $p$ for a conservative margin of error.)
A margin of error based on 95% or 99% (or another confidence level in the neighborhood) provides a reasonably accurate estimate of the probability. 
However, using simulation to *approximate multiple probabilities simultaneously* requires a little more care with the confidence level.


In the previous section we used simulation to estimate $\IP(X=6)$.
Now suppose we want to approximate $\IP(X = x)$ for each value of $x = 2,3,4,5,6,7,8$.
We could run a simulation to obtain results like those in @fig-dice-sum-marginal-sim and the table before it.
Each of the relative frequencies in the table is an approximation of the true probability, and so each of the relative frequencies should have a margin of error, say 0.01 for a simulation based on 10000 repetitions.
Thus, the simulation results yield a *collection* of seven interval estimates, an interval estimate of $\IP(X = x)$ for each value of $x = 2,3,4,5,6,7,8$.
Each interval in the collection either contains the respective true probability or not.
The question is then: In what percent of simulations will *every* interval in the collection contain the respective true probability?

@fig-multiple-ci1 summarizes the results of 100 simulations.
Each simulation consists of 10000 repetitions, with results similar to those in @fig-dice-sum-marginal-sim and the table before it.
Each simulation is represented by a row in @fig-multiple-ci1, consisting of seven 95% interval estimates, one for each value of $x$.
(The rows have been sorted before plotting; see the next paragraph.)
Each panel represents a different value of $x$; for each value of $x$, around 95 out of the 100 simulations yield estimates that contain the true probability $\IP(X=x)$, represented by the vertical line.


```{r}
#| echo: false
#| warning: false
#| message: false
x = 2:8
p_vec = c(1, 2, 3, 4, 3, 2, 1) / 16

n = 10000
N = 100

zmax = 5
z = 2

sim = data.frame(t(rmultinom(N, n, p_vec) / n))
names(sim) = paste("x=", x, sep = "")

good_ci = NULL

for (i in 1:length(x)) {
  good_ci_i = (abs(sim[, i] - p_vec[i]) < z * sqrt(p_vec[i] * (1 - p_vec[i]) / n))
  good_ci <- good_ci |> bind_cols(good_ci_i)
}

n_good_ci = apply(good_ci, 1, sum)
n_good_sets = sum(n_good_ci == length(x))

sim <- sim |>
  mutate(n_good_ci = n_good_ci) |>
  arrange(n_good_ci) |>
  mutate(repetition = row_number())

phat_lims = c(max(0, min(p_vec - zmax * sqrt(p_vec * (1 - p_vec) / n))),
              min(1, max(p_vec + zmax * sqrt(p_vec * (1 - p_vec) / n))))

plot_i = list()

for (i in 1:length(x)) {
  
  p = p_vec[i]
  
  sim_i = sim |>
    select(i, repetition) |>
    rename(phat = 1) |>
    mutate(ci_lb = pmax(0, phat - z * sqrt(p * (1 - p) / n)),
           ci_ub = pmin(1, phat + z * sqrt(p * (1 - p) / n)),
           good_ci = (abs(phat - p) <= z * sqrt(p * (1 - p) / n)))
  
  p <- ggplot(sim_i, aes(x = phat, y = repetition, color = good_ci)) +
    geom_point() +
    geom_segment(aes(x = ci_lb, xend = ci_ub,
                     y = repetition, yend = repetition,
                     color = good_ci)) +
    scale_x_continuous(labels = label_number(accuracy = 0.001),
                       breaks = waiver(),
                       n.breaks = 4) +
    # scale_x_continuous(limits = phat_lims) + 
  scale_color_manual(
    values = c("orange", "skyblue"),
    aesthetics = c("color", "fill")
  ) +
        geom_vline(xintercept = p, color = "black", size = 1.0) +
    labs(title = paste("x =", x[i]),
         x = "",
         y = "Simulation") +
    theme_classic() +
    theme(legend.position = "none",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(size = 7, angle = 90, vjust = 0.5, hjust = 1))
        # geom_rect(aes(xmin = 0,xmax=1,ymin=0,ymax=n_good_sets),fill="black",alpha=0.2)
  
  if (i > 1) {
    p <- p +
      theme(axis.title.y = element_blank(),
            axis.text.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.line.y = element_blank())
  }
  
  plot_i[[i]] = p
  
}
```






```{r}
#| label: fig-multiple-ci1
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Results of 100 simulations. Each simulation yields a collection of seven 95% confidence intervals."

do.call(grid.arrange, c(plot_i, nrow = 1))

```


However, let's zoom in on the bottom of @fig-multiple-ci1.
@fig-multiple-ci2 displays the results of the `r N - n_good_sets` simulations at the bottom of @fig-multiple-ci1.
Look carefully row by row in @fig-multiple-ci2; in each of these simulations at least one of the seven intervals in the collection does not contain the true probability.
In other words, *every* interval in the collection contains the respective true probability in only `r n_good_sets` of the 100 simulations (the other simulations in @fig-multiple-ci1).)
While we have 95 percent confidence in our interval estimate of $\IP(X = x)$ for any single $x$, we only have around `r n_good_sets` percent confidence in our approximate *distribution* of $X$.
Our confidence "grade" has gone from "A" range (95 percent) to "C" range (`r n_good_sets` percent).



::: {#fig-multiple-ci2}

```{r}
#| echo: false
#| warning: false
#| message: false

plot_i2 = list()

for (i in 1:length(x)) {
  p = plot_i[[i]]
  p <- p +
    ylim(0, N - n_good_sets)
  plot_i2[[i]] = p

}

do.call(grid.arrange, c(plot_i2, nrow = 1))

```

Subset of `r N - n_good_sets` simulations from @fig-multiple-ci1. In each of these simulations, at least one 95% confidence interval does not contain the respective true probability.

:::


When approximating multiple probabilities based on a single simulation, such as when approximating a distribution, margins of error and interval estimates need to be adjusted to obtain *simultaneous* 95% confidence.
The easiest way to do this is to make all of the intervals in the collection wider.

There are many procedures for adjusting a collection of interval estimates to achieve simultaneous confidence; we won't get into any technical details.
As a very rough, but simple and typically conservative rule, when approximating many probabilities based on a single simulation, we recommend making the margin of error twice as large as when approximating a single probability.
That is, **use a margin of error of
$2/\sqrt{N}$ (rather than $1/\sqrt{N}$) to achieve simultaneous 95% confidence when approximating many probabilities based on a single simulation.**


@fig-multiple-ci1-adjust displays the same simulation results as @fig-multiple-ci1, but now the margin of error for each confidence interval is 2 times greater.
We can see that all of the original "bad" intervals turn "good" when widened, and now there is (greater than) 95% simultaneous confidence.

```{r}
#| echo: false
#| warning: false
#| message: false


zmax = 5
z = 2 * 2



good_ci = NULL

for (i in 1:length(x)) {
  good_ci_i = (abs(sim[, i] - p_vec[i]) < z * sqrt(p_vec[i] * (1 - p_vec[i]) / n))
  good_ci <- good_ci |> bind_cols(good_ci_i)
}

n_good_ci = apply(good_ci, 1, sum)
n_good_sets = sum(n_good_ci == length(x))

sim <- sim |>
  mutate(n_good_ci = n_good_ci) |>
  arrange(n_good_ci) |>
  mutate(repetition = row_number())

phat_lims = c(max(0, min(p_vec - zmax * sqrt(p_vec * (1 - p_vec) / n))),
              min(1, max(p_vec + zmax * sqrt(p_vec * (1 - p_vec) / n))))

plot_i = list()

for (i in 1:length(x)) {
  
  p = p_vec[i]
  
  sim_i = sim |>
    select(i, repetition) |>
    rename(phat = 1) |>
    mutate(ci_lb = pmax(0, phat - z * sqrt(p * (1 - p) / n)),
           ci_ub = pmin(1, phat + z * sqrt(p * (1 - p) / n)),
           good_ci = (abs(phat - p) <= z * sqrt(p * (1 - p) / n)))
  
  p <- ggplot(sim_i, aes(x = phat, y = repetition, color = good_ci)) +
    geom_point() +
    geom_segment(aes(x = ci_lb, xend = ci_ub,
                     y = repetition, yend = repetition,
                     color = good_ci)) +
    scale_x_continuous(labels = label_number(accuracy = 0.001),
                       breaks = waiver(),
                       n.breaks = 4) +
    # scale_x_continuous(limits = phat_lims) + 
  scale_color_manual(
    values = c("skyblue", "orange"),
    aesthetics = c("color", "fill")
  ) +
        geom_vline(xintercept = p, color = "black", size = 1.0) +
    labs(title = paste("x =", x[i]),
         x = "",
         y = "Simulation") +
    theme_classic() +
    theme(legend.position = "none",
          plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(size = 7, angle = 90, vjust = 0.5, hjust = 1))
        # geom_rect(aes(xmin = 0,xmax=1,ymin=0,ymax=n_good_sets),fill="black",alpha=0.2)
  
  if (i > 1) {
    p <- p +
      theme(axis.title.y = element_blank(),
            axis.text.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.line.y = element_blank())
  }
  
  plot_i[[i]] = p
  
}
```




```{r}
#| label: fig-multiple-ci1-adjust
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Results of 100 simulations. Each simulation yields a collection of seven 95% confidence intervals. The margin of error has been adjusted to obtain simultaneous confidence."

do.call(grid.arrange, c(plot_i, nrow = 1))

```

### Beware a false sense of precision

Why don't we always run something like one trillion repetitions so that our margin of error is tiny?
There is a cost to simulating and storing more repetitions in terms of computational time and memory.
Also, remember that simulating one trillion repetitions doesn't guarantee that the margin of error is actually based on anywhere close to one trillion repetitions, especially when conditioning on a low probability event.

Most importantly, keep in mind that any probability model is based on a series of assumptions and these assumptions are not satisfied exactly by the random phenomenon.
A precise estimate of a probability *under the assumptions of the model* is not necessarily a comparably precise estimate of the true probability.
Reporting probability estimates out to many decimal places conveys a false sense of precision and should typically be avoided.



For example, the probability that any particular coin lands on heads is probably not 0.5 *exactly*.
But any difference between the true probability of the coin landing on heads and 0.5 is likely not large enough to be practically meaningful^[See the footnotes in @sec-rel-freq.].
That is, assuming the coin is fair is a reasonable model.

Suppose we assume that the probability that a coin lands on heads is exactly 0.5 and that the results of different flips are independent.
If we flip the coin 1000 times the probability that it lands on heads at most 490 times is 0.2739864.
(We will see a formula for computing this value later.)
If we were to simulate one trillion repetitions (each consisting of 1000 flips) to estimate this probability then our margin of error would be 0.000001; we could expect accuracy out to the sixth decimal place. 
However, reporting the probability with so many decimal places is somewhat disingenuous.
If the probability that the coin lands on heads were 0.50001, then the probability of at most 490 heads in 1000 flips would be 0.2737757.
If the probability that the coin lands on heads were 0.5001, then the probability of at most 490 heads in 1000 flips would be 0.2718834.
Reporting our approximate probability as something like 0.2739864 $\pm$ 0.000001 says more about the precision in our *assumption* that the coin is fair than it does about the true probability that the coin lands on heads at most 490 times in 1000 flips.
A more honest conclusion would result from running 10000 repetitions and reporting our approximate probability as something like 0.27 $\pm$ 0.01.
Such a conclusion reflects more genuinely that there's some "wiggle room" in our assumptions, and that any probability computed according to our model is at best a reasonable approximation of the "true" probability. 



For most of the situations we'll encounter in this book, estimating a probability to within 0.01 of its true value will be sufficient for practical purposes, and so basing approximations on 10000 independently simulated values will be appropriate.
Of course, there are real situations where probabilities need to be estimated much more precisely, e.g., the probability that a bridge will collapse.  Such situations require more intensive methods.

:::: {.callout-note appearance="simple"}
::: {#exm-donny-moe}
Donny Dont runs a simulation to approximate the probability of an event $A$.
In 1,000,000 repetitions, event $A$ occurs on 437,952 repetitions.
He computes a margin of error (for 95% confidence) of $1/\sqrt{1000000} = 0.001$.
Donny tries a few different ways of reporting his results.
Explain to him what is wrong, missing, or could be improved in each of the following.


1.  I estimate that $\IP(A)$ is 0.437952.
1.  I estimate that $\IP(A)$ is 43.7952% with a margin of error of 0.1%.
1.  I estimate that $\IP(A)$ is between 0.436952 and 0.438952.
1.  I estimate with 95% confidence that under these assumptions $\IP(A)$ is between 0.437 and 0.439.

:::
::::



:::: {.callout-tip collapse=true}
::: {#sol-donny-moe}


1.  Donny has not provided a margin of error.
1.  We're okay with Donny expressing the proportion as a percent.
However, 0.001 is technically a margin of error of 0.1 *percentage points*.
A margin of error of 0.1% implies a *percentage change*, leading to interval endpoints of $0.437952\times (1 - 0.001) = 0.437514$ and $0.437952\times (1 + 0.001) = 0.438390$.
With a margin of error of 0.001, the interval endpoints are really $0.437952 -  0.001 = 0.436952$ and $0.437952 + 0.001 = 0.438952$.
The numbers are fairly similar in this case, but in general, the margins of error we have discussed are additive and therefore should be reported as *percentage points*. 
1.  We don't know the context, but in many situations reporting estimates to six decimal places as Donny has done is not necessary and could convey a false sense of precision.
1.  We like Donny's statement!
He has provided an interval estimate, reported his level of confidence, rounded to an appropriate number of decimal places (in most contexts) so as not to convey a false sense of precision, and drawn attention to to the fact that the estimate of the probability is predicated on the model assumptions.
It would have also been fine if he had replaced "is between 0.437 and 0.439" with "is 0.438 with a margin of error of 0.001".
In practice, Donny should replace vague statements like "these assumptions" and "$\IP(A)$" with contextual details, but the general form of his answer is very good.

:::
::::

### Exercises

::: {#exr-approximate-moe-birthday}
Use simulation to approximate the probability that at least two people in a group of $n=30$ share a birthday in @exm-birthday.
Compute the margin of error and write a clearly worded sentence reporting your approximate probability in context. 
:::


::: {#exr-approximate-moe-collector}
The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3).
Each package contains a single unknown prize.
Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3).
For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.
Let $X$ be the number of distinct prizes obtained in these 3 packages.
Let $Y$ be the number of these 3 packages that contain prize 1.

Suppose you simulate 10000 $(X, Y)$ pairs and use the results to approximate all of

a.  Marginal distribution of $X$
a.  Marginal distribution of $Y$
a.  Joint distribution of $X$ and $Y$

What is the approximate margin of error for simultaneous 95% confidence?

:::


## Approximating expected values: Averages {#sec-LRA}


On any single repetition of a simulation a particular event either occurs or not.
Summarizing simulation results for events involves simply counting the number of repetitions on which the event occurs and finding related proportions.

On the other hand, random variables typically take many possible values over the course of many repetitions.
We are still interested in relative frequencies of events, like $\{X=6\}$, $\{Y \ge 3\}$, and $\{X > 5, Y \ge 3\}$.
But for random variables we are also interested in their distributions which describe the possible values that the random variables can take and their relative likelihoods.
A *marginal distribution* contains all the information about the pattern of variability of a single random variable alone, and a *joint distribution* contains all the information about the pattern of variability of a collection of random variables.
It is also useful to summarize some key features of the pattern of variability.


One summary characteristic of a marginal distribution of a random variable is the *expected value*.
In @sec-literacy-ev and @sec-dist-intro-ev we discussed how an expected value can be interpreted as the *long run average value* of a random variable.
We can approximate the long run average value by simulating many values of the random variable and computing the average (a.k.a. *mean*) in the usual way: sum all the simulated values and divide by the number of simulated values.

:::: {.callout-note appearance="simple"}
::: {#exm-dice-sim-tactile-ev}
Let $X$ be the sum of two rolls of a fair four-sided die, and let $Y$ be the larger of the two rolls (or the common value if a tie).
Recall your tactile simulation from @exm-dice-sim; see ours in @tbl-dice-sim-tactile-results.
Based only on the results of your simulation, approximate the long run average value of each of the following.
(Don't worry if the approximations are any good yet.)



1.  $X$
1.  $Y$
1.  $X^2$
1.  $XY$

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-dice-sim-tactile-ev}

```{r}
#| echo: false

u1 = c(2, 1, 3, 4, 3, 3, 2, 2, 1, 3)
u2 = c(1, 1, 3, 3, 2, 4, 3, 4, 2, 4)
x = u1 + u2
y = pmax(u1, u2)

die_df = data.frame(1:10, u1, u2, x, y, x ^ 2, x * y)


```


We reproduce the results of our simulation in 
@tbl-dice-sim-tactile-results-ev with additional columns for $X^2$ and $XY$.
Results vary naturally so your simulation results will be different, but the same ideas apply.

```{r}
#| label: tbl-dice-sim-tactile-results-ev
#| echo: false


knitr::kable(
  die_df, booktabs = TRUE,
  col.names = c("Repetition", "First roll", "Second roll", "X", "Y", expression(X^2), "XY"),
  caption = "Results of 10 repetitions of two rolls of a fair four-sided die"
)

```

1.  Approximate the long run average value of $X$ by summing the 10 simulated values of $X$ and dividing by 10.
$$
\frac{`r paste(x, collapse=" + ")`}{10} = `r round(mean(x), 3)`
$$
1.  Approximate the long run average value of $Y$ by summing the 10 simulated values of $Y$ and dividing by 10.
$$
\frac{`r paste(y, collapse=" + ")`}{10} = `r round(mean(y), 3)`
$$
1.  First, for each repetition square the value of $X$ to obtain the $X^2$ column.
Then approximate the long run average value of $X^2$ by summing the 10 simulated values of $X^2$ and dividing by 10.
$$
\frac{`r paste(x ^ 2, collapse=" + ")`}{10} = `r round(mean(x ^ 2), 3)`
$$
1.  First, for each repetition compute the product $XY$ to obtain the $XY$ column.
Then approximate the long run average value of $XY$ by summing the 10 simulated values of $XY$ and dividing by 10.
$$
\frac{`r paste(x * y, collapse=" + ")`}{10} = `r round(mean(x * y), 3)`
$$


Of course, 10 repetitions is not enough to reliably approximate the *long run* average value.
But whether the average is based on 10 values or 10 million, an average is computed in the usual way: sum the values and divide by the number of values.

:::
::::


:::: {.callout-note appearance="simple"}
::: {#exm-meeting-sim-tactile-normal-ev}
Recall @sec-language-simulation-tactile-meeting-normal where we assumed the arrival time $X$ (minutes after noon) followed a Normal(30, 10) distribution, represented by the spinner in @fig-meeting-normal-spinner.
@tbl-meeting-tactile-normal-sim-table displays 10 simulated values of $X$.
Based only on the results of this simulation, approximate the long run average value of $X$.
(Don't worry if the approximation is any good yet.)

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-meeting-sim-tactile-normal-ev}


Approximate the long run average value of $X$ by simply computing the average in the usual way: sum the 10 simulated values of $X$ and divide by 10.
It's just that when $X$ is continuous each simulated value will be distinct with lots of decimal places.

$$
{\scriptscriptstyle
\frac{`r paste(round(x_normal_10, 3), collapse="... + ")`}{10} = `r round(mean(x_normal_10), 3)`
}
$$

:::
::::

We have seen a few examples of how to compute expected values for *discrete* random variables as probability-weighted average values.
The computation of expected values for *continuous* random variables is more complicated.
However, expected values can also be interpreted as long run average values for continuous random variables.
Therefore, expected values can be approximated in the same way for discrete and continuous random variables: simulate lots of values and compute the average.


In the examples in the section we only considered 10 simulated repetitions to emphasize that we're simply computing an average in the usual way.
But to get a good approximation of an expected value, we'll need to simulate many more values and average.
We'll soon explore what happens to the average as we simulate more values, but first a caution about averages of transformations.

### Averages of transformations

:::: {.callout-note appearance="simple"}
::: {#exm-dd-lra}
Donny Don't says: "In @exm-dice-sim-tactile-ev, why bother creating columns for $X^2$ and $XY$?
If I want to find the average value of $X^2$ I can just square the average value of $X$.
For the average value of $XY$ I can just multiply the average value of $X$ and the average value of $Y$."
Do you agree?
(Check to see if this works for your simulation results.)
If not, explain why not.

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-dd-lra}





It is easy to check that Donny has made a mistake just by inspecting the simulation results: `r round(mean(x), 3)`^2^ $\neq$ `r round(mean(x ^ 2), 3)`,
`r round(mean(x), 3)` $\times$ `r round(mean(y), 3)`  $\neq$ `r round(mean(x * y), 3)`.
<!-- $`r paste(round(mean(x), 3), sep = "")`^2 \neq `r paste(round(mean(x ^ 2), 3), sep = "")`$, $`r paste(round(mean(x), 3), sep = "")`\times `r paste(round(mean(y), 3), sep = "")`  \neq `r paste(round(mean(x * y), 3), sep = "")`$. -->
To see why, suppose we had just performed two repetitions, resulting in the first two rows of @tbl-dice-sim-tactile-results-ev.

$$
\text{Average of $X^2$} = \frac{3^2 + 2^2}{2} =6.5 \neq 6.25= \left(\frac{3 + 2}{2}\right)^2=(\text{Average of $X$})^2
$$

Squaring first and then averaging (which yields 6.5) is not the same as averaging first and then squaring (which yields 6.25), essentially because $(3+2)^2\neq 3^2 + 2^2$.

Similarly,
$$
{\small
\text{Average of $XY$} = \frac{(3)(2) + (2)(1)}{2} =4 \neq 3.75= \left(\frac{3 + 2}{2}\right)\left(\frac{2 + 1}{2}\right)=(\text{Average of $X$})\times (\text{Average of $Y$})
}
$$
Multiplying first and then averaging (which yields 4) is not the same as averaging first and then multiplying (which yields 3.75), essentially because $(3)(2)+(2)(1)\neq(3+2)(2+1)$.

:::
::::


We often transform random variables to obtain other random variables, e.g. $X$ to $g(X)$.
To obtain the average of the transformed variable, we cannot simply plug the average of the original variable into the transformation formula.
Instead, we need to transform the values of the variable first and then average the transformed values.
In general the order of transforming and averaging is *not* interchangeable.
Whether in the short run or the long run, in general
\begin{align*}
\text{Average of $g(X)$} & \neq g(\text{Average of $X$})\\
\text{Average of $g(X, Y)$} & \neq g(\text{Average of $X$}, \text{Average of $Y$})
\end{align*}

In terms of expected value, in general
\begin{align*}
\E(g(X)) & \neq g(\E(X))\\
\E(g(X, Y)) & \neq g(\E(X), \E(Y))
\end{align*}


::: {.callout-warning appearance="default"}
Be careful!
Many common mistakes in probability result from not heeding this general principle about averages (expected values) of transformations.
:::



### Long run averages {#sec-sim-lra}





```{r}
#| echo: false

n = 10 ^ (1:3)

last_n = 1000

r = 4

x_n = matrix(sample(2:8, size = last_n * r, replace = TRUE, prob = c(1, 2, 3, 4, 3, 2, 1) / 16), ncol = r)

x_n[1:n[1], 1] = x

xbar_n = matrix(rep(NA, last_n * r), ncol = r)


for (rs in 1:r) {
  xbar_n[, rs] = cumsum(x_n[, rs]) / (1:last_n)
}



xbar_n = xbar_n %>% as.data.frame() %>%
  mutate(i_n = row_number()) %>%
  pivot_longer(cols = !i_n,
                      names_to = "set",
                      values_to = "average") %>%
  mutate(set = str_remove(set, "V"))

i_n = 1:nrow(xbar_n)

```

We have investigated long run relative frequencies; see @sec-rel-freq and @sec-moe in particular.
Now let's see what happens to averages in the long run.
Continuing @exm-dice-sim-tactile-ev let $X$ be the sum of two rolls of a fair four-sided die.
@tbl-dice-lra-table displays the results of `r n[1]` pairs of rolls of a fair four-sided die.
The first column is the repetition number (first pair, second pair, and so on) and the second column represents $X$, the sum of the two rolls.
The third column displays the *running sum of $X$ values*, and the fourth column the *running average of $X$ values*.
@fig-dice-lra-plot displays the running average as a function of the number of repetitions.
Of course, the results depend on the particular sequence of rolls.
We encourage you to roll the dice and construct your own table and plot.

 

```{r}
#| label: tbl-dice-lra-table
#| echo: false
#| tbl-cap: "Results and running average of $X$, the sum of two rolls of a fair four-sided die."

knitr::kable(
  data.frame(i_n[1:n[1]],
             x_n[1:n[1]],
             cumsum(x_n[1:n[1]]),
             xbar_n %>% filter(set == "1") %>% filter(i_n <= n[1]) %>% select(average)),
  align = "r",
  col.names = c("Repetition", "Value of X",
                "Running sum of X",
                "Running average of X"),
  digits = 3,
  booktabs = TRUE
)

```




```{r}
#| label: fig-dice-lra-plot
#| echo: false
#| fig-cap: "Running average of $X$ for the 10 pairs of rolls in @tbl-dice-lra-table."

ggplot(xbar_n %>%
         filter(set == "1") %>%
         filter(i_n <= n[1]),
       aes(x = i_n,
           y = average,
           col = set)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 5, lty = "dotted") +
  scale_x_continuous(breaks = 1:n[1]) +
  scale_y_continuous(limits = c(2, 8)) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Repetition",
       y = "Running average of X")
  

```

Now we'll perform 90 more repetitions for a total of 100.
@fig-dice-lra-plot2-1 summarizes the results, while @fig-dice-lra-plot2-2 also displays the results for 3 additional simulations of 100 pairs of rolls.
The running average fluctuates considerably in the early stages, but settles down and tends to get closer to 5 as the number of repetitions increases.
However, each of the four simulations results in a different average of $X$ after 100 pairs of rolls: `r xbar_n %>% filter(set == "1", i_n == n[2]) %>% pull(average)` (gray), `r xbar_n %>% filter(set == "2", i_n == n[2]) %>% pull(average)` (orange), `r xbar_n %>% filter(set == "3", i_n == n[2]) %>% pull(average)` (blue), `r xbar_n %>% filter(set == "4", i_n == n[2]) %>% pull(average)` (green).
Even after 100 pairs of rolls the running average of $X$ still fluctuates from simulation to simulation.



```{r}
#| label: fig-dice-lra-plot2
#| echo: false
#| fig-cap: "Running average of $X$, the sum of two rolls of a fair four-sided die, for four simulations of 100 pairs of rolls."
#| fig-subcap: 
#|   - "A single simulation of 100 pairs of rolls"
#|   - "Four simulations, each of 100 pairs of rolls"
#| layout-ncol: 2


ggplot(xbar_n %>%
         filter(set == "1") %>%
         filter(i_n <= n[2]),
       aes(x = i_n,
           y = average,
           col = set)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 5, lty = "dotted") +
  scale_x_continuous(breaks = seq(0, n[2], 10)) +
  scale_y_continuous(limits = c(2, 8)) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Repetition",
       y = "Running average of X",
       col = "Simulation")


ggplot(xbar_n %>%
         filter(i_n <= n[2]),
       aes(x = i_n,
           y = average,
           col = set)) +
  geom_line(aes(linetype = set)) +
  geom_point(aes(shape = set)) +
  geom_hline(yintercept = 5, lty = "dotted") +
  scale_x_continuous(breaks = seq(0, n[2], 10)) +
  scale_y_continuous(limits = c(2, 8)) +
  theme_classic() +
  labs(x = "Repetition",
       y = "Running average of X")



```

Now we'll add 900 more repetitions for a total of 1000 in each simulation.
@fig-dice-lra-plot3-1 summarizes the results for our original set and @fig-dice-lra-plot3-2 also displays the results for three additional simulations.
Again, the running average of $X$ fluctuates considerably in the early stages, but settles down and tends to get closer to 5 as the number of repetitions increases.
Compared to the results after 100 repetitions, there is less variability between simulations in the running average of $X$ after 1000 repetitions: `r xbar_n %>% filter(set == "1", i_n == n[3]) %>% pull(average)` (gray), `r xbar_n %>% filter(set == "2", i_n == n[3]) %>% pull(average)` (orange), `r xbar_n %>% filter(set == "3", i_n == n[3]) %>% pull(average)` (blue), `r xbar_n %>% filter(set == "4", i_n == n[3]) %>% pull(average)` (green).
Now, even after 1000 repetitions the running average of $X$ isn't guaranteed to be exactly 5, but we see a tendency for the running average of $X$ to get closer to 5 as the number of repetitions increases.


```{r}
#| label: fig-dice-lra-plot3
#| echo: false
#| fig-cap: "Running average of $X$, the sum of two rolls of a fair four-sided die, for four simulations of 1000 pairs of rolls."
#| fig-subcap: 
#|   - "A single simulation of 1000 pairs of rolls"
#|   - "Four simulations, each of 1000 pairs of rolls"
#| layout-ncol: 2

ggplot(xbar_n %>%
         filter(set == "1"),
       aes(x = i_n,
           y = average,
           col = set)) +
  geom_line() +
  geom_hline(yintercept = 5, lty = "dotted") +
  scale_x_continuous(breaks = seq(0, n[3], 100)) +
  scale_y_continuous(limits = c(2, 8)) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Repetition",
       y = "Running average of X")

ggplot(xbar_n ,
       aes(x = i_n,
           y = average,
           col = set)) +
  geom_line(aes(linetype = set)) +
  geom_hline(yintercept = 5, lty = "dotted") +
  scale_x_continuous(breaks = seq(0, n[3], 100)) +
  scale_y_continuous(limits = c(2, 8)) +
  theme_classic() +
  labs(x = "Repetition",
       y = "Running average of X")

```

The marginal distribution of $X$, depicted in @fig-dice-sum-dist-plot22, shows that 5 is the "balance point" of the distribution.
In @exm-dice-ev-intro we saw that 5 is the probability-weighted average value of $X$, and we interpreted 5 as the value of $X$ we would "expect" to see on average in the long run.
In this sense, 5 is the "true" long run average value of $X$, and our simulation results agree.
We will discuss later "true" long run average values or "expected values" in much more detail later.
For now, we'll rely on simulation: we can approximate the long run average value of a random variable $X$ by simulating many values of $X$ and finding the average in the usual way.

Recall that a probability is a theoretical long run relative frequency.
A probability can be approximated by a relative frequency from a large number of simulated repetitions, but there is some simulation margin of error.

Likewise, the average value of $X$  after a large number of simulated repetitions is only an approximation to the theoretical long run average value of $X$, and there is margin of error due to natural variability in the simulation.
The margin of error is also on the order of $1/\sqrt{N}$ where $N$ is the number of independently simulated values used to compute the average.
However, the degree of variability of the random variable itself also influences the margin of error when approximating long run averages.
In particular, if $\sigma$ is the *standard deviation* (see @sec-sd) of the random variable, then the margin of error for the average is on the order of $\sigma / \sqrt{N}$.


Remember that the long run average value is just one feature of a marginal distribution.
There is much more to the long run pattern of variability of a random variable than just its average value.
We are also interested in percentiles, degree of variability, and quantities that measure relationships between random variables.
Two random variables can have the same long run average value but very different distributions.
For example, the [average temperature in both Phoenix, AZ and Miami, FL is around 75 degrees F](https://en.wikipedia.org/wiki/List_of_cities_by_average_temperature#North_America), but the distribution of temperatures is not the same.




### Averages in Symbulate {#sec-symbulate-mean}

Continuing @exm-dice-sim-tactile-ev let $X$ be the sum of two rolls of a fair four-sided die.
In Symbulate, we first simulate and store 10000 values of $X$.

```{python}
P = BoxModel([1, 2, 3, 4], size = 2)

X = RV(P, sum)

x = X.sim(10000)

```



We can approximate the long run average value of $X$ by computing the average---a.k.a., `mean`---of the 10000 simulated values in the usual way: sum the 10000 simulated values stored in `x` and divide by 10000. Here are a few ways of computing the mean of the simulated values.

```{python}

x.sum() / 10000

```

```{python}

x.sum() / x.count()

```


```{python}

x.mean()

```


Averages are computed the same way, regardless of whether the variable is discrete or continuous.
The following code computes the average of 5 then 10000 simulated values of $X$, a random variable with the Normal(30, 10) distribution from @sec-language-simulation-tactile-meeting-normal.


```{python}
X = RV(Normal(30, 10))

x = X.sim(5)

x

```


```{python}
x.mean()
```



```{python}
x = X.sim(10000)

x
```

```{python}
x.mean()
```

Our simulation suggests that the long run average of a random variable with a Normal(30, 10) distribution is approximately 30.
In general, one parameter of a Normal distribution represents its expected value, a.k.a., (long run) mean; the other parameter represents its standard deviation, which we will discuss soon (in @sec-sd).






### Linearity of averages

Now we'll introduce a useful properties of averages.


:::: {.callout-note appearance="simple"}
::: {#exm-dice-sim-tactile-ev-linearity}

Recall your tactile simulation from @exm-dice-sim-tactile).
Let $U_1$ be the result of the first roll, and $U_2$ the result of the second, so the sum is $X = U_1 + U_2$.


1.  Donny Don't says: "$X=U_1+U_2$, so I can find the average value of $X$ by finding the average value of $U_1$, the average value of $U_2$, and adding the two averages".  Do you agree? Explain.
1.  Donny Don't says: "$U_1$ and $U_2$ have the same distribution, so they have the same average value, so I can find the average value of $X$ by multiplying the average value of $U_1$ by 2". Do you agree? Explain.
1.  Donny Don't says: "$U_1$ and $U_2$ have the same distribution, so $X=U_1+U_2$ has the same distribution as $2U_1 = U_1 + U_1$". Do you agree?  Explain.

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-dice-sim-tactile-ev-linearity}




1.  Donny is correct! Our simulation results are in @tbl-dice-sim-tactile-results-ev.
The average value of $U_1$ is
$$
\frac{`r paste(u1, collapse=" + ")`}{10} = `r round(mean(u1), 3)`
$$
The average value of $U_2$ is
$$
\frac{`r paste(u2, collapse=" + ")`}{10} = `r round(mean(u2), 3)`
$$
The sum of these two values is equal to the average value of $X$.
To see why, suppose we had just performed two repetitions, resulting in the *last* two rows of @tbl-dice-sim-tactile-results-ev).
$$
{\scriptsize
\text{Average of $(U_1+U_2)$} = \frac{(1 + 2) + (3 + 4)}{2} = 5 = 2 + 3= \left(\frac{1 + 3}{2}\right)+\left(\frac{2 + 4}{2}\right) = (\text{Average of $U_1$}) + (\text{Average of $U_1$}) 
}
$$
We discuss further below.
1.  Donny is correct that $U_1$ and $U_2$ have the same distribution, and he has some good ideas about averages.
But we should remind Donny that a distribution represents the *long run* pattern of variability.
With only 10 repetitions, the results for $U_1$ will not necessarily follow the same pattern as those for $U_2$.
In our simulation, the average value of $U_1$ is `r mean(u1)` and the average value of $U_2$ is `r mean(u2)`.
Multiplying neither one of these numbers by 2 yields the average value of $X$.
    Donny would have been correct if he were talking about *long run* average values. Since $U_1$ and $U_2$ have the same distribution, the long run average value of $U_1$ is equal to the long run average value of $U_2$, and so the long run average value of $X$ is equal to the long run average value of $U_1$ multiplied by two.
1.  Donny is not correct.  In particular, $X$ and $2U_1$ do not have the same possible values; for example, $X$ can be 3 but $2U_1$ cannot.
The long run average value is just one feature of a distribution.
Just because $X$ and $2U_1$ have the same long run average value does not necessarily mean they have the same full long run pattern of variability.
In particular, relationships between random variables will affect distributions of transformations of them.
$U_1$ and $U_2$ have the same marginal distribution, but the joint distribution of $(U_1, U_2)$ is not the same as that of $(U_1, U_1)$, and so the distribution of $U_1+U_2$ is not the same as that of $U_1+U_1$.

:::
::::

In general the order of transforming and averaging is not interchangeable.
However, the order is interchangeable for *linear* transformations.

::: {#thm-linearity-average}
### Linearity of averages

If $X$ and $Y$ are random variables and $m$ and $b$ are non-random constants,
whether in the short run or the long run,

\begin{align*}
\text{Average of $(mX+b)$} & = m(\text{Average of $X$})+b\\
\text{Average of $(X+Y)$} & = \text{Average of $X$} +\text{Average of $Y$}
\end{align*}

:::

The following just restates in terms of long run averages (expected values)

::: {#thm-linearity-ev}
### Linearity of expected value

If $X$ and $Y$ are random variables and $m$ and $b$ are non-random constants,

\begin{align*}
\E(mX+b) & = m\E(X)+b\\
\E(X+Y) & = \E(X) + \E(Y)
\end{align*}

:::


For example, if $X$ measures temperature in degrees Celsius with average 24&deg;C, then $1.8X+32$ measures temperature in degrees Fahrenheit with average 75.2&deg;F.

Averaging involves adding and dividing.
Linear transformations involve only adding/subtracting and multiplying/dividing.
The ability to interchange the order of averaging and *linear* transformations follows simply from basic properties of arithmetic (commutative, associative, distributive).

Note that the average of the sum of $X$ and $Y$ is the sum of the average of $X$ and the average of $Y$ *regardless of the relationship between $X$ and $Y$.*
We will explore this idea in more detail later.



### Averages of indicator random variables

Recall that indicators are the bridge between events and random variables.
Indicators are also the bridge between relative frequencies and averages.

:::: {.callout-note appearance="simple"}
::: {#exm-dice-sim-tactile-ev-indicator}

Recall your tactile simulation from @exm-dice-sim-tactile.
Let $A$ be the event that the first roll is 3 and $\ind_A$ the corresponding indicator random variable.
Based only on the results of your simulation, approximate the long run average value of each of $\ind_A$.
What do you notice?

:::
::::

:::: {.callout-tip collapse=true}
::: {#sol-dice-sim-tactile-ev-indicator}


```{r}
#| echo: false

indA = as.numeric(u1 == 3)

```



Our simulation results are in @tbl-dice-sim-tactile-results-ev).
Approximate the long run average value of $\ind_A$ by summing the 10 simulated values of $\ind_A$ and dividing by 10.
$$
\frac{`r paste(indA, collapse=" + ")`}{10} = \frac{`r sum(indA)`}{10}
$$
The average of $\ind_A$ is the relative frequency of event $A$!
When we sum the 1/0 values of $\ind_A$ we count the repetitions on which $A$ occurs.
That is, the numerator in the average calculation for $\ind_A$ is the frequency of event $A$, and dividing by the number of repetitions yields the relative frequency of event $A$. 

:::
::::

If $\ind_A$ is the indicator random variable of an event $A$, whether in the short run or the long run,
$$
\text{Average of $\ind_A$} = \text{Relative frequency of $A$}
$$
In terms of our long run notation, the above long run result is
$$
\E(\ind_A) = \IP(A)
$$

Indicators provide a bridge between events and random variables, and between probability and expected value.

### Exercises

::: {#exr-simulation-ev-class-size}

Suppose that a total of 350 students at a college are taking a particular statistics course.
The college offers five sections of the course, each taught by a different instructor.
The class sizes are shown in the following table.

|                    |     |     |     |     |     |
|:-------------------|----:|----:|----:|----:|----:|
| Section            |   A |   B |   C |   D |   E |
| Number of students |  35 |  35 |  35 |  35 | 210 |

We are interested in: What is the average class size?

1.  Suppose we randomly select one of the 5 *instructors*. 
Let $X$ be the class size for the selected instructor. Specify the distribution of $X$. 
(A table is fine.)
1.  Compute and interpret $\text{E}(X)$.
1.  Compute and interpret $\text{P}(X = \text{E}(X))$.
1.  Suppose we randomly select one of the 350 *students*. 
Let $Y$ be the class size for the selected student. Specify the distribution of $Y$. 
(A table is fine.)
1.  Compute and interpret $\text{E}(Y)$.
1.  Compute and interpret $\text{P}(Y = \text{E}(Y))$.
1.  Comment on how these two expected values compare, and explain why they differ as they do. 
Which average would you say is more relevant?

:::


::: {#exr-simulation-ev-collector}
The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3).
Each package contains a single unknown prize.
Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3).
For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.
Let $X$ be the number of distinct prizes obtained in these 3 packages.
Let $Y$ be the number of these 3 packages that contain prize 1.

1.  Explain how you could, in principle, conduct a simulation by hand and use the results to approximate
    a.  $\E(X)$
    a.  $\E(Y)$
    a.  $\E(X^2)$
    a.  $\E(XY)$
1.  Write Symbulate code to conduct a simulation and approximate the values in part 1.
:::


::: {#exr-simulation-ev-continuous-dice}
Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4).
Let $X$ be the sum of the two spins and let $Y$ be the larger of the two spins.


1.  Describe in words how you could use simulation to approximate
    a.  $\E(X)$
    a.  $\E(Y)$
    a.  $\E(X^2)$
    a.  $\E(XY)$
1.  Write Symbulate code to conduct a simulation to approximate the quantities in part 1.
:::






## Measuring variability: Variance and standard deviation {#sec-sd}


The long run average value is just one feature of a distribution.
Random variables vary, and the distribution describes the entire pattern of variability.
It is also convenient to measure the overall degree of variability in a single number.
Some values of a variable are close to its mean and some are far, so to measure variability in a single number we might ask: how far are the values away from the mean on average?
Variance and standard deviation are numbers that address this question.



Consider again a random variable $X$ that follows a Normal(30, 10) distribution; we'll assume $X$ is measured in minutes (after noon) as in the meeting problem.
Any Normal distribution has two parameters, the mean and the standard deviation; the Normal(30, 10) distribution has mean 30 (minutes) and standard deviation 10 (minutes).
In @sec-symbulate-mean we saw simulation evidence supporting that the mean is 30.
Now we'll investigate the standard deviation, which measures, roughly, the average distance from the mean.


We'll motivate the calculation of standard deviation using using just the 10 simulated values in @tbl-meeting-tactile-normal-sim-table, reproduced in @tbl-sim-sd-calc.
For now focus on only the first three columns of @tbl-sim-sd-calc.
We see how far a value is away from the mean by subtracting the mean, resulting in a "deviation".
Deviations are positive for values that are above the mean and negative for values that are below the mean.
For example, the value `r round(x_normal_10[1], 3)` is `r abs(round(x_normal_10[1] - mean(x_normal_10), 3))` minutes `r if_else(x_normal_10[1] - mean(x_normal_10) > 0, "above", "below")` the mean.





```{r}
#| label: tbl-sim-sd-calc
#| echo: false
#| tbl-cap: "Calculation of standard deviation based on 10 simulated values"

sd_calc_df = data.frame(repetition = factor(1:length(x_normal_10)),
           x = x_normal_10) |>
  mutate(
    deviation = x - mean(x),
    absolute_deviation = abs(deviation),
    squared_deviation = deviation ^ 2
)

total_row = 
sd_calc_df |>
      summarise(across(-1, sum)) |>
  add_column(repetition = c("Sum"), .before = 1)

average_row = 
sd_calc_df |>
      summarise(across(-1, mean)) |>
  add_column(repetition = c("Average"), .before = 1)

sd_calc_df |>
  bind_rows(total_row, average_row) |>
  kbl(digits = 3) |>
  kable_styling()
```


We might try to compute the average deviation from the mean, but this will always be 0.
The mean is the balance point---that is, the center of gravity---so the (positive) deviations above the mean will always balance out, in total, with the (negative) deviations below the mean.
However, regarding degree of variability, we only care about how far values are away from the mean, not if they're above or below.
So we take the absolute value of each deviation and then find the average.
See the fourth column of @tbl-sim-sd-calc, resulting in an average absolute deviation of `r round(mean(abs(x_normal_10 - mean(x_normal_10))), 3)` minutes.

@tbl-sim-sd-calc motivates the calculation, but we're really interested in what happens in the long run, so let's carry out the calculation for many simulated values.

```{python}
X = RV(Normal(30, 10))

x = X.sim(10000)

x
```

The mean is about 30.

```{python}
x.mean()
```

Now we compute the absolute deviations from the mean.

```{python}

abs(x - x.mean())

```

Then we average the absolute deviations.

```{python}

abs(x - x.mean()).mean()

```


Unfortunately, the above calculation yields roughly 8 rather than the standard deviation of 10.
It turns out that for a Normal(30, 10) distribution the long run average *absolute* deviation from the mean is about 8.
We can conceptualize standard deviation as average distance from the mean, but the actual calculation of standard deviation is a little more complicated.
Technically, we must first *square* all the distances and  then average; the result is the *variance*.
Then the square root of the variance is the *standard deviation*^[It can be shown that the standard deviation is always at least as big as the average absolute deviation. For a Normal distribution, the average absolute deviation is about 0.8 times the standard deviation.].

\begin{align*}
\text{Variance of } X & = \text{Average of } [(X - \text{Average of } X)^2]\\
\text{Standard deviation of } X & = \sqrt{\text{Variance of } X}
\end{align*}

Returning to the 10 simulated values in @tbl-sim-sd-calc, the fifth column contains the squared deviations.
Notice that squaring the deviations has a similar effect to taking the absolute value: a value that is 3 units above the mean has the same squared deviation as a value that is 3 units below the mean (since $3^2 = (-3)^2$).
Now we average the squared deviations to obtain the variance.
The average is computed in the usual way: sum all the values and divide by the number of values^[If you have some familiarity with statistics, you might have seen a formula for variance or standard deviation that includes dividing by *one less* than the number values ($n-1$). Dividing by $n$ or $n-1$ could make a difference in a small sample of data.  However, we will always be interested in *long run* averages, and it typically won't make any practical difference whether we divide by say 10000 or 9999. We'll always compute averages by dividing by the number of values that we're summing.].
But now each value included in the average is the squared deviation of $X$ from the mean, rather than the value of $X$ itself.
The variance of the 10 simulated values is `r round(mean((x_normal_10 - mean(x_normal_10))^2), 3)`.
This probably seems like a weird number, and it is: because we squared all the deviations before averaging, the measurement units of the variance are *minutes^2^*.
To get back to the original measurement units, we take the square root of the variance, $\sqrt{`r round(mean((x_normal_10 - mean(x_normal_10))^2), 3)`}$, resulting in the *standard deviation* of `r round(sqrt(mean((x_normal_10 - mean(x_normal_10))^2)), 3)` minutes.



Now back to the long run, using 10000 simulated values `x`.
The following code shows the "long way" of computing variance and standard deviation.
First, find the squared distance between each simulated value and the mean.

```{python}

(x - x.mean()) ** 2 

```

Then compute the average squared deviation to get the variance.

```{python}

((x - x.mean()) ** 2).mean()

```

Now take the square root of the variance to get the standard deviation.

```{python}

sqrt(((x - x.mean()) ** 2).mean())

```


We see that the standard deviation is about 10---as it should be for values simulated from a Normal(30, 10) distribution---and the variance is about $10^2 = 100$.
Fortunately, `var` and `sd` will carry out these calculations more quickly.

```{python}
x.var()
```

```{python}
x.sd()
```



:::: {.callout-note appearance="simple"}
::: {#exm-normal-uniform-sd-compare}
We'll compare long run average and standard deviation for the Uniform(0, 60) distribution and the Normal(30, 10) distribution.


1.  Make an educated guess for the long run average value of a Uniform(0, 60) distribution.
1.  Will the standard deviation for a Uniform(0, 60) distribution be greater than, less than, or equal to 10, the standard deviation for a Normal(30, 10) distribution?
Explain without doing any calculations.
(Hint: It might help to compare the spinners in @sec-language-simulation-tactile-meeting or the simulations from @sec-meeting-sim.)
1.  Make an educated guess for the standard deviation of a Uniform(0, 60) distribution.

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-normal-uniform-sd-compare}




1.  It seems reasonable that the long run average value of a Uniform(0, 60) distribution is 30, the balance point of the distribution.
1.  While the Uniform(0, 60) and Normal(30, 10) distributions have the same mean of 30, the Uniform(0, 60) has a larger standard deviation than the Normal(30, 10) distribution.
In comparison to a Normal(30, 10) distribution, a Uniform(0, 60) distribution will give higher probability to ranges of values near the extremes of 0 and 60, as well as lower probability to ranges of values near 30.
Thus, there will be more values far from the mean of 30 and fewer values close, and so the average distance from the mean and hence standard deviation will be larger for the Uniform(0, 60) distribution than for the Normal(30, 10) distribution.
See @fig-normal-uniform-hist which compares histograms of simulated values from the two distributions.
1.  In a Uniform(0, 60) distribution, values are "evenly spread" from 0 to 60, so distances from the mean are "evenly spread" from 0 (for 30) to 30 (for 0 and 60).
We might expect the standard deviation---roughly the average distance from the mean---to be about 15, halfway between 0 and 30.
It turns out that the standard deviation is about 17; 15 is the average absolute deviation from the mean.
While the "average distance" interpretation helps our conceptual understanding of standard deviation, the process of squaring the distances, then averaging, and then taking the square root makes guessing the actual value of standard deviation difficult.


:::
::::


```{python}
#| label: fig-normal-uniform-hist
#| fig-cap: "Histograms of many simulated values from each of the Normal(30, 10) and Uniform(0, 60) distributions."

U = RV(Uniform(0, 60))

u = U.sim(10000)

plt.figure()

x.plot()
u.plot()

plt.legend(['Normal(30, 10)', 'Uniform(0, 60)']);
plt.show()

```


```{python}
u.sd()
```

```{python}
abs(u - u.mean()).mean()
```



:::: {.callout-note appearance="simple"}
::: {#exm-sd-matching}

The plots below summarize hypothetical distributions of quiz scores in six classes.
Each quiz score is a whole number between 0 and 10 inclusive.
All plots are on the same scale with quiz scores on the horizontal axis, and probability on the vertical axis.


1.  Donny Dont says that of these six plots, C represents the smallest SD, since there is "no variability in the heights of the bars".
Do you agree that C represents "no variability"?
Explain.
1.  What is the smallest *possible* value the SD of quiz scores could be?
What would need to be true about the distribution for this to happen?
(This scenario might not be represented by one of these six plots.)
1.  Without doing any calculations, identify which of these six classes exhibits the smallest standard deviation of quiz scores. 
1.  Without doing any calculations, arrange the classes in order based on their standard deviations from smallest to largest.  
1.  In one of the classes, the standard deviation of quiz scores is 5.
Which one?
Why?
1.  Is the standard deviation in F greater than, less than, or equal to 1?
Why?
1.  Provide a ballpark estimate of standard deviation in each case.

:::
::::



```{r}
#| label: fig-sd-matching-plot
#| echo: false
#| layout-ncol: 3

x1 = 0:10
p1 = c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1)
p1 = p1/sum(p1)

x2 = 0:10
p2 = c(6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6)
p2 = p2/sum(p2)

x3 = 0:10
p3 = rep(1/11, 11)

x4 = c(0, 10)
p4 = c(0.5, 0.5)

x5 = 3:7
p5 = c(1, 2, 3, 2, 1)
p5 = p5/sum(p5)

x6 = c(6, 7, 8)
p6 = c(0.1, 0.8, 0.1)

xlimits = c(0, 10)
xs = 0:10

plot(x1, p1, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="A", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x2, p2, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="B", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x3, p3, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="C", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x4, p4, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="D", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x5, p5, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="E", type="h", lwd=2, xaxt="n")
axis(1, xs)
plot(x6, p6, xlim=xlimits, ylim=c(0,1), xlab="", ylab="Probability", main="F", type="h", lwd=2, xaxt="n")
axis(1, xs)

# sqrt(sum(x1^2*p1)-sum(x1*p1)^2)
# sqrt(sum(x2^2*p2)-sum(x2*p2)^2)
# sqrt(sum(x3^2*p3)-sum(x3*p3)^2)
# sqrt(sum(x4^2*p4)-sum(x4*p4)^2)
# sqrt(sum(x5^2*p5)-sum(x5*p5)^2)
# sqrt(sum(x6^2*p6)-sum(x6*p6)^2)

```


:::: {.callout-tip collapse=true}
::: {#sol-sd-matching}



1.  We disagree with Donny.
Standard deviation measures variability of the *values of the variable*, not their probabilities.
If we were to simulate values according to the distribution in C, we would observe some 0s, some 1s, some 2s, all the way through some 10s (with roughly equal frequency).
So there would certainly be variability in the values of the variable.
Remember that values of the variable are along the horizontal axis, so standard deviation measures average distance from the mean horizontally.
1.  The smallest possible value of standard deviation is 0, which occurs only if the random variable is a constant (with probability 1).
In this context, if every student had the same quiz score, e.g., if 100% of students scored an 8, then the standard deviation would be 0.
The distribution plot would have a single spike at a single value.
1.  Remember that values of the variable are along the horizontal axis, so standard deviation measures average distance from the mean horizontally.
The distribution in F represents the smallest standard deviation.
The mean is 7, most of the scores are 7, and some of the scores are only 1 unit away from the mean.
In all other situations, the probability that the random variable is equal to its mean is smaller, and the probability that the random variables takes a value more than 1 unit away from its mean is larger than in F.
1.  In all plots other than F the mean is 5, so the smallest standard deviation occurs where the values tend to be close to 5, and the largest occurs where the values tend to be far from 5.  In order from smallest to largest standard deviation: F, E, A, C, B, D.
1.  In D, the score takes values 0  and 10 with probability 0.5.
The mean is 5, and all deviations are 5 units away from the mean, so the average squared deviation will be $5^2$ and the standard deviation will be 5.
1.  Less than 1.
Don't forget that there is a high probability of a deviation of 0 in this case.
So the average deviation will be somewhere between 0 and 1.
1.  Some of these are harder than others.
In E, many values are 0 units away from mean, many values are 1 unit away, and some values are 2.
So the standard deviation in E is maybe around 1.
In C, there are values that are 0 units away, and about as many values that are each 1, 2, 3, 4, and 5 units away; we might expect standard deviation to be around 2.5.
But remember, while considering the average absolute deviation helps intuition, standard deviation is actually the square root of the average squared deviation so the exact value can be difficult to ascertain without computation.
The actual values are: 	F = 0.45, E = 1.15, A = 2.4, C = 3.1, B = 3.7, D = 5.

:::
::::

Variance and standard deviation are both based on average squared deviations from the mean.
Variance has some nice mathematical properties (which we'll see later), but standard deviation is the more "practical" number since it has the same measurement units as the variable.
In computations we often work with variances then take the square root at the end to report and interpret standard deviations.

Standard deviation is the most commonly used single-number measure of variability, but it's not the only one.
Average absolute deviation also measures variability; why not use that?
It turns out that squaring deviations, rather than taking absolute values, leads to nicer mathematical properties^[Think Pythagorean theorem: it's $a^2+b^2=c^2$. On the other hand, for absolute values we only have the triangle inequality $|a+b| \le |a| + |b|$.].
Also, standard deviation is the natural measure of variability for Normal distributions (we'll investigate why later).
While standard deviation is commonly used, there are other, sometimes better, ways to summarize variability.
For example, we will see later how percentiles can be used to summarize the pattern of variability. 


The following definiton states our notion of variance in expected value terms.

::: {#def-variance}
### Variance and standard deviation of a random varible

The **variance** of a random variable $X$ is 
$$
\Var(X) = \E((X-\E(X))^2)
$$
The **standard deviation** of a random variable $X$ is $\SD(X) = \sqrt{\Var(X)}$.
:::

Recall that an expected value is a long run average.
Thefore we can interpret $\E(\cdot)$ as "simulate many values of what's inside $(\cdot)$ and average".
In this way
$$
\E((X-\E(X))^2) = \text{Long Run Average of } [(X - \text{Long Run Average of } X)^2]
$$

Recall that for discrete random variables we can compute expected values as probability-weighted average values.
We can compute variances for discrete random variables in a similar way.



:::: {.callout-note appearance="simple"}
::: {#exm-sd-compute-dice}
In the dice rolling problem, let $Y$ be the larger of the two rolls.
The marginal distribution of $Y$ is represented by @tbl-dice-max-dist-table.
In @exm-dice-ev-intro we computed $\E(Y) = 3.125$.

1.  Compute $\Var(Y)$.
1.  Compute $\SD(Y)$.
1.  Describe in detail how $\Var(Y)$ can be simulated via approximation
1.  Write Symbulate code to approximate $\Var(Y)$ and $\SD(Y)$ and compare to the values from parts 1 and 2.
:::
::::

:::: {.callout-tip collapse=true}
::: {#sol-sd-compute-dice}

1.  $Y$ takes values 1, 2, 3, 4, and $\E(Y)=3.125$, so $(Y-\E(Y))^2$ takes values $(1-3.125)^2$, $(2-3.125)^2$, $(3-3.125)^2$, $(4-3.125)^2$, with respective probability 1/16, 3/16, 5/16, 7/16.
To compute $\E((Y-\E(Y))^2)$ as a probability-weighted average value, multiply each possible of $(Y-\E(Y))^2$ by its probability and sum.
$$
(1-3.125)^2\times 0.0625 + (2-3.125)^2 \times 0.1875 + (3-3.125)^2 \times 0.3125 + (4-3.125)^2 \times 0.4375  = 0.8594
$$
See @tbl-sd-compute-dice for more detail.
$\Var(Y) = 0.8594$.
1.  $\SD(Y)=\sqrt{\Var(Y)} = \sqrt{0.8594} = 0.9270$.
1.  We have already discussed how to simulate a value of $Y$ in this content.
To approximate the variance
    -   Simulate many values of $Y$
    -   Compute the average of the simulated values of $Y$ (to approximate $\E(Y)$)
    -   From each simulated value of $Y$ subtract the average, and then square
    -   Compute the average of the squared deviations from the previous part to approximate the variance
1.  See below for the code, both the long way and using the `var` and `sd` shortcuts.
The simulation-based approximations are close to the values from parts 1 and 2.

:::
::::


```{r}
#| label: tbl-sd-compute-dice
#| echo: false
#| tbl-cap: "Steps in computing the variance of $Y$ in @exm-sd-compute-dice."


y = 1:4
p = c(1, 3, 5, 7) / 16

ev = sum(y * p)

knitr::kable(
  data.frame(y, y - ev, (y - ev)^2, p, (y - ev)^2 * p),
  col.names = c("$y$", "$y - \\E(Y)$", "$(y - \\E(Y))^2$", "$\\IP(Y=y)$", "$(y - \\E(Y))^2\\IP(Y=y)$"),
  booktabs = TRUE,
  digits = 4
)

```  

```{python}
P = BoxModel([1, 2, 3, 4], size = 2)

Y = RV(P, max)

y = Y.sim(10000)

y
```

```{python}
y.mean()
```


```{python}
y - y.mean()
```

```{python}
(y - y.mean()) ** 2
```


```{python}
((y - y.mean()) ** 2).mean()
```


```{python}
y.var()
```

```{python}
y.sd()
```


:::: {.callout-note appearance="simple"}
::: {#exm-sd-compute-dice2}
Continuing @exm-sd-compute-dice.

1.  Compute $\E(Y^2)$.
1.  Describe in detail how $\E(Y^2)$ can be approximated via simulation.
1.  Compute $\E(Y^2) - (\E(Y))^2$.
What do you notice?
:::
::::

:::: {.callout-tip collapse=true}
::: {#sol-sd-compute-dice2}

1.  $Y$ takes values 1, 2, 3, 4, so $Y^2$ takes values $1^2, 2^2, 3^2, 4^2$, with respective probability 1/16, 3/16, 5/16, 7/16.
To compute $\E(Y^2)$ as a probability-weighted average value, multiply each possible of $Y^2$ by its probability and sum.
$$
1^2\times 0.0625 + 2^2 \times 0.1875 + 3^2 \times 0.3125 + 4^2 \times 0.4375  = 10.625
$$
$\E(Y^2) = 10.625$.
Notice this is *not* the same as $\E(Y)^2=3.125^2.$
1.  We have already discussed how to simulate a value of $Y$ in this content.
To approximate $\E(Y^2)$
    -   Simulate many values of $Y$
    -   Square each simulated value of $Y$
    -   Compute the average of the squared values from from the previous part to approximate $\E(Y^2)$.
See the Symbulate code below.
1.  $\E(Y^2) - (\E(Y))^2 = 10.625 - 3.125^2 = 0.8594$, which is $\Var(Y)$.

:::
::::

```{python}
(y ** 2)
```


```{python}
(y ** 2).mean()
```


```{python}
(y ** 2).mean() - (y.mean()) ** 2
```

@exm-sd-compute-dice2 illustrates an alternative formula for computing variance.
@def-variance represents the concept of variance.
However, variance is usually computed using the following equivalent but slightly simpler formula.

::: {#lem-variance-shortcut}
$$
\Var(X) = \E(X^2) - (\E(X))^2
$$
:::


That is, the variance of $X$ is the expected value of the square of $X$ minus the square of the expected value of $X$.
 

We will see that variance has many nice theoretical properties. 
Whenever you need to compute a standard deviation, first find the variance and then take the square root at the end.

We will see how to compute variance for continuous random variables later.
But @def-variance and @lem-variance-shortcut apply for both discrete and continuous random variables.
Furthermore, variance can be approximated via simulation in the same way for discrete or continuous random variables: simulate many values of the random variable and compute the average of the squared deviations from the mean.



### Standardization

Standard deviation provides a "ruler" by which we can judge a particular value of a random variable relative to the distribution of values.
This idea is particularly useful when comparing random variables with different measurement units but whose distributions have similar shapes.


:::: {.callout-note appearance="simple"}
::: {#exm-sat-z-score}
SAT scores have, approximately, a Normal distribution with a mean of 1050 and a standard deviation of 200.
ACT scores have, approximately, a Normal distribution with a mean of 21 and a standard deviation of 5.5.
Darius's score on the SAT is 1500.  Alfred's score on the ACT is 31.
We'll investigate who scored relatively better on their test.


1.  Compute the deviation from the mean for Darius's SAT score.
How large is this value relative to the standard deviation for SAT scores (which measures, roughly, the average deviation from the mean)?
1.  Compute the deviation from the mean for Alfred's ACT score.
How large is this value relative to the standard deviation for ACT scores?
1.  Who scored relatively better on their test?
Explain.

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-sat-z-score}



1.  Darius's score is $1500-1050 = 450$ points above the mean SAT score.
The standard deviation of SAT scores is 200 points.
Roughly, the deviation of Darius's score from the mean is $450/200 = 2.25$ times larger the average deviation.  
That is, Darius's SAT score of 1500 is *2.25 standard deviations* above the mean SAT score.
1.  Alfred's score is $31-21 = 10$ points above the mean ACT score.
The standard deviation of ACT scores is 5.5 points.
Roughly, the deviation of Alfred's score from the mean is $10/5.5 = 1.82$ times larger than the average deviation.
That is, Alfred's ACT score of 31 is *1.82 standard deviations* above the mean ACT score.
1.  Both scores are above average, but relative to other test scores, Darius's is farther above average than Alfred's.
Both distributions are Normal, so the probability that an SAT score is greater than Darius's is smaller than the probability that an ACT score is greater than Alfred's.
That is, Darius scored relatively better.
See @fig-sat-z-score-plot.

:::
::::




```{r}
#| label: fig-sat-z-score-plot
#| echo: false
#| fig-cap: "Comparison of the Normal distributions in @exm-sat-z-score."

p1 = plot_standardized_normal(mu = 1050, sigma = 200, value = 1450, variable_name = "SAT score")

p2 = plot_standardized_normal(mu = 21, sigma = 5.5, value = 30, variable_name = "ACT score", shade_color = "orange")

p1 / p2

```


Standard deviation provides a "ruler" by which we can judge a particular value of a random variable relative to the distribution of values.
Consider the plot for SAT scores in @fig-sat-z-score-plot.
For now, pay attention to the two horizontal axis scales on each plot; we'll discuss the Normal "bell shape" in more detail later.
There are two scales on the variable axis: one representing the actual measurement units, and one representing "standardized units".
In the standardized scale, values are measured in terms of standard deviations away from the mean:

-   The mean corresponds to a value of 0.
-   A one unit increment on the standardized scale corresponds to an increment equal to the standard deviation in the measurement unit scale.

For example, each one unit increment in the standardized scale corresponds to a 200 point increment in the measurement unit scale for SAT scores, and a 5.5 point increment in the measurement unit scale for ACT scores.
An SAT score of 1250 is "1 standard deviation above the mean"; an ACT score of 10 is "2 standard deviations below the mean".
Given a specific distribution, the more standard deviations a particular value is away from its mean, the more extreme or "unusual" it is.

Given a value of a variable, its **standardized value** marks where the value lies on the standardized scale (e.g., 1500 on the SAT scale corresponds to 2.25 on the standardized scale).

$$
\text{Standardized value} = \frac{\text{Value - Mean}}{\text{Standard deviation}}
$$


::: {.callout-warning appearance="default"}
Standardization is useful when comparing random variables with different measurement units but whose distributions have similar shapes (like the two Normal distributions in @fig-sat-z-score-plot).
However, standardized values are only based on two features of a distribution---mean and standard deviation---rather than the complete pattern of variability.
Distributions with different shapes have different patterns of variability.
We will see later than when comparing distributions with different shapes, it is better to compare percentiles rather than standardized values to determine what is "extreme" or "unusual".
:::

Any random variable can be standardized, but keep in mind that just how extreme any particular standardized value is depends on the shape of the distribution.
We will see that standardization is most natural for random variables that follow a Normal distribution.

### Normal distributions (briefly)

Standardization is most natural for random variables that follow a Normal distribution.
The Normal(30, 10) model that we assumed for arrival times in the meeting problem is an example of a *Normal distribution*.
The pattern of variability for any Normal distribution follows a particular bell shape, like in @fig-sat-z-score-plot.
A Normal distribution has two parameters: its mean (typically denoted $\mu$) and its standard deviation (typically denoted $\sigma$).
For Normal distributions the probability that a value is within (or beyond) a given number of standard deviations from the mean follows a specific pattern called the "empirical rule".
For example, the empirical rule for Normal distributions specifies that

-   68% of values are within 1 standard deviation of the mean
-   95% of values are within 2 standard deviations of the mean
-   99.7% of values are within 3 standard deviations of the mean

```{r}
#| echo: false
#| label: fig-normal-empirical-rule
#| fig-cap: Illustration of the empirical rule for Normal distributions

knitr::include_graphics(c("_graphics/normal_empirical.png"))

```

Therefore the key to working with Normal distributions is to work in terms of standardized values.
The "standard" Normal distribution is a Normal(0, 1) distribution, with a mean 0 and a standard deviation of 1.
Notice how the empirical rule corresponds to the spinner in @fig-standard-normal-spinner.


```{r}
#| label: fig-standard-normal-spinner
#| echo: false
#| fig-cap: "A standard *Normal(0, 1)* spinner. Only selected rounded values are displayed, but in the idealized model the spinner is infinitely precise so that any real number is a possible outcome. Notice that the values on the axis are *not* evenly spaced."


x = c("","<-2",-1, 0, 1, ">2")
p = c(pnorm(-2), pnorm(-1:2) - pnorm(-2:1), 1-pnorm(2))

xp <- data.frame(x, p)

cdf = c(0, cumsum(xp$p))



plotp = (cdf[-1] + cdf[-length(cdf)]) / 2
  
spinner2 <- ggplot(xp, aes(x="", y=p, fill=x))+
  geom_bar(width = 1, stat = "identity", color="black", fill="white", linetype=1) + 
  # coord_polar("y", start=0) +
  coord_curvedpolar("y", start = 0) +
  theme_void() +
  # plot the possible values on the outside
  scale_y_continuous(breaks = cdf[-c(1, length(cdf))], labels=c(-2, -1, 0, 1, 2)) +
  # theme(axis.text.x=element_text(angle=c(90-180/50*(0:49), -90-180/50*(50:99)), size=8)) +
  theme(axis.text.x=element_text(angle = 0, size=12)) +
  # annotate(geom="segment", y=(0:19)/20+0.000, yend = (0:19)/20+0.000,
  #          x=1.48, xend= 1.52) +
  # plot the probabilities as percents inside
    geom_text(aes(y = plotp,
                label = percent(p, accuracy = 0.1)), size=4, color=c(NA, rep("black",4), rep(NA, 1)))

spinner2
```

If a random variable follows a Normal distribution, a value of it can be simulated by spinning the standard Normal spinner in @fig-standard-normal-spinner to determine how many standard deviations the value is away from the mean (above or below) and then converting to the measurement units of the variable.

We have only introduced a small part of the empirical rule in this section, corresponding to 1, 2, or 3 standard deviations away from the mean.
We will cover Normal distributions and the empirical rule in much more detail later.


### Exercises



::: {#exr-simulation-variance-collector}
The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3).
Each package contains a single unknown prize.
Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3).
For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.
Let $X$ be the number of distinct prizes obtained in these 3 packages.
Let $Y$ be the number of these 3 packages that contain prize 1.

1.  Explain how you could, in principle, conduct a simulation by hand and use the results to approximate
    a.  $\Var(X)$
    a.  $\SD(X)$
1.  Write Symbulate code to conduct a simulation and approximate the values in part 1.
1.  Compute the theoretical values of $\Var(X)$ and $\SD(X)$ and compare to the simulation results.
:::



::: {#exr-simulation-variance-continuous-dice}
Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4).
Let $X$ be the sum of the two spins and let $Y$ be the larger of the two spins.


1.  Use simulation to approximate the marginal distributions of $X$ and $Y$.
1.  Which will have the larger standard deviation, $X$ or $Y$?
Make a ballpark estimate the of the standard deviation of each.
1.  Describe in words how you could use simulation to approximate
    a.  $\Var(X)$ and $\SD(X)$
    a.  $\E(Y)$ and $\SD(Y)$
1.  Write Symbulate code to conduct a simulation to approximate the quantities in the previous part.
:::




## Measuring relationships: Covariance and correlation {#sec-sim-corr}

TBA



### Exercises


::: {#exr-simulation-covariance-collector}
TBA
:::

::: {#exr-simulation-covariance-1}
TBA
:::

## Conditioning {#sec-simulation-conditioning}


We can implement conditioning in simulations by only considering repetitions that satisfy the condition.
Conditioning can be thought of as taking a subset of, or "filtering", the simulation results.

### Using simulation to approximate conditional probabilities {#sec-simulation-conditioning-probabilities}

Conditional probabilities can be approximated using simulated relative frequencies in a similar way to unconditional probabilities, but the presence of conditioning requires more care.





:::: {.callout-note appearance="simple"}
::: {#exm-impeach-sim}
Recall @exm-conditional-probability-def.
Consider simulating a randomly selected U.S. adult and determining whether or not the person is age 18-29 and whether or not they use Snapchat.
Let $A$ be the event that the selected adult is age 18-29, $C$ be the event that the selected adult uses Snapchat, and $\IP$ correspond to randomly selecting an American adult.
Suppose that $\IP(A) = 0.20$, $\IP(C) = 0.24$, and $\IP(A\cap C) = 0.13$.


1.  Donny Don't says, "we need two spinners to simulate this situation: One spinner with areas of 0.20 and 0.80 for age 18-29 or not, and another spinner with areas of 0.24 and 0.76 to represent uses Snapchat or not.
Then spin each spinner once to simulate one repetition."
Do you agree? Explain.
1.  How could you perform one repetition of the simulation using just a single spinner?
(Hint: it needs 4 sectors.)
1.  How could you perform a simulation, using the spinner in the previous part, to estimate $\IP(C | A)$?
1.  What determines the order of magnitude of the the margin of error for your estimate in the previous part?
1.  What is another method for performing the simulation and estimating $\IP(C |A)$ that has a smaller margin of error?
What is the disadvantage of this method?

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-impeach-sim}



1.  Donny's simulation assumes that age and Snapchat use are independent, but we know that younger people will be more likely to use Snapchat than older people.
In general, you can not simulate pairs of events simply from the marginal probabilities of each.
1.  You can construct a spinner for the possible occurrences of the *pairs* of events---both occur, $A$ occurs and $C$ does not, $C$ occurs and $A$ does not, neither occurs---and their *joint* probabilities.
From the three given probabilities we can determine (see the interior cells in the two-way table in the solution to @exm-conditional-probability-def):
    -   age 18-29 and uses Snapchat: $\IP(A\cap C)= 0.13$
    -   age 18-29 and does not use Snapchat: $\IP(A\cap C^c)= 0.07$
    -   not age 18-29, and uses Snapchat: $\IP(A^c\cap C)= 0.11$
    -   not age 18-29, and does not use Snapchat: $\IP(A^c\cap C^c)= 0.69$ 
    See the spinner in @fig-impeach-sim-spinner.
1.  The following method fixes the number of total spins, say 10000.
    -   Spin the joint spinner from the previous part once to simulate a (age, Snapchat) pair.
    -   Repeat a fixed number of times, say 10000.
    -   Discard the repetitions on which the person was not age 18-29, that is, the repetitions on which $A$ did not occur.
    You would expect to have around 2000 repetitions left.
    -   Among the remaining repetitions (on which $A$ occurred), count the number of repetitions on which $C$ also occurred.
    So for the roughly 2000 repetitions for which the person is age 18-29, count the repetitions on which the person also uses Snapchat; you would expect a count of around 1300.
    -   Estimate $\IP(C|A)$ by dividing the two previous counts to obtain a conditional relative frequency.
    $$
    \IP(C | A)\approx \frac{\text{Number of repetitions on which both $A$ and $C$ occurred}}{\text{Number of repetitions on which $C$ occurred}}
    $$
1.  Only those repetitions in which $A$ occurred are used to estimate $\IP(C|A)$.
So the order of magnitude of the margin of error is determined by the number of repetitions on which $A$ occurs.
This would be around 2000 repetitions for a margin of error of roughly $1/\sqrt{2000} = 0.022$, rather than 0.01 based on the original 10000 repetitions.
1.  The previous method simulated a fixed number of repetitions first, and then discarded the ones that did not meet the condition $A$.
We could instead discard repetitions that do not meet the condition as we go, and keep performing repetitions until we get a fixed number, say 10000, that do satisfy the condition $A$.
In this way, the estimate $\IP(C |A)$ will be based on the fixed number of repetitions, say 10000, that satisfy event $A$.
The disadvantage is increased computational burden; we will need to simulate and discard many repetitions in order to achieve the desired number that satisfy the condition.
Roughly, we would need to simulate about 50000 repetitions in total to obtain 10000 repetitions that satisfy event $A$.
The advantage is a more precise estimate of $\IP(C|A)$ than in the previous part.


:::
::::





```{r}
#| label: fig-impeach-sim-spinner
#| echo: false
#| fig-cap: "Spinner corresponding to @exm-impeach-sim."
#| warning: false





df <- data.frame(value = c(13, 7, 11, 69) / 100,
                 group = c("age 18-29,\n Snapchat", "age 18-29,\n not Snapchat", "not age 18-29\n Snapchat", "not age 18-29\n not Snapchat"))

# Get the positions
df2 <- df |>
  mutate(csum = rev(cumsum(rev(value))), 
         pos = value / 2 + lead(csum, 1),
         pos = if_else(is.na(pos), value / 2, pos))

ggplot(df,
       aes(x = "",
           y = value,
           fill = fct_inorder(group))) +
  geom_col(width = 1, color = 1) +
  geom_text(aes(label = percent(value)),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y", direction = -1) +
  scale_y_continuous(breaks = df2$pos, labels = df$group) +
  scale_fill_manual(values = rep("white", 4)) +
  # scale_fill_manual("white") +
  theme(axis.ticks = element_blank(),
        axis.title = element_blank(),
        axis.text = element_text(size = 8), 
        legend.position = "none", # Removes the legend
        panel.background = element_rect(fill = "white")) 
 
 

```






The conditional probability of event $A$ given event $B$ can be approximated by simulating---according to the assumptions encoded in the probability measure $\IP$---the random phenomenon a large number of times and computing the relative frequency of $A$ *among repetitions on which $B$ occurs*.

$$
{\small
\IP(A|B) \approx \frac{\text{number of repetitions on which $A$ and $B$ occur}}{\text{number of repetitions on which $B$ occurs}}, \quad \text{for a large number of repetitions simulated according to $\IP$}
}
$$
When using simulation to approximate $\IP(A|B)$, we first use $B$ to determine which repetitions to *keep*, then we find the relative frequency of $A$.


Remember that the margin of error when approximating a probability based on a simulated relative frequency depends on the number of independently simulated repetitions used to calculate the relative frequency.
When approximating $\IP(A|B)$ as above, the margin of error is determined by the number of independently simulated repetitions *on which $B$ occurs*.

There are two basic ways to use simulation^[All of our simulations are based on *independently* simulated repetitions. More sophisticated methods, such as Markov chain Monte Carlo (MCMC) methods, allow dependent repetitions and can approximate conditional probabilities much more efficiently.] to approximate a conditional probability $\IP(A|B)$.

-   Simulate the random phenomenon for a set number of repetitions (say 10000), *discard those repetitions on which $B$ does not occur*, and compute the relative frequency of $A$ among the remaining repetitions (on which $B$ does occur). 
    -   Disadvantage: the margin of error is based on only the number of repetitions used to compute the relative frequency.
    So if you perform 10000 repetitions but $B$ occurs only on 1000, then the margin of error for estimating $\IP(A|B)$ is roughly on the order of $1/\sqrt{1000} = 0.032$ (rather than $1/\sqrt{10000} = 0.01$).
    Especially if $\IP(B)$ is small, the margin of error could be large resulting in an imprecise estimate of $\IP(A|B)$. 
    -   Advantage: not computationally intensive.
-   Simulate the random phenomenon *until obtaining a certain number of repetitions (say 10000) on which $B$ occurs*, discarding those repetitions on which $B$ does not occur as you go, and compute the relative frequency of $A$ among the remaining repetitions (on which $B$ does occur).  
    -    Advantage: the margin of error will be based on the set number of repetitions on which $B$ occurs.
    -    Disadvantage: requires more time/computer power.
    Especially if $\IP(B)$ is small, it will require a large number of repetitions of the simulation to achieve the desired number of repetitions on which $B$ occurs.
    For example, if $\IP(B)=0.1$, then it will require roughly 100,000 repetitions in total to obtain 10,000 on which $B$ occurs.

### Conditioning in Symbulate

In Symulate, `filter` can be used to extract repetitions that satisfy a condition.
First we'll simulate age and Snapchat use for 10000 hypothetical adults.
Each ticket in the `BoxModel` has a (age, Snapchat) pair of labels, like the spinner in @fig-impeach-sim-spinner.


```{python}
P = BoxModel([('Age 18-29', 'Snapchat user'), ('Age 18-29', 'Not Snapchat user'), ('Not Age 18-29', 'Snapchat user'), ('Not Age 18-29', 'Not Snapchat user')],
             probs = [0.13, 0.07, 0.11, 0.69])

sim_all = P.sim(10000)

sim_all
```

```{python}
sim_all.tabulate()
```

Now we'll apply `filter` to retain only those age 18-29.
The function `is_Age18` takes as an input^[`Age_Snapchat` is a pair so `Age_Snapchat[0]` is the first component (Age) and `Age_Snapchat[1]` is the second component (Snapchat user).] a (age, Snapchat) pair and returns `True` if age 18-29 (and `False` otherwise).
Applying `filter(is_Age18)` will only return results for which `is_Age18` returns `True`.

```{python}
def is_Age18(Age_Snapchat):
    return Age_Snapchat[0] == 'Age 18-29'
  
sim_given_Age18 = sim_all.filter(is_Age18)

sim_given_Age18
```


```{python}
sim_given_Age18.tabulate()

```

Conditional relative frequencies are computed based only on repetitions which satisfy the event being conditioned on.

```{python}
sim_given_Age18.tabulate(normalize = True)

```

Based on these results, we would estimate $\IP(C |A)$ to be around the true value of 0.65 with a margin of error of roughly $1/\sqrt{2000} = 0.022$.


In Symbulate, the "given" symbol `|` applies the second method to simulate a fixed number of repetitions that satisfy the event being conditioned on.
Be careful when using `|` when conditioning on an event with small probability.
In particular, be careful when conditioning on the value of a continuous random variable (which we'll discuss in more detail soon).

Below we use `RV` syntax to carry out the simulation and conditioning^[In Symbulate, events being conditioned on need to be based on `RV`s. But the code shows that Symbulate has a pretty broad interpretation of what can be an `RV`.].
Technically, a random variable always returns a number, but `RV` in Symbulate does allow for non-numerical outputs.
In most situations, we will usually deal with true random variables, and the code syntax below will be more natural.

The following code simulates (Age, Snapchat) pairs until 10000 adults age 18-29 are obtained.

```{python}
Age, Snapchat = RV(P)

sim_given_Age18 = ( (Age & Snapchat) | (Age == 'Age 18-29') ).sim(10000)

sim_given_Age18
```


```{python}
sim_given_Age18.tabulate()

```

Since all 10000 simulated pairs satisfy the event being conditioned on (age 18-29), they are all included in the computation of the conditional relative frequencies.

```{python}
sim_given_Age18.tabulate(normalize = True)
```

Based on these results, we would estimate $\IP(C |A)$ to be around the true value of 0.65 with a margin of error of roughly $1/\sqrt{10000} = 0.01$.
We have obtained a more precise estimate, but the simulation takes longer to run.

    
### Using conditional probabilities to simulate

In @exm-impeach-sim we directly simulated pairs of events using joint probabilities, and used the results to approximate conditional probabilities.
But in many problems conditional probabilities are provided or can be determined directly.


:::: {.callout-note appearance="simple"}
::: {#exm-impeach2-sim}

Recall @exm-conditional-probability-def2.
Suppose that 


-   65% of American adults age 18-29 use Snapchat
-   24% of American adults age 30-49 use Snapchat
-   12% of American adults age 50-64 use Snapchat
-   2% of American adults age 65+ use Snapchat

Also suppose that

-   20% of American adults are age 18-29
-   33% of American adults are age 30-49
-   25% of American adults are age 50-64
-   22% of American adults are age 65+

Consider simulating a randomly selected U.S. adult and determining the person's age group and whether or not they use Snapchat.
How could you perform one repetition of the simulation using spinners based solely on the percentages provided above, without first constructing a two-way table or finding $\IP(A_1\cap C)$, etc?
(Hint: you'll need a few spinners, but you might not spin them all in a single repetition.)


:::
::::

:::: {.callout-tip collapse=true}
::: {#sol-impeach2-sim}


It's a two-stage simulation: first spin a spinner to determine age group, then given the result spin an appropriate spinner to determine Snapchat use.
There will be 4 spinners for Snapchat use, but only 1 will be spun---along with the age spinner---in any single repetition.
See @fig-impeach-sim-spinner2.


-   "Age" spinner: Areas of 0.20, 0.33, 0.25, 0.22 corresponding to, respectively, 18-29, 30-49, 50-64. 65+.
Spin this to determine age group.
-   "Snapchat" spinners---only one of the following will be spun in a single repetition:
    -   Snapchat given age 18-29: areas of 0.65 and 0.35 corresponding to, respectively, uses Snapchat and does not use Snapchat.
    If the result of the "age" spinner is 18-29, spin this spinner to determine whether or not the person uses Snapchat.
    -   Snapchat given age 30-49: areas of 0.24 and 0.76 corresponding to, respectively, uses Snapchat and does not use Snapchat.
    If the result of the "age" spinner is 30-49, spin this spinner to determine whether or not the person uses Snapchat.
    -   Snapchat given age 50-64: areas of 0.12 and 0.88 corresponding to, respectively, uses Snapchat and does not use Snapchat.
    If the result of the "age" spinner is 50-64, spin this spinner to determine whether or not the person uses Snapchat.
    -   Snapchat given age 65+: areas of 0.02 and 0.98 corresponding to, respectively, uses Snapchat and does not use Snapchat.
    If the result of the "age" spinner is 65+, spin this spinner to determine whether or not the person uses Snapchat.

:::
::::

```{r}
#| label: fig-impeach-sim-spinner2
#| echo: false
#| fig-cap: "Spinners corresponding to @exm-impeach2-sim. The spinner in the top row is spun first to simulate age group, then the corresponding spinner in the bottom row is spun to determine Snapchat use."
#| warning: false

four_colors = c("#E69F00", "#56B4E9", "#009E73", "#F0E442")

df <- data.frame(value = c(20, 33, 25, 22) / 100,
                 group = c("18-29", "30-49", "50-64", "65+"))

# Get the positions
df2 <- df |>
  mutate(csum = rev(cumsum(rev(value))), 
         pos = value / 2 + lead(csum, 1),
         pos = if_else(is.na(pos), value / 2, pos))

age_spinner = ggplot(df,
       aes(x = "",
           y = value,
           fill = fct_inorder(group))) +
  geom_col(width = 1, color = 1) +
  geom_text(aes(label = percent(value)),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y", direction = -1) +
  scale_y_continuous(breaks = df2$pos, labels = df$group) +
  scale_fill_manual(values = four_colors) +
  # scale_fill_manual("white") +
  theme(axis.ticks = element_blank(),
        axis.title = element_blank(),
        axis.text = element_text(size = 10, color = four_colors), 
        legend.position = "none", # Removes the legend
        panel.background = element_rect(fill = "white")) 
 


conditional_spinner <- function(possible_values, probs, color, title){
  df <- data.frame(value = probs / sum(probs),
                   group = possible_values)
  
  # Get the positions
  df2 <- df |>
    mutate(csum = rev(cumsum(rev(value))), 
           pos = value / 2 + lead(csum, 1),
           pos = if_else(is.na(pos), value / 2, pos))
  
  ggplot(df,
         aes(x = "",
             y = value,
             fill = fct_inorder(group))) +
    geom_col(width = 1, color = color) +
    geom_text(aes(label = percent(value)),
              position = position_stack(vjust = 0.5)) +
    coord_polar(theta = "y", direction = -1) +
    scale_y_continuous(breaks = df2$pos, labels = df$group) +
    scale_fill_manual(values = rep("white", 4)) +
    labs(title = title) +
    theme(axis.ticks = element_blank(),
          axis.title = element_blank(),
          axis.text = element_text(size = 6), 
          legend.position = "none", # Removes the legend
          panel.background = element_rect(fill = "white"),
          plot.title = element_text(color = color)) 
}



s1 <- conditional_spinner(probs = c(0.65, 0.35),
                    possible_values = c("uses\n Snapchat", "does not use"),
                    color = four_colors[1],
                    title = "Given age 18-29")

s2 <- conditional_spinner(probs = c(0.24, 0.76),
                    possible_values = c("uses\n Snapchat", "does not use"),
                    color = four_colors[2],
                    title = "Given age 30-49")

s3 <- conditional_spinner(probs = c(0.12, 0.88),
                    possible_values = c("uses\n Snapchat", "does not use"),
                    color = four_colors[3],
                    title = "Given age 50-64")

s4 <- conditional_spinner(probs = c(0.02, 0.98),
                    possible_values = c("uses\n Snapchat", "does not use"),
                    color = four_colors[4],
                    title = "Given age 65+")

grid.arrange(age_spinner, s1, s2, s3, s4, layout_matrix = rbind(c(1, 1, 1, 1), c(2, 3, 4, 5)))
```


A two-stage simulation like the one above basically implements the multiplication rule, joint = conditional $\times$ marginal.
We first simulate age based on marginal probabilities, then use conditional probabilities to simulate Snapchat use, resulting in (age, Snapchat) pairs with the appropriate joint relationship.



In Symbulate, we can code the scenario in @exm-impeach2-sim by defining a custom probability space.
An outcome is a (Age, Snapchat) pair.
Each of the 5 spinners corresponds to a `BoxModel`.
We define a function that defines how to simulate one repetition in two stages, using the `draw` method^[`.draw()` is like `.sim(1)` but they have different properties. We will usually work with `.sim()` to actually run a simulation. `.draw()` is useful in situations like this where we have to build a custom probability space from scratch.].
Then we use that function to define a custom `ProbabilitySpace`.

```{python}

def Age_Snapchat_sim():
    Age = BoxModel(['18-29', '30-49', '50-64', '65+'], probs = [0.20, 0.33, 0.25, 0.22]).draw()
    if Age == '18-29':
        Snapchat = BoxModel(['Use', 'NotUse'], probs = [0.65, 0.35]).draw()
    if Age == '30-49':
        Snapchat = BoxModel(['Use', 'NotUse'], probs = [0.24, 0.76]).draw()
    if Age == '50-64':
        Snapchat = BoxModel(['Use', 'NotUse'], probs = [0.12, 0.88]).draw()
    if Age == '65+':
        Snapchat = BoxModel(['Use', 'NotUse'], probs = [0.02, 0.98]).draw()
    return Age, Snapchat
    
P = ProbabilitySpace(Age_Snapchat_sim)
P.sim(10)

```


Once we have simulated pairs, we can proceed as in @sec-simulation-conditioning-probabilities.
For example, the following approximates conditional probabilities of age group given that the adult uses Snapchat, based on 10000 repetitions which satisfy the condition; compare to part 7 of @exm-conditional-probability-def2.

```{python}
Age, Snapchat = RV(P)

sim_given_Snapchat = ( Age | (Snapchat == 'Use') ).sim(10000)

sim_given_Snapchat.tabulate(normalize = True)

```




### Conditioning on values of random variables

If $X$ is a discrete random variable, we can condition on it equalling the value $x$ by conditioning on the event $\{X = x\}$.


:::: {.callout-note appearance="simple"}
::: {#exm-dice-tactile-conditional-prob}

We'll continue with the dice rolling example: roll two fair four-sided dice and let $X$ be the sum and $Y$ the larger of the rolls.
For each of the following, describe how to approximate the probability based on 10000 repetitions of a tactile simulation (in principle). 



1.  $\IP(X = 6 | Y = 4)$.
1.  $\IP(Y = 4 | X = 6)$.

:::
::::

:::: {.callout-tip collapse=true}
::: {#sol-dice-tactile-conditional-prob}


We have already seen how to simulate $(X, Y)$ pairs.

1.  Simulate an $(X, Y)$ pair.
If $Y=4$ keep the pair, otherwise discard it.
Continue until 10000 $(X, Y)$ pairs with $Y=4$ are obtained.
Count the number of pairs for which $X=6$ and divide by 10000 to approximate $\IP(X = 6 | Y = 4)$, with a margin of error of 0.01.
1.  Simulate an $(X, Y)$ pair.
If $X=6$ keep the pair, otherwise discard it.
Continue until 10000 $(X, Y)$ pairs with $X=6$ are obtained.
Count the number of pairs for which $Y=4$ and divide by 10000 to approximate $\IP(Y = 4 | X = 6)$, with a margin of error of 0.01.

:::
::::

To approximate a conditional probability of an event involving a random variable $X$ given the value of a random variable $Y$, we first need to simulate $(X, Y)$ pairs.
The variable being conditioned on ($Y$ here) determines which pairs to *keep*, and the other variable determines what to find the relative frequency of.


Here is some code for conditioning on $\{Y = 4\}$.

```{python}

P = DiscreteUniform(1, 4) ** 2

X = RV(P, sum)
Y = RV(P, max)

( (X & Y) | (Y == 4) ).sim(10)

```


```{python}

(X | (Y == 4) ).sim(10000).tabulate()

```

```{python}

(X | (Y == 4) ).sim(10000).tabulate(normalize = True)

```

Below we simulate values of $X$ given $Y=y$ for each of the values $y = 2, 3, 4$.
(We omit conditioning on $Y=1$ since then $X = 2$ with probability 1.)
Each of the three simulations below approximates a separate conditional distribution of $X$ values.


```{python}

x_given_Y_eq4 = (X | (Y == 4) ).sim(10000)

x_given_Y_eq3 = (X | (Y == 3) ).sim(10000)

x_given_Y_eq2 = (X | (Y == 2) ).sim(10000)

```

We plot the three distributions on a single plot to compare how the distribution of $X$ changes depending on the given value of $Y$.

```{python}
#| eval: false

x_given_Y_eq4.plot()
x_given_Y_eq3.plot(jitter = True) # shifts the spikes a little
x_given_Y_eq2.plot(jitter = True) # so they don't overlap

```


```{python}
#| echo: false

plt.figure()
x_given_Y_eq4.plot()
x_given_Y_eq3.plot(jitter = True) # shifts the spikes a little
x_given_Y_eq2.plot(jitter = True) # so they don't overlap
plt.show()

```




Extra care is required when conditioning on the value of a continuous random variable.
We'll consider the Bivariate Normal model of the meeting problem from  @sec-meeting-sim. 

:::: {.callout-note appearance="simple"}
::: {#exm-uniform-sum-max-conditional-sim-forever}

Suppose we want to approximate the conditional probability that Cady arrives first given that Regina arrives at 12:40.


1.  Donny Don't writes the Symbulate code below to approximate this probability.
What do you think will happen when Donny runs his code?
1.  Can you think of how to fix Donny's code?
(Hint: when we say "Regina arrives at 12:40", what do we really mean?)

:::
::::

```{python}
#| eval: false
# Donny's code - don't try to run this!
R, Y = RV(BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7))

y_given_Req40 = (Y | (R == 40) ).sim(10000)

y_given_Req40.count_lt(40) / 10000

```






:::: {.callout-tip collapse=true}
::: {#sol-uniform-sum-max-conditional-sim-forever}


1.  Donny's code will run forever!
Using `.sim(10000)` with conditioning via `|` will continue the simulation until obtaining 10000 repetitions that satisfy the condition.
Remember, $R$ is a *continuous* random variable, so $\IP(R = 40)=\IP(R = 40.00000000000000000\ldots) = 0$.
The simulation will never return a single $(R, Y)$ pair  with $Y$ equal to $40.0000000000000\ldots$, let alone 10000 of them.
1.  "Regina arrives at 12:40" doesn't really mean $R$ "is equal to 40" but rather $R$ "is close enough to 40", where "close enough" depends on the context.
Here, rounding to the nearest minute seems reasonable, in which case "Regina arrives at 12:40" really means "Regina arrives within 0.5 minutes (30 seconds) of 12:40".
So we want to condition on the event $\{40 - 0.5 < R < 40 + 0.5\}=\{|R - 40|<0.5\}$ rather than $\{R = 40\}$.
See the code below, where we condition on the event `(abs(R - 40) < 0.5)`.
Aside from the conditioning event, Donny's code is fine, but note that we have changed the number of repetitions from 10000 to 1000; see the discussion below.

:::
::::

```{python}
R, Y = RV(BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7))

y_given_Req40 = (Y | (abs(R - 40) < 0.5) ).sim(1000)

y_given_Req40.count_lt(40) / 1000

```


::: {.callout-warning appearance="default"}
Be careful when conditioning on the value of a continuous random variable.
Remember that the probability that a continuous random variable is equal to a particular value is 0.
Mathematically, when we condition on $\{X=x\}$ we are really conditioning on $\{|X-x|<\ep\}$---the event that the random variable $X$ is within $\ep$ of the value $x$---and seeing what happens in the idealized limit when $\ep$ approaches 0.
Practically, $\ep$ represents the degree of precision which determines "close enough" in the problem context, e.g., $\ep=0.01$ if "within 0.01" is close enough.
When conditioning on a continuous random variable $X$ in a simulation, *never* condition on $\{X=x\}$; rather, condition on $\{|X-x|<\ep\}$ where $\ep$ represents a suitable degree of precision.
What counts as "suitable" depends on the context and the scale of the $X$ variable.
For example, if our variable is household income (U.S. dollars) and we're conditioning on household income "equal to" 100,000 dollars, then $\ep$ of 1000 dollars might be reasonable.
:::

The event $\{|X-x|<\ep\}$ will have non-zero probability, but the probability might be small.
Conditioning on low probability events introduces some computational challenges.
Remember that the margin of error in using a relative frequency to approximate a probability is based on the number of independently simulated repetitions used to compute the relative frequency.
When approximating a conditional probability with a conditional relative frequency, the margin of error is based only on the number of repetitions that satisfy the condition.
Naively discarding repetitions that do not satisfy the condition can be horribly inefficient.
For example, when conditioning on an event with probability 0.01 we would need to run about 1,000,000 repetitions to achieve 10,000 that satisfy the condition.
There are more sophisticated and efficient methods (e.g., "Markov chain Monte Carlo (MCMC)" methods), but they are beyond the scope of this book.
When conditioning on the value of a continuous random variable with `|` in Symbulate, be aware that you might need to change either the number of repetitions (but try not to go below 1000) or the degree of precision $\ep$ in order for the simulation to run in a reasonable amount of time.

In the Bivariate Normal model of the meeting problem the event $\{|R - 40| < 0.5\}$ has probability 0.04.
Running `(Y | (abs(R - 40) < 0.5) ).sim(1000)` requires about 25000 repetitions in the background to achieve the 1000 the satisfy the condition.
The margin of error for approximating conditional probabilities is roughly $1/\sqrt{1000} = 0.03$.



```{python}

R, Y = RV(BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7))

( (R & Y) | (abs(R - 40) < 0.5) ).sim(10)

```



### Conditional averages

TBA

### Exercises

::: {#exr-simulation-condition-collector}
The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3).
Each package contains a single unknown prize.
Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3).
For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.
Let $X$ be the number of distinct prizes obtained in these 3 packages.
Let $Y$ be the number of these 3 packages that contain prize 1.

1.  Explain how you could, in principle, conduct a simulation by hand and use the results to approximate
    a.  $\IP(Y = 0 | X = 1)$
    a.  The conditional distribution of $Y$ given $X=1$
    a.  $\IP(X = 1 | Y = 0)$
    a.  The conditional distribution of $X$ given $Y=0$
1.  Write Symbulate code to conduct a simulation and approximate the values in part 1.
Each simulation should be based on 10000 repetitions that satisfy the conditioning event.
:::


::: {#exr-simulation-condition-dartboard}
Write Symbulate code to conduct the simulation in @exr-tactile-dartboard.
Use conditioning to discard any repetitions where the dart lands off the board.
Use the simulation results to approximate:

1.  The marginal distribution of $R$ (via plot)
1.  $\IP(R < 1)$
1.  $\IP(R > 11)$
1.  $\E(R)$
1.  $\SD(R)$.
:::

::: {#exr-simulation-condition-continuous-dice}
Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4).
Let $X$ be the sum of the two spins and let $Y$ be the larger of the two spins.


1.  Describe in words how you could use simulation to approximate
    a.  $\IP(Y < 2.7 | X = 3.5)$
    a.  The conditional distribution of $Y$ given $X = 3.5$
1.  Write Symbulate code to conduct a simulation to approximate the quantities from the previous part.

Hint: be careful!
What do we really mean by conditioning on $X = 3.5$?
:::





## Independence {#sec-simulation-independence}


For independent events, the multiplication rule simplifies

\begin{align*}
\text{If $A$ and $B$ are independent then } && \IP(A \cap B) & = \IP(A)\IP(B)\\
\text{If independent then } && \text{Joint} & = \text{Product of Marginals}
\end{align*}

Similarly, the joint distribution of independent random variables is this product of their marginal distributions.
For this reason, independence is represented by the product `*` syntax in Symbulate.

For example, in the meeting problem, if Regina's arrival follows a Uniform(0, 60) model, Cady's follows a Normal(30, 10) model, and they arrive independently of each other, we can simulate pairs of arrivals as follows; note the use of `*`.

```{python}
P = Uniform(0, 60) * Normal(30, 10)
P.sim(5)
```

We can think of `*` as "spin each spinner independently", but what `*` really does is create a joint probability space as the product of two marginal probability spaces.

::: {.callout-warning appearance="default"}
Be careful: `*` plays different roles for probability spaces and named distributions (like `Uniform`, `Normal`) than it does for random variables.
Using `*` with probability spaces indicates that the spaces are *independent*.
Likewise, using `*` with *distributions* of random variables, as in `X, Y = RV(Distribution_X * Distribution_Y)`, indicates that the random variables are *independent* since their joint distribution is the product of their marginal distributions.
In contrast, using `*` directly on random variables, as in `X * Y`, literally means multiplication.
(@sec-rv-versus-distribution has further discussion on the difference between a random variable and its distribution.)
:::

Note the two uses of `*` in the code below.
In the `P = ...` line, `*` means that the two components of the pair will be simulated independently (e.g., "spin the Uniform(0, 60) spinner then spin the Normal(30, 10) spinner"), resulting in random variables `R` (first component) and  `Y` (second component) that are independent.
In `(R * Y)`, `*` means multiply the values of `R` and `Y`.

```{python}
P = Uniform(0, 60) * Normal(30, 10)
R, Y = RV(P)

(R & Y & (R * Y) ).sim(5)
``` 

We could have also coded the following, which we interpret as defining random variables `R` and `Y` whose joint distribution is the product of their marginal distributions, `Uniform(0, 60)` for `R` and `Normal(30, 10)` for `Y`, and thus `R` and `Y` are independent.

```{python}
R, Y = RV(Uniform(0, 60) * Normal(30, 10))

(R & Y & (R * Y) ).sim(5)
``` 

:::: {.callout-note appearance="simple"}
::: {#exm-donny-sim-assume-independent}

Donny Don't writes the following code to simulate $X$ and $Y$ from @exm-dice-joint-independent-conditional, but it returns an error.
Can you explain why?
Think about it first, but if you need a hint, run the code to see the error.
How could you fix the code so it runs properly.
:::
::::

```{python}
#| eval: false

X = RV(BoxModel([2, 3, 4, 5, 6, 7, 8], probs = [1/16, 2/16, 3/16, 4/16, 3/16, 2/16, 1/16]))
Y = RV(BoxModel([1, 2, 3, 4], probs = [1/16, 3/16, 5/16, 7/16]))

(X & Y).sim(10)

```

:::: {.callout-tip collapse=true}
::: {#sol-donny-sim-assume-independent}

Donny's code defines the correct marginal distributions for $X$ and $Y$, but to simulate $X, Y$ pairs we need to know their joint distribution.
Recall the moral of @exm-dice-joint-independent-conditional and the discussion following it: marginal distributions alone are not enough to determine the joint distribution.

The error message is "Events must be defined on same probability space", which in this case really should be "random variables must be defined on same probability space", but even that is maybe not the most informative message.
The idea is that we have not provided enough information to determine how to pair $X$ and $Y$ values when running the simulation.
If the random variables were defined on the same probability space, the probaility space outcome would be simulated first and then both $X$ and $Y$ would be computed for the same outcome, so there would be no problem when simulating pairs.
One way to define the random variables on the same probability space is to specify their joint distribution and then simulate pairs directly from the joint distribution.

Recall from @exm-dice-joint-independent-conditional that $X$ and $Y$ here are independent, so their joint distribution is the product of their marginal distribution.
The code below achieves Donny's goal, using the `*` syntax.

:::
::::

```{python}
X, Y = RV(BoxModel([2, 3, 4, 5, 6, 7, 8], probs = [1/16, 2/16, 3/16, 4/16, 3/16, 2/16, 1/16]) * 
          BoxModel([1, 2, 3, 4], probs = [1/16, 3/16, 5/16, 7/16]))

(X & Y).sim(10)
```


:::: {.callout-note appearance="simple"}
::: {#exm-donny-sim-assume-independent2}

Continuing @exm-donny-sim-assume-independent2, Donny says: "That error is annoying. 
If $X$ and $Y$ are *independent* then their marginal distributions determine their joint distribution, so my code should be fine."
How would you respond?
(You might agree with Donny here. 
If so, imagine you have been assigned to argue against Donny.)
:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-donny-sim-assume-independent2}
Donny is correct that if random variables are independent their marginal distributions determine their joint distribution.
The issue is that independence is an *assumption*---see @sec-independence-is-an-assumption ---and Symbulate requires you to be explicit about all your assumptions.
There are 3 main assumptions in this example:

-   $X$ is assumed to have a particular marginal distribution
-   $Y$ is assumed to have a particular marginal distribution
-   $X$ and $Y$ are assumed to be independent

Donny's code has defined the first two assumptions, but not the third.

Suppose Donny had tried to run `(X & Y).sim(10)` without first defining `X`, hence not specifying the first assumption above.
That would also result in an error, because there would not be enough information to run the simulation.
If you don't specify the distribution of a random variable---either directly or by defining it as a function on a probability space---Symbulate will not assume a distribution by default.

Likewise, Symbulate won't assume random variables are independent unless you tell it to.
You, like Donny, might want Symbulate to assume independence by default, but that's just not the way it works.
And it's probably much safer that way because there are many real situations where independence is not a reasonable assumption, and assuming independence by default might lead to wildly inaccurate results.


:::
::::

Symbulate does offer a compromise, via the `AssumeIndependent` command, which allows code like Donny's in @exm-donny-sim-assume-independent while also requiring explicit specification of independence 
The following code would achieve Donny's goal in @exm-donny-sim-assume-independent.

```{python}
#| eval: true

X = RV(BoxModel([2, 3, 4, 5, 6, 7, 8], probs = [1/16, 2/16, 3/16, 4/16, 3/16, 2/16, 1/16]))
Y = RV(BoxModel([1, 2, 3, 4], probs = [1/16, 3/16, 5/16, 7/16]))

X, Y = AssumeIndependent(X, Y)

(X & Y).sim(10)

```

While `AssumeIndependent` works, we discourage its use for two reasons.
First, the code is clunky; in a sense the definition of `X` and `Y` with `X = RV(...)` and `Y = RV(...)` is incomplete until they are redefined with `X, Y = AssumeIndependent(X, Y)`.
More importantly,  when dealing with multiple random variables it is their joint distribution that describes fully their probabilitistic behavior.
Therefore we encourage you to get in the habit of defining joint distributions (possibly using the "marginal then conditional" construction).
In many situations random variables are not independent, so marginal distributions alone are not enough.
In the special case of independence, define the joint distribution directly as the product of marginal distributions using `*` rather than using `AssumeIndependent`.


### Exercises

## Working with Symbulate

In this section we explore a little deeper some aspects of coding simulations with Symbulate.

### Two "worlds" in Symbulate {#sec-symbulate-two-worlds}

Recall the dice rolling simulation in @sec-technology-intro.
Suppose we want to simulate realizations of the event $A= \{Y < 3\}$.
We saw previously that we can define the event `(Y < 3)` in Symbulate and simulate True/False realizations of it.

```{python}
P = RV(DiscreteUniform(1, 4) ** 2)

Y = RV(P, max)

A = (Y < 3)

A.sim(10)
```

Since event $A$ is defined in terms of $Y$, we can also first simulate values of `Y`, store the results as `y`, and then determine whether event $A$ occurs for the simulated `y` values using[^simulation-23] `(y < 3)`. (The results won't match the above because we are making a new call to `sim`.)

[^simulation-23]: Python automatically treats `True` as 1 and `False` as 0, so the code `(y < 3)` effectively returns both True/False realizations of the event itself and 1/0 realizations of the corresponding indicator random variable.

```{python}
y = Y.sim(10)

y
```

```{python}
(y < 3)
```

These two methods illustrate the two "worlds" of Symbulate, which we call "random variable world" and "simulation world".
Operations like transformations can be performed in either world.
Think of random variable world as the "before" world and simulation world as the "after" world, by which we mean before/after the `sim` step.

Most of the transformations we have seen so far happened in random variable world.
For example, we have seen how to define the sum of two dice in *random variable world* in a few ways, e.g., via

```{python}
#| eval: false

P = BoxModel([1, 2, 3, 4], size = 2)

U = RV(P)

X = U.apply(sum)
```


The sum transformation is applied to define a new random variable `X`, before the `sim` step.
We could then call, e.g., `(U & X).sim(10)`.

We could also compute simulated values of the sum in *simulation world* as follows.

```{python}
#| eval: true
#| label: sim-world-example

P = BoxModel([1, 2, 3, 4], size = 2)

U = RV(P)

u = U.sim(10)

u
```

```{python}
u.apply(sum)

```



The above code will simulate all the pairs of rolls first, store them as `u` (which we can think of as a table), and then apply the sum to the simulated values (which adds a column to the table).
That is, the sum transformation happens after the `sim` step.

While either world is "correct", we generally take the random variable world approach.
We do this mostly for consistency, but also to emphasize some of the probability concepts we'll encounter.
For example, the fact that a sum of random variables (defined on the same probability space) is also a random variable is a little more apparent in random variable world.
However, it is sometimes more convenient to code in simulation world; for example, if complicated transformations are required.

:::: {.callout-note appearance="simple"}
::: {#exm-donny-rv-same-probspace}

Donny Don't writes the following code to simulate $X$ and $Y$ in the dice problem, but it returns an error.
Can you explain why?
Think about it first, but if you need a hint, run the code to see the error.
:::
::::

```{python}
#| eval: false

X = RV(BoxModel([1, 2, 3, 4], size = 2), sum)
Y = RV(BoxModel([1, 2, 3, 4], size = 2), max)

(X & Y).sim(10)

```

:::: {.callout-tip collapse=true}
::: {#sol-donny-rv-same-probspace}


The problem is that there is one box model used to determine values of `X` and a separate box model for `Y`; we can't simulate `(X, Y)` *pairs* of values if we're using different boxes.
The code above is basically saying to roll one fair four-sided die twice and compute the sum, then roll another four-sided die twice and compute the max, but we can only compute $X$ *and* $Y$ (`X & Y`) for the same pair of rolls.

The error message is "Events must be defined on same probability space", which in this case really should be "random variables must be defined on same probability space", but the actual message at least reflects the spirit of the error. 
:::
::::

:::: {.callout-note appearance="simple"}
::: {#exm-donny-sim-same-probspace}

Donny Don't tries again to simulate just $X$ in the dice problem, this time in simulation world, but Donny's code below still returns an error.
Can you explain why?
Think about it first, but if you need a hint, run the code to see the error.
:::
::::

```{python}
#| eval: false

P = BoxModel([1, 2, 3, 4], size = 2)
U1, U2 = RV(P)

u1 = U1.sim(10)
u2 = U2.sim(10)

x = u1 + u2
```

:::: {.callout-tip collapse=true}
::: {#sol-donny-sim-same-probspace}
The error is basically the same as in @exm-donny-rv-same-probspace.
Running `U1.sim(10)` simulates one set of pairs of rolls to compute `u1`, but running `u2 = U2.sim(10)` simulates a separate set of pairs of rolls to compute `u2`.
The error occurs when running `u1+u2` because it only makes sense to add the first roll and second roll for the same pairs of rolls.

The error message is "Results objects must come from the same simulation", which is maybe not the most informative message, but at least reflects the spirit of the error. 

:::
::::

:::: {.callout-note appearance="simple"}
::: {#exm-donny-sim-world-assume-independent}

Continuing @exm-donny-sim-same-probspace, Donny says: "That error is annoying. 
If $U_1$ and $U_2$ are independent then I should be able to simulate then independently and then add them, so my code should be fine."
How would you respond?
(You might agree with Donny here. 
If so, imagine you have been assigned to argue against Donny.)
:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-donny-sim-world-assume-independent}
This is essentially the same issue we discussed in @sol-donny-sim-assume-independent2.
Symbulate requires you to be explicit about all your assumptions.
Symbulate won't let you operate on multiple random variables unless you have been explicit about how they're related.
In particular, Symbulate won't assume random variables are independent unless you explicitly tell it to when you define the `RV`s (e.g., by specifying their joint distribution as the product of their marginal distributions using `*`).
You, like Donny, might want the ability to simulate individual independent random variables separately and then combine the results of the simulations, but that's just not the way Symbulate works.
And it's probably much safer that way because there are many real situations where independence is not a reasonable assumption, and combining the results from independent simulations might lead to wildly inaccurate results.


:::
::::



When working in random variable world, it only makes sense to transform or simulate random variables defined on the same probability space.
Likewise, in simulation world, it only makes sense to apply transformations to values generated in the same simulation, with all assumptions---including indepedence, if appropriate---clearly defined, via a single `sim` step.

The "simulation" step should be implemented in a single call to `sim`, and in that single step you should simulate realizations of all random variables of interest (e.g., with `&`).
Afterwards you can select certain columns of the simulation results using brackets, and manage these columns in simulation world.
For example, if we wanted to sum the rolls in simulation world, we could use the following code^[We wrote this code to compare to the previous block that returned an error. Even though the revised code works, it's clunky because we unpack the rolls and then rejoin them in random variable world and then unpack them again in simulation world. We could simplify a little by not unpacking and rejoining in random variable variable world, using `U = RV(P)`; `u1_and_u2 = U.sim(10)`. This still isn't the preferred way to sum the rolls, but we're just illustrating a few ways to work in both random variable world and simulation world.] which has a single call to `sim` and runs without error.

```{python}
P = BoxModel([1, 2, 3, 4], size = 2)
U1, U2 = RV(P)

u1_and_u2 = (U1 & U2).sim(10)

u1 = u1_and_u2[0]
u2 = u1_and_u2[1]

x = u1 + u2
x
```





### Brief summary of Symbulate commands


We will see a variety of scenarious throughout the book, but many simulations using Symbulate can be carried out with relatively few commands.
The following table comprises the
requisite Symbulate commands for a wide variety of situations.


Command                    Function
-------------------------- -----------------------------------------------------------------------------------------
`BoxModel`                 Define a box model
`ProbabilitySpace`         Define a custom probability space
`RV`                       Define random variables, vectors, or processes
`RandomProcess`            Define a discrete or continuous time stochastic process
`apply`                    Apply transformations
`[]` (brackets)            Access a component of a random vector, or a random process at a particular time
`*` (and `**`)             Define independent probability spaces or distributions
`AssumeIndependent`        Assume random variables or processes are independent
`|` (vertical bar)          Condition on events
`&`                        Join multiple random variables into a random vector
`sim`                      Simulate outcomes, events, and random variables, vectors, and processes
`tabulate`                 Tabulate simulated values
`plot`                     Plot simulated values
`filter` (and relatives)   Create subsets of simulated values (`filter_eq`, `filter_lt`, etc)
`count` (and relatives)    Count simulated values which satisfy some critera (`count_eq`, `count_lt`, etc)
Statistical summaries      `mean`, `median`, `sd`, `var`, `quantile`, `corr`, `cov`, etc.
Common models              `Normal`, `BivariateNormal`, and many others we will see

In addition to Symbulate commands, we can use basic Python commands to

-   define functions to define random variables
-   define for loops to investigate changing parameters
-   customize plots produced by the Symbulate `plot` command (add axis labels, legends, titles, etc)
-   summarize results of multiple simulations in tables and Matplotlib plots (e.g., for different values of problem parameters)

The next section and @sec-sim-matching-n will provide some examples of how we can use Symbulate together with Python (or R) code.


### Working with Symbulate output in Python and R



Symbulate has many built in commands that facilitate the summarization of simulation output in basic plots, tables, and statistics.
However, it is also possible to convert Symbulate output into a *data frame* which can be manipulated using (non-Symbulate) Python or R code.
This section provides a brief introduction.

Let's start with some Symbulate code and output (from the dice rolling simulation in @sec-technology-intro).

```{python}

P = BoxModel([1, 2, 3, 4], size = 2)

X = RV(P, sum)
Y = RV(P, max)

xy = (X & Y).sim(10000)

xy
```

[`pandas`](https://pandas.pydata.org/)---commonly nicknamed as `pd`---is a popular Python package for data science.
We can convert the output of a Symbulate `sim` to a pandas `DataFrame`.

```{python}
#| eval: false

import pandas as pd
```

```{python}
xy_df = pd.DataFrame(xy)

xy_df
```

By default the column names are just their index (0, 1, 2,...), but they can be renamed.

```{python}
xy_df = xy_df.rename(columns={0: "x", 1: "y"})

xy_df
```

Now we can work with the simulation output as we would any pandas `DataFrame`.
Here are just a few examples

```{python}
xy_df["y"].value_counts(normalize = True).sort_index()
```

```{python}
xy_df["x"].value_counts().sort_index().plot.bar()
plt.show()
```

```{python}
pd.crosstab(xy_df["x"], xy_df["y"])
```


R is another popular software environment for statistical computing and graphics.
Symbulate is a Python package, but there are a number of ways to interface between R and Python.
Using an IDE such as Positron, you can toggle between R and Python (as well as other formats). 
The following provides examples of code cells you can include in a Quarto document that you can edit in Positron and run both Python and R code.

Using Quarto, we can first run a Symbulate simulation and convert the output to a pandas `DataFrame` (`xy_df`) using a Python code block.

```{python}
#| echo: fenced

P = BoxModel([1, 2, 3, 4], size = 2)

X = RV(P, sum)
Y = RV(P, max)

xy = (X & Y).sim(10000)

xy_df = pd.DataFrame(xy)

xy_df = xy_df.rename(columns={0: "x", 1: "y"})
```

Now we can use the R package [`reticulate`](https://rstudio.github.io/reticulate/) and access `xy_df` within an R code block (as `py$xy_df`).

```{{r}}

library(reticulate)
```

```{r}
#| echo: fenced

py$xy_df |> head()

```

Now we have an R data frame that we can manipulate using commands from R packages.
For example, we can use the R package `ggplot2` to create visualizations of Symbulate output.

```{{r}}

library(ggplot2)
```


```{r}
#| echo: fenced

xy_df = py$xy_df

N = nrow(xy_df)

ggplot(xy_df,
       aes(x = factor(x), y = factor(y))) +
  stat_bin_2d(aes(fill = after_stat(count / N))) +
  labs(x = "Sum of the two rolls",
       y = "Larger of the two rolls",
       fill = "Proportion of pairs",
       title = "10000 pairs of rolls of a fair four-sided die")
```





## Case Study: Matching Problem {#sec-sim-matching-n}

Dice rolling provides a simple scenario for us to introduce ideas, but it's not very exciting.
Now we'll apply ideas from this chapter to investigate a more interesting problem: the matching problem.
We'll also see how we can combine Symbulate and Python code.
Our analysis will illustrate *sensitity analysis*, where we see how probabilities, distributions, and expected values change as we vary parameters or assumptions. 

Consider the matching problem for a general $n$: objects labeled $1, 2, 3, \ldots, n$ are placed at random in spots labeled $1, 2, 3, \ldots, n$ with spot 1 the correct spot for object 1, etc.
Let the random variable $X$ count the number of objects (out of $n$) that are put back in the correct spot; $X$ is the number of "matches".
Let $\IP$ denote the probability measure corresponding to the assumption that the objects are equally likely to be placed in any spot, so that the $n!$ possible placements are equally.

We have previously considered the case $n=4$ (@exm-matching-outcome, @exm-matching-indicator, @exr-matching-rv-distribution).
By enumerating the $4! = 24$ possible outcomes (see @tbl-matching-outcome and @tbl-matching-indicator-tab) we found the distribution of $X$ when $n=4$, displayed in @tbl-matching-rv-distribution and @fig-matching-rv-distribution.
When $n=4$ the probability of at least one match is 0.625, and the expected value of $X$ is 1.





```{r}
#| label: tbl-matching-rv-distribution
#| echo: false
#| tbl-cap: "Distribution of $X$, the number of matches in the matching problem with $n=4$ and uniformly random placement of objects in spots."

y = c(0, 1, 2, 4)
p = c(9, 8, 6, 1) / 24

kbl(
  data.frame(y, p),
  col.names = c("x", "P(X=x)"),
  booktabs = TRUE,
  digits = 4
) |>
  kable_styling()

```  




```{r}
#| label: fig-matching-rv-distribution
#| echo: false
#| fig-cap: "Distribution of $X$, the number of matches in the matching problem with $n=4$ and uniformly random placement of objects in spots."

ggplot(data.frame(y, p),
       aes(x = y,
           xend = y,
           y = 0,
           yend = p)) +
  geom_segment(linewidth = 1.2, col = "skyblue") +
  # scale_color_manual(values = c("#56B4E9", "#E69F00", "#999999")) +
  scale_x_continuous(breaks = 0:4) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "x",
       y = "P(X = x)")

```




When $n=4$ we could enumerate the $4!=24$ possible outcomes, but such a strategy is not feasible for a general $n$.
For example, if $n=60$ then there are $60! \approx 10^{82}$ possible outcomes, which is about the total number of atoms in the observable universe.
Therefore we need other strategies to investigate the problem.

We'll use simulation to perform a *sensitivity analysis* to investigate how the distribution of $X$, the probability of at least one match, and the expected value of $X$ depend on $n$.

::: {.callout-warning appearance="default"}
This is not really a warning but before proceeding, stop to think: what do you expect?
How do you expect the probability of at least one match to depend on $n$?
Will the probability increase, decrease, or stay about the same as $n$ gets larger?
What about the expected value of the number of matches?
It's always a good idea to think about a problem and make some initial guesses before just jumping into calculations or simulations.
:::


:::: {.callout-note appearance="simple"}
::: {#exm-matching-sim-describe}

For the matching problem for a given $n$, describe in detail how you would use simulation to approximate:
  
1.  The distribution of $X$
1.  $\IP(X \ge 1)$
1.  $\E(X)$.

:::
::::


:::: {.callout-tip collapse=true}
::: {#sol-matching-sim-describe}


We could use a box model.

-   The box has $n$ tickets, labeled $1, 2, \ldots, n$, one for each object.
-   An outcome is simulated by selecting $n$ tickets from the box *without* replacement and recording their order, e.g., (2, 1, 3, 4) if $n=4$.
-   Let $x$ be the number of matches for the simulated outcome, e.g., $x=2$ for outcome (2, 1, 3, 4).
-   The above two steps consist of one repetition, yielding one realized value of the random variable $X$.
-   Repeat these steps many times to obtain many simulated values of $X$.

1.  Summarize the simulated values of $X$ and their relative frequencies to approximate the distribution of $X$.
1.  Count the number of repetitions on which $X\ge 1$ and divide by the total number of repetitions to approximate $\IP(X\ge 1)$, the probability of at least one match.
1.  We have seen that an expected value can be interpreted as a long run average value.
To approximate $\E(X)$, compute the average of the many simulated $X$ values---sum all simulated $X$ values and divide by the number of simulated $X$ values.

:::
::::

We'll start by coding a simulation for $n=4$ so we can compare our simulation results to the analytical results to check that our simulation process is working correctly.
Since Python uses zero-based indexing, we label the objects $0, 1, \ldots, n-1$.

```{python}

n = 4

labels = list(range(n)) # list of labels [0, ..., n-1]
labels

```


Now we define the box model and simulate a few outcomes.
Note that `replace = False`.

```{python}

P = BoxModel(labels, size = n, replace = False)

P.sim(5)

```

We simulate many outcomes to check that they are roughly equally likely.

```{python}

P.sim(24000).tabulate()

```


Remember that a random variable $X$ is a function whose inputs are the sample space outcomes.
In this example the function "counts matches", so would like to define $X$ as `X = RV(P, count_matches)`.
Unfortunately, such a function isn't built in like `sum` or `max`, but we can write a custom `count_matches` Python function.
The `count_matches` function below starts a counter at 0 and then goes spot-by-spot through each spot in the outcome and increments the counter by 1 any time there is a match (along the lines of the discussion in @sec-indicator-rv).
Don't worry too much about the Python syntax yet.
What's important is that we have defined a *function* that we can use to define a random variable.


```{python}

def count_matches(outcome):
    count = 0
    for i in range(0, n, 1):
        if outcome[i] == labels[i]:
            count += 1
    return count
  
outcome = (1, 0, 2, 3) # an example outcome, with 2 matches
count_matches(outcome) # the function evaluated for the example outcome

```


Now we can use the function `count_matches` to define a Symbulate `RV` just like we have used `sum` or `max`.

```{python}

X = RV(P, count_matches)

X((1, 0, 2, 3)) # evaluate X for the sample outcome

```

We can simulate many values of $X$ and use the simulated values to approximate the distribution of $X$, the probability of at least one match, and the expected value of $X$.

```{python}

x = X.sim(10000)

x.tabulate(normalize = True)

```

```{python}

x.plot()
plt.show()

```


```{python}

x.count_geq(1) / x.count()

```

```{python}

x.sum() / x.count()

```

The simulated distribution of $X$ is close to the true distribution in @tbl-matching-rv-distribution when $n=4$; the simulated relative frequencies are within the margin of error (about 0.01-0.02 for 10000 simulated values) of the true probabilities.
We also see that the average of the simulated $X$ values is around the theoretical expected value of 1.


It appears that our simulation is working properly for $n=4$.
To investigate a different value of $n$, we simply need to revise the line `n = 4`.
Because we want to investigate many values of $n$, we wrap all the above code in a Python function `matching_sim` which takes `n` as an input^[Because of the way we defined `count_matches` we need to redefine it if we change `n` and `labels`, which is why `count_matches` is defined inside `matching_sim`.] and outputs our objects of interest: a plot of the distribution of simulated $X$ values, the approximation of $\IP(X \ge 1)$, and the approximation of $\E(X)$. 

```{python}

def matching_sim(n):
  
    labels = list(range(n))
    
    def count_matches(omega):
        count = 0
        for i in range(0, n, 1):
            if omega[i] == labels[i]:
                count += 1
        return count
    
    P = BoxModel(labels, size = n, replace = False)
    X = RV(P, count_matches)
    
    x = X.sim(10000)
    
    plt.figure()
    x.plot('impulse')
    plt.show()
    
    return x.count_geq(1) / x.count(), x.sum() / x.count()

```

For example, for $n=4$ we simply call

```{python}

matching_sim(4)

```

Now we can easily investigate different values of $n$.
For example, for $n=10$ we see that the approximate probability of at least one match is around 0.63 and the approximate expected value of the number of matches is around 1.

```{python}

matching_sim(10)

```

We can use a for loop to automate the process of changing the value of $n$, running the simulation, and recording the results.
If `ns` is the list of $n$ values of interest we basically just need to run

```{python}
#| eval: false

for n in ns:
    matching_sim(n)
```

In Python we can also use list comprehension

```{python}
#| eval: false

[matching_sim(n) for n in ns]
```

The table below summarizes the simulation results for $n=4, \ldots, 10$.
The first line defines the values of $n$, and the second line implements the for loop.
We have used the Python package [`tabulate`](https://pypi.org/project/tabulate/) to add a little formatting to the table.
(Don't confuse this with the Symbulate `tabulate` method!)
Note that we have temporarily redefined `matching_sim` to remove the lines that produced the plot, but we have not displayed the revised code here.
(We will bring the plot back soon.)


```{python}
#| echo: false

def matching_sim(n):
    labels = list(range(n))
    def count_matches(omega):
        count = 0
        for i in range(0, n, 1):
            if omega[i] == labels[i]:
                count += 1
        return count
    
    P = BoxModel(labels, size = n, replace = False)
    X = RV(P, count_matches)
    
    x = X.sim(10000)
    
    # plt.figure()
    # x.plot()
    # plt.show()
    
    return x.count_geq(1) / x.count(), x.sum() / x.count()

```


```{python}
#| eval: false

from tabulate import tabulate 
```



```{python}

ns = list(range(4, 11, 1))

results = [matching_sim(n) for n in ns]

print(tabulate({'n': ns,
                'Approximate P(X >= 1), Approximate E(X)': results},
               headers = 'keys', floatfmt=".3f"))
               
```




Stop and look at the table; what do you notice?
How do the probability of at least one match and the expected value of the number of matches depend on $n$?
They don't!
Well, maybe they do, but they don't appear to change very much with $n$ after we take into account simulation margin of error^[The simulation margin of error for relative frequency of at least one match is about 0.01 based on 10000 simulated values. We haven't discussed simulation margins of error when aproximating expected values yet. In this case, the margin of error for a single average based on 10000 simulated values is about 0.02.] of about 0.01-0.02.
It appears that regardless of the value of $n$, the probability of at least one match is around 0.63 and the expected value of the number of matches is around 1.

If we're interested in more values of $n$, we just repeat the same process with a longer list of `ns`.
The code below uses the Python package [`Matplotlib`](https://matplotlib.org/) to create a plot of the probability of at least one match and the expected value of the number of matches versus $n$.
While there is some natural simulation variability, we see that the probability of at least one match (about 0.63) and the expected value of the number of matches (about 1) essentially do not depend on $n$!

```{python}
#| eval: false

from matplotlib import pyplot as plt
```

```{python}
#| cache: true

ns = list(range(4, 101, 1))

results = [matching_sim(n) for n in ns]

plt.figure()
plt.plot(ns, results)
plt.legend(['Approximate E(X)', 'Approximate P(X >= 1)'])
plt.xlabel('n')
plt.ylabel('value')
plt.show()

```



What about the distribution of $X$?
This [Colab notebook](https://colab.research.google.com/drive/1wqc3ZJhLTKC-zP27WcnT-z-AIh0wBnoS?usp=sharing) contains code for investigating how the distribution of $X$ depends on $n$.
The basic simulation code is identical to what we have already seen.
The notebook adds a few lines to create a Jupyter widget, which produces an interactive plot (with some additional formatting) of the distribution; you can change the slider to see how the distribution of $X$ changes with $n$.
Take a few minutes to play with the slider; what do you see?


You should see that unless $n$ is really small (like 5 or less) the distribution of $X$ is basically the same for any value of $n$!
We will see soon that the number of matches follows, approximately, a "Poisson(1)" distribution, regardless of the value of $n$ (unless $n$ is really small).
In particular, the probability of 0 matches is approximately equal to 0.37, and also approximately equal to the probability of exactly 1 match.



```{r}
#| label: tbl-matching-poisson-distribution
#| echo: false
#| tbl-cap: "Approximate distribution of $X$, the number of matches in the matching problem for general $n$ and uniformly random placement of objects in spots."

y = 0:7
p = dpois(y, 1)

kbl(
  data.frame(y, p),
  col.names = c("x", "P(X=x)"),
  booktabs = TRUE,
  digits = 4
) |>
  kable_styling()

```  





```{r}
#| label: fig-matching-poisson-distribution
#| echo: false
#| fig-cap: "Approximate distribution of $X$, the number of matches in the matching problem for general $n$ and uniformly random placement of objects in spots."

ggplot(data.frame(y, p),
       aes(x = y,
           xend = y,
           y = 0,
           yend = p)) +
  geom_segment(linewidth = 1.2, col = "skyblue") +
  # scale_color_manual(values = c("#56B4E9", "#E69F00", "#999999")) +
  scale_x_continuous(breaks = 0:7) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "x",
       y = "P(X = x)")

```







Summarizing, our sensitivity analysis^[We might also be interested in other sensitivity analyses, such as what if the objects are not placed uniformly at random in the spots.] of the matching problem reveals that, unless $n$ is really small,

-   the probability of at least one match does is approximately 0.632
-   the expected value---that is, long run average--- of the number of matches is approximately 1
-   the distribution of the number of matches is approximately the "Poisson(1)" distribution.

We will investigate these observations further later.
For now, marvel at the fact that no matter if there are 10 or 100 or 1000 people in you next Secret Santa gift exchange, it's roughly 2 to 1 odds in favor of somebody drawing their own name!


### Exercises


::: {#exr-sensitivity-dartboard-bvn}
Katniss throws a dart at a circular dartboard with radius 12 inches.
Suppose that the dartboard is on a coordinate plane, with the center of the dartboard at (0, 0) and the north, south, east, and west edges, respectively, at coordinates (0, 12), (0,-12), (12, 0), (-12, 0).
When the dart hits the board its $(X, Y)$ coordinates are recorded.

Assume that $X$ and $Y$ each follow a Normal(0, $\sigma$), independently. 
Note that it is possible for the dart to land off the board.
Let $R$ be the distance (inches) from the location of the dart to the center of the dartboard.

Combine Symbulate and Python code to perform a sensivity analysis of how the following depend on $\sigma$ (for say values of $\sigma<5$):

-   $\IP(R < 1)$
-   $\IP(R > 12)$ 
-   $\E(R)$
 

:::


## Simulating from distributions

TBA 

## Do not confuse a random variable with its distribution {#sec-rv-versus-distribution}


TBA


## Chapter exercises

TBA


