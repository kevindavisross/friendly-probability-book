[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Friendly Introduction to Probability",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#why-study-probability-and-simulation",
    "href": "index.html#why-study-probability-and-simulation",
    "title": "A Friendly Introduction to Probability",
    "section": "Why study probability and simulation?",
    "text": "Why study probability and simulation?\nWhy study probability?\n\nProbability is the study of uncertainty, and life is uncertain\nProbability is used in a wide variety of fields, including: statistics, physics, engineering, biology, medicine, finance, actuarial science, political science, law, sports , …\nMany topics and problems in probability are frequently misunderstood and sometimes counter intuitive, so it’s worthwhile to take a careful study\n“Probabilistic thinking” is an important component of statistical literacy (e.g. how to assess risk when making decisions)\nProbability provides the foundation for many important statistical concepts and methods such as p-values and confidence intervals\n\nWhy use simulation to study probability?\n\nMany concepts encountered in probability can seem esoteric; simulation helps make them more concrete.\nSimulation provides an effective tool for analyzing probability models and for exploring effects of changing assumptions\nSimulation can be used to check analytical solutions\nSimulation is often the best or only method for investigating many problems which are too complex to solve analytically\nSimulation allows for statistical approaches to solving probability problems (e.g., treat the simulated values as data to summarize and analyze)\nSimulation-based reasoning is an important component of statistical literacy (e.g., understanding a p-value via simulation)\nMany statistical procedures employ simulation-based methods (e.g. bootstrapping)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#learn-by-doing",
    "href": "index.html#learn-by-doing",
    "title": "A Friendly Introduction to Probability",
    "section": "Learn by doing",
    "text": "Learn by doing\n\n\n\n\n\n\nThere are many examples in this book. Examples are used to both motivate new topics and to help you practice your understanding of the material. You should attempt the examples on your own before reading the solutions. To encourage you to do so, the solutions have been hidden.\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\nYou can reveal the solution by clicking on the “Solution (click to expand)” button.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#dont-do-what-donny-dont-does",
    "href": "index.html#dont-do-what-donny-dont-does",
    "title": "A Friendly Introduction to Probability",
    "section": "Don’t do what Donny Don’t does",
    "text": "Don’t do what Donny Don’t does\nSome of the examples in this book feature a character named Donny Don’t. The moral of these examples is (usually) “Don’t do what Donny Don’t does”. (This is a Simpson’s reference.) Donny represents a student who makes many of the mistakes commonly made by students studying probability. The idea of these problems is for you to learn from the common mistakes that Donny makes, by identifying why he is wrong and by helping him understand and correct his mistakes. But be careful: sometimes Donny is right!",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "A Friendly Introduction to Probability",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the completion of this book, you should be able to:\n\nInterpret conditional and unconditional probabilities and expected values\nIdentify coherent probability models, events and random variables\nApply common probability models in real contexts\nDesign simulation studies to investigate random phenomena\nAnalyze simulation results\nSolve probability problems using mathematical properties and tools\nDescribe distributions of random variables\nConstruct representations of distributions",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#symbulate",
    "href": "index.html#symbulate",
    "title": "A Friendly Introduction to Probability",
    "section": "Symbulate",
    "text": "Symbulate\nThis book uses the Python package Symbulate which provides a user friendly framework for conducting simulations involving probability models. The syntax of Symbulate reflects the “language of probability” and makes it intuitive to specify, run, analyze, and visualize the results of a simulation. In Symbulate, probability spaces, events, random variables, and random processes are symbolic objects which can be manipulated, independently of their simulated realizations. Symbulate’s consistency with the mathematics of probability reinforces understanding of probabilistic concepts. The article (Ross and Sun 2019) discusses Symbulate and its features in more detail.\nThe best way to interact with Symbulate is through Google Colab or Jupyter notebooks. A notebook is organized by cells which contain text or code that can be run interactively with output displayed after the cell.\nSymbulate can be run online in a Colab notebook by including the following line in the first cell.\n\npip install git+https://github.com/kevindavisross/symbulate\n\nSymbulate can also be used in RMarkdown or Quarto documents, if you install the package on your device. To install Symbulate on your own computer, it is recommended that you first install the Anaconda distribution, which is a Python environment with many scientific packages installed (including all of the packages that Symbulate is built on). After installing Anaconda, you can install Symbulate using the pip command above.\nYou should always include the following command once in each notebook to import Symbulate during a Python session.\n\nfrom symbulate import *\n\nThe Symbulate command plot() produces graphics. These graphics can be customized (by changing axis limits, adding titles, legends, etc) using Matplotlib, and in particular the pyplot method, which can be imported by including the lines\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nColab or Jupyter notebooks provide a natural interface for Symbulate. The code in this book matches as closely as possible the commands that would be entered into cells in a notebook. However, certain commands that appear throughout the book are needed only to properly produce the output in this book, and not if working directly in notebooks (e.g., some print statements, instances of plt.figure() or plt.show())",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "A Friendly Introduction to Probability",
    "section": "About this book",
    "text": "About this book\nThis book was created with Quarto.\n\n\n\n\nRoss, Kevin, and Dennis L. Sun. 2019. “Symbulate: Simulation in the Language of Probability.” Journal of Statistics Education 27 (1): 12–28. https://doi.org/10.1080/10691898.2019.1600387.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "literacy-probability.html",
    "href": "literacy-probability.html",
    "title": "1  What is Probability?",
    "section": "",
    "text": "1.1 Randomness\nWe hear the word “probability” often. Here are just a few quotes from recent online articles which mention probability.\nYou have some familiarity with the words “probability”, “chance”, “odds”, or “likelihood” from everyday life. But what do we really mean when talk about “probability”?\nThis chapter provides a brief but non-technical introduction to randomness and probability. Many of the topics introduced in this chapter will be covered in much more detail in later chapters.\nA wide variety of situations involve probability. Consider just a few examples.\nThe subject of probability concerns random phenomena.\nSome phenomena involve physical randomness, like flipping coins, rolling dice, drawing Powerballs at random from a bin, or random digit dialing. In many other situations randomness just vaguely reflects uncertainty. We will refer to as “random” any scenario that involves a reasonable degree of uncertainty.\nIn this book, “random” and “uncertain” are synonyms. Unfortunately, some of the everyday meanings of “random”, like “haphazard” or “unexpected”, are contrary to what we mean by “random” in this book. For example, we would consider Steph Curry attempting a free throw to be a random phenomenon because we’re not certain if he’ll make it or miss it; but we would not consider this process to be haphazard or unexpected.\nRandom does not necessarily mean equally likely. In a random phenomenon, certain outcomes or events might be more or less likely than others. For example,\nUncertainty is not something to be feared, and randomness is often desirable. In particular, many statistical applications often employ the planned use of randomness with the goal of collecting “good” data. For example,",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-randomness",
    "href": "literacy-probability.html#sec-randomness",
    "title": "1  What is Probability?",
    "section": "",
    "text": "The probability that you roll doubles in a turn of a board game.\nThe probability you win the next Powerball lottery if you purchase a single ticket, 4-8-15-16-42, plus the Powerball number, 23.\nThe probability that a randomly selected Cal Poly student is a California resident.\nThe probability that the high temperature in San Luis Obispo, CA tomorrow is above 90 degrees F.\nThe probability that Hurricane Martin makes landfall in the U.S in 2028.\nThe probability that the Philadelphia Eagles win the next Superbowl.\nThe probability that the Republican candidate wins the 2032 U.S. Presidential Election.\nThe probability that extraterrestrial life currently exists somewhere in the universe.\nThe probability that Alexander Hamilton actually wrote 51 of The Federalist Papers. (The papers were published under a common pseudonym and authorship of some of the papers is disputed.)\nThe probability that you ate an apple on April 17, 2019.\n\n\n\n\n\n\n\n\nExample 1.1 What is one feature that all of the situations have in common? How are the situations above similar, and how are they different? Is the interpretation of “probability” the same in all situations? The goal here is to just think about these situations, and not to compute any probabilities (or to even think about how you would).\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.1. This example is intended to motivate discussion, so you might have thought of some other ideas we don’t address here. That’s good! And some of the things you considered might come up later in the book. Here are a few observations.\nThe one feature that all of the situations have in common is uncertainty. Sometimes the uncertainty arises from a physical phenomenon that can result in multiple potential outcomes, like rolling dice or drawing the winning Powerball number. In other cases, there is uncertainty because there will be only one outcome but it is in the future, like tomorrow’s high temperature or the result of the next Superbowl. But there can also be uncertainty about the past: there are some Federalist papers for which the author is unknown, and you probably don’t know for sure whether or not you ate an apple on April 17, 2019.\nWhenever there is uncertainty, it is reasonable to consider the relative likelihood or plausibility of possibilities. For example, even though you don’t know for certain whether you ate an apple on April 17, 2019, you might think the probability is high if you’re usually an apple-a-day person (or you were in 2019). We don’t know for sure what team will win the next Superbowl, but we might think that the Eagles are more likely than the Cleveland Brows to be the winner.\nWhile all of the situations in this example involve uncertainty, it seems that there are different “types” of uncertainty. Even though we don’t know which side a die will land on, the notion of “fairness” implies that the sides are “equally likely”. Likewise, there are some rules to how the Powerball drawing works, and it seems like these rules should determine the probability of drawing that particular winning number.\nHowever, there aren’t any specific “rules of uncertainty” that govern whether or not you ate an apple on April 17, 2019. You either did or you didn’t, but that doesn’t mean these two possibilities are necessarily equally likely or plausible. Regarding the Superbowl, of course there are rules that govern the NFL season and playoffs, but there are no “rules of uncertainty” that tell us precisely how likely any particular team is to win any particular game, let alone how likely a team is to advance to and win the Superbowl.\nIt also seems that there are different interpretations of probability. Given that a six-sided die is fair, we might all agree that the probability that it lands on any particular side is 1/6. Similarly, given the rules of the Powerball lottery, we might all agree on the probability that a drawing results in a particular winning number. However, there isn’t necessarily consensus about what the high temperature will be in San Luis Obispo tomorrow; different weather prediction models, forecasters, or websites might provide different values for the probability that the high temperature will be above 90 degrees Fahrenheit. Similarly, Superbowl odds might vary by source. Situations like tomorrow’s weather or the Superbowl where there is no consensus about the “rules of uncertainty” require some subjectivity in determining probabilities.\nFinally, some of these situations are naturally repeatedable. We could (in principle) roll a pair of dice many times and see how often we get doubles, or repeat the Powerball drawing over and over to see how the winning numbers behave. However, many of these situations involve something that only happens once, like the next Superbowl, tomorrow, or April 17, 2019. Even when the phenomenon happens only once in reality, we can still develop models of what might happen if we were to hypothetically repeat the phenomenon many times. For example, meteorologists use historical data and meteorological models to forecast many potential paths of a hurricane.\n\n\n\n\n\n\nDefinition 1.1 A phenomenon is random if there are multiple potential possibilities, and there is uncertainty about which possibility is realized. Uncertainty is understood in broad terms, and in particular does not only concern future occurrences.\n\n\n\n\n\nAbout 84% of students at Cal Poly are California residents, so it’s more likely than not that a randomly selected Cal Poly student is a California resident.\nNot all NFL teams are equally likely to win the next Superbowl.\n\n\n\nRandom selection involves selecting a sample of individuals at random from a population (e.g., via random digit dialing), with the goal of selecting a representative sample.\n\nRandom assignment involves assigning individuals at random to groups (e.g., in a randomized experiment), with the goal of constructing groups that are similar in all aspects so that the effect of a treatment (like a new vaccine) can be isolated.\n\n\n1.1.1 Exercises\n\nExercise 1.1 For each of the following, provide examples of random phenomenon that fit the description. Try to think of examples that are interesting to you personally!\n\nJust two possible outcomes, but they are not equally likely.\nPhysically repeatable (at least in principle).\nWell defined “rules of randomness”.\nInvolves subjectivity in determining probabilities.\nInvolves uncertainty about the future.\nInvolves uncertainty about the present or past.\nAssociated with the planned use of randomness in a particular statistical study.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-interpretations",
    "href": "literacy-probability.html#sec-interpretations",
    "title": "1  What is Probability?",
    "section": "1.2 Interpretations of probability",
    "text": "1.2 Interpretations of probability\n\nThe probability of an event associated with a random phenomenon is a number in the interval \\([0, 1]\\) measuring the event’s likelihood, degree of uncertainty, or relative plausibility. A probability can take any value in the continuous scale from 0 to 1, and can be reported either as a decimal (e.g., 0.305) or as a percent (e.g., 30.5%).\n\nA few examples of probabilities:\n\nThe probability that a fair coin lands on heads 5 times in 10 flips is 0.246.\nA group of people all put their names in a hat for a Secret Santa gift exchange; the probability that at least one person in the group draws their own name is 0.632.\nThe probability that a randomly selected full term baby weighs more than 4000 grams at birth is 0.09.\nThe probability that a magnitude 5+ earthquake occurs somewhere in the world within the next 48 hours is 0.96.\nAccording to FiveThirtyEight as of Nov 8, 2016, the probability that Donald Trump would win the 2016 U.S. Presidential Election was 0.286.\n\nThroughout this book we will see many methods for computing and approximating probabilities such as these. But given the value of a probability, what does it mean? For example, what does it mean for there to be a “30% chance of rain tomorrow”? Just as there are various types of randomness, there are a few ways of interpreting probability, most notably, long run relative frequency and subjective probability.\n\n1.2.1 Long run relative frequency\nOne of the oldest documented1 problems in probability is the following: If three fair six-sided dice are rolled, what is more likely—a sum of 9 or a sum of 10? Let’s try to answer this question by simply rolling dice and seeing what happens. Roll three fair six-sided dice, find the sum, and repeat; then see how often we get a sum of 9 versus a sum of 10. Table 1.1 displays the results of a few repetitions. We encourage you to try this out on your own now; of course, your results will naturally be different from ours.\n\n\n\n\nTable 1.1: Results of 10 sets of three rolls of a fair six-sided die.\n\n\n\n\n\n\nRepetition\nFirst roll\nSecond roll\nThird roll\nSum\n\n\n\n\n1\n3\n6\n3\n12\n\n\n2\n1\n2\n4\n7\n\n\n3\n4\n2\n4\n10\n\n\n4\n2\n2\n1\n5\n\n\n5\n4\n6\n1\n11\n\n\n6\n5\n1\n2\n8\n\n\n7\n3\n1\n3\n7\n\n\n8\n5\n5\n6\n16\n\n\n9\n5\n6\n3\n14\n\n\n10\n4\n5\n2\n11\n\n\n\n\n\n\n\n\nA sum of 9 occurred in 0 repetitions and a sum of 10 occurred in 1 repetition. We see that a sum of 10 occurred more frequently than a sum of 9, but our results should not be very convincing. After all, we only performed 10 repetitions and your results are probably different than ours. We can get a much better picture by performing many, many repetitions. This would be a time consuming process by hand, but it’s quick and easy on a computer. We can have a computer simulate, say, one million repetitions—each repetition resulting in the sum of three rolls—to produce a table like Table 1.1 but with one million rows instead of 10, and then count how many repetitions result in each possible value of the sum. Figure 1.1 displays the results of such a computer simulation. We’ll see throughout the book how to conduct and analyze computer simulations like this; just focus on the process and results for now. A sum of 9 occurred in 115392 or 11.5% of the one million repetitions, and a sum of 10 occurred in 125026 or 12.5% of repetitions. The simulation results suggest that a sum of 10 is more likely to occur than a sum of 9, because a sum of 10 did occur more often than a sum of 9 when we rolled the dice many times. It seems reasonable to conclude that when rolling three fair six-sided dice the probability that the sum is 10 is greater than the probability that the sum is 9.\n\n\n\n\n\n\n\n\nFigure 1.1: Results of one million sets of three rolls of fair six-sided dice. Sets in which the sum of the dice is 9 (10) are represented by the orange (blue) spike.\n\n\n\n\n\nIn the dice rolling problem we assessed relative likelihoods of a sum of 9 or 10 by repeating the phenomenon many times. The sum of any single set of three rolls is uncertain, but over many sets of three rolls a clear pattern of which sums occur more frequently than others emerges in Figure 1.1. This is the idea behind the relative frequency interpretation of probability. We’ll investigate this idea further in the context of the most iconic random phenomenon: coin flipping.\nWe might all agree2 that the probability that a single flip of a fair coin lands on heads is 1/2, a.k.a., 0.5, a.k.a, 50%. There are only two outcomes, heads (H) and tails (T), and the notion of “fairness” implies that they should be equally likely, so we have a “50/50 chance” of heads. But how else can we interpret this 50%? As in the dice rolling problem, we can consider what would happen if we flipped the coin many times. Now, if we flipped the coin twice, we wouldn’t expect to necessarily see one head and one tail. But in many flips, we might expect to see heads on something close to 50% of flips.\nLet’s try this out. Table 1.2 displays the results of 10 flips of a fair coin. The first column is the flip number (first flip, second flip, and so on) and the second column is the result of the flip (H or T). The third column displays the running number of flips that result in H and the fourth column displays the running proportion of flips that result in H. For example, the first flip results in T so the running proportion of H after 1 flip is 0/1 = 0; the first two flips result in (T, H) so the running proportion of H after 2 flips is 1/2 = 0.5; the first three flips result in (T, H, H) so the running proportion of H after 3 flips is 2/3 = 0.667; and so on. Figure 1.2 plots the running proportion of H by the number of flips. We see that with just a small number of flips, the proportion of H fluctuates considerably and is not guaranteed to be close to 0.5. Of course, the results depend on the particular sequence of coin flips. We encourage you to flip a coin 10 times and compare your results.\n\n\n\n\nTable 1.2: Results and running proportion of H for 10 flips of a fair coin.\n\n\n\n\n\n\nFlip\nResult\nRunning count of H\nRunning proportion of H\n\n\n\n\n1\nT\n0\n0.000\n\n\n2\nH\n1\n0.500\n\n\n3\nH\n2\n0.667\n\n\n4\nH\n3\n0.750\n\n\n5\nT\n3\n0.600\n\n\n6\nT\n3\n0.500\n\n\n7\nT\n3\n0.429\n\n\n8\nT\n3\n0.375\n\n\n9\nT\n3\n0.333\n\n\n10\nH\n4\n0.400\n\n\n\n\n\n\n\n\n.\n\n\n\n\n\n\n\n\nFigure 1.2: Proportion of flips resulting in H versus number of flips for the 10 coin flips in Table 1.2\n\n\n\n\n\nAs in the dice rolling example, we shouldn’t be satisfied with the results of just 10 repetitions. Now we’ll flip the coin 90 more times for a total of 100 flips. Figure 1.3 (a) displays the results, while Figure 1.3 (b) also displays the results for 3 additional sets of 100 flips. The running proportion of H fluctuates considerably in the early stages, but settles down and tends to get closer to 0.5 as the number of flips increases. However, each of the four sets results in a different proportion of heads after 100 flips: 0.41 (gray), 0.49 (orange), 0.52 (blue), 0.53 (green). Even after 100 flips the proportion of flips that result in H isn’t guaranteed to be very close to 0.5.\n\n\n\n\n\n\n\n\n\n\n\n(a) One set of 100 flips.\n\n\n\n\n\n\n\n\n\n\n\n(b) Four sets of 100 flips.\n\n\n\n\n\n\n\nFigure 1.3: Running proportion of H versus number of flips for four sets of 100 coin flips.\n\n\n\nNow we’ll flip the coin 900 more times for a total of 1000 flips in each of the four sets. Figure 1.4 (a) displays the results, while Figure 1.4 (b) also displays the results for 3 additional sets of 1000 flips. Again, the running proportion fluctuates considerably in the early stages, but settles down and tends to get closer to 0.5 as the number of flips increases. Compared to the results after 100 flips, there is less variability between sets in the proportion of H after 1000 flips: 0.498 (gray), 0.485 (orange), 0.506 (blue), 0.462 (green). Now, even after 1000 flips the proportion of flips that result in H isn’t guaranteed to be exactly 0.5, but we see a tendency for the proportion to get closer to 0.5 as the number of flips increases.\n\n\n\n\n\n\n\n\n\n\n\n(a) One set of 1000 flips.\n\n\n\n\n\n\n\n\n\n\n\n(b) Four sets of 1000 flips.\n\n\n\n\n\n\n\nFigure 1.4: Running proportion of H versus number of flips for four sets of 1000 coin flips.\n\n\n\nIn a large number of flips of a fair coin we expect the proportion of flips which result in H to be close to 0.5, and the more flips there are the closer to 0.5 we expect the proportion to be. That is, the probability that a flip of a fair coin results in H, 0.5, can be interpreted as the long run proportion of flips that result in H, or in other words, the long run relative frequency of H.\n\nDefinition 1.2 The probability of an event associated with a random phenomenon can be interpreted as a long run proportion or long run relative frequency: the probability of the event is the proportion of repetitions on which the event would occur in a very large number of hypothetical repetitions of the random phenomenon.\n\nThe concept of long run relative frequency quantifies how often we would expect an event associated with a random phenomenon to occur if the phenomenon were repeated many, many times. The closer the probability is to 1, the more often we would expect the event to occur; the closer the probability is to 0, the less often we would expect the event to occur. Roughly, we would expect an event that has probability 0.9 to occur “90% of the time” in the long run.\nReturning to rolling three fair six-sided dice, we’ll see later that the probability of a sum of 9 is 0.116 (rounded to three decimal places) and the probability of a sum of 10 is 0.125 . Even without knowing how to compute these values we can interpret them as long run relative frequencies. The probability of 0.116 means that in 11.6% of sets of three rolls of fair six-sided dice the sum is 9. The random phenomenon involves a set of 3 rolls, so we consider many sets of 3 rolls, each set resulting in a sum which is either 9 or not. If we roll three fair six-sided dice and find the sum then repeat to get many sets of 3 rolls, we would expect the proportion of sets for which the sum is 9 to be close to 0.116. Indeed this is what we observe in the simulation summarized by Figure 1.1. Likewise, in 12.5% of sets of three rolls of fair six-sided dice the sum is 10. In this sense, a sum of 10 is more likely than a sum of 9; in the long run, a greater proportion of sets of three rolls result in a sum of 10 than a sum of 9.\n\n\n\n\n\n\n\nExample 1.2 In each of the following, write a clearly worded sentence interpreting the numerical value of the probability as a long run relative frequency in context. (Just take the numerical values—0.1, 0.078, 0.25, and 0.73—as given. We’ll see how to compute probabilities like these later.)\n\nThe probability that a roll of a fair ten-sided die lands on 1 is 0.1.\nThe probability that the largest of 5 rolls of a fair ten-sided die is at most 6 is 0.078.\nThe probability that two flips of a fair coin both land on H is 0.25.\nThe probability that in 100 flips of a fair coin the proportion of flips that land on H is between 0.45 and 0.55 is 0.73.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.2. Solution to Exercise 1.2\n\nAbout 10% of rolls of a fair ten-sided result in a roll of 1. The phenomenon is a roll of a far ten-sided die and the event of interest is whether the die lands on 1. If we roll a fair ten-sided die many, many times, we would expect the proportion of rolls that land on 1 to be close to 0.1.\nIn about 7.8% of sets of 5 rolls of a fair ten-sided die, the largest roll is at most 6. In other words, about 7.8% of sets of 5 rolls of a fair ten-sided die contain no rolls greater than 6. The phenomenon involves a set of 5 rolls of a ten-sided die, so we consider many sets of 5 rolls, each set resulting in a largest roll which is either at most 6 or not. (For example, if the 5 rolls are (4, 1, 3, 4, 2) then the largest roll is 4.) If we roll a fair ten-sided 5 times and find the largest roll then repeat to get many sets of 5 rolls, we would expect the proportion of sets for which the largest roll is at most 6 be close to 0.078.\nIn about 25% of sets of two fair coin flips, both flips in the set land on H. The phenomenon involves two flips of a coin, so we consider what would happen over many sets of two flips each.\nIn about 73% of sets of 100 fair coin flips, the proportion of H for the set is between 0.45 and 0.55. The phenomenon involves 100 coin flips, so we consider many sets of 100 coin flips, each set resulting in a proportion of H that is either between 0.45 and 0.55 or not. Imagine adding many more paths to Figure 1.3 (b), each corresponding to a set of 100 flips; we would expect 73% of paths to end in a value between 0.45 and 0.55 after 100 flips.\n\n\n\n\n\nThe relative frequency interpretation of probability is most natural in situations like coin flipping or dice rolling which we can actually physically repeat. In many contexts, the long run relative frequency interpretation, while still valid, is more conceptual and requires us to imagine many hypothetical repetitions of the random phenomenon.\n\n\n\n\n\n\n\nExample 1.3 The weather forecast calls for a 30% chance of rain in your city tomorrow. You ask Donny Don’t to interpret the 30% as a long run relative frequency. Donny says: “it will rain in 30% of the city tomorrow”. You ask him to elaborate; he says: “Well, there are many different locations in the city. In some of the locations it will rain, in some it won’t. It will rain in 30% of the locations, and not in the other 70%. That is, rain will cover 30% of the area of the city, and the other 70% won’t have rain.” Do you agree? If not, how would you interpret the 30% as a long run relative frequency?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.3. Solution to Example 1.3\nOne key to correctly interpreting probabilities is to consider the appropriate random phenomenon. Donny seems to think the random phenomenon involves selecting locations in the city. However, there is a 30% chance of rain in your city tomorrow, so the random phenomenon involves days. Yes, there is only one tomorrow, but there are—at least hypothetically—many days which have weather conditions similar to those forecast for tomorrow. On each of those days it either rains or not. What counts as rain? If we follow the U.S. National Weather Service, on any given day it rains in the city if there is accumulation over the day of at least 0.0254cm (0.01in) of rain at any point in the city. If we imagine manys days with weather conditions similar to those forecast for tomorrow, it will rain on 30% of these days, and on 70% of these days it won’t rain.\nOur interpretation also sheds light on another common misinterpretation. Namely, a 30% chance of rain does not mean “it will rain for 30% of the day tomorrow; that is, it will rain for 7.2 hours tomorrow”.\n\n\n\n\nA simulation involves an artificial recreation of the random phenomenon, usually using a computer. One implication of the relative frequency interpretation is that the probability of an event can be approximated by simulating the random phenomenon a large number of times and determining the proportion of simulated repetitions on which the event occurred. After many repetitions the relative frequency of the event will settle down to a single constant value, and that value is the approximately the probability of the event.\nOf course, the accuracy of simulation-based approximations of probabilities depends on how well the simulation represents the actual random phenomenon. Conducting a simulation can involve many assumptions which impact the results. Simulating many flips of a fair coin is one thing; simulating the evolution of meteorological conditions over time is an entirely different story.\n\n\n\n\n\n\n\nExample 1.4 In the first 7 games of his NBA career, Paolo Banchero attempted 60 free throws and successfully made 44. Donny Don’t says “the probability that Paolo Banchero successfully makes a free throw attempt is 44/60 = 0.733.” Do you agree? Explain.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.4. Donny is correctly computing a relative frequency, but he is confusing the short run with the long run. A probability is a long run relative frequency. The probability that Paolo Banchero successfully makes a free throw can be interpreted as the proportion of free throw attempts that he successfully makes over many attempts. The observed relative frequency of 0.733 is only an approximation of the long run probability. And with only 60 attempts, it’s not necessarily a good approximation of the long run (even if we ignore that players can get better or worse over time).\nThe same considerations apply to players with many more attempts. For example, Giannis Antetokounmpo has attempted over 5000 free throws in his career and successfully made about 70%. But 0.70 is still just an approximation of Antetokounmpo’s true free throw probability since the long run includes all future attempts as well (ignoring that players can get better or worse over time). The difference is that 0.70 is likely a much better estimate of Antetokounmpo’s true free throw probability than 0.733 is of Banchero’s.\n\n\n\n\nBe careful to distinguish between the short run and the long run. Observed relative frequencies based on past data (sometimes called “empirical probabilities”) are only short run approximations to theoretical probabilities which represent long run relative frequencies. The quality of the approximations depends on the extent to which what has happened is representative of all the possibilities that might happen.\nA simulation models the long run. A natural question is: “how many simulated repetitions are required to represent the long run?” We’ll investigate further later. For now we’ll just provide a very rough benchmark: we can generally expect the relative frequency based on 10000 independent repetitions to be within 0.01 of the corresponding probability.\nFinally, recall that contrary to colloquial uses of the word, random does not mean haphazard. Individual outcomes of a random phenomenon are uncertain, but the long run relative frequency interpretation implies a predictable pattern over a large number of (usually hypothetical) repetitions. For example, Figure 1.1 displays a clear distribution of the sum of the rolls of three fair six-sided dice after one million repetitions of the phenomenon. We don’t know what the sum will be when we roll the dice, but we can say that it’s equally likely to be 10 or 11, more likely to be 10 than 9, more likely to be 9 than 8, and so on. Also, we know that if we roll the dice many times, close to 12.5% of sets of three rolls will result in a sum of 10.\n\n\n1.2.2 Subjective probability\nThe long run relative frequency interpretation is most natural in repeatable situations like flipping coins, rolling dice, drawing Powerballs, or randomly selecting U.S. adults (e.g., via random digit dialing). In many other situations, it is difficult to conceptualize the long run. The next Superbowl will only be played once, the 2032 U.S. Presidential Election will only be conducted once (we hope), and there was only one April 17, 2019 on which you either did or did not eat an apple. While these situations are not naturally repeatable they still involve randomness (uncertainty) and it is still reasonable to assign probabilities. At this point in time we might think that the Philadelphia Eagles are more likely than the Cleveland Browns to win the next Superbowl and that a current U.S. Senator is more likely than Dwayne Johnson to win the U.S. 2032 Presidential Election. If you’ve always been an apple-a-day person, you might think there’s a good chance you ate one on April 17, 2019; if you’re allergic to apples, your probability might be close to 0. Even when an uncertain phenomenon is not naturally repeated, it is still reasonable to quantify the relative degree of likelihood or plausibility of related events.\nHowever, the meaning of probability does seem different in physically repeatable situations like coin flips than in single occurrences like the next Superbowl. Let’s switch sports and consider the World Series of Major League Baseball. Consider the 2022 World Series, which the Houston Astros won. As of June 17, 2022,\n\nAccording to FiveThirtyEight, the Los Angeles Dodgers had a 20% chance of winning the 2022 World Series, and the San Diego Padres had an 8% chance.\nAccording to FanGraphs, the Dodgers had a 12.4% chance of winning the 2022 World Series, and the Padres had a 9.9% chance.\nAccording to gambling site Odds Shark, the Dodgers had a 20% chance of winning the 2022 World Series, and the Padres had a 7.7% chance.\n\nEach source, as well as many others, assigned different probabilities to the Dodgers or Padres winning. Which source, if any, was “correct”?\nFor a fair coin flip, we could perform a simulation to verify that the probability that it lands on H is 0.5. Our simulation results would vary, but with enough repetitions we could all agree that the proportion of flips that land on H seems to be converging to 0.5. We could also agree on how to conduct the simulation: each repetition involves a fair coin flip. If we’re concerned about a particular coin being weighted or biased we can simulate the fair coin flip in some other way, such as writing H and T on two cards, shuffling well, and drawing a card. There is no ambiguity about the assumptions—two equally likely outcomes—and in the long run we would reach the same conclusion. That is, we can agree on the “rules” of a fair coin flip, and these rules determine a single value, 0.5, for the probability that it lands on H.\nNow consider a future World Series, say 2030. Even though the actual 2030 World Series will only happen once, we could still perform a simulation involving hypothetical repetitions. However, simulating the World Series involves first simulating the 2030 season to determine the playoff match ups, then simulating the playoffs to see which teams make the World Series, then simulating the World Series match up itself. And simulating the 2030 season involves simulating all the individual games. Even just simulating a single game involves many assumptions; differences in opinions with regards to these assumptions can lead to different probabilities. For example, on June 17, 2022, according to FiveThirtyEight the Dodgers had a 68% chance of beating the Cleveland Guardians in their game that day, but according to FanGraphs it was 66%. Even if the differences in probabilities between sources is small, many small differences over the course of the season could result in large differences in predictions for the World Series champion. (We’re not even considering uncertainty due to any changes in the rules of baseball, MLB, or the world between now and 2030.)\nUnlike physically repeatable situations such as flipping a coin, there is no single set of “rules” for conducting a simulation of a single baseball game between two teams, let alone a whole season of games or the World Series champion. Therefore, there is no single long run relative frequency that determines the probability that a certain team wins the World Series. Instead we consider subjective probability.\n\nDefinition 1.3 A subjective probability (a.k.a. personal probability) of an event associated with a random phenomenon is a number in [0, 1] representing the degree of likelihood, certainty, or plausibility a given individual assigns to the event.\n\nAs the name suggests, different individuals (or probabilistic models) might have different subjective probabilities for the same event. In contrast, in the long run relative frequency interpretation the probability of an event is agreed to be the single number that its long run relative frequency converges to.\nThink of subjective probabilities as measuring relative degrees of likelihood, uncertainty, or plausibility rather than long run relative frequencies. For example, in the FiveThirtyEight forecast, the Dodgers were about 2.5 times more likely to win the 2022 World Series than the Padres (\\(2.5 = 0.20 / 0.08\\)). Relative likelihoods can also be compared across different forecasts or scenarios. For example, FiveThirtyEight assessed that the Dodgers were about 1.6 (\\(1.6 = 0.20 / 0.124\\)) times more likely to win the World Series than FanGraphs did. Also, FiveThirtyEight believed that the likelihood that a fair coin lands on H is about 2.5 (\\(2.5 = 0.5 / 0.2\\)) times larger than the likelihood that the Dodgers would win the 2022 World Series.\n\n\n\n\n\n\n\nExample 1.5 Your favorite local weatherperson forecasts a 30% chance of rain tomorrow and a 60% chance of rain the next day in your city.\n\nExplain how these probabilities are subjective.\nYou ask Donny Don’t to interpret these values as relative degrees of likelihood. Donny says: “Well, 30% is not that big, so it’s not going to rain that hard tomorrow. Also, 60% is twice is big as 30%, so it’s going to rain twice as hard two days from now as it will tomorrow”. Do you agree? Explain.\nDonny says: “Can’t we just look at the data from all the days with weather conditions similar to the ones forecast for tomorrow, and see how often it rained on those days to find the probability of rain tomorrow? No subjectivity about that!” How would you respond?\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.5. \n\nWeather is complicated and depends on many factors. Different models for how meteorological conditions evolve over time based on different assumptions or data can provide different forecasts. One model might predict a 30% chance of rain tomorrow; another might say 25%. There is no one single agreed upon set of “rules”—model, assumptions, data—for forecasting the weather, and therefore there is not a single agreed upon value for the probability of rain tomorrow.\nProbabilities measure degree of uncertainty of whether or not it will rain rather than the severity of any rain. On any single day it either rains or doesn’t; we discussed what counts as rain in Example 1.3. It is two times more likely to rain two days from now than it is tomorrow. It doesn’t matter how hard it rains, if at all, either day. Looking at it another way: if there is a 30% chain of rain then there is a 70% chance that it does not rain tomorrow. Therefore, the weatherperson is more certain—in fact, 1.167 times more certain—that it will not rain tomorrow than they are that it will rain two days from now.\nDonny’s idea is not terrible, but there are still a few issues. First it’s much easier said than done to identify all the days with weather conditions similar to those forecast for tomorrow. There are many variables involved in the weather; which variables do we use and what counts as “similar”? There would still be subjective choices to be made in determining an appropriate reference group of days. Second, even if we identify an appropriate reference group, the relative frequency of rain still only provides an approximation of the probability of rain. The probability measures the degree of likelihood of rain tomorrow, which is a conceptually different quantity from the past frequency of rain on similar days. (We discussed related ideas in Example 1.4.) Finally, Donny has suggested one way of approximating the probability, but there are still many other reasonable approaches which might result in different probabilities.\n\n\n\n\n\nThe chance of rain in your city tomorrow and FiveThirtyEight’s MLB predictions are outputs of probabilistic forecasts. A probabilistic forecast combines observed data and statistical or mathematical models to make predictions. Rather than providing a single prediction such as “it will rain tomorrow” or “the Los Angeles Dodgers will win the 2022 World Series”, probabilistic forecasts provide a range of scenarios and their relative likelihoods. Such forecasts are subjective in nature, relying upon the data used and assumptions of the model. Changing the data or assumptions can result in different forecasts and probabilities. In particular, probabilistic forecasts are usually revised over time as more information becomes available.\nSubjective probabilities can be calibrated by weighing the relative favorability of different bets3, as in the following example.\n\n\n\n\n\n\n\nExample 1.6 What is your subjective probability that Professor Ross (the author) has a TikTok account? Consider the following two bets, and suppose you must choose only one.\n\nYou win $100 if Professor Ross has a TikTok account, and you win nothing otherwise.\nA box contains 40 green and 60 gold marbles that are otherwise identical. The marbles are thoroughly mixed and one marble is selected at random. You win $100 if the selected marble is green, and you win nothing otherwise.\n\n\nWhich of the above bets would you prefer? Or are you completely indifferent? What does this say about your subjective probability that Professor Ross has a Tik Tok account?\nIf you preferred bet B to bet A, consider bet C which has a similar setup to B but now there are 20 green and 80 gold marbles. Do you prefer bet A or bet C? What does this say about your subjective probability that Professor Ross has a Tik Tok account?\nIf you preferred bet A to bet B, consider bet D which has a similar setup to B but now there are 60 green and 40 gold marbles. Do you prefer bet A or bet D? What does this say about your subjective probability that Professor Ross has a Tik Tok account?\nContinue to consider different numbers of green and gold marbles. Can you zero in on your subjective probability?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.6. Since the bets all have the same payouts, you should prefer the one that gives you the greatest probability of winning!\n\nIf you choose bet B, the probability of winning is 0.4 (which we could verify with a simulation).\n\nIf you prefer bet B to bet A, then your subjective probability that Professor Ross has a TikTok account is less than 0.4.\nIf you prefer bet A to bet B, then your subjective probability that Professor Ross has a TikTok account is greater than 0.4.\nIf you’re indifferent between bets A and B, then your subjective probability that Professor Ross has a TikTok account is equal to 0.4.\n\n\nIf you choose bet C, the probability of winning is 0.2.\n\nIf you prefer bet C to bet A, then your subjective probability that Professor Ross has a TikTok account is less than 0.2.\nIf you prefer bet A to bet C, then your subjective probability that Professor Ross has a TikTok account is greater than 0.2.\nIf you’re indifferent between bets A and C, then your subjective probability that Professor Ross has a TikTok account is equal to 0.2.\n\n\nIf you choose bet D, the probability of winning is 0.6.\n\nIf you prefer bet D to bet A, then your subjective probability that Professor Ross has a TikTok account is less than 0.6.\nIf you prefer bet A to bet D, then your subjective probability that Professor Ross has a TikTok account is greater than 0.6.\nIf you’re indifferent between bets A and D, then your subjective probability that Professor Ross has a TikTok account is equal to 0.6.\n\n\nContinuing in this way you can narrow down your subjective probability. For example, if you prefer bet B to bet A and bet A to bet C, your subjective probability is between 0.2 and 0.4. Then you might consider bet E corresponding to 30 gold marbles and 70 green to determine if you subjective probability is greater than or less than 0.3. At some point it will be hard to choose, and you will be in the ballpark of your subjective probability. (Think of it like going to the eye doctor: “which is better: 1 or 2?” At some point you can’t really see a difference.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Bet B with a 0.4 probability of selecting green\n\n\n\n\n\n\n\n\n\n\n\n(b) Bet C with a 0.2 probability of selecting green\n\n\n\n\n\n\n\n\n\n\n\n(c) Bet C with a 0.6 probability of selecting green\n\n\n\n\n\n\n\nFigure 1.5: The three marble bins in Example 1.6.\n\n\n\nOf course, the strategy in the above example isn’t an exact science, and there is a lot of behavioral psychology behind how people make choices in situations like this4, especially when betting with real money. But the example provides a very rough idea of how you might discern a subjective probability of an event. The example also illustrates that probabilities can be “personal”; your information or assumptions will influence your assessment of the likelihood.\nWe close this section with some brief comments about subjectivity. Subjectivity is not bad; “subjective” is not a “dirty” word. Any probability model involves some subjectivity, even when probabilities can be interpreted naturally as long run relative frequencies. For example, assuming a die is fair does not codify an objective truth about the die. Instead, “fairness” reflects a reasonable and tractable mathematical model. In the real world, any “fair” six-sided die has small physical imperfections that cause the six faces to have different probabilities. However, the differences are usually small enough to be ignored for most practical purposes. Assuming that the probability that the die lands on each side is 1/6 is much more tractable than assuming the probability of a 1 is 0.1666666668, the probability of a 2 is 0.1666666665, etc. (Furthermore, measuring the probability of each side so precisely would be extremely difficult.) But assuming that the probability that the die lands on each side is 1/6 is also subjective. We might agree more easily on the probability that a six-sided die lands on 1 than on the probability that the Philadelphia Phillies win the 2030 World Series. But the fact that there can be many reasonable probability models for a situation like the 2030 World Series does not make the corresponding subjective probabilities any less valid than long run relative frequencies.\n\n\n1.2.3 Which interpretation to use?\nIn short, both! Fortunately, the mathematics of probability works the same way regardless of the interpretation. We can—and will—use the long run relative frequency and subjective interpretations interchangeably. When we introduce a new concept or problem we will employ whichever interpretation we think helps us best understand the concept or solve the problem.\nLong run relative frequency and subjective are not the only interpretations of probability. However, we will not delve further into the philosophy of probability5. You might still have questions such as:\n\nIf we flip a coin and cover it before observing what side it lands on, is the flip still random?\nIf we measure precisely all the features that determine the coin’s trajectory and what side it will land on (initial velocity, air resistance, etc.), is the flip still random?\nIs the probability of heads in the previous two cases 0.5? Or 0 or 1? Does it even make sense to talk about the probability of heads if the outcome is determined?\nWhat really is “true randomness”?\n\nYou can debate questions like these with your friends, but our position is that probability is applicable in any situation involving a reasonable degree of uncertainty. If you flip the coin but cover it, the uncertainty of the flip is not resolved so it still makes sense (to us) to say the probability that heads is facing up is 0.5. In practical situations you’re rarely, if ever, going to measure precisely all the features that determine the outcome, so you can still use probability to assess the degree of plausibility of various events. We are certainly ignoring some philosophical issues or questions6, but our brief introduction to instances of randomness and interpretations of probability provides sufficient background for discussing many interesting practical problems in a wide variety of applications.\n\n\n1.2.4 Exercises\n\nExercise 1.2 In each of the following, write a clearly worded sentence interpreting the numerical value of the probability as a long run relative frequency in context. (Just take the numerical values as given for now. We’ll see how to compute probabilities like these later.)\n\nThe probability of rolling doubles when you roll two fair six-sided dice is 1/6.\nThe probability of rolling doubles on three consecutive rolls of two fair six-sided dice is 0.00463.\nThe probability that the sum of 100 rolls of a fair six-sided die is less than 370 is 0.12.\nRoll a fair six-sided die until you roll a 6 three times and then stop. The probability that you roll the die at least 10 times is 0.822.\nThe probability that a randomly selected U.S. adult uses TikTok is 0.2.\n\n\n\nExercise 1.3 Various sources posted odds for who would win the 2024 U.S. Presidential Election. As of June 30, 2023, the website bonus.com listed the following probabilities. (They also assigned probabilities to other candidates that aren’t included here.)\n\n\n\nPotential candidate\nProbability of winning 2024 election\n\n\n\n\nJoe Biden\n44%\n\n\nDonald Trump\n29%\n\n\nRon DeSantis\n19%\n\n\nGavin Newsom\n11%\n\n\nKamala Harris\n5%\n\n\n\n\nAccording to bonus.com as of June 30, 2023, how many times more likely was Joe Biden to win than Gavin Newsom?\nHow many times more likely was Ron DeSantis to not win than to win?\nAnother source listed the probability for Kamala Harris as 10%. How many times more likely was Kamala Harris to win according to this source relative to bonus.com?\nSay it’s October 2032 and we’re trying to predict the outcome of the 2032 U.S. Presidential election. How would a table of probabilities one month before the election compare to a table one year before the election? We obviously can’t predict the future, but in general terms what would you expect? (Hint: the bonus.com predictions were made over a year in advance of the 2024 election, and we see five candidates with not-so-small probabilities. Would you expect that to be true a month before the election?)\n\n\n\nExercise 1.4 Identify your subjective probability of each of the following (to the nearest 0.05 or 0.1 is fine). Explain how you arrived at your value by considering bets like those in Example 1.6.\n\nThe probability that your favorite sports team will win a championship in the next ten years.\nThe probability that you will eventually visit all 50 current U.S. states at some time in your life.\nThe probability that there will be more than 50 U.S. states in 2050.\nThe probability that we live in a multiverse.\nChoose a situation of interest to you and identify your subjective probability!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-consistency",
    "href": "literacy-probability.html#sec-consistency",
    "title": "1  What is Probability?",
    "section": "1.3 Working with probabilities",
    "text": "1.3 Working with probabilities\nIn the previous section we encountered two interpretations of probability: long run relative frequency and subjective. Fortunately, the mathematics of probability work the same way regardless of the interpretation.\n\n1.3.1 Consistency requirements\nAny probability assessment must satisfy some basic logical consistency requirements. Roughly, probabilities cannot be negative and the sum of probabilities over all possibilities must be 1 (or 100%). We will formalize these requirements in mathematical formulas later. For now, we just proceed using intuition.\n\n\n\n\n\n\n\nExample 1.7 As of Jun 21, 2023, FiveThirtyEight listed the following probabilities for who would win the 2023 World Series.\n\n\n\nTeam\nProbability\n\n\n\n\nAtlanta Braves\n19%\n\n\nTampa Bay Rays\n16%\n\n\nLos Angeles Dodgers\n10%\n\n\nHouston Astros\n7%\n\n\nNew York Yankees\n7%\n\n\nOther\n\n\n\n\nAccording to FiveThirtyEight (as of Jun 21, 2023):\n\nAre these probabilities most naturally interpreted as long run relative frequencies or subjective probabilities? Explain.\nWhat must be the probability that the Braves do not win the 2023 World Series?\nWhat must be the probability that either the Braves or the Rays win?\nWhat must be the probability that one of the above five teams is the World Series champion?\nWhat must be the probability that a team other than the above five teams is the World Series champion? That is, what value goes in the “Other” row in the table?\nDonny Don’t says, “These are subjective probabilities, so I can’t use them to perform a simulation.” Explain to Donny how you could conduct a simulation that reflects these probabilities, say using a spinner (like from a kids game).\nWhat would you expect the results of 10000 repetitions of a simulation of the World Series champion to look like? Construct a table summarizing what you expect. Is this necessarily what would happen?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.7. \n\nThese probabilities are most naturally interpreted as subjective probabilities, because there is no single set of “rules”—model, assumptions, data—that determines long run relative frequencies.\n81%. Either the Braves win or they don’t; if there’s a 19% chance that the Braves win, there must be a 81% chance that they do not win in order to account for 100% of the possibilities. If we think of this as a simulation with 10000 repetitions (see the last part), each repetition results in either the Braves winning or not, so if they win in 1900 of repetitions then they must not win in the other 8100.\n35%. There is only one World Series champion, so if say the Braves win then no other team can win. Because “Braves win” and “Rays win” are distinct events we can add their probabilities to find the probability of the event “Braves or Rays win”. Thinking again of the simulation, the repetitions in which the Braves win are distinct from those in which the Rays win. If the Braves win in 1900 repetitions and the Rays win in 1600 repetitions, then on a total of 3500 repetitions either the Braves or Rays win.\n59%. As in the previous part, we can add the five probabilities to see that the probability that one of the five teams above wins must be 59%.\n41%. Either one of the five teams above wins, or some other team wins. If one of the five teams above wins in 5900 repetitions, then in 4100 repetitions the winner is not one of these five teams.\nThese particular values are subjective, but we can still treat them as given and use them to conduct a simulation. Imagine that we construct a spinner7 like in Figure 1.6. Spinning this spinner once simulates a World Series winner according to the given probabilities. We could conduct many repetitions by spinning the spinner many times.\nEach repetition results in a World Series champion and in the long run we would expect the Braves would be the champion in 19%, or 1900, of the 10000 repetitions. We would expect the simulation results to look like\n\n\n\nTeam\nRepetitions\n\n\n\n\nAtlanta Braves\n1900\n\n\nTampa Bay Rays\n1600\n\n\nLos Angeles Dodgers\n1000\n\n\nHouston Astros\n700\n\n\nNew York Yankees\n700\n\n\nOther\n4100\n\n\n\nOf course, there would be some natural variability from simulation to simulation, just like in the sets of 1000 coin flips in Figure 1.4. But the above counts represent about what we would expect.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.6: Spinner representation of the subjective probabilities in Example 1.7.\n\n\n\n\n\nConsistency does not tell us how to assign probabilities to events. Rather, consistency requires that however we assign probabilities they must fit together in a logically coherent way. In the previous example, there is no rule that says the probability that the Braves win must be 0.19; this value is subjective. However, once we have specified that the probability is 0.19, consistency requires that the probability that the Braves do not win must be 0.81.\n\n\n\n\n\n\n\nExample 1.8 Suppose your subjective probabilities for the 2023 World Series champion satisfy the following conditions.\n\nThe Astros and Dodgers are equally likely to win\nThe Rays are 1.5 times more likely than the Astros to win\nThe Braves are 2 times more likely than the Rays to win\nThe winner is as likely to be among these four teams— Braves, Rays, Dodgers, Astros— as not\n\nConstruct a table of your subjective probabilities like the one in Example 1.7.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.8. Here, probabilities are specified indirectly via relative likelihoods. We need to find probabilities that are in the given ratios and add up to 1 ( or 100%). It helps to designate one outcome as the “baseline”. It doesn’t matter which one, though it’s convenient to choose the one with the smallest probability; we’ll choose the Astros.\n\nSuppose the Astros account for 1 “unit”. It doesn’t really matter what a unit8 is, but let’s say it corresponds to 1000 repetitions of a simulation. That is, the Astros win in 1000 repetitions. Careful: we haven’t yet specified how many total repetitions there are, or how many units the entire simulation accounts for. We’re just starting with a baseline of what happens for the Astros.\nThe Astros and Dodgers are equally like to win, so the Dodgers also account for 1 unit.\nThe Rays are 1.5 times more likely than the Astros to win, so the Rays account for 1.5 units. If 1 unit is 1000 repetitions, then the Rays win in 1500 repetitions, 1.5 times more often than the Astros.\nThe Braves are 2 times more likely than the Rays to win, so the Braves account for \\(2\\times 1.5=3\\) units. If 1 unit is 1000 repetitions, then the Braves win in 3000 repetitions.\nThe four teams account for a total of \\(1+1+1.5+3 = 6.5\\) units. Since the winner is as likely to among these four teams as not, then “Other” also accounts for 6.5 units.\nIn total, there are 13 units which account for 100% of the probability. The Astros account for 1 unit, so their probability of winning is \\(1/13=0.077\\) or about 7.7%. Likewise, the probability that the Rays win is \\(3/13=0.231\\) or about 23.1%.\n\n\n\n\nTable 1.3: Table solution for Example 1.8\n\n\n\n\n\n\n\n\n\n\n\n\nTeam\nUnits\nHypothetical repetitions\nProbability (as fraction, decimal)\nProbability (as percent)\n\n\n\n\nAtlants Braves\n3.0\n3000\n3/13 = 0.231\n23.1%\n\n\nTampa Bay Ray\n1.5\n1500\n1.5/13 = 0.115\n11.5%\n\n\nLos Angeles Dodgers\n1.0\n1000\n1/13 = 0.077\n7.7%\n\n\nHouston Astros\n1.0\n1000\n1/13 = 0.077\n7.7%\n\n\nOther\n6.5\n6500\n6.5/13 = 0.500\n50.0%\n\n\nTotal\n13.0\n13000\n1\n100.0%\n\n\n\n\n\n\nYou should verify that all of the probabilities are in the specified ratios. For example, the Braves are 2 times more likely (\\(2 = 0.231 / 0.115\\)) than the Rays to win, and the Rays are 1.5 times more likely \\((1.5 \\approx 0.115 / 0.077)\\) than the Astros to win.\n\n\n\n\nExample 1.8 illustrates one way of formulating probabilities. We start by specifying probabilities in relative terms, and then “normalize” these probabilities so that they add up to 1 (or 100%) while maintaining the ratios. As in the example, it helps to consider one outcome as a “baseline” and to specify all likelihoods relative to the baseline.\nFigure 1.7 provides a visual representation of Example 1.8. The ratios provided in the problem setup are enough to draw the shape of the plot, represented by Figure 1.7 (a) without a scale on the vertical axis. The heights are equal for the Astros and the Dodgers, the height for the Rays is 1.5 times the height for the Astros, the height for the Braves is 2 times the height for the Rays, and if we stacked the bars for the Braves, Rays, Astros, and Dodgers on top of another another they would be as tall as the Other bar. Figure 1.7 (b) simply adds a (vertical) probability axis to ensure the heights of the bars sum to 1. Figure 1.7 (b) represents the “normalization” step, but it does not affect the shape of the plot or the relative heights of the bars.\n\n\n\n\n\n\n\n\n\n\n\n(a) Relative heights without absolute scale.\n\n\n\n\n\n\n\n\n\n\n\n(b) Heights scaled to sum to 1 to represent probabilities.\n\n\n\n\n\n\n\nFigure 1.7: Bar chart representation of the subjective probabilities in Example 1.8.\n\n\n\nThe fact that the probabilities must sum to 1 over all possibilities might seem obvious. Other consistency requirements are more subtle.\n\n\n\n\n\n\n\nExample 1.9 Consider a Cal Poly student who frequently has blurry, bloodshot eyes, generally exhibits slow reaction time, always seems to have the munchies, and disappears at 4:20 each day. Which of the following, A or B, has a higher probability?9 (Assume the two probabilities are not equal.)\n\nA: The student has a GPA above 3.0.\nB: The student has a GPA above 3.0 and smokes marijuana regularly.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.9. A has the higher probability. Many people say B, associating the description of the student with the “smokes marijuana regularly” part of event B. But every student who satisfies event B also satisfies event A, so the probability for event A can’t be any smaller than that of event B.\n\n\n\n\nThe previous example illustrates that our psychological judgment is often inconsistent with the mathematical logic of probabilities, so be careful when interpreting probabilities!\n\n\n1.3.2 Odds\nThe words “probability”, “chance”, “likelihood”, and “odds” are colloquially treated as synonyms. However, in the mathematical language of probability, odds provide a different way of reporting a probability. Rather than reporting probability on a 0 to 1 (or 0% to 100%) scale, odds report probabilities in terms of ratios.\n\n\n\n\n\n\n\nExample 1.10 Continuing Example 1.7, suppose the probability that the Dodgers win the 2023 World Series is 0.10.\n\nWhat is the probability that the Dodgers do not win the 2023 World Series?\nThe odds that the Dodgers win the World Series are “9 to 1 against”. What do you think this means?\nWhat are the odds that the Dodgers do not win the World Series?\nIf the probability that the Rays win is 0.16, what are the odds for the Rays?\nWhat are the odds that either the Dodgers or the Rays win?\nSuppose the San Francisco Giants have 19 to 1 odds against winning. What is the probability that the Giants win the World Series?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.10. \n\nThe probability that the Dodgers win is 0.1, so the probability that they do not win is 0.9.\nThe values in the previous part are in a 9 to 1 ratio: the probability of not winning (0.9) is 9 times greater than the probability of winning (0.1). So the odds against the Dodgers winning the World Series are 9 to 1; “against” because the Dodgers are less likely to win than to not win.\nThe probabilities are still in the 9 to 1 ratio, but we can say that the odds are 9 to 1 in favor of the Dodgers not winning. We could also say the odds are 1 to 9 in favor of the Dodgers winning, but odds are typically reported with the larger value first—9 to 1 instead of 1 to 9.\nThe probability that the Rays win is 0.16 and that they don’t win is 0.84, and \\(0.84/0.16 = 5.25\\). So the odds are 5.25 to 1 against the Rays winning. Odds are often reported as whole numbers, so we could say the odds are 21 to 4 against the Rays winning (since 21/4 = 5.25).\nThe probability that either the Dodgers or the Rays win is 0.16 + 0.10 = 0.26, so the probability that neither of these teams wins is 0.74. The ratio of these values is \\(0.74/0.26 = 2.85\\), so there are 2.85 to 1 odds against the winner being either the Dodgers or the Rays (or 57 to 20 in whole numbers). (Notice that 2.85 is not related in a simple way to the previous values 9 and 5.25.)\nThe odds tell us that the probability that the Giants do not win is 19 times greater than the probability that they do win. Let the event that the Giants win account for 1 “unit” so that the event that they do not win accounts for 19 units, for a total of 20 units. Then10: the probability that the Giants win is \\(1/20 = 0.05\\). Note that the probability of not winning, \\(19/20 = 0.95\\), is 19 times greater than the probability of winning.\n\n\n\n\n\n\nDefinition 1.4 The odds of an event is a ratio involving the probability that the event occurs and the probability that the event does not occur. Odds can be expressed as either “in favor” of or “against” the event occurring, depending on the order of the ratio.\n\n\\[\n\\begin{aligned}\n\\text{odds in favor of an event} & = \\frac{\\text{probability that the event occurs}}{\\text{probability that the event does not occur}} \\\\\n& \\\\\n\\text{odds against an event} & = \\frac{\\text{probability that the event does not occur}}{\\text{probability that the event occurs}}\\end{aligned}\n\\]\nIn many situations odds are typically reported as odds against. While the odds of an event is a just a single number, odds are often reported as a ratio of whole numbers, e.g., 11 to 1, 7 to 2. \nAs discussed at the end of Section Section 1.2.2 bets can be used to discern probabilities or odds.\n\n\n\n\n\n\n\nExample 1.11 Ron and Leslie agree to the following bet. They’ll ask Professor Ross if he has a TikTok account. If he does, Leslie will pay Ron $200; if not, Ron will pay Leslie $100. (Neither has any direct information about whether or not Professor Ross has a TikTok account.)\n\nGiven this setup, which of the following is being judged as more likely: that Professor Ross has a TikTok account, or that he does not? Why?\nWhat are this bet’s odds?\nRon and Leslie agree that this is a fair bet, and neither would accept worse odds. What is their subjective probability that Professor Ross has a TikTok account?\nSuppose they were to hypothetically repeat this bet many times, say 3000 times. Given the probability from the previous part, how many times would you expect Leslie to win? To lose? What would you expect Leslie’s net dollar winnings to be? In what sense is this bet “fair”? (Remember: Leslie’s winnings are Ron’s losses and vice versa.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.11. \n\nThe larger potential payout corresponds to the less likely event. So they think Professor Ross is more likely to not have a TikTok account than to have one.\nThe payouts are in a 2 to 1 ratio, so the odds that Professor Ross has a TikTok account are 2 to 1 against.\nThe odds that Professor Ross has a TikTok account are 2 to 1 against, so Professor Ross is twice as likely to not have a TikTok account than to have one. This corresponds to a subjective probability11 that Professor Ross has a TikTok account of 1/3 (and a probability that he does not have one of 2/3).\nThe probability that Leslie wins is 2/3, so you would expect her to win in 2000 of the 3000 repetitions. She wins $100 each time she wins, so you would expect her to win a total of $200,000 on games she wins. The probability that she loses is 1/3, so you would expect her to lose in 1000 of the 3000 repetions. She loses $200 each time, so you would expect her to lose a total of $200,000 on the games she loses. So you would expect Leslie’s net winnings to be 0, and likewise for Ron. The bet is fair in the sense that neither party is expected to profit or lose in the long run.\n\n\n\n\n\n\n\n\n\n\nWinner\nExpected number of repetitions\nLeslie’s winnings per repetition ($)\nLeslie’s expected total winnings ($)\n\n\n\n\nLeslie\n2000\n100\n200,000\n\n\nRon\n1000\n-200\n-200,000\n\n\nTotal\n3000\nNA\n0\n\n\n\n\n\n\n\nThe previous example illustrates that the odds of a fair bet on whether or not an event will occur, determined by the ratio of the payouts, imply a probability for the event.\n\\[\\begin{align*}\n\\text{probability that event occurs} & = \\frac{\\text{odds in favor of the event}}{1+\\text{odds in favor of the event}}\\\\\n& \\\\\n& = \\frac{1}{1+\\text{odds against the event}}\n\\end{align*}\\]\nWe have defined odds as a ratio of probabilities; these are sometimes called “fractional odds”. But odds can be reported in other ways. In particular, “moneyline odds” (a.k.a., “American odds”) are expressed in terms of the net profit on a 100 dollar bet12. For example, in Example 1.7 the moneyline odds for the Dodgers are +900. This means that someone who bets 100 dollars on the Dodgers to win the World Series would receive 100+900 dollars if the Dodgers actually win, for a net profit of +900 dollars after subtracting the initial stake of 100 dollars. A $100 bet at +900 moneyline odds results in a profit of $900 if the bet is won or a loss of the initial $100 stake otherwise; the amounts 900 and 100 are in a 9 to 1 ratio (against winning), implying a probability of \\(1/(1+9) = 0.10\\) of winning the bet.\n\n\n1.3.3 Why do we need consistency?\nRegardless of the interpretation probabilities must follow basic logical consistency requirements. If these requirements are mistakenly not satisfied, bad things can happen.\n\n\n\n\n\n\n\nExample 1.12 Donny Don’t thinks the Dodgers have a pretty good chance to win the World Series. He thinks their only real competition is the Yankees. The following are Donny’s subjective probabilities for which team will win the World Series.\n\n\n\nTeam\nProbability\n\n\n\n\nLos Angeles Dodgers\n0.50\n\n\nNew York Yankees\n0.25\n\n\nOther\n0.10\n\n\n\n\nWhat is wrong with Donny’s probabilities?\nWhat are Donny’s odds that the Dodgers win? (Consider only Donny’s probability that the Dodgers win13.)\nWould Donny agree to a bet where he pays you $100 if the Dodgers win but you pay him $100 if the Dodgers do not win?\nWhat are Donny’s odds that the Yankees win? Would Donny agree to a bet where he pays you $150 if the Yankees win but you pay him $50 if the Yankees do not win?\nWhat are Donny’s odds that a team other than the Dodgers or Yankees wins? Would Donny agree to a bet where he pays you $180 if an other team wins but you pay him $20 if the winner is either the Yankees or Dodgers?\nSuppose you and Donny agree to make all of the bets in the three previous parts. Consider your net profit for each of the potential outcomes (Dodgers win, Yankees win, other wins). What do you notice? Who would you rather be in this situation: you or Donny?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.12. \n\nDonny’s probabilities do not add up to 1. If we had listed the odds for every outcome (see below) instead of the probabilities, his mistake would have been less obvious.\nDonny’s odds that the Dodgers win are \\(\\frac{0.5}{0.5}=1\\), or even odds.\nDonny believes that the Dodgers are equally likely to win as to not win so, yes, he would agree to this bet with even payouts.\nDonny’s odds that the Yankees do not win are \\(\\frac{0.75}{0.25}=3\\), or 3 to 1 odds against the Yankees winning. Donny believes that the Yankees are 3 times more likely to not win than to win. Since the payouts are in a 3 to 1 ratio with the larger payout corresponding to the Yankees winning (the less likely event), then Donny would agree to this bet.\nDonny’s odds that an other team does not win are \\(\\frac{0.9}{0.1}=9\\), or 9 to 1 odds against an other team winning. Donny believes that an other team is 9 times more likely to not win than to win. Since the payouts are in a 9 to 1 ratio with the larger payout corresponding to an other team winning (the less likely event), then Donny would agree to this bet.\nGiven Donny’s odds for each outcome, he would agree to each of these bets.\n\nIf the Dodgers win, you win the first bet but lose the other two, so your net profit is 100 - 50 - 20 = 30.\nIf the Yankees win, you win the second bet but lose the other two, so your net profit is 150 - 100 - 20 = 30\nIf an other team wins, you win the third bet but lose the other two, so your net profit is 180 - 100 - 50 = 30.\n\nRegardless of the outcome, you are guaranteed to earn a net profit of $30, and Donny is guaranteed to lose a net of $30. That’s free money for you with no risk, and pretty bad business on Donny’s part.\n\n\n\n\n\nThe situation in Example 1.12 is known as a “Dutch book”. A Dutch book14 is a set of probabilities and bets which guarantees a profit, regardless of the outcome of the gamble. Probabilities that fail to satisfy logical consistency requirements allow for the possibility of Dutch books. The fact that no one should ever want to get caught in a Dutch book, like Donny was in the previous problem, is one justification of why even probabilities should satisfy logical consistency requirements.\n\n\n1.3.4 Exercises\n\nExercise 1.5 Various sources posted odds for who would win the 2024 U.S. Presidential Election. As of June 30, 2023, the website bonus.com listed the following probabilities.\n\n\n\nPotential candidate\nProbability of winning 2024 election\n\n\n\n\nJoe Biden\n44%\n\n\nDonald Trump\n29%\n\n\nRon DeSantis\n19%\n\n\nGavin Newsom\n11%\n\n\nKamala Harris\n5%\n\n\n\n\nAccording to bonus.com, what is the probability that either Donald Trump or Ron DeSantis wins the 2024 election?\nAccording to bonus.com, what is the probability that a candidate other than these five wins the 2024 election?\nAccording to bonus.com, is the probability that Joe Biden wins the Democratic nomination greater than, less than, or equal to 44%? Why?\nAccording to bonus.com, what are the odds against Kamala Harris wining the 2024 election?\nSuppose that a source gives Dwayne Johnson 500 to 1 odds of winning. What is the probability that Dwayne Johnson wins?\n\n\n\nExercise 1.6 Suppose that at some point your subjective probabilities for who would win the 2024 U.S. Presidential Election satisfied the following.\n\nJoe Biden is 5 times more likely to win than Kamala Harris, and no other Democratic candidate has a chance of winning\nThe Democratic candidate and the Republican candidate are equally likely to be the winner\nDonald Trump is twice as likely to win as any other Republican candidate.\n\nCreate a table of your subjective probabilities.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#probabilities-proportions-and-percentages",
    "href": "literacy-probability.html#probabilities-proportions-and-percentages",
    "title": "1  What is Probability?",
    "section": "1.4 Probabilities, proportions, and percentages",
    "text": "1.4 Probabilities, proportions, and percentages\nIt is helpful to think of probabilities as proportions—fractions or decimals—or percentages. When dealing with percentages (or proportions or probabilities) be sure to ask “percent of what?” Thinking in fraction terms, be careful to identify the correct reference group which corresponds to the denominator.\n\n\n\n\n\n\n\nExample 1.13 The following two phrases contain exactly the same words, just in different orders. Which is larger, the numerical value of 1 or 2?\n\nThe percentage of men that are greater than six feet tall who play in the National Basketball Association (NBA).\nThe percentage of men that play in the National Basketball Association (NBA) who are greater than six feet tall.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.13. The value of the percentage in (2) is much larger.\n\nThere are over a billion men in the world who are greater than six feet tall, only a few hundred of whom play in the NBA. The percentage of men greater than six feet tall who play in the NBA is pretty close to 0.\nThere only a few hundred men who play in the NBA, almost all of whom are greater than six feet tall. The percentage of men who play in the NBA that are greater than six feet tall is pretty close to 100%.\n\nThink in terms of fractions. The corresponding fractions would have the same numerator—number of men who are both greater than six feet tall and play in the NBA—but vastly different denominators.\n\\[\\begin{align*}\n(1): & \\quad \\frac{\\text{number of men who are greater than six feet tall and play in the NBA}}{\\text{number of men who are greater than six feet tall}}\\\\\n(2): & \\quad \\frac{\\text{number of men who are greater than six feet tall and play in the NBA}}{\\text{number of men who play in the NBA}}\n\\end{align*}\\]\n\n\n\n\nWhen working with multiple percentages (or proportions or probabilities), it is helpful to construct hypothetical tables of counts.\n\n\n\n\n\n\n\nExample 1.14 Are Americans in favor of free tuition at public colleges and universities? Suppose that15\n\n83% of Democrats are in favor of free tuition\n60% of Independents are in favor of free tuition\n39% of Republicans are in favor of free tuition\n\nAlso suppose that16\n\n32% of Americans are Democrats\n42% of Americans are Independents\n26% of Americans are Republicans\n\nWe’ll use this information to investigate the following questions, as well as a few others.\n\nWhat percentage of Americans are in favor of free college tuition?\nWhat percentage of Americans who are in favor of free college tuition are Democrats?\n\n\nDonny Don’t answers the second question: “That’s easy. We’re told that 83% of Americans in favor of free college tuition are Democrats.” Is Donny necessarily correct? Explain without doing any calculations.\nFor the next few parts, consider a hypothetical group of 10000 Americans and assume the percentages provided apply to this group. How many people in the group are Democrats?\nHow many Americans in the group are Democrats who are in favor of free college tuition?\nFill in the counts in each cell of the following “two-way” table.\n\n\n\n\n\n\n\n\n\n\n\nDemocrat\nIndependent\nRepublican\nTotal\n\n\n\n\nIn favor of free tuition\n\n\n\n\n\n\nNot in favor of free tuition\n\n\n\n\n\n\nTotal\n\n\n\n10000\n\n\n\nWhat percentage of Americans in this group who are in favor of free college tuition are Democrats? Answer as unreduced fraction, a decimal (proportion), and a percent.\nSuppose we had started with a hypothetical group of 100,000 Americans. How would the table of counts change? Would the answer to the previous part change?\nNow answer the original question: What percentage of Americans who are in favor of free college tuition are Democrats? Hint: do we need to know how many Americans there are?\nWhat percentage of Americans who are Democrats are in favor of free college tuition? Answer as unreduced fraction, a decimal (proportion), and a percent.\nWhat percentage of Americans are Democrats in favor of free college tuition? Answer as unreduced fraction, a decimal (proportion), and a percent.\nCompare the unreduced fractions for the previous three parts. What is the same? What is different?\nWhat percentage of Americans are in favor of free college tuition? Answer as unreduced fraction, a decimal (proportion), and a percent.\nSuppose that we were only told that 61.9% of Americans overall support free tuition, and that we not given the values 83%, 60%, 39%. Would we be able to complete the two-way table?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.14. \n\nDonny is confusing two different percentages, which refer to two different groups.\n\nWe are given that 83% of Democrats are in favor of free college tuition. This percentage applies to Democrats; among Democrats what percentage are in favor of free college tuition?\nWhat we want is the percent of Americans in favor of free tuition who are Democrats. This percentage applies to Americans in favor of free tuition; among Americans in favor of free tuition what percentage are Democrats?\n\nWe are given that 32% of Americans are Democrats. Of the 10000 Americans, 32%, that is 3200, are Democrats. (\\(10000 \\times 0.32 = 3200\\))\nWe are given that 83% of Democrats are in favor of free college tuition. Out of the 3200 Democrats, 83%, that is 2656 are in favor of free tuition. (\\(3200 \\times 0.83 = 2656\\))\nWe fill in the total count for each party first, then we determine the number who are in favor of free tuition within each party. For example, of the 10000 Americans, 42%, that is 4200, are Independent, and 60% of the 4200 Independents are in favor of free tuition. (\\(4200 \\times 0.6 = 2520\\))\n\n\n\n\n\n\n\n\n\n\n\nDemocrat\nIndependent\nRepublican\nTotal\n\n\n\n\nIn favor of free tuition\n2656\n2520\n1014\n6190\n\n\nNot in favor of free tuition\n544\n1680\n1586\n3810\n\n\nTotal\n3200\n4200\n2600\n10000\n\n\n\nLook at the “in favor” row of the table. Out of 6190 Americans in this group who are in favor of free college tuition, 2656 are Democrats. Since \\(\\frac{2656}{6190}\\approx 0.429\\), about 42.9% of Americans in this group who are in favor of free college tuition are Democrats.\nIf we had started with a hypothetical group of 100,000 Americans for which the given percentages applied, then the count in every cell in the table would be 10 times greater. However, ratios and percentages would still be the same. The answer to the previous part would not change; it would still be \\(\\frac{26560}{61900} =\\frac{2656}{6190}\\approx 0.429\\).\nNow we are interested in Americans in general rather than the 10000 Americans in our hypothetical group. But as the previous part illustrates, the relative percentages will be the same regardless of the size of the group, assuming that the percentages provided in the setup apply to the group. We don’t need to know how many Americans there are; we can just start with a nice round number like 10000 and construct a hypothetical table of counts representing the proper percentages. Since we’re assuming the percentages provided in the setup apply to Americans, we can say that 42.9% of Americans who are in favor of free college tuition are Democrats.\nWe were told that the percentage of Americans who are Democrats that are in favor of free college tuition is 83%. But we can also look at the Democrat column in the table: \\(\\frac{2656}{3200} = 0.83\\). Pay careful attention to the difference in wording between this part and the previous one.\nOut of 10000 Americans, 2656 are Democrats in favor of free college tuition, so \\(\\frac{2656}{10000}= 26.56\\%\\) of Americans are Democrats in favor of free college tuition.\nThere are subtle but important differences in wording between the percentages of interest in the previous three parts. Note that the numerator is the same in each part: 2656, the number of Americans in the group who are both Democrats and in favor of free tuition. But the denominators are different, each corresponding to a different reference group\n\nthe percentage of Americans who are in favor free tuition… (denominator of 6190)\nthe percentage of Americans who are Democrats… (denominator of 3200)\nthe percentage of Americans… (denominator of 10000)\n\nOut of 10000 Americans, 6190 are in favor of free college tuition, so 61.9% of Americans are in favor of free college tuition.\nEven if 61.9% of Americans overall support free tuition, it would not be safe to assume that 61.9% of Democrats support, 61.9% of Independent support, and 61.9% of Republicans support. We would expect support to vary by party, but without such information we would not be able to complete the two-way table.\n\n\n\n\n\nTwo-way tables (a.k.a., contingency tables) of counts are a useful tool for probability problems dealing with two “dimensions” (like political party and free tuition support). For the purposes of constructing the table and computing related probabilities, any value can be used for the hypothetical17 total count18.\nFigure 1.8 provides a visual representation of Example 1.14. The mosaic plot in Figure 1.8 (a) has three bars, each representing a political party. The widths of the bars are scaled based on the proportions of Americans within each party. The breaks within each bar are scaled based on the proportions who do and do not support free tuition within the party. The mosaic plot in Figure 1.8 (b) has the roles of the dimensions reversed, and displays how party affiliation varies based on support for free tuition or not.\n\n\n\n\n\n\n\n\n\n\n\n(a) Support for free tuition within party.\n\n\n\n\n\n\n\n\n\n\n\n(b) Political party affiliation based on support for free tuition or not.\n\n\n\n\n\n\n\nFigure 1.8: Mosaic plots for Example 1.14.\n\n\n\nIn Example 1.14, we needed information about support for free tuition within in each party to fill in the table. That is, it was not enough to know that 61.9% of Americans overall support free tuition. In general, knowing probabilities of individual events alone is not enough to determine probabilities of combinations of them.\n\n\n\n\n\n\n\nExample 1.15 Suppose19 that 47% of American adults20 have a pet dog and 25% have a pet cat.\n\nStart constructing a two-way table. What are the two “dimensions”?\nDonny Don’t says, “72% (which is 47% + 25%) of American adults have a pet dog or a pet cat.” Is that necessarily true? Under what circumstance (however unrealistic) would this be true? Construct a two-way table for this scenario.\nGiven only the information provided, what is the smallest possible percentage of American who adults have a pet dog or a pet cat (or both)? Under what circumstance (however unrealistic) would this be true? Construct a two-way table for this scenario.\nDonny Don’t says that 11.75% (which is 47% \\(\\times\\) 25%) of Americans have both a pet dog and a pet cat. Explain to Donny why that’s not necessarily true. Without further information, what can you say about the percentage of American adults who have both a pet dog and a pet cat?\nFor the remaining parts, suppose that 14% of American adults have both a pet dog and a pet cat. Construct a corresponding two-way table.\nWhat is the percentage of American adults who have a pet dog or a pet cat (or both)?\nDonny Don’t says, “I thought ‘or’ means ‘add’. In Example 1.7 I added 19% and 16% to get the probability that the Braves or the Rays win. Why can’t I add 47% and 25% to get the percentage who have a pet dog or a pet cat?” Explain the difference between the two examples, and help Donny correct his error.\nDonny Don’t says, “Wait, you told me that the percentage who have a pet dog or pet cat includes those who have both, so why are you telling me to subtract 14% after I add 47% and 25%?” Does Donny have a point? Explain.\nWhat percentage of American adults who have a pet cat also have a pet dog? Is it 47%?\nWhat percentage of American adults who do not have a pet cat have a pet dog? Is this the same value as in the previous part?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.15. \n\nThere is a cat dimension—has cat or not—and a dog dimension—has dog or not. The table has four interior cells.\n\n\n\n\nHas dog\nNo dog\nTotal\n\n\n\n\nHas cat\n\n\n\n\n\nNo cat\n\n\n\n\n\nTotal\n\n\n\n\n\n\nDonny’s conclusion isn’t necessarily true because some people have both a pet dog and a pet cat. It’s theoretically possible that 72% have a pet dog or a pet cat, but this would only be true if absolutely no Americans have both a pet dog and a pet cat (which is obviously not realistic). The two-way table corresponding to Donny’s claim is\n\n\n\n\nHas dog\nNo dog\nTotal\n\n\n\n\nHas cat\n0\n25\n25\n\n\nNo cat\n47\n28\n75\n\n\nTotal\n47\n53\n100\n\n\n\nThe situation in the previous part corresponds to the largest possible value, 72%, which occurs when the percentage who have both a dog and cat is as small as possible (0%). Now we consider the reverse situation. The percentage who have both a dog and cat can’t be greater than the percentage who have a cat, 25%. It is theoretically possible for the percentage who have both a dog and cat to be 25%, but only if every person who has a cat also has a dog, which isn’t realistic. The two-way table would be\n\n\n\n\nHas dog\nNo dog\nTotal\n\n\n\n\nHas cat\n25\n0\n25\n\n\nNo cat\n22\n53\n75\n\n\nTotal\n47\n53\n100\n\n\n\nThus the smallest possible percentage of American adults who have a pet dog or a pet cat is 47%.\nIn the first two parts of this problem we have provided two theoretically possible (though unrealistic) scenarios of how Donny’s claim would be false: if no Americans who have a pet cat have a pet dog, and if all Americans who have a pet cat also have a pet dog. Obviously, somewhere between 0% and 100% of Americans who have a pet cat also have a pet dog, but what is this percentage? Donny’s claim would only be true if exactly 47% of American adults who have a pet cat also have a pet dog. (Equivalently, his claim would be true if exactly 25% of American adults who have a pet dog also have a pet cat.) But all we are given is that 47% of American adults in general have a pet dog. The likelihood of having a pet dog could plausibly change based on whether or not the adult has a cat. We need more information about the relationship between pet dog and pet cat ownership before we can determine what percentage of American adults have both. Without further information, all we can say is that between 0% and 25% of Americans have both a pet dog and a pet cat.\nIf 14% of American adults have both a pet dog and a pet cat the two-way table is\n\n\n\n\nHave dog\nNo dog\nTotal\n\n\n\n\nHave cat\n14\n11\n25\n\n\nNo cat\n33\n42\n75\n\n\nTotal\n47\n53\n100\n\n\n\n58% of American adults have a pet dog or a pet cat (58 = 14 + 11 + 33). In other words, 42% of of American adults have neither a pet dog nor a pet cat.\nThe difference between the two examples is that it’s not possible for both the Braves and Rays to win the World Series in the same year, but it is possible for an American adult to have both a pet dog and a pet cat. By adding 47% and 25%, Donny has double-counted the 14% who have both a dog and a cat. Donny can correct for the double-counting by subtracting 14% from his 72%: 47 + 25 - 14 = 58.\nDonny is correct that “or” includes both, so we do want to count those who have both a pet dog and a pet cat. The problem with adding 47% and 25% is that it double-counts both. Think of 47% as 14% + 33% and 25% as 14% + 11%; when we add 47% and 25% we add the 14% twice. We only want to count those who have both a pet dog and a pet cat once, which is why we subtract 14%.\nOut of the 25 (hypothetical) adults who have a pet cat, 14 also have a pet dog, and \\(\\frac{14}{25} = 0.56\\). So 56% of American adults who have a pet cat also have a pet dog. American adults who have a pet cat are more likely than American adults in general to have a pet dog.\nOut of the 75 (hypothetical) American adults who do not have a pet cat, 33 have a pet dog, and \\(\\frac{33}{75} = 0.44\\). So 44% of American adults who do not have a pet cat have a pet dog. American adults with pet cats are more likely than American adults without pet cats to have a pet dog.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion who have a pet dog for those with and without pet cats.\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion who have a pet cat for those with and without pet dogs.\n\n\n\n\n\n\n\nFigure 1.9: Mosaic plots for Example 1.15.\n\n\n\nWe can treat probabilities like proportions or percentages, so what’s the difference? Remember that probabilities measure likelihoods of events corresponding to random (uncertain) phenomena. The probability of an event can be interpreted as a long run proportion. For example, if we randomly select an American adult what is the probability that they have a pet dog? We can imagine repeatedly selecting American adults; if 47% of American adults have a pet dog, then the proportion of randomly selected adults that have a pet dog will converge to 0.47 in the long run. A probability represents a theoretical long run value. A proportion or percentage typically represents an observed short run value. In Example 1.15, we assumed 47%, 25%, and 14% applied to all American adults, but the values actually come from a random sample of just hundreds of American adult respondents.\nIn Example 1.13, switching the places of the words “greater than six feet tall” and “play in the NBA” resulted in two very different percentages. Without going into a grammar lesson, pay careful attention to how probabilities (or proportions or percentages) are worded. Think carefully about what the ordering of the words represents, and look out for words like “if” or “given” which signify information that influences probabilities.\n\n\n\n\n\n\n\nExample 1.16 A NY Times article titled “When They Warn of Rare Disorders, These Prenatal Tests are Usually Wrong” investigated the efficacy of noninvasive prenatal screenings (NIPS, usually blood tests) for microdeletions (small missing pieces of chromosomes) that cause a wide range of conditions. The results of the screenings are used to provide genetic counseling for pregnant women. The article claims the screenings are in widespread use: “One large test maker, Natera, said that in 2020 it performed more than 400,000 screenings for one microdeletion—the equivalent of testing roughly 10 percent of pregnant women in America.”\nWe’ll investigate the screening for 22q11.2 deletion syndrome, a.k.a., DiGeorge syndrome, a disorder caused when a small part of chromosome 22 is missing. Medical problems associated with DiGeorge syndrome include heart defects, poor immune system function, a cleft palate, complications related to low levels of calcium in the blood, and delayed development with behavioral and emotional problems.\nSuppose that if we randomly select a pregnant woman who is screened21\n\nThe probability that the baby actually has DiGeorge syndrome is 0.00025.\nIf the baby has DiGeorge syndrome, the probability that the test returns a positive result22 is 0.9.\nIf the baby does not have DiGeorge syndrome, the probability that the test returns a (false) positive is 0.0026.\n\nWe’ll investigate a few things, but our main question of interest is: If the screening for a randomly selected pregant woman returns a positive result23, what is the probability that the baby actually has DiGeorge syndrome?\n\nBefore proceeding, make a guess for the probability in question; do you think it is closest to 0.1, 0.3, 0.5, 0.7, or 0.9?\nDonny Don’t says, “A baby either has DiGeorge syndrome or not so 0.90 and 0.0026 should add up to 1, and 0.0026 should really be 0.1.” Explain to Donny why 0.9 and 0.0026 don’t need to add to 1, and what 0.1 represents in this context.\nConsidering a hypothetical population of screenings, interpret the probabilities as percents in context.\nConstruct a hypothetical two-way table of counts.\nCompute and interpret the probability that the test returns a positive result. (For this and the remaining parts, express your answer first as an unreduced fraction based on the table, then as a decimal, and interpret the value in words as a percent.)\nCompute and interpret the probability the test result is correct.\nThe value in the previous part seems pretty high. However, explain why we should not assess the effectiveness of the screening based on the probability that the test is correct alone. Hint: consider a separate test that never returns a positive result; what would be the probability that this test is correct?\nRecall the original question: If the screening for a randomly selected pregnant woman returns a positive result, what is the probability that the baby actually has DiGeorge syndrome? Compute and interpret this probability.\nIn light of your original guess, is the previous answer surprising? Explain why the probability is so low. Hint: consider the hypothetical counts in the table.\nIf the screening for a randomly selected pregnant woman returns a positive result, how many times more likely is it for the baby to not have DiGeorge syndrome than to have it?\nCompare the probability of having DiGeorge syndrome before and after the positive test. How much more likely is it for a baby who tests positive to have DiGeorge syndrome than one for whom the test result is unknown?\nIf the screening for a randomly selected pregnant woman does not return a positive result, what is the probability that the baby does not have DiGeorge syndrome?\nNIPS are in widespread use, but what if the tests were only used for pregnant women with known risk factors? Suppose that among pregnant women who have a known risk factor for DiGeorge syndrome24 the probability that the baby has DiGeorge syndrome is 10 times greater, 0.0025 instead of 0.00025. If the screening for a randomly selected pregnant woman with this risk factor returns a positive result, what is the probability that the baby actually has DiGeorge syndrome? How does this compare to the value in part 8?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.19. \n\nWe don’t know what you guessed, but many people guess 0.7 or 0.9. Afterall, it seems like the test is positive for most babies that have DiGeorge syndrome, and positive for only a small percentage of babies that don’t have it. But this argument ignores one important piece of information: most babies do not have DiGeorge syndrome. We’ll see the influence this has below.\nThe probabilities do not need to add to 1 because they apply to different groups: 0.9 to babies with DiGeorge syndrome, and 0.0026 to babies without DiGeorge syndrome. What Donny really needs to consider is this: Among babies with DiGeorge syndrome, the test result is either positive or not. If 0.9 is the probability that a baby with DiGeorge syndrome tests positive, then 0.1 is the probability that a baby with DiGeorge syndrome does not test positive; both probabilities apply to babies with DiGeorge syndrome. Likewise, if 0.0026 is the probability that a baby without DiGeorge syndrome tests positive, then 0.9974 is the probability that a baby without DiGeorge syndrome does not test positive25.\nConsidering a hypothetical population of babies (of pregnant women who are screened):\n\n0.025% of babies have DiGeorge syndrome\n90% of babies with DiGeorge syndrome test positive\n0.26% of babies without DiGeorge syndrome test positive\n\nBe very careful with 0s. For example, mistaking 0.025 percent for 0.025 can have a huge impact.\nThere are two dimensions: whether or not the baby has DiGeorge syndrome, and whether or not the test is positive. Assuming 1000000 babies (of pregnant women who are screened), 0.025% or 250 have DiGeorge syndrome and 999750 do not. Of the 250 who have DiGeorge syndrome, 90% or 225 test positive (\\(225 = 250 \\times 0.9\\)). Of the 999750 who do not have DiGeorge syndrome, 0.26% or 2599 test positive (\\(2599 = 999750 \\times 0.0026\\)).\n\n\n\n\nHas DiGeorge\nDoes not have DiGeorge\nTotal\n\n\n\n\nPositive\n225\n2599\n2824\n\n\nNot positive\n25\n997151\n997176\n\n\nTotal\n250\n999750\n1000000\n\n\n\nImagine we have one million cards and we write “positive” on 2824 of them. Shuffle the cards, select one and note if it is positive or not, then replace the card and repeat. If we repeat this process many times, the proportion of selections that return a positive result will converge to \\(\\frac{2824}{1000000} = 0.0028\\). In practice, we randomly select a pregnant woman who is screened and see if the test result is positive. In the long run, 0.28% of pregnant women who are screened test positive for DiGeorge syndrome.\nThe test is correct for 225 babies who have DiGeorge syndrome and test positive and for 997151 babies who do not have DiGeorge syndrome and do not test positive. \\(\\frac{225 + 997151}{1000000} = 0.9974\\). The test result is correct for 99.74% of pregnant women who are screened for DiGeorge syndrome.\nA screening that never returned a positive result would be correct for all the babies without DiGeorge syndrome and incorrect for all the babies with it, so the probability that this screening is correct is just the probability that a baby does not have DiGeorge syndrome, 0.99975, which is even greater than the value in the previous part. Any screening is going to divide the participants into two groups—those who test positive and those who do not—and we want to consider how effective the test is within each of these groups, not just its overall accuracy.\nLook at the “positive” row of the table. Among the 2824 babies who test positive, 225 have DiGeorge syndrome, so the probability that a baby who tests positive has DiGeorge syndrome is \\(\\frac{225}{2824} = 0.0797\\). 7.97% of babies who test positive have DiGeorge syndrome.\nThe value from the previous part seems low to many people. Only 7.97% of babies who test positive actually have DiGeorge syndrome? The counts in the table help us see why this value is so low. It is true that the test is correct for most babies with DiGeorge syndrome (225 out of 250) and incorrect only for a small proportion of babies without DiGeorge Syndrome (2599 out of 999750). But since relatively few babies have DiGeorge syndrome, the sheer number of false positives (2599) swamps the number of true positives (225). A high percentage of the positive tests are due to babies who do not have DiGeorge syndrome; that is, most of the positives are false positives. See Figure 1.10 for an illustration.\nThe probability that a baby who tests positive does not have DiGeorge syndrome is \\(\\frac{2599}{2824} = 0.9203\\). A baby who tests positive is 11.55 times more likely to not have DiGeorge syndrome than to have it. (\\(\\frac{0.9203}{0.0797} = 11.55\\))\nBefore observing the test result, the probability that a baby has DiGeorge syndrome is 0.00025. The probability that a baby who tests positive has DiGeorge syndrome is \\(0.0797\\). A baby who tests positive is about 319 times more likely to have DiGeorge syndrome than a baby for whom the test result is not known (\\(\\frac{0.0797}{0.00025} = 319\\)). So while 0.0797 is still small in absolute terms, the probability of having DiGeorge syndrome given a positive test is much larger relative to the probability of having DiGeorge syndrome before the test result is known.\nLook at the “not positive” row of the table. Among the 997176 babies who do not test positive, 997151 do not have DiGeorge syndrome, so the probability that a baby who does not test positive does not have DiGeorge syndrome is \\(\\frac{997151}{997176} = 0.999975\\). In contrast to the positives, almost all of the negative results are true negatives.\nRedo the table with 0.00025 replaced by 0.0025.\n\n\n\n\nHas DiGeorge\nDoes not have DiGeorge\nTotal\n\n\n\n\nPositive\n2250\n2594\n4844\n\n\nNot positive\n250\n994906\n995156\n\n\nTotal\n2500\n997500\n1000000\n\n\n\nAmong pregnant women with this risk factor, the probability that a baby actually has DiGeorge syndrome given a positive test is \\(\\frac{2250}{4844} = 0.464\\). The probability of having a baby with DiGeorge syndrome given a positive test is 5.83 times greater among those with this risk factor than for pregnant women in general. (\\(0.464 / 0.0797 = 5.83\\).)\n\n\n\n\n\nRemember to ask “percentage of what”? For example, the percentage of babies who have DiGeorge syndrome that test positive is a very different quantity than the percentage of babies who test positive that have DiGeorge syndrome.\nLikewise, always ask “probability of what”? For example, the probability that a baby who has DiGeorge syndrome tests positive is a very different quantity than the probability that a baby who tests positive has DiGeorge syndrome; in the first probability we are given that the baby has DiGeorge syndrome, in the second that the baby tests positive. Probabilities are often conditional on information; look out for words like “if” or “given” which signify this information. Revising or changing the order of information will usually change probabilities.\n“Posterior” conditional probabilities (e.g., probability of DiGeorge syndrome given a positive test) can be highly influenced by the original unconditional “prior” probabilities (e.g. probability of DiGeorge syndrome), sometimes called the base rates. Example 1.16 and Figure 1.10 illustrate that when the base rate for a condition is very low and the test for the condition is less than perfect there can be a relatively high probability that a positive test is a false positive. The last part of Example 1.16 illustrates how changing the prior unconditional probability (base rate) influences the posterior conditional probability.\n\n\n\n\n\n\n\n\nFigure 1.10: Illustration of Example 1.16. Each dot represents the baby of a randomly selected pregnant woman who is screened; there are 4000 dots. Only one of these 4000 babies has DiGeorge syndrome (4000 * 0.00025 = 1), represented by the dark blue dot in the top left corner. The other 3999 dots represent babies without DiGeorge syndrome. Suppose the baby with DiGeorge syndrome tests positive. Among the 3999 babies without DiGeorge syndrome, 11 test positive (roughly 0.26% of 3999); these false positives are represented by the light blue dots in the first row. There are 12 positive results, only 1 of which is a true positive. That is, the probability that a positive test result is a true positive is 1/12 = 0.083. (The values aren’t quite the same as in Example 1.16 due to some rounding, but the picture conveys the idea.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Conditioning on DiGeorge Syndrome status.\n\n\n\n\n\n\n\n\n\n\n\n(b) Conditioning on test result.\n\n\n\n\n\n\n\nFigure 1.11: Mosaic plots for Example 1.16.\n\n\n\nPeople have a tendency to ignore base rates; you probably did if your original guess in Example 1.16 was 0.7 or 0.9. Don’t neglect the base rates when evaluating probabilities! We will discuss the role that base rates play and how to revise probabilities in light of new information in much more detail later.\nWe close this section with a brief tangent relating to the discussion in Section 1.2.3. In Example 1.16 there is uncertainty due to the random selection, uncertainty about whether the test will be positive or not, and uncertainty that someone who tests positive actually has the condition. You might consider these three different kinds of randomness, with three different interpretations of corresponding probabilities. For example, you might interpret the probability that a randomly selected person has the condition (0.00025) as a long run relative frequency; however, once the person is selected and tests positive they either have the condition or not—we just don’t know for sure—so you might interpret the probability that they have the condition given a positive test (0.0797) differently. The point is: how we interpret the probabilities does not affect how we solve the problem. The probabilities involved in Example 1.16 “fit together” in the same way regardless of the interpretation; given the context and values 0.00025, 0.9, and 0.0026 we must arrive at 0.0797. Furthermore, to make sense of the value 0.0797 we used both long run relative frequency and relative degrees of likelihood interpretations. We will treat many examples like Example 1.16; we will generally not distinguish between different types of randomness, and we will use interpretations of probability interchangeably.\n\n1.4.1 Exercises\n\nExercise 1.7 In each of the following, which is greater: (a) or (b)? Or are they equal? Or is there not enough information to decide?\n\nSurfing\n\nThe probability that a randomly selected Californian likes to surf.\nThe probability that a randomly selected American is a Californian who likes to surf\n\nCal Poly alums\n\nThe probability that a California resident is a Cal Poly alum.\nThe probability that a Cal Poly alum is a California resident\n\n\n\n\nExercise 1.8 Continuing Example 1.15.\n\nIs the overall percentage of American adults who have a pet cat closer to the value in part 9 or part 10? Why do you think that is?\nWhat percentage of American adults who have a pet dog also have a pet cat?\nWhat percentage of American adults who do not have a pet dog have a pet cat?\n\n\n\nExercise 1.9 Continuing Example 1.15. Now suppose that 11.75% of American adults have both a pet cat and a pet dog (as Donny claimed was necessarily true). Redo Example 1.15 and Exercise 1.8 under this assumption. What is true in this scenario that wasn’t true in Example 1.15?\n\n\nExercise 1.10 Suppose that you have applied to two graduate schools, A and B. Your subjective probability of being accepted is 0.6 for school A and 0.7 for school B.\n\nWhat is the largest possible probability of being accepted by both schools? Under what scenario (however unrealistic) would this be true? Explain.\nWhat is the smallest possible probability of being accepted by both schools? Under what scenario (however unrealistic) would this be true? Explain.\nExplain why the probability of being accepted by both schools is not necessarily 0.42.\nFor the remaining parts, suppose your subjective probability of being accepted at both schools is 0.55. If you are accepted at school A, what is your probability of also being accepted at school B?\nIf you are accepted at school A, what is your probability of not being accepted at school B?\nIf you are not accepted at school A, what is your probability of being accepted at school B?\nIf you are accepted at school B, what is your probability of also being accepted at school A?\nIf you are not accepted at school B, what is your probability of being accepted at school A?\nHow much more likely are you to be accepted at school A if you are accepted at school B than if you are not accepted at school B?\nHow much more likely are you to be accepted at school A if you are accepted at school B compared to before receiving the decision from school B?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-literacy-conditioning",
    "href": "literacy-probability.html#sec-literacy-conditioning",
    "title": "1  What is Probability?",
    "section": "1.5 Conditioning on information",
    "text": "1.5 Conditioning on information\nA probability is a measure of the likelihood or degree of uncertainty or plausibility of an event. A “conditional” probability revises this measure to reflect any additional information about the outcome of the underlying random phenomenon. In Example 1.16 the probability that a baby has DiGeorge syndrome is 0.00025, but if the screening returns a positive result then the probability increases to 0.0797. Always look out for words like “if” or “given” which signify information that influences probabilities.\n\n\n\n\n\n\n\nExample 1.17 In each of the following parts, which of the two probabilities, (a) or (b), is greater, or are they equal? You should answer conceptually without attempting any calculations.\n\nImagine that you randomly select, from birth records, a person who was born in 1950.\n\nThe probability that a person born in 1950 lives to age 100.\nThe probability that a person born in 1950 lives to age 100 given that they are alive in 2045.\n\nImagine the 2032 U.S. Presidential Election (we’re doing so as of this writing in 2023). Assume (a) and (b) below are not 0.\n\nThe probability that Dwayne “The Rock” Johnson wins the 2032 U.S. Presidential Election.\nThe probability that Dwayne “The Rock” Johnson wins the 2032 U.S. Presidential Election given that he does not win the nomination of the Democratic or the Republican Party.\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.17. \n\nThe probability in (b) is greater. Someone who has already lived to age 95 has a better chance of living at least 5 more years than a person has of living from birth to age 100. Think in fraction terms. The denominator in (a) is all people born in 1950; the denominator in (b) is all people born in 1950 who are alive in 2045. It’s the same numerator in each case—people born in 1950 who live until age 100—but (b) has a much smaller denominator, so the fraction corresponding to (b) is larger.\nThis is more subjective, but our assessment is that the probability in (a) is greater. As of this writing (2023), the 2032 election is still many years away so there is a great deal of uncertainty about who will even run let alone win (to say nothing about uncertainty regarding changes in the U.S. and the world that might happen before 2032 and affect the election). Dwayne Johnson’s name has been tossed around in the media as a potential presidential candidate, so let’s say he has some non-zero probability of winning, represented by (a) (which could be very small). As of this writing, we would assess the probability of someone other than the Democratic or Republican nominee winning a U.S. presidential election to be very small, and some pretty major changes would need to occur in order for us to change that assessment. So the information that Dwayne Johnson is the nominee of neither party would lead us to decrease his probability of winning the election.\n\n\n\n\n\nIn a sense, all probabilities are conditional upon some information, even if that information is vague (“well, it has to be one of these possibilities”). Be careful to clearly identify what information is reflected in probabilities, and don’t make assumptions. In part 1 of Example 1.17 if we’re randomly selecting a person from 1950 birth records, then we shouldn’t assume that the person is alive today when evaluating the probability in (a); the selected person could have died between 1950 and now. That is, “the probability that a person born in 1950 lives to age 100” is not the same as “the probability that a person born in 1950 who is alive today lives to age 100”. In part 2 of Example 1.17, we shouldn’t assume that Dwayne Johnson actually runs for president in 2032; the value of our probability should reflect that uncertainty. That is, “the probability that Dwayne Johnson wins the 2032 U.S. Presidential Election” is not the same as “the probability that Dwayne Johnson wins the 2032 U.S. Presidential Election given that he declares himself a candidate”.\n\n\n\n\n\n\n\nExample 1.18 Consider a group of 5 people: Harry, Fleur, Viktor, Cedric, Angelina. Suppose each of their names is written on a slip of paper and the 5 slips of paper are placed into a hat. The papers are mixed up and 2 are pulled out, one after the other without replacement. (That is, the first paper is not added back to the hat before selecting the second.)\n\nWhat is the probability that Harry is the first name selected?\nWhat is the probability that Harry is the second name selected?\nIf you were asked question (2) before question (1), would your answer change? Should it?\nIf Fleur is the first name selected, what is the probability that Harry is the second name selected?\nIf Harry is not the first name selected, what is the probability that Harry is the second name selected?\nIf Harry is the first name selected, what is the probability that Harry is the second name selected?\nConstruct a hypothetical table corresponding to the results of the draws. Hint: one dimension represents the result of the first draw which is Harry or not, and the other dimension represents the second draw.\nIf Fleur is the second name selected, what is the probability that Harry was the first name selected?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.18. \n\nThe probability that Harry is the first name selected is 1/5, which is an answer we think most people would agree with. There are 5 names which are equally likely to be the first one selected, 1 of which is Harry.\nThe probability that Harry is the second name selected is also 1/5. Many people might answer this as 1/4, since after selecting the first person there are now 4 names left. But we show and discuss below that the unconditional probability is 1/5.\nYour answer to question (2) certainly shouldn’t change depending on whether we ask question (1) first. But perhaps after seeing question (1) you are implicitly assuming that Harry has not been selected first? But there is nothing in question (2) that gives you any additional information about what happened on the first card.\nIf Fleur is the first name selected, the probability that Harry is the second name selected is 1/4. We think most people find this intuitive. If Fleur is first, there are 4 cards remaining, equally likely to be the next card, of which 1 is Harry.\n1/4, similar to the previous part. If Harry is not selected first, there are 4 cards remaining, equally likely to be the next card, of which 1 is Harry.\nIf Harry is the first name selected, the probability that Harry is the second name selected is 0 since the cards are drawn without replacement.\nHere is a two-way table of 1000 hypothetical repetitions. Harry is selected first in \\(1000\\times 1/5 = 200\\) repetitions, in which case he can’t be selected second. Among the 800 repetitions where Harry is not selected first, he is selected second in \\(800\\times 1/4 = 200\\) repetitions. Harry is selected second in 200 of the 1000 total repetitions, so the probability that Harry is selected second is \\(200/1000 = 1/5\\).\n\n\n\n\nHarry first\nHarry not first\nTotal\n\n\n\n\nHarry second\n0\n200\n200\n\n\nHarry not second\n200\n600\n800\n\n\nTotal\n200\n800\n1000\n\n\n\nIf Fleur is the second name selected, the probability that Harry was the first name selected is 1/4. It doesn’t really matter what is “first” and what is “second”, but rather the information conveyed. In part 4, what’s important is that you know that one of the cards selected was Fleur, so the probability that the other card selected is Harry is 1/4. But this part conveys the same information.\n\n\n\n\n\nBe careful to distinguish between conditional and unconditional probabilities. A conditional probability reflects additional information about the outcome of the random phenomenon. In the absence of such information, we must continue to account for all the possibilities. When computing probabilities, be sure to only reflect information that is known. Especially when considering a phenomenon that happens in stages, don’t assume that when considering what happens second that you know what happened first.\nIn Example 1.18, the question “if Harry is not the first name selected, what is the probability that Harry is the second name selected?” involves a conditional probability, since we are given additional information about the outcome; it is no longer possible that Harry was the first name selected. The question “What is the probability that Harry is the second name selected?” involves an unconditional probability. The words “the probability that Harry is the second name selected” alone do not imply that Harry was not selected first; we still need to account for the possibility that Harry was selected first.\nImagine shuffling the five cards and putting two on a table face down. Now point to one of the cards and ask “what is the probability that THIS card is Harry?” Well, all you know is that this card is one of the five cards, each of the 5 cards is equally likely to be the one you’re pointing to, and only one of the cards is Harry. Should it matter whether the face down card you’re pointing to was the first or second card you laid on the table? No, the probability that THIS card is Harry should be 1/5, regardless of whether you put it down first or second.\nNow turn over one other card that you’re not pointing to, and see what name is on it. The probability that the card you’re pointing to is Harry has now changed, because you have some information about the outcome of the shuffle. If the card you turned over says Harry, you know the probability that the card you’re pointing to is Harry is 0. If the card you turned over is not Harry, then you know that the probability that the card you’re pointing to is Harry is 1/4. It is not “first” or “second” that matters; it is whether or not you have obtained additional information by revealing one of the cards.\nAnother way of asking the question is: Shuffle the five cards; what is the probability that Harry is the second card from the top? Without knowing any information about the result of the shuffle, all you know is that Harry should be equally likely to be in any one of the 5 positions, so the probability that he is the second card from the top should be 1/5. It is only after revealing information about the result of the shuffle, say the top card, that the probability that Harry is in the second position changes.\nWe often start with a probability for an event and then revise it whenever additional information becomes available. The original, unconditional probability is called a “prior probability” or “base rate”; the revised, conditional probability is called a “posterior probability”. We will discuss the role that base rates play and how to revise probabilities in light of additional information in much more detail later. But remember: Don’t neglect the base rates when evaluating probabilities!\n\n\n\n\n\n\n\nExample 1.19 Within both the colleges of Agriculture and Architecture at Cal Poly, about 49% of admitted students are female, about 84% of admitted students went to high school in CA, and the median GPA of admitted students is about 4.1.\nAn orientation group of 100 newly admitted Cal Poly students includes 75 students in Agriculture and 25 students in Architecture. A student is randomly selected from this group. The selected student is Maddie, who is female, went to high school in CA, and had a high school GPA of 4.1.\n\nIf you are trying to decide which college Maddie is in, is the information that she is female, went to high school in CA, and had a high school GPA of 4.1 helpful? Why?\nDonny Don’t says, “The information about Maddie applies equally well to Agriculture or Architecture and doesn’t help us decide which college she’s in, so it’s just 50/50. Given the information about Maddie, the conditional probability that she is in Agriculture is 0.5.” Do you agree? If not, what is the conditional probability that Maddie is in the college of Agriculture given the information about her? Hint: what was the last sentence before this example!\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.19. \n\nThe information tells us that Maddie would be pretty typical for either group, so it doesn’t help us decide.\nDonny has neglected the base rate. The group has 75 students in Agriculture and 25 students in Architecture. If we randomly select a student from this group, the unconditional probability that the selected student is in Agriculture is 0.75 (the base rate). Yes, the information about Maddie applies equally well to either college, but that means we have no reason to revise our probability from the base rate. The conditional probability that Maddie is in Agriculture given the information about her is still 0.75.\n\n\n\n\n\nWe use the terminology “unconditional” and “conditional” probability, but any probability is conditional on some information. A better way to think about it might just be “before” and “after”. When new information becomes available we revise our probability. The unconditional (prior) probability is the probability before the revision, reflecting any information that was previously available. The conditional (posterior) probability is the probability after the revision, updated to reflect the newly available information. Probabilities are often updated sequentially as more information becomes available, with the conditional (posterior) probability after one piece of information is received becoming the unconditional (prior) probability before the next.\nDo not think of “unconditional” as “based on no information”. Any probability should reflect as much relevant information as possible, even if it plays the role of an unconditional probability.\n\n\n\n\n\n\n\nExample 1.20 Marge takes a home pregnancy test which turns out positive. She decides to perform an analysis like in Example 1.16 to find the conditional probability that she is actually pregnant given the positive test. She knows she’ll need a base rate—that is, an unconditional probability that she is pregnant before the positive test—so she Googles “what percent of women are pregnant?” Information from the CDC suggests that 10.2% of American women aged 15–44 are pregnant at any point in time. Is 0.102 an appropriate value for Marge to use as her base rate? Or is it too high or too low? How will this influence her conditional probability that she is actually pregnant given the positive test? Explain. Hint: did Marge Google the right question?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.20. The value 0.102 is too low for Marge to use as a base rate, and so her conditional probability that she is actually pregnant given the positive test will also be too low. The idea is that a woman who takes a pregnancy test is more likely to be pregnant than a woman in general, simply because many women who take pregnancy tests do so because they suspect they might be pregnant26.\nIf we randomly select an American woman aged 15-44 to take a pregnancy test, then 0.102 would be an appropriate base rate. But we are not told that Marge is a randomly selected woman, so we should not assume that she is. What we do know is that “Marge took a pregnancy test”. Why? From our perspective, it seems more plausible that she took the test because she suspected she might be pregnant as opposed to just “randomly” deciding to take it. And if there is a reason for her to suspect she might be pregnant, then it’s more likely that she actually is and our base rate should reflect that, resulting in a value greater than 0.102. It should be even clearer from Marge’s perspective; she knows why she took the test (e.g., missed period, morning sickness, etc.) and her personal base rate should reflect her information.\nNow we’re not saying it would be easy to determine what an appropriate base rate is, but it should definitely be greater than 0.102. Whatever the prior probability of pregnancy, it will influence the posterior probability of pregnancy given a positive test. Knowing that the test is positive will lead us to revise our probability of pregnancy upward, but if we start with a prior probability that is too low, then our posterior probability will also be too low. (See the last part of Example 1.16 for a related example.)\n\n\n\n\n\n1.5.1 Exercises\n\nExercise 1.11 In each of the following, which is greater: (a) or (b)? Or are they equal? Or is there not enough information to decide? Answer without doing any computations.\n\nShuffle a standard deck of playing cards (52 cards, 4 of which are aces) and deal 5 cards without replacement.\n\nThe probability that the first card dealt is an ace.\nThe probability that the firth card dealt is an ace.\n\nShuffle a standard deck of playing cards (52 cards, 4 of which are aces) and deal 5 cards without replacement.\n\nThe probability that the first card dealt is an ace.\nThe probability that the fifth card dealt is an ace if the first card dealt is an ace.\n\nRandomly select a college student.\n\nThe probability that the selected student went surfing yesterday.\nThe probability that the selected student went surfing yesterday if they student attends Cal Poly.\n\nBoth ballerinas and football players are graceful and nimble. A group of people contains both some ballerinas and some football players. A person is randomly selected from this group; the person is graceful and nimble.\n\nThe probability that the selected person is a ballerina.\nThe probability that the selected person is a football player.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-probofwhat",
    "href": "literacy-probability.html#sec-probofwhat",
    "title": "1  What is Probability?",
    "section": "1.6 Probability of what?",
    "text": "1.6 Probability of what?\nA probability takes a value in the sliding scale from 0 to 1 (or 0% to 100%). Throughout the book we will study how to compute probabilities in many situations. But don’t just focus on computation. Always remember to interpret probabilities properly. This section covers a few ideas to keep in mind when interpreting probabilities.\n\n\n\n\n\n\n\nExample 1.21 In each of the following parts, which of the two probabilities, a or b, is greater, or are they equal? You should answer conceptually without attempting any calculations.\n\nFlip a coin which is known to be fair 10 times.\n\nThe probability that the results are, in order, HHHHHHHHHH.\nThe probability that the results are, in order, HHTHTTTHHT.\n\nFlip a coin which is known to be fair 10 times.\n\nThe probability that all 10 flips land on H.\nThe probability that exactly 5 flips land on H.\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.21. \n\nMany people would say the probability in (b) is larger, but the probabilities in (a) and (b) are equal27. The sequence in (b) seems to look “more random”. However, the probability of seeing that particular sequence—H then H then T then H then T…—is the same as seeing the sequence H then H then H then H then H… If the coin is fair and the flips are independent, all possible sequences of flips are equally likely. Think of it this way: choose any flip, say the third. Then that flip is equally likely to be H (as in the third flip for (a)) or T (as in the third flip for (b)). No matter which flip it is, or the results of the other flips, any flip is equally likely to be H or T.\nOf course, our response assumes that the coin is fair. If the coin is known to be fair then the sequences in (a) and (b) are equally likely. However, if we actually observed the sequence in (a) we might suspect that the coin is actually not fair. There is an important difference between assumption and observation.\nThe probability in (b) is larger. Contrast this to the previous part. There is only one sequence which results in 10 heads, HHHHHHHHHH. However, there are many sequences28 which result in exactly 5 heads—HHHHHTTTTT, HTHTHTHTHT, TTHHTHTHHT, etc—of which HHTHTTTHHT is just one possibility.\n\n\n\n\n\nPay close attention to the differences in the two parts in Example 1.21. The first part involves probabilities of the particular outcome sequence. The second part involves more general “events” that the particular outcome sequence might satisfy. The following provides another example of this “particular” versus “general” dichotomy.\n\n\n\n\n\n\n\nExample 1.22 In each of the following parts, which of the two probabilities, a or b, is greater, or are they equal? You should answer conceptually without attempting any calculations.\n\nIn the Powerball lottery there are roughly29 300 million possible winning number combinations, all equally likely.\n\nThe probability you win the next Powerball lottery if you purchase a single ticket, 4-8-15-16-42, plus the Powerball number, 23.\nThe probability you win the next Powerball lottery if you purchase a single ticket, 1-2-3-4-5, plus the Powerball number, 6.\n\nContinuing with the Powerball\n\nThe probability that the numbers in the winning number are in a row.\nThe probability that the numbers in the winning number are not in a row.\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.22. \n\nMany people would say the probability in (a) is larger, since the sequence in (a) looks “more random”, but the probabilities in (a) and (b) are equal. Since the outcomes are equally likely, the probability that any single sequence is the winning number is (roughly) 1/300,000,000. If you don’t believe this, ask yourself: Why would the Powerball conduct its drawing in such a way that some numbers are more likely to be winners than others? And if some numbers were more likely than others, why wouldn’t people know about this?\nThe probability in (b) is larger. Contrast this to the previous part. There are only a handful of winning numbers for which the numbers are in a row: 1 through 6, 2 through 7, 3 through 8, etc. However, almost all of the 300 million possibilities do not have numbers in a row.\n\n\n\n\n\nWhen interpreting probabilities, be careful not to confuse “the particular” with “the general”.\n“The particular:” A very specific event, surprising or not, often has low probability.\n\nFor a fair coin, observing the particular sequence HHTHTTTHHT in 10 flips is just as likely as observing HHHHHHHHHH.\nThe probability that the winning powerball number is 4-8-15-16-42-(23) is exactly the same as the probability that the winning powerball number is 1-2-3-4-5-(6).\n\nThe probability that you get a text from your best friend at 7:43pm two weeks from today inviting you to dinner at your favorite pizza place after you’ve just ordered pizza from there is probably pretty small. None of these items — getting a text, having a friend invite you to dinner, ordering pizza from your favorite pizza place — is unusual, but the chances of them all combining in this way at this particular time are fairly small.\n\n“The general:” While a very specific event often has low probability, if there are many like events their combined probability can be high.\n\nThere are many possible sequences of 10 coin flips which result in 5 heads.\nFor almost all of the possible Poweball combinations the numbers are not in order.\nThe probability that some time in the next month or so a friend texts a dinner invitation is probably fairly high.\n\n\n\n\n\n\n\n\nExample 1.23 Which of the following two probabilities is greater, or are they equal? You should answer conceptually without attempting any calculations.\n\nThe probability that you win the next Powerball lottery if you purchase a single ticket.\nThe probability that someone wins the next Powerball lottery. (FYI: especially when the jackpot is large, there are hundreds of millions of tickets sold.)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.23. The probability in (2) is much greater. (This is an understatement.)\n\nThe probability that a specific powerball ticket is the winning number is about 1 in 300 million. So if you buy a single ticket, it is extremely unlikely that you will win.\nHowever, if hundreds of millions of powerball tickets are sold, the probability that someone somewhere wins is pretty high.\n\nWe elaborate on these ideas below.\n\n\n\n\nThe probability that you win the next Powerball lottery if you purchase a single ticket is about 1 in 300 million. Let’s put this number in perspective. There are about 260 million adults (over age 18) in the U.S.30 Suppose that the name of every adult in the U.S. is written on a 3x5 index card. These 260 million cards stacked would stretch about 62 miles high; that’s commonly referenced as the distance from the earth to where space begins. The stack would also weigh about 400 tons, about as much 4 blue whales. Suppose we shuffle the cards—much easier said than done—and select one. The probability that your name is on the selected card is about 1 in 260 million. The chances that your next Powerball ticket is the winning number are a little less likely than this31.\nHowever, if hundreds of millions of Powerball tickets are sold, the probability that someone somewhere wins is pretty high. For example, if 500 million tickets are sold then there is a roughly 80% chance that at least one ticket has the winning number (under certain assumptions).\nEven if an event has extremely small probability, given enough repetitions of the random phenomenon, the probability that the event occurs on at least one of the repetitions is often high32.\nConsider the headline of this news article from 2010: “Man mauled by bear after lightning strike”. We certainly feel sorry for this poor man, but just how unlikely is such an occurrence? Let’s look a little closer.\nThe headline seems to imply that the man got struck by lightning and then, while he was trying to reach safety, a bear attacked. But the mauling occurred four years after the lightning strike. Getting mauled by a bear and struck by lightning within one’s lifetime is certainly much more likely than both happening on the same day.\n“Getting struck by lightning” is often colloquially used to describe a rare event, but how unlikely is it? One study estimates that about 250,000 people in the world are struck by lightning each year, and the National Weather Service estimates that the probability that you get struck by lightning within your lifetime is 1/15,000. Still not very likely, but maybe not as rare as you might think.\nGetting mauled by a bear is much less likely than being struck by lightning. There are only about 40 bear attacks of humans each year. However, if the headline had been “Man bitten by shark after lightning strike” or “Man attacked by mountain lion after lightning strike” or “Man trampled by moose after lightning strike” it probably would have been equally newsworthy. Thus we should account for all similar animal attacks, not just bear attacks, when assessing the likelihood.\nThe probability that you get struck by lightning and mauled by a bear today is certainly very small. But the probability that someone somewhere within their lifetime gets both struck by lightning and attacked by an animal is orders of magnitude higher. In general, even though the probability that something very specific happens to you today is often extremely small, the probability that something similar happens to someone some time is often quite high.\nWhen something surprising happens, don’t just consider the probability of that particular outcome. Rather, consider all the other possible outcomes that would have been equally surprising if they had occurred, and consider the probability that at least one of them would happen (which often turns out to be not so small). From this perspective, most coincidences turn out to be much more probable than they seem at first.\nWhen assessing a probability, always ask “probability of what”? Does the probability represent “the particular” or “the general”? Is it the probability that the event happens in a single occurrence of the random phenomenon, or the probability that the event happens at least once in many occurrences? Keep these questions in mind when assessing numerical probabilities. Remember that something that has a “one in a million chance” of happening to you today will happen to about 7000 people in the world every day.\n\n1.6.1 How likely is “likely”?\nConsider each of the following statements (presented in no particular order). If you were to assign a numerical value to the probability of rain tomorrow in each case, what would it be?\n\nIt is likely that it will rain tomorrow.\nIt is probable that it will rain tomorrow.\nThere is little chance that it will rain tomorrow.\nIt is highly unlikely that it will rain tomorrow.\nWe doubt that it will rain tomorrow.\nThere is a very good chance that it will rain tomorrow.\nIt is almost certain that it will rain tomorrow.\nIt is improbable that it will rain tomorrow.\nIt will probably not rain tomorrow.\nIt is highly likely that it will rain tomorrow.\nIt is almost certain that it will not rain tomorrow.\nIt will probably rain tomorrow.\nWe believe that it will rain tomorrow.\nThere is a better than even chance that it will rain tomorrow.\n\nIn a study conducted in the 1960s (Barclay et al. (1977)), twenty-three military officers were asked to provide numerical probabilities for a similar set of statements (“It is almost certain that the Soviets will invade Czechoslovakia”, “It is highly likely that the Soviets will invade Czechoslovakia”, etc.) For most of the statements there was considerable variability in the responses. For example,\n\nProbabilities assigned to “almost certain” ranged from 0.75 to 0.99.\nProbabilities assigned to “highly likely” ranged from 0.50 to 0.99.\nProbabilities assigned to “likely” ranged from 0.30 to 0.90.\nProbabilities assigned to “probable” ranged from 0.25 to 0.90.\n\nRecent similar studies have produced comparable results that exhibit wide variability in the numerical values people associate with words describing probabilities. Studies like these provide evidence of differences in how people perceive probability.\nOne way to avoid ambiguity is to provide numerical values of probability rather than just vague words like “likely” or “probable”. However, people can still perceive numbers differently. An event that has a probability of 0.4 is four times more likely than an event with a probability of 0.1, but how likely is either event? Depending on their background, people might interpret a probability of 0.4 differently. Someone familiar with baseball knows that 0.4 would be an extremely high value for the probability that a particular batter successfully gets a hit in at bat, while someone familiar with basketball knows that 0.4 would be extremely low value for the probability that a particular player successfully scores on a free throw attempt. An audience that routinely encounters probabilities close to 0 will perceive a probability of 0.4 differently than one that commonly deals with probabilities around 0.5. When reporting probabilities, it is helpful to provide some benchmarks from a context more familiar to the audience to provide a sense of scale33.\nFor example, for people from California you might provide benchmarks based on county populations. If you randomly select a single California resident (about 39 million people) there is, roughly, a\n\n25% chance they are from Los Angeles County (about 9.7 million people)\n8% chance they are from Orange County (about 3.2 million people)\n0.7% chance they are from San Luis Obispo County (about 300 thousand people)\n0.1% chance they are from Calaveras County (about 46 thousand people)\n\nProviding a few values in this manner can help the audience gauge the magnitude of a probability like 0.2 or 0.0134.\nBe sure to keep in mind “the particular versus the general”. When reporting the value of a probability, provide enough contextual detail so that the audience can distinguish “the particular from the general”. If the probability of interest represents “the particular”, then provide benchmarks in terms of “the particular”; likewise for “the general”. In the California county example, we could use the values provided for a single randomly selected resident to benchmark “particular” probabilities (what is the probability this happens to me?). For “general” probabilities we could revise in terms like “if we randomly select 100 CA residents, there is a 50% chance that at least one resident is from San Luis Obispo County”.\nSo how likely is “likely”? We hope you see that there is no clear answer to this question. When communicating probabilities, our best advice is to:\n\nReport numerical values instead of ambiguous words.\nProvide enough contextual detail to identify “probability of what?”. In particular, be careful to distinguish “the particular from the general”.\nProvide the value of a few helpful benchmark probabilities in a familiar context to provide a sense of scale.\nRemember that despite your best efforts, people might still perceive probabilities differently.\n\n\n\n1.6.2 Exercises\n\nExercise 1.12 Create your own analogy for how unlikely that a single ticket wins the Powerball lottery. How would you describe a 1 in 300 million chance?\n\n\nExercise 1.13 In each of the following, which is greater: (a) or (b)? Or are they equal? Or is there not enough information to decide?\n\nElection interference\n\nThe probability that Russian agents successfully interfere with the 2024 U.S. Presidential election through posts on Facebook with the goal of helping the Republican candidate get elected.\nThe probability that non-U.S. actors attempt to interfere with the 2024 U.S Presidential election.\n\nRoll a six-sided die which is known to be fair 10 times.\n\nThe probability that the results are, in order, 1223334444.\nThe probability that the results are, in order, 4614253226.\n\nRoll a six-sided die which is known to be fair 10 times.\n\nThe probability that the results are, in order, 1234561234.\nThe probability that you roll each of the six faces at least once.\n\n\n\n\nExercise 1.14 Search online to find some benchmark probabilities (e.g., 0.25, 0.1, 0.01, 0.001, 0.0001, etc.) in a context that is interesting and familiar to you.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-literacy-ev",
    "href": "literacy-probability.html#sec-literacy-ev",
    "title": "1  What is Probability?",
    "section": "1.7 “Expected” value",
    "text": "1.7 “Expected” value\nWe are often interested in numerical values associated with a random phenomenon. If we flip a coin 100 times we might be interested in the number of flips which land on heads or the longest streak of heads. Forecasting tomorrow’s weather, we might be interested in the high temperature or amount of precipitation. Predicting the next Superbowl, we might be interested in the total number of points scored or the margin of victory.\nWhen dealing with uncertain numerical quantities, we often ask: what value do we expect? In this section we’ll introduce how we might answer this question. We’ll also give a first warning to be careful about what we mean by “expected” values.\n\n\n\n\n\n\n\nExample 1.24 This is a very simplified example illustrating the basic idea of how insurance works. Every year an insurance company sells many thousands of car insurance policies to drivers within a particular risk class. Each policyholder pays a “premium” of $1000 at the start of the year, and the insurance company agrees to pay for the cost of all damages that occur during the year. Suppose that each policy incurs damage of either $0, $5000, $20000, or $50000 with the following probabilities.\n\n\n\nAmount of damage ($)\nProfit ($)\nProbability\n\n\n\n\n0\n1000\n0.910\n\n\n5000\n-4000\n0.070\n\n\n20000\n-19000\n0.019\n\n\n50000\n-49000\n0.001\n\n\n\nThe insurance company’s profit on a policy at the end of the year is the difference between the premium of $1000 and any damage paid out. For example, a policy that incurs no damage results in a profit of $1000; a policy that incurs $5000 in damage results in a profit of -$4000 (that is, a loss of $4000) for the insurance company.\n\nInterpret the probabilities 0.91, 0.07, 0.019, and 0.001 as long run relative frequencies in this context.\nCompute the probability that a policy results in a positive profit for the insurance company.\nImagine 100,000 hypothetical policies. How many of these policies would you expect to result in a profit of $1000? -$4000? -$19000? -$49000?\nWhat do you expect the total profit for these 100,000 policies to be?\nWhat do you expect the average profit per policy for these 100,000 policies to be?\nCompute the probability that a policy has a profit equal to the value from part 5.\nCompute the probability that a policy has a profit greater than the value from part 5.\nIs the value from part 5 the most likely value of profit for a single policy?\nIs the value from part 5 the profit you would expect for a single policy?\nExplain in what sense the value from part 5 is “expected”.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.24. \n\nIf the insurance company sells many such policies, 91% of policies will incur $0 in damage and result in a profit of $1000, 7% of policies will incur $5000 in damage and result in a profit of -$4000, etc.\nIn this scenario a policy results in a positive profit for the insurance company only if it incurs no damage, so the probability is 0.91.\nOver many policies, we would expect 91% of policies to result in a profit of $1000, so we would expect \\(100000\\times 0.91 = 91000\\) of these policies to result in a profit of $1000. Continue in a similar manner to complete the “expected number of policies” column in the table below.\nWe expect 91000 polices to each result in a profit of $1000, for a total expected profit from these policies of \\(91000 \\times 1000 = 91000000\\). Continue in a similar manner to complete the “expected total profit” column in the table below. The expected total profit for all 100000 policies is $22,000,000.\n\n\n\n\n\n\n\n\n\n\nAmount of damage ($)\nNet profit ($)\nProbability\nExpected number of policies\nExpected total profit ($)\n\n\n\n\n0\n1000\n0.910\n91000\n91,000,000\n\n\n5000\n-4000\n0.070\n7000\n-28,000,000\n\n\n20000\n-19000\n0.019\n1900\n-36,100,000\n\n\n50000\n-49000\n0.001\n100\n-4,900,000\n\n\nTotal\nNA\n1\n100000\n22,000,000\n\n\n\nThe expected total profit for these 100000 policies is $22,000,000, so the expected average profit per policy is $220. (\\(\\frac{22000000}{100000} = 220\\))\nThe probability that a policy has a profit equal to $220 is 0. In this scenario, the only possible values of profit are 1000, -4000, -19000, and -49000.\nThe probability that a policy has a profit greater than $220 is 0.91. Over many policies, 91% of policies have a profit greater than the expected average profit per policy.\nNo! Not only is $220 not the most likely value, it’s not even a possible value of the profit of a policy.\nNo! It’s not even possible for a single policy to have a profit of $220.\nOver many policies, we expect the average profit per policy to be $220. That is, $220 is the long run average profit per policy.\n\n\n\n\n\nA single policy either results in a positive profit for the insurance company or not. For a group of policies we can compute the relative frequency of a positive profit: count the number of policies with a positive profit and divide by the total number of policies. The probability that a policy results in a positive profit can be interpreted as a long run relative frequency over many policies.\nBut there is more to the profit on a policy than whether it is positive or not; we are also interested in the amount of profit. For a group of policies we can compute the average profit: add up the values of the profits and divide by the total number of policies. The long run average value over many policies is called the “expected value” of profit.\nBe careful: the term “expected value” is somewhat of a misnomer. The expected value is not necessarily the value we expect on a single repetition of the random phenomenon. In Example 1.24 the expected value of profit is $220, but it is not possible for a single policy to have a profit of $220. Rather, $220 is the average profit per policy we expect to see in the long run over many policies. A probability can be interpreted as a long run relative frequency; an expected value can be interpreted as a long run average value.\n\n\n\n\n\n\n\nExample 1.25 Continuing Example 1.24. We considered what we would expect for 100000 hypothetical policies, but what about an unspecified large number of policies?\n\nImagine that we have recorded the profit for each of a large number of policies (not necessarily 100000). Explain in words the process by which you would compute the average profit per policy. (In other, more general, words: how do you compute an average of a list of numbers?)\nGiven that the profit of any policy is either 1000, -4000, -19000, or -49000, how could we simplify the calculation of the sum in the previous part? Write a general expression for the average profit per policy in this scenario.\nWhat do you think the expression in the previous part converges to in the long run?\nExplain how the value in the previous part is a “probability-weighted average value”.\nCompute the expected value of damage (not profit) as a probability-weighted average value.\nInterpret the value from the previous part as a long run average value in this context.\nHow is the expected value of profit related to the expected value of damage? Does this make sense? Why?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.25. \n\nCompute an average in the usual way: add up all the values and divide by the number of values. If there were 100000 policies, we would add up the 100000 values of profit and divide by 100000; this is basically what we did in part 5 of Example 1.24).\nThe profit of any policy is either 1000, -4000, -19000, or -49000, so when we add up the profits of many policies we’re adding the same values over and over. If 91000 values are equal to 1000, then we add \\(1000 + 1000 + \\cdots\\), 91000 times; in other words, the contribution to the sum for the policies with a profit of $1000 is \\(1000\\times 91000\\). For a general number of policies, the contribution to the sum of the policies with a profit of 1000 is \\(1000\\times\\) number of policies with a profit of 1000. The average profit per policy can be expressed as \\[\n{\\scriptscriptstyle\n\\frac{1000\\times \\text{number with profit of 1000} + (-4000)\\times \\text{number with profit of -4000}  + (-19000) \\times \\text{number with profit of -19000}  + (-49000) \\times \\text{number with profit of -49000} }{\\text{total number of policies}}\n}\n\\]\nDivide through by the total number of policies \\[\n{\\scriptstyle\n1000\\times \\frac{\\text{number with profit of 1000}}{\\text{total number of policies}} + (-4000)\\times \\frac{\\text{number with profit of -4000}}{\\text{total number of policies}}  + (-19000) \\times \\frac{\\text{number with profit of -19000}}{\\text{total number of policies}}  + (-49000) \\times \\frac{\\text{number with profit of -49000}}{\\text{total number of policies}}\n}\n\\] The fractions in the expression above are the relative frequencies of each value of profit. In the long run (over many policies), the relative frequencies will converge to the respective probabilities; for example, \\(\\frac{\\text{number with profit of 1000}}{\\text{total number of policies}}\\) will converge to 0.91. Therefore, the long run average profit per policy is \\[\n1000\\times 0.910 + (-4000)\\times 0.070 + (-19000) \\times 0.019 + (-49000) \\times 0.001 = 220\n\\]\nThe profit for each policy is either 1000, -4000, -19000, or -49000. However, when computing the average profit per policy we can’t simply average these four values since many policies will have a profit of 1000 and very few will have a profit of -49000. In a sense, 1000 will have more “weight” in the average profit per policy than -49000 does. Therefore, we multiply each possible value of profit by its corresponding probability and then add to get a “probability-weighted average value” which reflects how likely each possible value is.\nMultiply each value of damage by its corresponding probability and then sum. \\[\n0\\times 0.910 + 5000\\times 0.070 + 20000 \\times 0.019 + 50000 \\times 0.001 = 780\n\\]\nOver many policies we expect the long run average damage per policy to be $780.\nThe expected value of profit is $1000 minus the expected value of damage: \\(220 = 1000 - 780\\). The profit on any policy is the difference between the premium of $1000 and the amount of damage, so it makes sense that the average profit per policy is $1000 minus the average damage per policy.\n\n\n\n\n\nThe previous example illustrates that the long run average value is also the probability-weighted average value. That is, we multiplied each possible value by its corresponding probability and then summed. Interpreting an expected value as a probability-weighted average value might be more natural in situations involving subjective probabilities.\n\n\n\n\n\n\n\nExample 1.26 As of this writing there are currently fifty U.S. states, with Hawaii being the last new state admitted (in 1959). How many new states will be admitted in the next twenty years? Sam assesses that 0 new states is most plausible, and 10 times more plausible than 1 new state, which is 10 times more plausible than 2 new states, which is 10 times more plausible than 3 new states, and more than 3 states has negligible plausibility. What is Sam’s expected value of the number of new states? How do you interpret this value?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.26. First compute Sam’s subjective probabilities. Let 3 new states represent 1 “unit”, then 2 new states represents 10 units, 1 new state 100 units, and 0 new states 1000 units, for a total of 1111 units. Rescale the values so they sum to 1 to obtain Sam’s subjective probabilities.\n\n\n\n\n\n\n\n\nNumber of new states\nUnits\nProbability (as fraction, rounded decimal)\n\n\n\n\n0\n1000\n1000/1111 = 0.9001\n\n\n1\n100\n100/1111 = 0.0900\n\n\n2\n10\n10/1111 = 0.0090\n\n\n3\n1\n1/1111 = 0.0009\n\n\nTotal\n1111\n1\n\n\n\nNow compute Sam’s expected value as a probability-weighted average value \\[\n0\\left(\\frac{1000}{1111}\\right)  + 1\\left(\\frac{100}{1111}\\right) + 2\\left(\\frac{10}{1111}\\right) + 3 \\left(\\frac{1}{1111}\\right) = \\frac{123}{1111} = 0.1107\n\\]\nThis does not mean that Sam expects 0.11 new states; it’s not possible to have 0.11 new states. Rather, 0.11 represents an average of the possible values of the number of new states, weighted to reflect the relative plausibilities of the possible values.\n\n\n\n\nWe will see other interpretations of expected values later. In particular, we will see in what sense an expected value can be interpreted as a “best guess” of an uncertain random quantity.\nReturning to Example 1.24, the insurance company’s profit is the policyholder’s loss. Most policyholders pay the $1000 premium and incur no damage. Furthermore, the expected value of the loss for a policyholder is $220. Why are people willing to buy insurance despite this? Individuals live in the short run; any individual is either going to incur damage or not. Insurance is protection against the risk of a large loss. Even though the probability of occurrence is small, incurring a large amount of damage like $50000 would have serious financial consequences for most individuals. Many people are willing to trade a sure but relatively small monetary loss like $1000 to protect against an unlikely but serious loss like $50000.\nOn the other hand, insurance companies operate in the long run. Over many policies, an insurance company is virtually guaranteed an average profit of $220 per policy. The insurance company will lose, and lose big, on some policies. But these losses are more than offset in the long run by the relatively small profits on the large number of policies that incur no damage.\n\n1.7.1 Exercises\n\nExercise 1.15 A roulette wheel has 18 black spaces, 18 red spaces, and 2 green spaces, all the same size and each with a different number on it. Suppose you bet $1 on black. If the wheel lands on black, you win your initial bet back plus an additional $1; otherwise you lose the money you bet. That is, your net winnings are either +1 or -1 dollar.\n\nCompute the probability-weighted average value of your net winnings.\nIs the value in the previous part the net winnings you would expect on a single bet?\nExplain in what sense the value from the first part is “expected”.\n\n\n\nExercise 1.16 A roulette wheel has 18 black spaces, 18 red spaces, and 2 green spaces, all the same size and each with a different number on it. Suppose you bet $1 on 7. If the wheel lands on 7, you win your initial bet back plus an additional $35; otherwise you lose the money you bet. That is, your net winnings are either +35 or -1 dollar.\n\nCompute the probability-weighted average value of your net winnings.\nIs the value in the previous part the net winnings you would expect on a single bet?\nExplain in what sense the value from the first part is “expected”.\n\n\n\nExercise 1.17 Compare Exercise 1.15 and Exercise 1.16. Are the two $1 bets — bet on black versus bet on 7 — identical? In what way are these betters the same? In what ways are they different?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-sim",
    "href": "literacy-probability.html#sec-sim",
    "title": "1  What is Probability?",
    "section": "1.8 A brief introduction to simulation",
    "text": "1.8 A brief introduction to simulation\nHere’s a seemingly simple problem. Flip a fair coin four times and record the results in order. For the recorded sequence, compute the proportion of the flips which immediately follow a H that result in H. What value do you expect for this proportion? (If there are no flips which immediately follow a H, i.e. the outcome is either TTTT or TTTH, discard the sequence and try again with four more flips.)\nFor example, the sequence HHTT means the first and second flips are heads and the third and fourth flips are tails. For this sequence there are two flips which immediately followed heads, the second and the third, of which one (the second) was heads. So the proportion in question for this sequence is 1/2.\nSo what value do you expect for this proportion? We think it’s safe to say that most people would answer 1/2. After all, it shouldn’t matter if a flip follows heads or not, right? We would expect half of the flips to land on heads regardless of whether the flip follows H, right? We’ll see there are some subtleties lurking behind these questions.\nTo get an idea of what we would expect for this proportion, we could conduct a simulation: flip a coin 4 times and see what happens. Table 1.4 displays the results of a few repetitions; each repetition consists of an ordered sequence of 4 coin flips for which the proportion in question is measured. (Flips which immediately follow H are in bold.)\n\n\n\nTable 1.4: Simulated outcomes for 10 sets of four flips of a fair coin, each set with at least one flip following a flip of H.\n\n\n\n\n\n\n\n\n\n\n\n\nRepetition\nOutcome\nFlips that follow H\nH that follow H\nProportion of H followed by H\n\n\n\n\n1\nHHTT\n2\n1\n0.5\n\n\n2\nHTTH\n1\n0\n0\n\n\ndiscarded\nTTTH\n0\nNA\ntry again\n\n\n3\nHTHT\n2\n0\n0\n\n\n4\nTHHH\n2\n2\n1\n\n\n5\nHHTT\n2\n1\n0.5\n\n\n6\nHHHT\n3\n2\n0.667\n\n\n7\nHTTH\n1\n0\n0\n\n\n8\nTHHT\n2\n1\n0.5\n\n\n9\nTHTT\n1\n0\n0\n\n\n10\nHHHH\n3\n3\n1\n\n\n\n\n\n\nTable 1.5 and Figure 1.12 summarize the results of these 10 repetitions of the simulation.\n\n\n\n\nTable 1.5: Table of observed values of the proportion of H followed by H and their frequencies for the ten sets of coin flips in Table 1.4.\n\n\n\n\n\n\nProportion of H following H\nFrequency\nRelative frequency\n\n\n\n\n0.0000\n4\n0.4\n\n\n0.5000\n3\n0.3\n\n\n0.6667\n1\n0.1\n\n\n1.0000\n2\n0.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.12: Dot plot: Each dot represents the proportion of H followied by H for a set of four coin flips in Table 1.4\n\n\n\n\n\nWe can keep repeating the above process to investigate what happens in the long run. Rather than actually flipping coins, we use a computer to run a simulation. Figure 1.13 summarizes the results of 1,000,000 successful repetitions of the simulation, after discarding the sequences with no flips following H. (We will see how to program, run, and summarize simulations like this in later chapters.) While you can’t see the individual “dots” like in Figure 1.12 each dot would represent a sequence of 4 coin flips (with at least one flip following a H) and the value being plotted is the proportion of H followed by H for that sequence. The results would look like those in Table 1.4, albeit a table with 1,000,000 rows (after discarding rows with no flips immediately following H.)\n\n\n\n\n\n\n\n\n\n\n\n(a) Table of observed values and frequencies.\n\n\n\n\n\n\n\n\n\n\n\n(b) Spike plot: heights of the spikes represent the relative simulated relative frequencies of each possible value of proportion of H followied by H for a set of four coin flips\n\n\n\n\n\n\n\nFigure 1.13: Proportion of flips immediately following H that result in H for 1,000,000 sets of 4 coin flips, each set having at least one flip immediately following H. For example, the proportion of H followed by H is 0 in 429,123 of the sets.\n\n\n\nWe asked the question: what would you expect for the proportion of the flips which immediately follow a H that result in H? That depends on how we define what’s “expected”. If we are interested in the value that is most likely to occur when we flip a coin four times, then the answer is 0: we see that in the long run a little over 40% of the sets resulted in a proportion of 0, while only about 30% of sets resulted in a value of 1/2. We see that Figure 1.13 (b) is not centered at 1/2; a higher percentage of repetitions resulted in a proportion below 1/2 than above 1/2. We think that most people would find this surprising.\nAnother way to interpret “expected” is as “average”; in particular, expected value can be interpreted as the long run average value. After 1,000,000 repetitions, each involving a set of four fair coin flips, we have 1,000,000 simulated values of the proportion of H following H. We could then average these values: add up all the values and divide by 1,000,000.\n\\[\n{\\scriptscriptstyle\n\\frac{0\\times 429123 + (1/2)\\times 285906 + (2/3) \\times 71414 + 1 \\times 213557}{1000000} = 0.404\n}\n\\]\nIt turns out that the long run average value is 0.405, which is not 1/2. Again, we think most people find this surprising.\nA reminder: the term “expected value” is somewhat of a misnomer. We are not saying that if we flip a coin four times we would expect the proportion of H following H for that set of flips to be 0.405. In fact, in any single set of four fair coin flips the only possible values for the proportion of H followed by H are 0, 1/2, 2/3, and 1. So in a set of four coin flips it’s not possible to see a proportion of 0.405. Rather, 0.405 is the average value of the proportion of H followed by H that we would expect to see in the long run over many sets of four fair coin flips.\nThe simulation provides evidence that, counter to our intuition, we would expect the proportion of H followed by H to be less than 0.5. So what is happening here? We will return to this example several times to investigate these results more closely. We’ll leave it as a mystery for now, but observe that:\n\nThe study of probability can involve some subtleties and our intuition isn’t always right.\nSimulation is an effective way of investigating probability problems, and can reveal interesting and surprising patterns.\nThere is a difference between (1) the probability that a flip following H lands on H and (2) the proportion of flips following H which result in H in a fixed sequence of fair coin flips35.\nIn a fixed number of fair coin flips, the proportion of flips following H which result in H is “expected” to be less than the true probability of H, even though the trials are independent.\n\n\n1.8.1 Exercises\n\nExercise 1.18 In a group of \\(n\\) people, what is the probability that at least two people in the group people have the same birthday?\n\nConsider \\(n=30\\): what do you think the probability that at least two people in a group of 30 people share a birthday is: 0-20%, 20-40%, 40-60%, 60-80%, 80-100%?\nHow large do you think \\(n\\) needs to be in order for the probability that at least two people share a birthday to be larger than 0.5?\nWe’ll save the answer to these questions for later, but they turn out to be unintuitive to many people, and simulation can shed some light. Explain how, in principle, you might perform a simulation using cards or slips of paper to estimate the probability that at least two people have the same birthday when \\(n=30\\). You can make some simplifying assumptions: Ignore multiple births and February 29 and assume that the other 365 days are all equally likely36.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-why-toys",
    "href": "literacy-probability.html#sec-why-toys",
    "title": "1  What is Probability?",
    "section": "1.9 Why study coins, dice, cards, and spinners?",
    "text": "1.9 Why study coins, dice, cards, and spinners?\nMany probability problems involve “toy” situations like flipping coins, rolling dice, shuffling cards, or spinning spinners. These situations might seem unexciting, or at least not very practically meaningful. However, coins and spinners and the like provide familiar, concrete situations which facilitate understanding of probability concepts. Furthermore, simple situations often provide insight into real and complex problems. The following is just one illustration.\nMany basketball players and fans alike believe in the “hot hand” phenomenon: the idea that making several shots in a row increases a player’s chances of making the next shot. However, the consensus conclusion of thirty years of studies on the hot hand, beginning with the seminal study Gilovich, Vallone, and Tversky (1985), had been that there is no statistical evidence that the hot hand in basketball is real. As a result, many statisticians regularly caution against the “hot hand fallacy”: the belief that the hot hand exists when, in reality, the degree of streaky behavior typically observed in sequential data is consistent with what would be expected simply by chance in independent trials.\nThe idea behind studies like Gilovich, Vallone, and Tversky (1985) is essentially the following. Consider a player who attempts 100 shots and makes 50%. If there is no hot hand, then we might expect the player to make 50% of shots both on attempts that follow hit streaks— usually considered three (or more) made attempts in a row—and on other attempts. Therefore, a success rate of 50% on both sets of attempts provides no evidence of the hot hand.\nHowever, recent research of Miller and Sanjurjo (2018a), Miller and Sanjurjo (2018c), Miller and Sanjurjo (2018b) concludes that previous studies on the hot hand in basketball, starting with Gilovich, Vallone, and Tversky (1985), have been subject to a bias. After correcting for the bias, the authors find evidence in favor of the hot hand effect in basketball shooting, suggesting the hot hand fallacy is not a fallacy after all. One interesting aspect of these studies is that Miller and Sanjurjo’s methods are simulation-based.\nMiller and Sanjurjo (2018a) introduced the coin flipping problem in Section Section 1.8) to illustrate the idea behind their research and the bias in previous studies. Consider again a player who attempts 100 shots and makes 50%. Even if there is no hot hand, Miller and Sanjurjo show that we would actually expect the player to have a shooting percentage of strictly less than 50% on the attempts which followed streaks, and strictly greater than 50% on the other attempts. The reason is similar to what we observed in the the coin flipping problem in Section 1.8: in a fixed number of trials, the proportion of H on trials following H is expected to be less than the true probability of H, even though the trials are independent. Therefore, for the example player a success rate of 50% on both sets of attempts actually provides directional evidence in favor of the hot hand. Properly acccounting for this bias leads to substantially different statistical analyses (i.e., p-values) and conclusions.\n\n1.9.1 Exercises\n\nExercise 1.19 Find the value of some probability in a real world situation of interest to you. Then describe how this situation could be modeled with coins, dice, cards, or spinners. How would you use your “toys” to simulate the situation and approximate the probability of interest?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#chapter-exercises",
    "href": "literacy-probability.html#chapter-exercises",
    "title": "1  What is Probability?",
    "section": "1.10 Chapter exercises",
    "text": "1.10 Chapter exercises\n\nExercise 1.20 True or false.\n\nProbability can be used to assess the likelihood or plausibility of an event associated with a phenomenon that only happens once.\nProbability can be used to assess the likelihood of an event associated with a phenomenon that happended in the past.\nThe subjective and long run relative frequency interpretations of probability can be used interchangeably.\nSuppose the probability that a randomly selected CP student has an internship this summer is 0.2, and the probability that a randomly selected CP student is taking at least one course this summer is 0.4. True false: the probability that a randomly selected CP student either has an internship or is taking at least one class (or both) must be 0.6.\nSuppose the probability that a randomly selected CP student has an internship this summer is 0.2, and the probability that a randomly selected CP student is taking at least one course this summer is 0.4. True false: the probability that a randomly selected CP student both has an internship and is taking at least one class must be 0.08.\n\n\n\nExercise 1.21 Short answer.\n\nYour subjective probability that the price of regular unleaded gasoline at your favorite gas station in SLO stays above $5 per gallon throughout the next month is 0.95. How many times more likely than not is it for the price to stay above $5 per gallon through the next month?\nIt is 3 times more likely than not that the high temperature tomorrow will be greater than 80 degrees F. What is the probability that the high temperature tomorrow will be greater than 80 degrees F?\nLaszlo, Nadja, and Nandor are having a tournament. Guillermo thinks that Nandor is 3.5 times more likely to win than Nadja, and Nadja is 2 times more likely to win than Lazlso. Find Guillermo’s probability that Nandor wins.\n\n\n\nExercise 1.22 In each of the following, which of a or b is strictly greater? Or are they equal? Or is there not enough information to decide? Explain your reasoning.\n\nSurfing Californians\n\nThe probability that a randomly selected Californian likes to surf\nThe probability that a randomly selected American is a Californian who likes to surf\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\nCal Poly graduates\n\nThe probability that a randomly selected Cal Poly graduate is a California resident\nThe probability that a randomly selected California resident is a Cal Poly graduate\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\nFlips a coin which is known to be fair six times and record the results in sequence\n\nThe probability that the first five flips are, in order, HHHHH\nThe probability that the first six flips are, in order, HTTHTH\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\nI catch my child hiding in the bathroom washing chocolate off her face. I ask what her what she’s doing, and she says she just had to go the bathroom.\n\nThe probability that my child just went to the bathroom.\nThe probability that my child just went to the bathroom and has secretly been eating chocolate cake.\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\nAmong American workers, 40% have a college degree and 10% belong to a labor union.\n\n4%\nThe percentage of American workers who have a college degree and belong to a labor union.\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\n\n\n\nExercise 1.23 Suppose\n\n85% of people have a dominant right hand.\n75% of people with a dominant right hand have a dominant right eye.\n55% of people who do not have a dominant right hand have a dominant right eye.\n\n\nWhat percent of people with a dominant eye have a dominant right hand?\nWhat percent of people with a dominant right eye do not have a dominant right hand?\nWhat percent of people without a dominant right eye have a dominant right hand?\nWhat percent of people with a dominant right hand have a dominant right eye?\nWhat percent of people have a dominant right eye and a dominant right hand?\n\n\n\n\n\n\nAldous, David. 2023. “Forty Thousand Coin Tosses Yield Ambiguous Evidence for Dynamical Bias.” 2023. https://www.stat.berkeley.edu/~aldous/Real-World/coin_tosses.html.\n\n\nBarclay, Scott, Rex Brown, Clinton III, Cameron Peterson, and Lawrence Phillips. 1977. “Handbook for Decision Analysis,” September, 284.\n\n\nBartoš, František, Alexandra Sarafoglou, Henrik R. Godmann, Amir Sahrani, David Klein Leunk, Pierre Y. Gui, David Voss, et al. 2024. “Fair Coins Tend to Land on the Same Side They Started: Evidence from 350,757 Flips.” https://arxiv.org/abs/2310.04153.\n\n\nDavid, F. N. 1955. “Studies in the History of Probability and Statistics i. Dicing and Gaming (a Note on the History of Probability).” Biometrika 42 (1/2): 1–15. http://www.jstor.org/stable/2333419.\n\n\nDiaconis, Persi, Susan Holmes, and Richard Montgomery. 2007. “Dynamical Bias in the Coin Toss.” SIAM Review 49 (2): 211–35. http://www.jstor.org/stable/20453950.\n\n\nDiaconis, Persi, and Brian Skrms. 2018. Ten Great Ideas about Chance. Princeton University Press. http://www.jstor.org/stable/j.ctvc77m33.\n\n\nGilovich, Thomas D., Robert P. Vallone, and Amos Tversky. 1985. “The Hot Hand in Basketball: On the Misperception of Random Sequences.” Cognitive Psychology 17 (3): 295–314. https://doi.org/https://doi.org/10.1016/0010-0285(85)90010-6.\n\n\nKahneman, Daniel. 2012. Thinking, Fast and Slow. London: Penguin.\n\n\nMiller, Joshua B., and Adam Sanjurjo. 2018a. “Surprised by the Hot Hand Fallacy? A Truth in the Law of Small Numbers.” Econometrica 86 (6): 2019–47. https://doi.org/10.3982/ECTA14943.\n\n\n———. 2018b. “A Cold Shower for the Hot Hand Fallacy: Robust Evidence That Belief in the Hot Hand Is Justified.” OSF Preprints. https://doi.org/10.31219/osf.io/pj79r.\n\n\n———. 2018c. “Is It a Fallacy to Believe in the Hot Hand in the NBA Three-Point Contest?” OSF Preprints. https://doi.org/10.31219/osf.io/dmksp.\n\n\nMurray, Daniel B., and Scott W. Teare. 1993. “Probability of a Tossed Coin Landing on Edge.” Phys. Rev. E 48 (October): 2547–52. https://doi.org/10.1103/PhysRevE.48.2547.\n\n\nTversky, Amos, and Daniel Kahneman. 1982. “Judgments of and by Representativeness.” In Judgment Under Uncertainty: Heuristics and Biases, edited by Daniel Kahneman, Paul Slovic, and AmosEditors Tversky, 84–98. Cambridge University Press. https://doi.org/10.1017/CBO9780511809477.007.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#footnotes",
    "href": "literacy-probability.html#footnotes",
    "title": "1  What is Probability?",
    "section": "",
    "text": "The Grand Duke of Tuscany posed this problem to Galileo, who published his solution in 1620. However, unbeknownst to Galileo, the same problem had been solved almost 100 years earlier by Gerolamo Cardano, one of the first mathematicians to study probability (David 1955).↩︎\nOr maybe not. We are considering heads and tails as the only outcomes, but what about a coin landing on its edge? It can happen, but the probability is very small; Murray and Teare (1993) estimates the probability that a U.S. nickel lands on its edge to be about 0.000167. Furthermore, there is evidence (Diaconis, Holmes, and Montgomery (2007), Aldous (2023), Bartoš et al. (2024)) that a coin is slightly more likely to land the same way it started. That is, if the coin starts facing heads up, the probability that it lands facing heads up is slightly greater than 0.5, but the difference is small. Quoting Section 7 of Diaconis, Holmes, and Montgomery (2007): “The classical assumptions of independence with probability 1/2 are pretty solid.” We hope you agree that assuming two equally likely outcomes is reasonable for practical purposes.↩︎\nWe do not advocate gambling. We merely use gambling contexts to motivate probability concepts.↩︎\nThere is a vast literature on how people make decisions when faced with uncertainty. Kahneman (2012) provides an excellent introduction.↩︎\nDiaconis and Skrms (2018) provides a nice introduction.↩︎\nFor example, we are not distinguishing between “aleatoric variability” and “epistemic uncertainty”.↩︎\nThis is the first of many spinners in this book. Our purpose in using spinners is not to advocate pie charts for summarizing data. Rather, we think spinners provide a concrete representation of probability distributions that helps facilitate understanding of difficult concepts.↩︎\nWe can also solve this problem using algebra. Let \\(x\\) be the probability, as a decimal, that the Astros are the winner. (Again, it doesn’t matter which team is the baseline.) Then \\(x\\) is also the probability that the Dodgers are the winner, \\(1.5x\\) for the Rays, and \\(3x\\) for the Braves. The probability that one of the four teams wins is \\(x + x + 1.5x + 3x = 6.5x\\), so the probability of Other is also \\(6.5x\\). The probabilities in decimal form must sum to 1, so \\(1 = x + x + 1.5x + 3x + 6.5x = 13x\\). Solve for \\(x=1/13\\) and then plug in \\(x=1/13\\) to find the other probabilities; e.g., \\(3x = 3(1/13) = 0.231\\) for the Braves.↩︎\nThis example is inspired by the famous “Linda problem” of Tversky and Kahneman (1982) which they used to illustrate the “conjunction fallacy”.↩︎\nYou could also solve this with algebra. Let \\(x\\) be the probability that the Giants win, so \\(19x\\) is the probability that they don’t win. The probabilities must sum to 1, so set \\(x + 19x = 1\\) and solve for \\(x\\).↩︎\nTechnically, Ron and Leslie could still have different subjective probabilities. Leslie would not agree to worse odds, but she would accept better if Ron offered them. For example, given a potential loss of $200, Leslie would also agree to a potential payout from Ron of $125 rather than $100. That is, Leslie would accept odds of 1.6 to 1 against (\\(200/125 = 1.6\\)), corresponding to a subjective probability of \\(1/(1 + 1.6) = 0.385\\). So Leslie’s subjective probability that Professor Ross has a TikTok account is at least 1/3. Similarly, Ron’s subjective probability that Professor Ross has a TikTok account is at most 1/3.↩︎\nTechnically this is only true if the moneyline odds are positive, which is the case when the probability of winning the bet is less than 0.5. Negative moneyline odds, which occur when the probability of winning the bet is greater than 0.5, represent how much money must be wagered in order to receive a net profit of $100. For example, moneyline odds of -900 indicate that you must bet $900 to receive $1000, for a net profit of 1000-900 = 100. A bet at -900 moneyline odds results in a profit of $100 if the bet is won or a loss of the initial $900 stake otherwise; the amounts 900 and 100 are in a 9 to 1 ratio (in favor of winning), implying a probability of \\(9/(1+9) = 0.90\\) of winning the bet.↩︎\nWe’re assuming Donny’s probability that the Dodgers don’t win is 50%. But if Donny’s probabilities don’t add to 100% why would we expect him to obey other consistency requirements? A fair question, but the point is that bad things can happen even if just one of the consistency requirements is violated. If we assume instead 35% as Donny’s probability that the Dodgers don’t win, we can construct a scenario similar to the one in this solution which guarantees us a sure profit with no risk.↩︎\n“Book” in the sense of a bookie taking bets, as opposed to a Dutch-language novel like De ontdekking van de hemel.↩︎\nThese values are based on a study by the Pew Research Foundation conducted in January 2020.↩︎\nThese values are based on surveys by Gallup, but the values change somewhat over time.↩︎\nCareful: we are only claiming that the total does not matter when constructing hypothetical tables. When collecting real data, the sample size matters a great deal. For example, a random sample of 1000 Americans provides a more precise estimate of the population proportion of all Americans who support free tuition than a sample of 100 Americans does. The Pew Research study was based on a random sample of over 12000 Americans.↩︎\nYou can only run into problems if you round. Suppose we had started with a group size of 100. Then the top left cell in the table would have been 26.56. If we had rounded this to 27, our answers would change. So when dealing with a hypothetical table of counts, don’t round. If you are uncomfortable with decimal counts, just add a few zeros to your total count and try again↩︎\nThis example is adapted from an article by Allan Rossman.↩︎\nThe values in this example are based on a Washington Post article which uses data from the 2018 General Social Survey. An earlier Washington Post article discusses discrepancies in estimates of pet ownership.↩︎\nThese values come from the NY Times article and a related study.↩︎\nThis is called the sensivity of the test.↩︎\nWe are treating “not positive” as “negative” but in practice there could also be inconclusive tests.↩︎\nDiGeorge syndrome isn’t the greatest example since most cases result from a purely random deletion on chromosome 22. However, DiGeorge syndrome can be inherited from a parent who has it.↩︎\nThis is called the specificity of the test↩︎\nPregnancy tests are included as part of health screenings for other reasons, but most women who take home pregnancy tests do so for pregnancy related reasons.↩︎\nAnd both equal to \\(\\left(\\frac{1}{2}\\right)^{10} =\\frac{1}{1024}\\)↩︎\n252 out of 1024 possibilities in fact↩︎\nThe exact count is 292,201,338. We will see how to compute this number later.↩︎\nSource: U.S. Census Bureau.↩︎\nThe statistician Ron Wasserstein has provided several fanciful perspectives on the likelihood of winning the Powerball lottery.↩︎\nFor an interesting investigation of this idea check out the Infinite Monkey Theorem Experiment at the site The Pudding.↩︎\nThis idea was inspired by Randall Munroe.↩︎\nFor probabilities closer to 1, we could report the chances of not being from these counties.↩︎\nThe probability that a flip following H lands on H is 0.5. This example shows that the proportion of flips following H which result in H in a fixed sequence of coin flips is a “biased estimator” of the probability that a flip following H lands on H.↩︎\nWhich isn’t quite true.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "language-probability.html",
    "href": "language-probability.html",
    "title": "2  The Language of Probability",
    "section": "",
    "text": "2.1 Outcomes\nA phenomenon is random if there are multiple potential possibilities, and there is uncertainty about which possibility is realized. This chapter introduces the fundamental terminology and objects of random phenomena, including\nProbability models put all of the above together. A probability model of a random phenomenon consists of a sample space of possible outcomes, associated events and random variables, and a probability measure which specifies probabilities of events and determines distributions of random variables according to the assumptions of the model and available information.\nThroughout this chapter we will illustrate ideas using the following examples.\nTotal or best? Roll a four-sided1 die twice and consider the sum and the larger of the two rolls (or the common roll if a die). Not very exciting? Maybe, but it is a familiar, simple, and concrete example. Also, a “toy” example can provide insight into more interesting problems, such as the following. In many sports, a competitor’s final ranking is based on the results of multiple attempts. Competitors in Olympic bobsled, for example, make four separate timed runs on the same course and their ranking is based on their total time. Competitors in Olympic shot put make six throws, but their ranking is based on their best throw. In sports with multiple attempts, how do the rankings compare if they are based on the total (or average) over all attempts (as in bobsled) or on the best attempt (as is shot put)?\nMatching problem. A group of people all put their names in a hat for a Secret Santa gift exchange. The names are shuffled and everyone draws a name from the hat. We might be interested in questions like: What is the probability that someone selects their own name? How many people are expected to draw their own name? How do the answers to these questions depend on the name of people in the group? This a is version of a well known probability problem called the “matching problem”. The general setup involves \\(n\\) distinct “objects” labeled \\(1, \\ldots, n\\) which are placed in \\(n\\) distinct “boxes” labeled \\(1, \\ldots, n\\), with exactly one object placed in each box; for how many objects does the label on the object match the label on the box it is placed in?\nMeeting problem. Several people plan to meet for lunch, but their arrival times are uncertain. We might be interested in whether they arrive within 15 minutes of one another, who arrives first and at what time, or how long the first person to arrive needs to wait for the others.\nCollector problem. Each box of a brand of cereal contains a single prize from a collection. We might be interested in how many boxes we need to buy to complete the collection, or how many boxes we need to buy to complete five collections (say one collection for each of five kids), or which prize we get in the most boxes.\nArrivals over time. Customers enter a deli and take a number to mark their place in line. When the deli opens the counter starts 0; the first customer to arrive takes number 1, the second 2, etc. We record the counter over time, continuously, as it changes as customers arrive. We might be interested in the number of customers that arrive in some window of time, the time between customer arrivals, or the amount of time it takes for some number of customers to arrive. (And this is just the arrivals; we might also be interested in questions which involve the departures, such as: how much time a customer spends in the deli or how many customers are in the deli at a certain time.)\nFull disclosure: many of the examples in this chapter involve rather dry tasks like discussing mathematical notation or listing elements of sets. Also, some of the things we do in these examples are rarely done in practice. So why bother? Many common mistakes in solving probability problems arise from misunderstanding these foundational objects. We hope that concrete—though sometimes uninteresting—examples foster understanding of fundamental concepts.\nThis chapter introduces what the fundamental objects of probability are, but not yet how to solve probability problems. Don’t worry; we’ll solve many interesting problems in the remaining chapters. Think of this chapter as introducing the “language” or “grammar” of probability. When first learning to write, we learn the basic elements of sentences: subjects, predicates, clauses, modifiers, etc. Understanding these fundamental building blocks is essential to learning how to write well, even if we don’t explicitly identify the subject, the verb, etc., in every sentence we write. Likewise, understanding the language of probability is crucial to learning how to solve probability problems, even if the language is sometimes unspoken.\nProbability models can be applied to any situation in which there are multiple potential outcomes and there is uncertainty about which outcome is realized. Due to the wide variety of types of random phenomena, an outcome can be virtually anything:\nAnd on and on. In particular, an outcome does not have to be a number.\nThe first step in defining a probability model for a random phenomenon is to identify the possible outcomes.\nMathematically, the sample space is a set containing all possible outcomes, while any individual outcome is an element in the sample space. The sample space is typically denoted2 \\(\\Omega\\), the uppercase Greek letter “Omega”. An outcome is typically denoted \\(\\omega\\), the lowercase Greek letter “omega”; \\(\\omega\\) denotes a generic outcome much like the symbol \\(u\\) in \\(\\sqrt{u}\\) denotes a generic input to the square root function. We write \\(\\omega \\in \\Omega\\) (read \\(\\in\\) as “in” or “an element of”) to represent that \\(\\omega\\) is a possible outcome of sample space \\(\\Omega\\).\nThe simplest random phenomena have just two distinct outcomes, in which case the sample space is just a set with two elements, e.g., \\(\\Omega=\\{\\text{no}, \\text{yes}\\}\\), \\(\\Omega=\\{\\text{off}, \\text{on}\\}\\), \\(\\Omega=\\{0, 1\\}\\), \\(\\Omega=\\{-1, 1\\}\\). For example, the sample space for a single coin flip could be \\(\\Omega = \\{H, T\\}\\). If the coin lands on heads, we observe the outcome \\(\\omega = H\\); if tails we observe \\(\\omega=T\\).\nIn simple examples we can describe the sample space by listing all possible outcomes. However, constructing a list of all possible outcomes is rarely done in practice. We do so here only to provide some concrete examples of sample spaces. While a random phenomenon always has a corresponding sample space, in most situations the sample space of outcomes is at best only vaguely specified and can not be feasibly enumerated.\nTable 2.1: Table representing the sample space of two rolls of a four-sided die. Each row represents an outcome.\n\n\n\n\n\n\nFirst roll\nSecond roll\n\n\n\n\n1\n1\n\n\n1\n2\n\n\n1\n3\n\n\n1\n4\n\n\n2\n1\n\n\n2\n2\n\n\n2\n3\n\n\n2\n4\n\n\n3\n1\n\n\n3\n2\n\n\n3\n3\n\n\n3\n4\n\n\n4\n1\n\n\n4\n2\n\n\n4\n3\n\n\n4\n4\nA random phenomenon is modeled by a single sample space. In Example 2.1 there was a single sample space whose outcomes represented the result of the pair of rolls; in particular, there was not a separate sample space for each of the individual rolls3. Whenever possible, a sample space outcome should be defined to provide the maximum amount of information about the outcome of random phenomenon.\nHere’s another concrete example where we can list all the outcomes in the sample space. However, keep in mind that enumerating the sample space is rarely done in practice.\nTable 2.2: Table representing the sample space in the matching problem with \\(n=4\\). Each row represents an outcome.\n\n\n\n\n\n\nSpot 1\nSpot 2\nSpot 3\nSpot 4\n\n\n\n\n1\n2\n3\n4\n\n\n1\n2\n4\n3\n\n\n1\n3\n2\n4\n\n\n1\n3\n4\n2\n\n\n1\n4\n2\n3\n\n\n1\n4\n3\n2\n\n\n2\n1\n3\n4\n\n\n2\n1\n4\n3\n\n\n2\n3\n1\n4\n\n\n2\n3\n4\n1\n\n\n2\n4\n1\n3\n\n\n2\n4\n3\n1\n\n\n3\n1\n2\n4\n\n\n3\n1\n4\n2\n\n\n3\n2\n1\n4\n\n\n3\n2\n4\n1\n\n\n3\n4\n1\n2\n\n\n3\n4\n2\n1\n\n\n4\n1\n2\n3\n\n\n4\n1\n3\n2\n\n\n4\n2\n1\n3\n\n\n4\n2\n3\n1\n\n\n4\n3\n1\n2\n\n\n4\n3\n2\n1\nIn the two previous examples, the sample space was discrete, in the sense that the outcomes could be enumerated in a list (though it could be a very long list). But in many cases, it is not possible to enumerate outcomes in a list, even in principle.\nFor example, consider the circular spinner (like from a kids game) in Figure 2.1. Imagine a needle anchored at the center of the circle which is spun and eventually lands pointing at a number on the outside of the circle. The values in the picture are rounded to two decimal places, but consider an idealized model where the spinner is infinitely precise and the needle infinitely fine so that any real number between 0 and 1 is a possible outcome. The sample space corresponding to a single spin of this spinner is the interval4 [0, 1]. There are uncountably many numbers in [0, 1] so it would not be possible to enumerate them in a list. The interval [0, 1] is an example of a continuous sample space.\nFigure 2.1: A continuous uniform spinner on [0, 1]. The values in the picture are rounded to two decimal places, but in the idealized model the spinner is infinitely precise so that any real number between 0 and 1 is a possible outcome.\nFigure 2.2: The square represents the sample space in Example 2.3). Each point within the square is a (Regina, Cady) pair of arrival times in \\([0, 60]\\).\nIn the previous example, outcomes were measured on a continuous scale; any real number between 0 and 60 was a possible arrival time. In practice we might round the arrival time to the nearest minute or second, but in principle and with infinite precision any real number in the continuous interval \\([0, 60]\\) is possible.\nFurthermore, even in situations where outcomes are inherently discrete, it is often more convenient to model them as continuous. For example, if an outcome represents the annual salary in dollars of a randomly selected U.S. household, it would be more convenient to model the sample space as the continuous interval6 \\([0, \\infty)\\) rather than discrete intervals like \\(\\{0, 1, 2, \\ldots\\}\\) or \\(\\{0, 0.01, 0.02, \\ldots\\}\\). Continuous models are often more tractable mathematically than discrete models.\nIn the previous examples, the sample space could be defined rather explicitly, either by direct enumeration or using set notation (like a Cartesian product). However, explicitly defining a sample space in a compact way is often not possible, as in the following example.\nAny random phenomenon has a corresponding sample space but in some situations explicitly defining a outcome is not feasible. For example, suppose the random phenomenon is tomorrow’s weather. In order to describe an outcome, we need to specify (among other things): temperature, atmospheric pressure, wind, humidity, precipitation, and cloudiness, and how it all evolves over over the course of tomorrow, possibly in multiple locations. Representing all of this information in a compact way to define even just one outcome is virtually impossible; explicitly defining a sample space of all possible outcomes is hopeless. Regardless, the sample space is still there in the background whether we specify it or not.\nEven though the sample space often is at best vaguely defined (“tomorrow’s weather”) and plays a background role, it is important to first consider what is possible before determining how probable events are. The sample space essentially defines the denominator in probability calculations. In particular, considering the sample space can help distinguish between “the particular and the general” (as discussed in Section 1.6).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-language-outcomes",
    "href": "language-probability.html#sec-language-outcomes",
    "title": "2  The Language of Probability",
    "section": "",
    "text": "the result of a coin flip\nthe results of a sequence of coin flips\na shuffle of a deck of cards\nthe weather conditions tomorrow in your city\nthe path of a particular Atlantic hurricane\nthe daily closing price of a certain stock over the next 30 days\na noisy electrical signal\nthe result of a diagnostic medical test\na sample of car insurance polices\nthe customers arriving at a store\nthe result of an election\nthe next World Series champion\na play in a basketball game\n\n\n\n\nDefinition 2.1 The sample space is the collection of all possible outcomes of a random phenomenon.\n\n\n\n\n\n\n\n\n\n\n\nExample 2.1 Roll a four-sided die twice, and record the result of each roll in sequence. For example, a 3 on the first roll and a 1 on the second is not the same outcome as a 1 on the first roll and a 3 on the second.\n\nIdentify the sample space.\nWe might be interested in the sum of the two rolls. Explain why it is still advantageous to define the sample space as in the previous part, rather than as just \\(2, \\ldots, 8\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.1. \n\nWe simply enumerate all the possible outcomes: first roll is a 1 and second roll is a 1, first roll is a 1 and second roll is a 2, etc. The sample space consists of 16 possible ordered pairs of rolls, which we can display in a list or table. See Table 2.1; any row is a possible outcome, and the table contains all possible outcomes.\nWe can write the sample space as a set of ordered pairs, \\[\\begin{align*}\n\\Omega & = \\{(1, 1), (1, 2), (1, 3), (1, 4),\\\\\n& \\qquad (2, 1), (2, 2), (2, 3), (2, 4),\\\\\n& \\qquad (3, 1), (3, 2), (3, 3), (3, 4),\\\\\n& \\qquad (4, 1), (4, 2), (4, 3), (4, 4)\\}.\n\\end{align*}\\] Any element of this set is a possible outcome \\(\\omega\\). For example, the outcome \\(\\omega = (4, 2)\\) occurs when the first roll is a 4 and the second roll is a 2.\nYes, we might be interested in the sum of the two dice. But we might also be interested in other things, like the larger of the two rolls, or if at least one 3 was rolled, or the result of the first roll. Knowing just the sum of the rolls does not provide as much information about the outcome of the random phenomenon as the sequence of individual rolls does.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.2 Consider the matching problem with \\(n=4\\). Label the objects 1, 2, 3, 4, and the spots 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. Identify an appropriate sample space.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.2. We can consider each outcome to be a particular placement of objects in the spots. For example, one outcome is when object 3 is placed in spot 1, object 2 in spot 2, object 1 in spot 3, and object 4 in spot 4; another is when object 3 is placed in spot 1, object 2 in spot 2, object 4 in spot 3, and object 1 in spot 4. The sample space consists of all the possible arrangments of the object labels into the 4 spots. There are 24 outcomes; see Table 2.2). Recording outcomes in this way provides more information than if we had chosen the sample space to correspond to, for example, the number of objects that were placed in the correct spot.\nUsing set notation the sample space is \\[\\begin{align*}\n\\Omega & = \\{1234, 1243, 1324, 1342, 1423, 1432 \\\\\n  & \\qquad 2134, 2143, 2314, 2341, 2413, 2431 \\\\\n  & \\qquad 3124, 3142, 3214, 3241, 3412, 3421 \\\\\n  & \\qquad 4123, 4132, 4213, 4231, 4312, 4321\\}\n\\end{align*}\\] For example, the outcome 3214 (or \\((3, 2, 1, 4)\\)) represents that object 3 is placed in spot 1, object 2 in spot 2, object 1 in spot 3, and object 4 in spot 4.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.3 Consider a version of the meeting problem where two people. Regina and Cady, will each definitely arrive between noon and 1, but their exact arrival times are uncertain. Rather than dealing with clock time, it is helpful to represent noon as time 0 and measure time as minutes after noon, including fractions of a minute, so that arrival times take values in the continuous interval [0, 60].\nDescribe an appropriate sample space. Hint: it might be easiest to draw a picture.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.3. We can represent an outcome as a (Regina, Cady) pair of arrival times, each in [0, 60]. For example, the outcome (30, 45.2) represents Regina arriving at 12:30:00 and Cady at 12:45:12, while (45.2, 0) represents Regina arriving at time (12:45:12) and Cady at noon. The sample space is the set of all possible pairs. Figure 2.2 displays the sample space5 as the set of points within the colored square with [0, 60] sides.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.4 Consider the collector problem with 3 prizes in the collection, labeled 1, 2, and 3. We open boxes one at a time. Identify an appropriate sample space. Is it possible to identify a sample space in which all outcomes have the same “length”?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.4. An outcome could represent the sequence of prizes we obtain in order. For example, (2, 3, 3, 2, 2, 2, 3, 1) represents prize 2 in the first box, prize 3 in the second and third boxes, prize 2 in the fourth, and so on, completing a collection with prize 1 in the eighth box. Outcomes recorded in this way can have different lengths if we only record the boxes we open until we complete a collection; for example (2, 3, 1) versus (2, 3, 3, 1) versus (2, 3, 3, 2, 1). However, it is often convenient for sample space outcomes to have the same length.\nWe can define outcomes with the same “length” if we assume the process continues indefinitely, that is, if we continue to open boxes even after we complete a set. Now an outcome is an infinite sequence, with each component of the sequence taking a value of 1, 2, or 3; for example, (2, 3, 3, 2, 2, 2, 3, 1, 2, 1, 1, 3, \\(\\ldots\\)). Thus the sample space7 is the set of all infinite sequences whose components take values in \\(\\{1, 2, 3\\}\\). Outcomes of this sample space all have the same “length”—infinite. Moreover, this sample space allows for a broader range of questions to be investigated. For example, we might be interested in the number of packages needed to obtain 5 complete collections (which might be relevant if you have 5 kids and they all want their own collection).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.5 Customers enter a deli and take a number to mark their place in line. When the deli opens the counter starts 0; the first customer to arrive takes number 1, the second 2, etc. We record the counter over time, continuously, as it changes as customers arrive. Time is measured in minutes after the deli opens (time 0). How might you define an appropriate sample space?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.5. A sample space outcome could be represented as a path of the value of the counter over time; a few such paths are illustrated in Figure 2.3. The horizontal axis represents time and the vertical axis represents the number of customers that have arrived. Notice the stairstep feature: a customer arrives and takes a number then the counter stays on that number for some time (the flat spots) until another customer arrives and the counter increases by one (the jumps). In other words, an outcome is a nondecreasing function mapping the time interval \\([0, \\infty)\\) to nonnegative integers \\(\\{0, 1, 2, \\ldots\\}\\), that only jumps by one unit at a time. The sample space consists of all possible functions of this form.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) A single sample path of the number of customer arrivals over time.\n\n\n\n\n\n\n\n\n\n\n\n(b) Several possible paths.\n\n\n\n\n\n\n\n\n\n\n\n(c) Many possible paths.\n\n\n\n\n\n\n\nFigure 2.3: Sample space outcomes for Example 2.5. Horizontal axes represent time and vertical axes represent the number of customers that have arrived.\n\n\n\n\n\n\n2.1.1 Counting outcomes\nWhen there are finitely many possibilities, we can ask: how many possible outcomes are there? In Example 2.1 and Example 2.2 we counted outcomes by enumerating them in a list. Of course, listing all the outcomes is unfeasible unless the sample space is very small. Now we’ll see a simple principle that can be applied to count outcomes.\n\n\n\n\n\n\n\nExample 2.6 A soft serve ice cream shop has three flavors: vanilla, chocolate, or swirl. Customers can choose to have a cone or a bowl.\n\nHow can you determine the number of different ways the ice cream can be served? (Two possible ways are vanilla in a cone and chocolate in a bowl).\nCustomers can also add rainbow or chocolate sprinkles8 or not. Now how many different ways can the ice cream be served?\nCustomers who request bowls can choose to add whipped cream. Is the number of different ways the ice cream can be served equal to the answer to the previous part multiplied by two?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.6. \n\nEach flavor can be served in 2 ways, cone or bowl. Since there are 3 flavors, the number of ways to serve is \\(2+2+2 = 3\\times2 = 6\\).\nEach of the 6 pairs from the previous part can be served in 3 ways, with rainbow sprinkles, with chocolate sprinkles, or without sprinkles. So the number of ways to serve is now \\(3\\times 2 \\times 3 = 18\\).\nNo. Only the bowls can get whipped cream so we can’t just multiply 18 by 2. Of the 18 possibilities from the previous part, 9 are in bowls. So these 9 can be served with or without whipped cream, but the other 9 in cones can only be served without whipped cream. The number of possibilities is now \\(9\\times 2 + 9 = 27\\).\n\n\n\n\n\nAll of the counting rules we will see are based on multiplying like in Example 2.6.\n\nLemma 2.1 (Multiplication principle for counting) Suppose that stage 1 of a process can be completed in any one of \\(n_1\\) ways. Further, suppose that for each way of completing the stage 1, stage 2 can be completed in any one of \\(n_2\\) ways. Then the two-stage process can be completed in any one of \\(n_1\\times n_2\\) ways. This rule extends naturally to a \\(\\ell\\)-stage process, which can then be completed in any one of \\(n_1\\times n_2\\times n_3\\times\\cdots\\times n_\\ell\\) ways.\n\nIn the multiplication principle it is not important whether there is a “first” or “second” stage. What is important is that there are distinct stages, each with its own number of “choices”. In Example 2.6, there was a bowl/cone stage, an ice cream flavor stage, and a sprinkle stage; it didn’t matter if the flavor was chosen first or second or third.\nWe can use the multiplication principle to verify the total number of possible outcomes for a few of our previous examples. In Example 2.1 an outcome is a pair (first roll, second roll). There are 4 possibilities for the first roll and 4 for the second, so \\(4\\times4 = 16\\) possible pairs. In Example 2.2 an outcome is an arrangement of the 4 outcomes in the 4 spots. There are 4 possibilities for the object placed in spot 1. After placing that object, there are 3 possibilities for spot 2, then 2 possibilities for spot 3, with one object left for spot 4. So there are \\(4\\times3\\times2\\times1 = 24\\) possible arrangements.\n\n\n\n\n\n\n\nExample 2.7 Use the multiplication principle to count the total number of possible outcomes in each of the following situations.\n\nRoll a six-sided die three times and record the result of each roll in sequence\nRoll a four-sided die and a six-sided die and record the result of each roll.\nFlip a coin four times and record the result of each flip in sequence\nThe number of arrangements of the objects in the matching problem with \\(n=10\\).\nThe number of possible draws in Example 1.18.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.7. \n\nAn outcome is a sequence of the results of each of the 3 flips. There are six possibilities for each roll, so \\(6\\times6\\times6= 6^3=216\\) possible outcomes.\nThere are 4 possibilities for one roll and 6 possibilities for the other, so there are \\(4\\times 6 = 24\\) possible outcomes.\nAn outcome is a sequence of the H/T results of each of the 4 flips. There are two possibilities for each flip, so \\(2\\times2\\times2\\times2 = 2^4=16\\) possible outcomes.\nThere are 10 objects that could potentially go in spot 1, then 9 objects that could potentially go in spot 2, 8 to spot 3, and so on, with 1 left for spot 10. This results in \\(10\\times9\\times8\\times\\cdots\\times1=10! = 3,628,800\\) possible outcomes. (That’s over 3.6 million possibilities; we certainly wouldn’t want to make a table!)\nThere are 5 possibilities for the first draw, then 4 possibilities for the second. If we record the outcome as the (first draw, second draw) result, there are \\(5\\times4 = 20\\) possible outcomes.\n\n\n\n\n\nThe multiplication principle provides the foundation for some other counting rules we will see later.\n\n\n2.1.2 Exercises\n\nExercise 2.1 Consider the outcome of a sequence of 4 flips of a coin.\n\nWithout enumerating the sample space, determine the number of outcomes.\nEnumerate the sample space and confirm the number of outcomes.\nWe might be interested in the number of flips that land on heads. Explain why it is still advantageous to define the sample space as in the previous part, rather than as \\(\\Omega=\\{0, 1, 2, 3, 4\\}\\).\n\n\n\nExercise 2.2 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.\n\nWithout enumerating the sample space, determine the number of outcomes.\nEnumerate the sample space and confirm the number of outcomes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-language-events",
    "href": "language-probability.html#sec-language-events",
    "title": "2  The Language of Probability",
    "section": "2.2 Events",
    "text": "2.2 Events\nAn event is something that might happen or might be true. For example, if we’re interested in the weather conditions in our city tomorrow, events include\n\nit rains\nit does not rain\nthe high temperature is 75°F (rounded to the nearest °F)\nthe high temperature is above 75°F\nit rains and the high temperature is above 75°F\nit does not rain or the high temperature is not above 75°F\n\nThere are many possible outcomes for tomorrow’s weather, but each of the above will be true only for certain outcomes.\n\nDefinition 2.2 An event is a subset of the sample space. An event represents a collection of outcomes that some criteria.\n\nThe sample space is the collection of all possible outcomes; an event represents only those outcomes which satisfy some criteria. Events are typically denoted with capital letters near the start of the alphabet, with or without subscripts (e.g. \\(A\\), \\(B\\), \\(C\\), \\(A_1\\), \\(A_2\\)).\nMathematically, events are sets, so events can be composed from others using basic set operations like unions (\\(A\\cup B\\)), intersections (\\(A \\cap B\\)), and complements (\\(A^c\\)).\n\nComplements. Read \\(A^c\\) as “not \\(A\\)”, the outcomes that do not satisfy \\(A\\)\nIntersections. Read \\(A\\cap B\\) as “\\(A\\) and \\(B\\)”, the outcomes that satisfy both \\(A\\) and \\(B\\)\nUnions. Read \\(A \\cup B\\) as “\\(A\\) or \\(B\\)”, the outcomes that satisfy \\(A\\) or \\(B\\). Unions (\\(\\cup\\), “or”) are always inclusive: \\(A\\cup B\\) occurs if \\(A\\) occurs but \\(B\\) does not, \\(B\\) occurs but \\(A\\) does not, or both \\(A\\) and \\(B\\) occur. Note that the complement of a union is the intersection of the complements, and vice versa: \\((A \\cup B)^c = A^c \\cap B^c\\) and \\((A \\cap B)^c = A^c \\cup B^c\\),\n\nIn the weather example above we can write\n\n\\(A\\): it rains\n\\(B=A^c\\): it does not rain\n\\(C\\): the high temperature is 75°F (rounded to the nearest °F)\n\\(D\\): the high temperature is above 75°F\n\\(E = A \\cap D\\): it rains and the high temperature is above 75°F\n\\(F = A^c \\cup D^c = (A\\cap D)^c = B\\cap D^c = E^c\\): it does not rain or the high temperature is not above 75°F\n\n\n\n\n\n\n\n\nExample 2.8 Every year the NBA Draft Lottery is conducted to determine which non-playoff teams will receive the top draft picks. Table 2.3 displays the teams that participated in the 2023 NBA Draft Lottery (held on May 16, 2023) along with some team statistics from the 2022-2023 season and the number of previous NBA championships won by the franchise (as of 2023).\nImagine it’s early May 2023 and the lottery hasn’t happened yet. The lottery determines—at random—the top three picks, but we’ll just consider the team who wins the first pick in the 2023 draft. The sample space is the 14 teams in Table 2.3. Identify each of the following events relating to the team that wins the top pick.\n\n\\(A\\), the team is in the Western Conference.\n\\(B\\), the team has never won a championship.\n\\(C\\), the team won fewer than 25 games (Wins) in the 2022-2023 season\n\\(D\\), the team scored over 115 points per game (PPG) in the 2022-2023 season\nIdentify and interpret \\(A\\cap B\\)\nIdentify and interpret \\(A \\cap B \\cap D\\)\nIdentify and interpret \\(A \\cup B\\)\nIdentify and interpret \\(B^c\\)\n\n\n\n\n\n\n\n\n\nTable 2.3: Teams in the 2023 NBA Draft Lottery\n\n\n\n\n\n\nTeam\nConference\nChampionships\nWins\nPPG\nFG3\nFG3A\nFG2\nFG2A\nFT\nFTA\n\n\n\n\nDetroit Pistons\nEastern\n3\n17\n110.3\n11.4\n32.4\n28.2\n54.6\n19.8\n25.7\n\n\nHouston Rockets\nWestern\n2\n22\n110.7\n10.4\n31.9\n30.2\n56.9\n19.1\n25.3\n\n\nSan Antonio Spurs\nWestern\n5\n22\n113.0\n11.1\n32.2\n32.0\n60.4\n15.8\n21.2\n\n\nCharlotte Hornets\nEastern\n0\n27\n111.0\n10.7\n32.5\n30.5\n57.9\n17.6\n23.6\n\n\nPortland Trail Blazers\nWestern\n1\n33\n113.4\n12.9\n35.3\n27.6\n50.1\n19.6\n24.6\n\n\nOrlando Magic\nEastern\n0\n34\n111.4\n10.8\n31.1\n29.8\n55.2\n19.6\n25.0\n\n\nIndiana Pacers\nEastern\n0\n35\n116.3\n13.6\n37.0\n28.4\n52.6\n18.7\n23.7\n\n\nWashington Wizards\nEastern\n1\n35\n113.2\n11.3\n31.7\n30.9\n55.2\n17.6\n22.4\n\n\nUtah Jazz\nWestern\n0\n37\n117.1\n13.3\n37.8\n29.2\n52.0\n18.7\n23.8\n\n\nDallas Mavericks\nWestern\n1\n38\n114.2\n15.2\n41.0\n24.8\n43.3\n19.0\n25.1\n\n\nChicago Bulls\nEastern\n6\n40\n113.1\n10.4\n28.9\n32.1\n57.9\n17.6\n21.8\n\n\nOklahoma City Thunder\nWestern\n1\n40\n117.5\n12.1\n34.1\n31.0\n58.5\n19.2\n23.7\n\n\nToronto Raptors\nEastern\n1\n41\n112.9\n10.7\n32.0\n31.1\n59.3\n18.4\n23.4\n\n\nNew Orleans Pelicans\nWestern\n0\n42\n114.4\n11.0\n30.1\n31.1\n57.5\n19.3\n24.4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.8. We’ll write each of the events as a set of teams, but you can also think of each event as a subset of the rows of Table 2.3.\n\n\\(A = \\{\\text{Houston, San Antonio, Portland, Utah, Dallas, Oklahoma City, New Orleans}\\}\\)\n\\(B = \\{\\text{Charlotte, Orlando, Indiana, Utah, New Orleans}\\}\\)\n\\(C=\\{\\text{Detroit, Houston, San Antonio}\\}\\)\n\\(D = \\{\\text{Indiana, Utah, Oklahoma City}\\}\\)\n\\(A\\cap B = \\{\\text{Utah, New Orleans}\\}\\) is the event that the team is in the Western Conference and has won no previous championships.\n\\(A \\cap B \\cap D=\\{\\text{Utah}\\}\\) is the event that the team is in the Western Conference, has won no previous championships, and scored over 115 points per game in the 2022-2023 season.\n\\(A \\cup B=\\{\\text{Charlottle, Houston, San Antonio, Portland, Orlando, Indians, Utah, Dallas, Oklahoma City, New Orleans}\\}\\) is the event that the team is in the Western Conference or has won no previous championships. Notice that teams that satisfy both \\(A\\) and \\(B\\), Utah and New Orleans, are included but only once.\n\\(B^c=\\{\\text{Detroit, Houston, San Antonio, Portland, Washington, Dallas, Chicago, Oklahoma City, Toronto}\\}\\) is the event that the team has won at least one previous championship.\n\n\n\n\n\nIn Example 2.8 notice that we ony said the winner was determined “at random”; we didn’t mention how. “At random” only implies that the winning team will be selected in a manner that involves uncertainly. “At random” does not necessarily imply that the 14 teams are equally likely. In fact, the 2023 NBA Draft Lottery was weighted to give teams with fewer wins the previous season a greater probability of winning the top pick. We’ll return to this idea later. For now, we’re just defining some events that are possible; later we will consider how probable they are.\nIf the outcomes of a sample space are represented by rows in a table, then events are subsets of rows which satisfy some criteria.\n\n\n\n\n\n\n\nExample 2.9 Roll a four-sided die twice, and record the result of each roll in sequence. Using the sample space from Example 2.1, identify the following events.\n\n\\(A\\), the event that the sum of the two dice is 4.\n\\(B\\), the event that the sum of the two dice is at most 3.\n\\(C\\), the event that the larger of the two rolls (or the common roll if a tie) is 3.\n\\(A\\cap C\\) (identify and interpret).\n\\(D\\), the event that the first roll is a 3.\n\\(E\\), the event that the second roll is a 3.\n\\(D \\cap E\\) (identify and interpret).\n\\(D \\cup E\\) (identify and interpret).\nIf the outcome is \\((1, 3)\\), which of the events above occurred?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.9. Remember that the sample space consists of 16 possible ordered pairs of rolls, (first roll, second roll); see Table 2.1. All events must be defined as subsets of this sample space.\n\n\\(A\\) consists of the outcomes (1, 3), (2, 2), and (3, 1). In set notation, event \\(A\\) is the set \\(\\{(1, 3), (2, 2), (3, 1)\\}\\). This event is highlighted in Table 2.4.\n\\(B\\) consists of the outcomes (1, 1), (1, 2), and (2, 1). In set notation, \\(B = \\{(1, 1), (1, 2), (2, 1)\\}\\).\n\\(C\\) consists of the outcomes (1, 3), (2, 3), (3, 1), (3, 2), and (3, 3). In set notation, \\(B = \\{(1, 3), (2, 3), (3, 1), (3, 2), (3, 3)\\}\\).\n\\(A\\cap C\\), which consists of the outcomes (1, 3) and (3, 1), is the event that both the sum of the two dice is 4 and the larger of the two rolls is 3. In set notation, \\(A \\cap C = \\{(1, 3), (3, 1)\\}\\).\nEach outcome in the sample space consists of a pair of rolls, so we must account for both rolls in defining events, even if the event of interest involves just the first roll. (Remember, there is always a single sample space upon which all events are defined.) So \\(D\\) consists of the outcomes (3, 1), (3, 2), (3, 3), and (3, 4). In set notation, \\(D = \\{(3, 1), (3, 2), (3, 3), (3, 4)\\}\\).\n\\(E\\) consists of the outcomes (1, 3), (2, 3), (3, 3), and (4, 3). In set notation, \\(E = \\{(1, 3), (2, 3), (3, 3), (4, 3)\\}\\). Note that this is not the same event as \\(D\\).\n\\(D \\cap E\\), which consists only of the outcome (3, 3), is the event that both rolls result in a 3. While an event is always a set, it can be a set consisting of a single outcome (or the empty set). In set notation, \\(D\\cap E = \\{(3, 3)\\}\\).\n\\(D \\cup E\\), which consists of the outcomes (3, 1), (3, 2), (3, 3), (3, 4), (1, 3), (2, 3), and (4, 3) is the event that at least one of the two rolls results in a 3. In set notation, \\(D \\cup E = \\{(3, 1), (3, 2), (3, 3), (3, 4), (1, 3), (2, 3), (4, 3)\\}\\). Notice that the union is inclusive: \\((3, 3)\\), the outcome that satisfies both \\(D\\) and \\(E\\), is an element of \\(D\\cup E\\). But also notice that the outcome \\((3, 3)\\) only appears once in \\(D\\cup E\\).\nIf the outcome is \\((1, 3)\\) then events \\(A\\), \\(C\\), \\(A\\cap C\\), \\(E\\), \\(D\\cup E\\) all occur. Events \\(B,\\) \\(D\\) and \\(D\\cap E\\) do not occur. The outcome \\((1, 3)\\) is an element of each of the sets \\(A\\), \\(C\\), \\(A\\cap C\\), \\(E\\), \\(D\\cup E\\), but not of \\(B,\\) \\(D\\) and \\(D\\cap E\\).\n\n\n\n\n\n\n\n\n\nTable 2.4: Table representing the sample space of two rolls of a four-sided die. The outcomes in orange comprise the event \\(A\\), the sum is equal to 4.\n\n\n\n\n\n\nFirst roll\nSecond roll\nSum is 4?\n\n\n\n\n1\n1\nno\n\n\n1\n2\nno\n\n\n1\n3\nyes\n\n\n1\n4\nno\n\n\n2\n1\nno\n\n\n2\n2\nyes\n\n\n2\n3\nno\n\n\n2\n4\nno\n\n\n3\n1\nyes\n\n\n3\n2\nno\n\n\n3\n3\nno\n\n\n3\n4\nno\n\n\n4\n1\nno\n\n\n4\n2\nno\n\n\n4\n3\nno\n\n\n4\n4\nno\n\n\n\n\n\n\n\n\nWe reiterate (again!) that there is a single sample space, upon which all events are defined. In the above example, events that involved only the first or second roll such as \\(D\\) and \\(E\\) were still defined in terms of pairs of rolls. An outcome in a sample space should be defined to record as much information as possible so that the occurrence or non-occurrence of all events of interest can be determined.\nSome events consist of a single outcome, or no outcomes at all (the “empty set” denoted \\(\\{\\}\\) or \\(\\emptyset\\)).\n\nDefinition 2.3 Events \\(A_1, A_2. A_3, \\ldots\\) are disjoint (a.k.a. mutually exclusive) if none of the events have any outcomes in common; that is, if \\(A_i \\cap A_j = \\emptyset\\) for all \\(i\\neq j\\).\n\nRoughly, disjoint events do not “overlap”. In Example 2.9, events \\(B\\) and \\(C\\) are disjoint since \\(B \\cap C = \\emptyset\\); there are no outcomes for which both the sum of the dice is at most 3 and the larger roll is a 3.\n\n\n\n\n\n\n\nExample 2.10 In the matching problem with \\(n=4\\) objects labeled 1, 2, 3, 4, are placed in spots labeled 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. Using the sample space from Example 2.2, identify the following events.\n\n\\(A\\), the event that all objects are put in the correct spot.\n\\(F\\), the event that no objects are put in the correct spot.\n\\(D\\), the event that exactly 3 objects are put in the correct spot.\n\\(A_3\\), the event that object 3 is put (correctly) in spot 3.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.10. Recall that each outcome is a particular placement of objects in the spots. For example, the outcome (3, 2, 1, 4)—which we’ll shorten to 3214—signifies that object 3 is put in spot 1, object 2 in spot 2, object 1 in spot 3, and object 4 in spot 4.\n\nThere is only one outcome, 1234, for which all objects are put in the correct spot, so \\(A=\\{1234\\}\\). Remember that an event is always a set, but it can be a set consisting of a single outcome.\nFor each outcome in the sample space check to see if the criteria holds to identify \\(F=\\{2143, 2341, 2413, 3142, 3412, 3421, 4123, 4312, 4321\\}\\) as the event that no objects are put in the correct spot.\nThere are no outcomes in which exactly 3 objects are put in the correct spot so \\(D=\\emptyset\\). (For \\(n=4\\), if three objects are in their correct spots, then the remaining object must be in its correct spot too.)\n\\(A_3=\\{1234, 1432, 2134, 2431, 4132, 4231\\}\\) is the event that object 3 is put (correctly) in spot 3. This event is highlighted in Table 2.5. Even though event \\(A_3\\) only concerns object 3, since the sample space consists of the placements of each of the objects then all events must be expressed in terms of these outcomes.\n\n\n\n\n\n\n\n\n\nTable 2.5: Table representing the sample space in the matching problem with \\(n=4\\). The outcomes in orange comprise the event \\(A_3\\), object 3 in spot 3.\n\n\n\n\n\n\nSpot 1\nSpot 2\nSpot 3\nSpot 4\nObject 3 in spot 3?\n\n\n\n\n1\n2\n3\n4\nyes\n\n\n1\n2\n4\n3\nno\n\n\n1\n3\n2\n4\nno\n\n\n1\n3\n4\n2\nno\n\n\n1\n4\n2\n3\nno\n\n\n1\n4\n3\n2\nyes\n\n\n2\n1\n3\n4\nyes\n\n\n2\n1\n4\n3\nno\n\n\n2\n3\n1\n4\nno\n\n\n2\n3\n4\n1\nno\n\n\n2\n4\n1\n3\nno\n\n\n2\n4\n3\n1\nyes\n\n\n3\n1\n2\n4\nno\n\n\n3\n1\n4\n2\nno\n\n\n3\n2\n1\n4\nno\n\n\n3\n2\n4\n1\nno\n\n\n3\n4\n1\n2\nno\n\n\n3\n4\n2\n1\nno\n\n\n4\n1\n2\n3\nno\n\n\n4\n1\n3\n2\nyes\n\n\n4\n2\n1\n3\nno\n\n\n4\n2\n3\n1\nyes\n\n\n4\n3\n1\n2\nno\n\n\n4\n3\n2\n1\nno\n\n\n\n\n\n\n\n\nWe can use the multiplication principle to count the number of outcomes that satisfy event \\(A_3\\) in Table 2.5. If object 3 is in spot 3, there are 3 objects that can go in spot 1, then 2 that can go in spot 2, leaving 1 for spot 4; for a total of \\(3\\times2\\times1\\times1=6\\) of the 24 outcomes which satisfy event \\(A_3\\).\nWhen more than just a few events are of interest, subscripts are commonly used to identify different events. In the previous example, we might also be interested in \\(A_1\\), the event that object 1 is placed in spot 1; \\(A_2\\), the event that object 2 is placed in spot 2; and so on.\nRemember that intervals of real numbers such as \\((a,b), [a,b], (a,b]\\) are also sets, and so can also be events. For example, if an outcome is the result of a single spin of the spinner in Figure 2.1, events include\n\n\\([0, 0.5]\\), the result is between 0 and 0.5 (the needle lands in the right half of the spinner)\n\\([0.75, 1]\\), the result is between 0.75 and 1 (the needle lands in the northwest quarter of the spinner)\n\\([0.595, 0.605)\\), the result rounded to two decimal places is 0.60\n\\(\\{0.6\\}\\), the result is 0.6 exactly (the needle points exactly at 0.60000000\\(\\ldots\\))\n\nIt is often helpful to conceptualize and visualize events (sets) with pictures, especially when dealing with continuous sample spaces.\n\n\n\n\n\n\n\nExample 2.11 Using the sample space from Example 2.3, identify the following events using pictures.\n\n\\(A\\), the event that Regina arrives after Cady.\n\\(B\\), the event that either Regina or Cady arrives before 12:30.\n\\(C\\), the event that Cady arrives first and Regina arrives at most 15 minutes after Cady.\n\\(D\\), the event that Regina arrives before 12:24.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.11. Figure 2.2 represents the sample space, a square with \\([0, 60]\\) sides. Each point within the square is a (Regina, Cady) pair of arrival times. We can shade the regions of the sample space corresponding to pairs of points that satisfy these events. See Figure 2.4.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.4: Depiction of the events in Example 2.11.\n\n\n\n\n\nIn Example 2.11 the sample space consists of (Regina, Cady) pairs of arrival times so any event must be expressed as a collection of pairs. Even though the criteria for event \\(D\\) involves only Regina’s arrival time, the event is not simply [0, 24]; we need to consider all (Regina, Cady) pairs for which the Regina component is in the interval [0, 24].\n\n\n\n\n\n\n\nExample 2.12 Consider the sample space in Example 2.5. Sketch a picture representing \\(A\\), the event that no arrivals occur in the first 5 minutes.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.12. The sample space consists of all possible non-decreasing integer-valued paths that start at 0 at time 0; a few outcomes are depicted in Figure 2.5. Only paths that result in 0 arrivals at time 5 satisfy event \\(A\\). Figure 2.5 highlights in orange a few possible outcomes that satisfy event \\(A\\). Event \\(A\\) consists of all paths that stay constant at 0 from time 0 until at least time 5.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.5: Sample space outcomes for Example 2.12. Paths in orange satisfy \\(A\\), the event that no arrivals occur in the first 5 minutes; paths in blue do not satisfy event \\(A\\).\n\n\n\n\n\nIn many situations it is not possible to explicitly define a sample space in a compact way, and so outcomes and events are often only vaguely defined. Nevertheless, there is always a sample space in the background representing possible outcomes, and collections of these outcomes represent events of interest.\n\n\n\n\n\n\n\nExample 2.13 Donny Don’t is asked a series of questions involving a pair of rolls of six-sided dice, such as “identify the event that the sum of the dice is at least 10”. Donny’s responses are below; explain to him what is wrong with his responses and help him understand the correct answers.\n\nThe possible rolls are 1 through 6, so the sample space is \\(\\{1, 2, 3, 4, 5, 6\\}\\).\nThe sum of the two dice can be 2 through 12, so the event that the sum of the two dice is at least 10 is \\(\\{10, 11, 12\\}\\).\nThe event that the first roll is a 3 is \\(\\{3\\}\\).\nThe event that the first roll is a 3 and the second roll is a 1 is \\(\\{3, 1\\}\\)\nDonny’s sample space from the first question might correspond to what dice rolling scenario?\nDonny says “OK, I get that \\(\\{1, 2, 3, 4, 5, 6\\}\\) is the sample space for a single roll of a six-sided die. But \\(\\{3, 1\\}\\) doesn’t make any as an event because the die can’t land on both 1 and 3.” Explain to Donny what the event \\(\\{3, 1\\}\\) represents in this scenario.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.13. \n\nThe questions involve a pair of rolls, so best to record an outcome as an ordered pair, e.g., (5, 2) for 5 on the first roll and 2 on the second. Therefore, the sample space would be the following set of 36 possible outcomes. \\[\\begin{align*}\n\\Omega  = & \\{\n(1, 1), (1, 2), \\ldots, (1, 6),\\\\\n& \\;\\; (2, 1), (2, 2), \\ldots, (2, 6),\\\\\n& \\;\\; \\vdots\\qquad \\qquad \\quad \\cdots \\qquad \\vdots\\\\\n& \\;\\; (6, 1), (6, 2), \\ldots, (6, 6)\n\\}\n\\end{align*}\\]\nDonny’s answers to the first two parts are inconsistent, since there is always a single sample space. So if he says the answer to the first part is \\(\\{1, \\ldots, 6\\}\\), then any event must be a subset of that sample space and his answer to the second part must be wrong. Using the sample space of 36 ordered pairs from the previous answer, the correct event that the sum of the two dice is at least 10 is \\(\\{(4, 6), (5, 5), (5, 6), (6, 4), (6, 5), (6, 6)\\}\\). If Donny’s sample space in the first part had been \\(\\{2, \\ldots, 12\\}\\), corresponding to the sum of the two dice, then his answer of \\(\\{10, 11, 12\\}\\) would have been correct. However, using such a sample space, he would not have been able to answer the remaining questions (which don’t involve the sum of the rolls). There is always one sample space on which all events are defined.\nDonny didn’t take into account that an outcome is a pair of rolls. The correct event is \\(\\{(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)\\}\\), the set of all pairs of rolls for which the first roll is 3.\nMaybe Donny is just using sloppy notation here, but it sure looks like he is confusing an outcome with an event. The answer should be \\(\\{(3, 1)\\}\\), the set containing the single outcome \\((3, 1)\\). Notice that this is not the same set as \\(\\{(1, 3)\\}\\). (But the set \\(\\{3, 1\\}\\) is the same as the set \\(\\{1, 3\\}\\).)\nThe sample space of \\(\\{1, 2, 3, 4, 5, 6\\}\\) could correspond to a single roll of a fair six-sided die. The possible outcomes for a single roll would be \\(\\{1, 2, 3, 4, 5, 6\\}\\).\nFor a single roll, \\(\\{3, 1\\}\\) is the event the the die lands on 3 or 1, that is, “1 or 3”; the set \\(\\{3, 1\\}\\) is the same as the set \\(\\{1, 3\\}\\). The event “1 or 3” occurs if the die lands on 1, so 1 satisifies the event and is in the corresponding set; The event “1 or 3” occurs if the die lands on 3, so 3 satisifies the event and is in the corresponding set. Therefore the event “1 or 3” corresponds to the set \\(\\{1, 3\\}\\). The event occurs if any of the outcomes that satisfy the event occurs (not if they all do). (Donny is right that the die can’t land on both 1 and 3, but the event “1 and 3” would be \\(\\{1\\}\\cap \\{3\\}=\\emptyset\\); there are no outcomes that satisfy the event “1 and 3”.)\n\n\n\n\n\n\n2.2.1 The collection of events of interest\nAn outcome is a possible realization of a random phenomenon. The sample space is the set of all possible outcomes. An event is a subset of the space space consisting of outcomes that satisfy some criteria. There are many events of interest for any random phenomenon. The collection of all events of interest is often denoted \\(\\mathcal{F}\\).\nAn event \\(A\\) is a set. The collection \\(\\mathcal{F}\\) of events of interest is a collection of sets. For the purposes of this text, \\(\\mathcal{F}\\) can be considered to be the set of all subsets9 of \\(\\Omega\\).\nAs an example, consider a single roll of a four-sided die.\n\n\n\n\n\n\nCaution\n\n\n\nThis section concerns a single roll of a fair four-sided die. Don’t confuse this scenario with many other examples that involve two rolls.\n\n\n\n\n\n\n\n\n\nExample 2.14 Consider a single roll of a four-sided die. The sample space consists of the four possible outcomes \\(\\Omega = \\{1, 2, 3, 4\\}\\).\n\nIdentify \\(A\\), the event that the die lands on 1.\nIdentify \\(B\\), the event that the die lands on an odd number.\nIdentify \\(C\\), the event that the die lands on 1 or 2.\nIdentify \\(D\\), the event that the die does not land on 4.\nWhich of the events \\(A, B, C, D\\) occur if the die lands on 3?\nIdentify all possible events for this sample space, and determine whether or not each event occurs if the die lands on 3.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.14. For a single roll of a four-sided die, the sample space consists of the four possible outcomes \\(\\Omega = \\{1, 2, 3, 4\\}\\). (Again, don’t confuse this scenario with other examples!) Any subset of this sample space is an event.\n\n\\(A = \\{1\\}\\) is the event that the die lands on 1.\n\\(B = \\{1, 3\\}\\) is the event that the die lands on an odd number. (This event occurs if the die lands on 1 so 1 is in \\(B\\); it also occurs if the die lands on 3 so 3 is in \\(B\\).)\n\\(C = \\{1, 2\\}\\) is the event that the die lands on 1 or 2.\n\\(D = \\{1, 2, 3\\}\\) is the event that the die does not land on 4.\nIf the die lands on 3 then events \\(B\\) and \\(D\\) occur and events \\(A\\) and \\(C\\) do not occur. Notice that 3 is an element of the sets \\(B\\) and \\(D\\) but not \\(A\\) and \\(C\\).\nAny subset of \\(\\{1, 2, 3, 4\\}\\) is an event, including \\(\\emptyset\\) and \\(\\{1, 2, 3, 4\\}\\) itself. Table 2.6 lists all possible events, and whether they occur if the single roll results in a 3 (that is, for the outcome \\(\\omega=3\\)).\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nWe usually think of a table as a list of all possible outcomes, with one row for each outcome. Table 2.6 is a different kind of table. Each row of Table 2.6 is an event, and the table lists the collection of all events (\\(\\mathcal{F}\\))\n\n\n\n\n\nTable 2.6: All possible events associated with a single roll of a four-sided die.\n\n\n\n\n\nEvent\nDescription\nOccurs upon observing outcome \\(\\omega=3\\)?\n\n\n\n\n\\(\\emptyset\\)\nRoll nothing (not possible)\nNo\n\n\n\\(\\{1\\}\\)\nRoll a 1\nNo\n\n\n\\(\\{2\\}\\)\nRoll a 2\nNo\n\n\n\\(\\{3\\}\\)\nRoll a 3\nYes\n\n\n\\(\\{4\\}\\)\nRoll a 4\nNo\n\n\n\\(\\{1, 2\\}\\)\nRoll a 1 or a 2\nNo\n\n\n\\(\\{1, 3\\}\\)\nRoll a 1 or a 3\nYes\n\n\n\\(\\{1, 4\\}\\)\nRoll a 1 or a 4\nNo\n\n\n\\(\\{2, 3\\}\\)\nRoll a 2 or a 3\nYes\n\n\n\\(\\{2, 4\\}\\)\nRoll a 2 or a 4\nNo\n\n\n\\(\\{3, 4\\}\\)\nRoll a 3 or a 4\nYes\n\n\n\\(\\{1, 2, 3\\}\\)\nRoll a 1, 2, or 3 (a.k.a. do not roll a 4)\nYes\n\n\n\\(\\{1, 2, 4\\}\\)\nRoll a 1, 2, or 4 (a.k.a. do not roll a 3)\nNo\n\n\n\\(\\{1, 3, 4\\}\\)\nRoll a 1, 3, or 4 (a.k.a. do not roll a 2)\nYes\n\n\n\\(\\{2, 3, 4\\}\\)\nRoll a 2, 3, or 4 (a.k.a. do not roll a 1)\nYes\n\n\n\\(\\{1, 2, 3, 4\\}\\)\nRoll something\nYes\n\n\n\n\n\n\nA random phenomenon corresponds to a single sample space, but there are many events of interest. Listing the collection of all possible events as in the previous table is rarely done in practice, but we do so here to provide a concrete example of \\(\\mathcal{F}\\).\n\n\n2.2.2 Exercises\n\nExercise 2.3 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.\n\nLet \\(A_1\\) be the event that prize 1 is obtained—that is, at least one of the packages contains prize 1—and define \\(A_2, A_3\\) similarly for prize 2, 3.\nLet \\(B_1\\) be the event that only prize 1 is obtained—that is, all three packages contain prize 1—and define \\(B_2, B_3\\) similarly for prize 2, 3.\n\nIdentify the following events as sets and interpret them in words\n\n\\(A_1\\) (hint: define \\(A_1^c\\) first)\n\\(B_1\\)\n\\(A_1 \\cap A_2 \\cap A_3\\)\n\\(A_1 \\cup A_2 \\cup A_3\\)\n\\(B_1 \\cap B_2 \\cap B_3\\)\n\\(B_1 \\cup B_2 \\cup B_3\\)\n\n\n\nExercise 2.4 Katniss throws a dart at a circular dartboard with radius 1 foot. (Assume that Katniss’s dart never misses the dartboard.)\nDraw a picture to represent each of these events.\n\n\\(A\\), Katniss’s dart lands within 1 inch of the center of the dartboard.\n\\(B\\), Katniss’s dart lands more than 1 inch but less than 2 inches away from the center of the dartboard.\n\\(E\\), Katniss’s dart lands within 1 inch of the outside edge of the dartboard.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-rv",
    "href": "language-probability.html#sec-rv",
    "title": "2  The Language of Probability",
    "section": "2.3 Random variables",
    "text": "2.3 Random variables\nStatisticians use the terms observational unit and variable. Observational units are the people, places, things, etc., for which data is observed. Variables are the measurements made on the observational units. For example, the observational units in a study could be college students, while variables could be age, high college GPA, major GPA, number of credits completed, number of Statistics courses taken, etc.\nIn probability, an outcome of a random phenomenon plays a role analogous to an observational unit in statistics. The sample space of outcomes is often only vaguely defined. In many situations we are less interested in detailing the outcomes themselves and more interested in whether or not certain events occur, or with measurements that we can make for the outcomes. For example, if the random phenomenon corresponds to randomly selecting a single student at a college an outcome would be the selected student, but we are more interested in quantities like the student’s GPA or number of credits completed. If we randomly select a sample of students, we are less interested in who the students are, and more interested in questions which involve variables such as what is the relationship between college GPA and major GPA? In probability, random variables play a role analogous to variables in statistics.\n\nDefinition 2.4 A random variable assigns a number measuring some quantity of interest to each outcome of a random phenomenon. That is, a random variable is a function that takes an outcome in the sample space as input and returns a number as output.\n\nIf we’re interested in the weather conditions in our city tomorrow, random variables include\n\nhigh temperature (°F)\namount of precipitation (cm)\nhumidity (%)\nmaximum wind speed (mph)\n\nEach of these quantities will take a value that depends on tomorrow’s weather conditions. Since there are a range of possibilities for tomorrow’s weather conditions, there is a range of values that each of these random variables can take.\nRandom variables are typically denoted by capital letters near the end of the alphabet, with or without subscripts: e.g. \\(X\\), \\(Y\\), \\(Z\\), or \\(X_1\\), \\(X_2\\), \\(X_3\\), etc.\n\n\n\n\n\n\n\nExample 2.15 Donny Don’t is working on a problem that starts “let \\(X\\) be a random variable representing tomorrow’s high temperature in your city”. Donny says: “There is only one tomorrow and there will only be one high temperature tomorrow in my city. Tomorrow’s high temperature will just be a single number, there’s nothing variable about it.” Explain to Donny what it means to say “tomorrow’s high temperature is a random variable”.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.15. Yes, tomorrow’s high temperature will be a single number, but we do not know what that number will be. Tomorrow’s weather conditions are uncertain, that is, random. Even if the forecast calls for a high of 75 degrees F, the high temperature could be 75 degrees, or 78 or 72 or 74, etc. A random variable represents all the different possible values that tomorrow’s high temperature might be depending on the uncertain weather conditions.\n\n\n\n\nA random variable is “variable” in the sense that it can take different values—that is, it can vary—and the value it takes is uncertain—that is, “random”.\n\n\n\n\n\n\n\nExample 2.16 Continuning Example 2.8. Let \\(X\\) be the number of previous championships won by the team that wins the top pick in the lottery. Explain what it means for \\(X\\) to be a random variable and identify its possible values.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.16. Before the lottery is conducted, the team that will win the top pick is uncertain and so their number of previous championships is also uncertain, and the value will vary depending on which team wins. The possible values are \\(\\{0, 1, 2, 3, 5, 6\\}\\).\n\n\n\n\nIn statistics, data is often stored in a spreadsheet or data table with rows corresponding to observational units and columns to variables. Likewise, in probability it helps to visualize a table with rows corresponding to outcomes and columns to random variables. Each outcome is associated with a value of the random variable. Since the outcome is uncertain, the value the random variable takes is also uncertain.\n\n\n\n\n\n\n\nExample 2.17 Roll a four-sided die twice, and record the result of each roll in sequence. Recall the sample space from Example 2.1. Let \\(X\\) be the sum of the two dice, and let \\(Y\\) be the larger of the two rolls (or the common value if both rolls are the same).\n\nConstruct a table identifying the values of \\(X\\) and \\(Y\\) for each outcome in the sample space. Hint: add columns to Table 2.1.\nEvaluate \\(X((1, 3))\\), \\(X((4, 3))\\), and \\(X((2, 2))\\).\nEvaluate \\(Y((1, 3))\\), \\(Y((4, 3))\\), and \\(Y((2, 2))\\).\nIdentify the possible values of \\(X\\).\nIdentify the possible values of \\(Y\\).\nIdentify the possible values of the pair \\((X, Y)\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.17. \n\nSee Table 2.7. The first column corresponds to sample space outcomes, and there is a column for each random variable.\n\\(X\\) is the sum of the two rolls, so \\(X((1, 3))=1+3=4\\), \\(X((4, 3))=4+3=7\\), and \\(X((2, 2))=2+2=4\\).\n\\(Y\\) is the larger of the two rolls (or the common value if a tie) so \\(Y((1, 3))=\\max(1, 3) = 3\\), \\(Y((4, 3))=\\max(4, 3) =4\\), and \\(Y((2, 2))=\\max(2, 2) = 2\\).\nThe possible values of \\(X\\) are \\(2, 3, 4, 5, 6, 7, 8\\).\nThe possible values of \\(Y\\) are \\(1, 2, 3, 4\\).\nThe possible values of the pair \\((X, Y)\\) are: (2, 1), (3, 2), (4, 2), (4, 3), (5, 3), (5, 4), (6, 3), (6, 4), (7, 4), (8,4). Notice that while, for example, 8 is a possible value of \\(X\\) and 1 is a possible value of \\(Y\\), (8, 1) is not a possible value of the pair \\((X, Y)\\); it’s not possible for the larger of the two dice to be 1 but their sum to be 8.\n\n\n\n\n\n\n\n\n\nTable 2.7: Table representing the sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die\n\n\n\n\n\n\nOutcome (First roll, second roll)\nX (sum)\nY (max)\n\n\n\n\n(1, 1)\n2\n1\n\n\n(1, 2)\n3\n2\n\n\n(1, 3)\n4\n3\n\n\n(1, 4)\n5\n4\n\n\n(2, 1)\n3\n2\n\n\n(2, 2)\n4\n2\n\n\n(2, 3)\n5\n3\n\n\n(2, 4)\n6\n4\n\n\n(3, 1)\n4\n3\n\n\n(3, 2)\n5\n3\n\n\n(3, 3)\n6\n3\n\n\n(3, 4)\n7\n4\n\n\n(4, 1)\n5\n4\n\n\n(4, 2)\n6\n4\n\n\n(4, 3)\n7\n4\n\n\n(4, 4)\n8\n4\n\n\n\n\n\n\n\n\nMathematically, a random variable \\(X\\) is a function that takes an outcome \\(\\omega\\) in the sample space \\(\\Omega\\) as input and returns a number \\(X(\\omega)\\) as output; we write \\(X:\\Omega\\mapsto \\mathbb{R}\\). The random variable itself is typically denoted with a capital letter (\\(X\\)); possible values of that random variable are denoted with lower case letters (\\(x\\)). Think of the capital letter \\(X\\) as a label standing in for a formula like “the sum of two rolls of a four-sided die” and \\(x\\) as a dummy variable standing in for a particular value like 3.\nIn Example 2.17, the pair \\((X, Y)\\) is a random vector10. The output of each of \\(X\\) and \\(Y\\) is a number; the output of \\((X, Y)\\) is an ordered pair of numbers. A random vector is simply a vector of random variables.\nOne of the main reasons for modeling a sample space as the set of possible outcomes rather than the set of all possible values of some random variable is that we often want to define many random variables on the same sample space, and study relationships between them. As a statistics analogy, you would not be able to study the relationship between college GPA and major GPA unless you measured both variables for the same set of students.\n\n2.3.1 Types of random variables\nThere are two main types of random variables.\n\nDiscrete random variables take at most countably many possible values (e.g., \\(0, 1, 2, \\ldots\\)). They are often counting variables (e.g., the number of coin flips that land on heads).\nContinuous random variables can take any real value in some interval (e.g., \\([0, 1]\\), \\([0,\\infty)\\), \\((-\\infty, \\infty)\\).). That is, continuous random variables can take uncountably many different values. Continuous random variables are often measurement variables (e.g., height, weight, income).\n\nIn some problems, there are many random variables of interest, as in the following example.\n\n\n\n\n\n\n\nExample 2.18 Recall Example 2.5. Customers enter a deli and take a number to mark their place in line. When the deli opens the counter starts 0; the first customer to arrive takes number 1, the second 2, etc. We record the counter over time, continuously, as it changes as customers arrive. Time is measured in minutes after the deli opens (time 0).\nThere are many random variables that could be of interest, including\n\n\\(N_t\\), the number of customers that have arrived by time \\(t\\), where \\(t\\ge0\\) is minutes after time 0\n\\(T_j\\), the time (in minutes after time 0) at which the \\(j\\)th customer arrives, for \\(j=1, 2, \\ldots\\)\n\\(W_j\\), the “waiting” time (in minutes) between the arrival of the \\(j\\)th and the \\((j-1)\\)th customer.\n\nFor each of the following random variables, classify it as discrete or continuous. Then identify its value for the outcome represented by the path in Figure 2.6 (as best as you can from the plot).\n\n\\(N_4\\)\n\\(N_{6.5}\\)\n\\(T_4\\)\n\\(T_5\\)\n\\(W_1\\)\n\\(W_5\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.6: A sample outcome for Example 2.5.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.18. Let \\(\\omega\\) denote the outcome represented by Figure 2.6.\n\nThe random variable \\(N_4\\) counts the number of customers who have arrived by time 4. \\(N_4\\) is a discrete random variable taking values in the countable set \\(\\{0, 1, 2, \\ldots \\}\\). To compute the value of \\(N_4\\) for the outcome \\(\\omega\\) in Figure 2.6, find time \\(t=4\\) on the horizontal axis and find the corresponding value on the vertical axis: \\(N_4(\\omega)=8\\) customers; for this outcome, the number of customers that have arrived by time 4 is 8.\nThe random variable \\(N_{6.5}\\) which counts the number of customers who have arrived by time 6.5 is a discrete random variable taking values in the countable set \\(\\{0, 1, 2, \\ldots \\}\\). \\(N_{6.5}(\\omega)=13\\) customers; the number of customers that have arrived by time 6.5 is 13. The number of customers is a whole number, but time is measured continuously (e.g., 6.5 minutes after opening). There is a different discrete random variable \\(N_t\\) corresponding to each value of time \\(t\\ge 0\\), but the possible values of each of these variables are \\(\\{0, 1, 2, \\ldots\\}\\).\nThe random variable \\(T_4\\), which measures the time at which the fourth customer arrives, is a continuous random variable (since we’re assuming time is measured continuously). The smallest possible value of \\(T_4\\) is 0, but there is no definite largest possible value of \\(T_4\\), so \\(T_4\\) can take theoretically take any value in the continuous time interval \\([0, \\infty)\\). The fourth customer arrives when the path jumps from 3 customers so far to 4. For the outcome \\(\\omega\\) in Figure 2.6 the path jumps from 3 to 4 a little after time 2 so \\(T_4(\\omega)\\approx 2.1\\) minutes after noon.\nThe random variable \\(T_5\\) which measures the arrival time of the fifth customer is a continuous random variable taking values in \\([0, \\infty)\\). The fifth customer arrives when the path jumps from 4 customers so far to 5. For this outcome the path jumps from 4 to 5 almost right after it jumps from 3 to 4, and almost right after time 2, so \\(T_5(\\omega)\\approx 2.2\\) minutes after noon. There is a different continuous random variable \\(T_j\\) for each customer \\(j=1, 2, \\ldots\\), but the possible values of each of these random variables is \\([0,\\infty)\\).\n\\(W_1\\) is the waiting time from open until the first customer arrives, a continuous random variable taking values in \\([0, \\infty)\\). For the outcome \\(\\omega\\) in Figure 2.6 the path jumps from 0 to 1 a little after time 0 so \\(W_1(\\omega)\\approx 0.1\\) minutes.\n\\(W_5\\) is the time elapsed between the arrival of the fourth customer (at roughly time 2.1 for outcome \\(\\omega\\)) and fifth customer (at roughly time 2.2 for outcome \\(\\omega\\)), which is about 0.1 minutes.\n\n\n\n\n\n\n\n2.3.2 A random variable is a function\nRecall that for a mathematical function11 \\(g\\), given an input \\(u\\), the function returns a real number \\(g(u)\\). For example, if \\(g\\) is the square root function, \\(g(u) = \\sqrt{u}\\), then \\(g(9) = 3\\) and \\(g(10) = 3.162278...\\). If the input comes from some set \\(S\\) (i.e. \\(u\\in S\\)), we write \\(g:S\\mapsto \\mathbb{R}\\).\nA random variable \\(X\\) is a function which maps each outcome \\(\\omega\\) in the sample space \\(\\Omega\\) to a real number \\(X(\\omega)\\); \\(X:\\Omega\\mapsto\\mathbb{R}\\). For a single outcome \\(\\omega\\), the value \\(x = X(\\omega)\\) is a single number; notice that \\(x\\) represents the output of the function \\(X\\) rather than the input. However, it is important to remember that the random variable \\(X\\) itself is a function, and not a single number.\nYou are probably familiar with functions expressed as simple closed form formulas of their inputs: \\(g(u)=5u\\), \\(g(u)=u^2\\), \\(g(u)=\\log u\\), etc. While any random variable is some function, the function is rarely specified as an explicit mathematical formula of its input \\(\\omega\\). Often, outcomes are not even numbers (e.g., sequences of coin flips), or only vaguely specified if at all (e.g., tomorrow’s weather conditions). In Example 2.17 we defined \\(X\\) through the words “sum of two rolls of a fair four-sided dice” instead of as a formula12.\nIt is more appropriate to think of a random variable as a function in the sense of a scale at a grocery store which maps a fruit to its weight, \\(X: \\text{fruit}\\mapsto\\text{weight}\\). Put an apple on the scale and the scale returns a number, \\(X(\\text{apple})\\), the weight of the apple. Likewise, \\(X(\\text{orange})\\), \\(X(\\text{banana})\\). The random variable \\(X\\) is the scale itself. This simplistic analogy assumes a sample space outcome is a single fruit. Of course, it’s even more complicated in reality since an outcome can be considered a set of fruits, so that we have for example \\(X(\\{\\text{2 apples}, \\text{3 oranges}\\})\\), and all fruits do not weigh the same, so that \\(X(\\text{this apple})\\) is not the same as \\(X(\\text{that apple})\\). But the idea is that a function is like a scale, with an input (fruits) and an output (weight). The input does not have to be a number, but the output does.\nSuppose I’m going to randomly select some fruits, put them in a brown grocery bag, and place it on the scale. It wouldn’t be feasible to enumerate all the combinations of fruits I could put in the bag, but even so you know that any possible combination has some weight which could be measured by the scale. There is still a function (scale) that maps an input (fruits in the bag) to a numerical output (weight), even if that function is not explicitly specified with a mathematical formula. Now suppose I’ve selected some fruits and put the bag on the scale. Even if you can’t see what fruits are inside the bag, you can still read the weight off the scale. But even if you only observe the weight, you know there was still a background random process of putting fruits in a bag which resulted in a particular outcome having the observed weight.\nThe “weighing fruits in a bag” scenario in the previous paragraph illustrates how probability usually works:\n\nWe typically don’t explicitly specify outcomes or the sample space, but we know that different outcomes can result in different values of random variables. That is, we know there is some function which maps outcomes of the random phenomenon to values of the random variable, even if we don’t have an explicit formula for the inputs to the function (sample space outcomes) or the function itself.\nWe might not observe outcomes in full detail (e.g., tomorrow’s weather conditions), but we often can still observe values of random variables (e.g., tomorrow’s high temperature).\n\n\n\n\n\n\n\n\nExample 2.19 Recall the sample space from Example 2.3. Let \\(R\\) be the random variable representing Regina’s arrival time, and \\(Y\\) for Cady.\n\nIdentify the function that defines \\(R\\), and the possible values of \\(R\\). (Hint: remember the sample space.)\nIdentify the function that defines \\(Y\\), and the possible values of \\(Y\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.19. \n\nRecall that an outcome is an ordered pair representing the arrival times of (Regina, Cady); we can write an outcome as \\(\\omega\\equiv(\\omega_1, \\omega_2)\\). Remember there is a single sample space corresponding to the pairs of arrival times, rather than a separate sample space for each. Therefore, random variables need to be defined on this single sample space; inputs to random variables defined on this sample space are pairs of arrival times. Regina’s arrival time is defined by the function \\(R(\\omega) \\equiv R((\\omega_1, \\omega_2))=\\omega_1\\). That is, \\(R\\) maps the ordered pair \\((\\omega_1, \\omega_2)\\) to its first coordinate \\(\\omega_1\\). For example, \\(R((45, 30.2)) = 45\\).\nOn this sample space, Cady’s arrival time is defined by the function \\(Y(\\omega) \\equiv Y((\\omega_1, \\omega_2))=\\omega_2\\). That is, \\(Y\\) maps the ordered pair to its second coordinate. The input to \\(Y\\) is a pair of numbers (Regina, Cady) and the output is Cady’s arrival time only. For example, \\(Y((45, 30.2)) = 30.2\\).\n\n\n\n\n\n\n\n2.3.3 Tranformations of random variables\nWe are often interested in random variables that are derived from others. For example, if the random variable \\(X\\) represents the radius (cm) of a randomly selected circle, then \\(Y = \\pi X^2\\) is a random variable representing the circle’s area (\\(\\text{cm}^2\\)). If the random variables \\(W\\) and \\(T\\) represent the weight (kg) and height (m), respectively, of a randomly selected person, then \\(S = W / T^2\\) is a random variable representing the person’s body mass index (\\(\\text{kg}/\\text{m}^2\\)).\nA function of a random variable is also a random variable. That is, if \\(X\\) is a random variable and \\(g\\) is a function, then \\(Y=g(X)\\) is also a random variable13. For example, if \\(u\\) is a radius of a circle, the function \\(g(u) = \\pi u^2\\) outputs its area; if \\(X\\) is a random variable representing the radius of a randomly selected circle then \\(Y = g(X)=\\pi X^2\\) is a random variable representing the circle’s area.\nSums and products, etc., of random variables defined on the same sample space are random variables. That is, if random variables \\(X\\) and \\(Y\\) are defined on the same sample space then \\(X+Y\\), \\(X-Y\\), \\(XY\\), and \\(X/Y\\) are also random variables. Similarly, it is possible to make comparisons such as \\(X\\ge Y\\) and apply other transformations for random variables defined on the same sample space.\n\n\n\n\n\n\n\nExample 2.20 Continuning Example 2.8. In basketball games, teams attempt field goals and they score points for made field goals. Made field goals are worth either 2 or 3 points. Teams also attempt free throws which are worth 1 point if made. Each team plays 82 games in a season.\nFor the team that wins the top pick in the lottery in the 2022-2023 season, let\n\n\\(W\\) be the number of wins\n\\(Y_1\\) be free throw attempts per game (FT)\n\\(Y_2\\) be 2 point field goal attempts per game (FG2)\n\\(Y_3\\) be 3 point field goal attempts per game (FG3)\n\\(X_1\\) be free throws made per game (FTA)\n\\(X_2\\) be 2 point field goals made per game (FG2A)\n\\(X_3\\) be 3 point field goals made per game (FG3A)\n\nInterpret the following random variables in this context. How could they be represented in a table like Table 2.3?\n\n\\(82 - W\\)\n\\(W / 82\\)\n\\(X_1 / Y_1\\)\n\\(\\frac{X_2 + X_3}{Y_2+Y_3}\\)\n\\(\\frac{Y_3}{Y_2+Y_3}\\)\n\\(3X_3 + 2X_2 + X_1\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.20. Table 2.8 provides a representation of these random variables. For the team that wins the 2023 NBA draft in the 2022-2023 season:\n\n\\(82 - W\\) is the team’s number of losses\n\\(W / 82\\) is the proportion of games in the season that the team won (a.k.a., winning percentage, as a decimal)\n\\(X_1 / Y_1\\) is the proportion of free throw attempts that the team successfully made (a.k.a., free throw percentage, as a decimal)\n\\(\\frac{X_2 + X_3}{Y_2+Y_3}\\) is the proportion of total field goal attempts that the team successfully made (a.k.a., field goal percentage, as a decimal)\n\\(\\frac{Y_3}{Y_2+Y_3}\\) is the proportion of the team’s total field goal attempts that were 3 point attempts\n\\(3X_3 + 2X_2 + X_1\\) is the total points per game scored by the team (any differences between Table 2.8 and PPG in Table 2.3 are due to rounding.)\n\n\n\n\n\n\n\n\n\nTable 2.8: The random variables from Example 2.20 for teams in the 2023 NBA Draft Lottery.\n\n\n\n\n\n\nTeam\n$W$\n$X_3$\n$Y_3$\n$X_2$\n$Y_2$\n$X_1$\n$Y_1$\n$82-W$\n$W/82$\n$X_1/Y_1$\n$\\frac{X_2+X_3}{Y_2+Y_3}$\n$\\frac{Y_3}{Y_2+Y_3}$\n$3X_3 + 2X_2 + X_1$\n\n\n\n\nDetroit Pistons\n17\n11.4\n32.4\n28.2\n54.6\n19.8\n25.7\n65\n0.207\n0.770\n0.455\n0.372\n110.4\n\n\nHouston Rockets\n22\n10.4\n31.9\n30.2\n56.9\n19.1\n25.3\n60\n0.268\n0.755\n0.457\n0.359\n110.7\n\n\nSan Antonio Spurs\n22\n11.1\n32.2\n32.0\n60.4\n15.8\n21.2\n60\n0.268\n0.745\n0.465\n0.348\n113.1\n\n\nCharlotte Hornets\n27\n10.7\n32.5\n30.5\n57.9\n17.6\n23.6\n55\n0.329\n0.746\n0.456\n0.360\n110.7\n\n\nPortland Trail Blazers\n33\n12.9\n35.3\n27.6\n50.1\n19.6\n24.6\n49\n0.402\n0.797\n0.474\n0.413\n113.5\n\n\nOrlando Magic\n34\n10.8\n31.1\n29.8\n55.2\n19.6\n25.0\n48\n0.415\n0.784\n0.470\n0.360\n111.6\n\n\nIndiana Pacers\n35\n13.6\n37.0\n28.4\n52.6\n18.7\n23.7\n47\n0.427\n0.789\n0.469\n0.413\n116.3\n\n\nWashington Wizards\n35\n11.3\n31.7\n30.9\n55.2\n17.6\n22.4\n47\n0.427\n0.786\n0.486\n0.365\n113.3\n\n\nUtah Jazz\n37\n13.3\n37.8\n29.2\n52.0\n18.7\n23.8\n45\n0.451\n0.786\n0.473\n0.421\n117.0\n\n\nDallas Mavericks\n38\n15.2\n41.0\n24.8\n43.3\n19.0\n25.1\n44\n0.463\n0.757\n0.474\n0.486\n114.2\n\n\nChicago Bulls\n40\n10.4\n28.9\n32.1\n57.9\n17.6\n21.8\n42\n0.488\n0.807\n0.490\n0.333\n113.0\n\n\nOklahoma City Thunder\n40\n12.1\n34.1\n31.0\n58.5\n19.2\n23.7\n42\n0.488\n0.810\n0.465\n0.368\n117.5\n\n\nToronto Raptors\n41\n10.7\n32.0\n31.1\n59.3\n18.4\n23.4\n41\n0.500\n0.786\n0.458\n0.350\n112.7\n\n\nNew Orleans Pelicans\n42\n11.0\n30.1\n31.1\n57.5\n19.3\n24.4\n40\n0.512\n0.791\n0.481\n0.344\n114.5\n\n\n\n\n\n\n\n\nRemember that we can visualize outcomes as rows in a spreadsheet with random variables as columns. Random variables defined on the same sample space can be put in a single spreadsheet. Each row corresponds to an outcome, and reading across any row there is a value in the column corresponding to each random variable. Random variables derived from transformations of other random variables append columns to the spreadsheet. New random variables can be defined by going row-by-row, outcome-by-outcome, and applying a transformation within each row to the values of other random variables.\nUsing capital letters like \\(X\\) or \\(Y\\) to denote random variables is standard practice. To help develop comfort with this mathematical notation, we will often label columns in tables with their random variable symbols (as we did in Table 2.8). Later, when writing code we will often denote random variables with symbols like X or Y. However, keep in mind that mathematical symbols like \\(X\\) or \\(Y\\) represent variables in a context. While you should develop comfort with the notation, you can—and probably should—use more informative labels like “wins” or wins rather than \\(W\\).\n\n\n\n\n\n\n\nExample 2.21 Continuing Example 2.19.\n\nWhat does the random variable \\(U_1 = R / 60\\) represent in context? What are the possible values of \\(U_1\\)?\nWhat does the random variable \\(T = \\min(R, Y)\\) represent in context? What are the possible values of \\(T\\)?\nWhat does the random variable \\(W = |R - Y|\\) represent in context? What are the possible values of \\(W\\)?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.21. \n\n\\(U_1= R / 60\\) represents Regina’s arrival time measured as a fraction of the hour after noon. For example, if Regina arrives 15 minutes after noon then \\(R=15\\) and \\(U_1= 15/60 = 0.25\\). \\(U_1\\) takes values in [0, 1].\n\\(T=\\min(R, Y)\\) represents the time (minutes after noon) of the first arrival. For example, if Regina arrives 15 minutes after noon and Cady 22.3 minutes after noon then \\(R=15\\), \\(C=22.3\\) and \\(T=\\min(15, 22.3) = 15\\). \\(T\\) takes values in \\([0, 60]\\). If either Regina and Cady arrives at time 0 (noon) then \\(T\\) is 0, the smallest possible value of \\(T\\); if both arrive at 1:00 then \\(T\\) is 60, the largest possible value of \\(T\\).\n\\(W=|R-Y|\\) represents the amount of time the first person to arrive waits for the second person to arrive. For example, if Regina arrives 15 minutes after noon and Cady 22.3 minutes after noon then \\(R=15\\), \\(C=22\\) and \\(W = |15-22.3| = 7.3\\). \\(W\\) takes values in \\([0, 60]\\). If both Regina and Cady arrive at the same time then \\(W\\) is 0; if one arrives at noon and the other at 1:00 then \\(W\\) is 60, the largest possible value of \\(W\\).\n\n\n\n\n\n\n\n2.3.4 Indicator random variables\nRandom variables that only take two possible values, 0 and 1, have a special name.\n\nDefinition 2.5 An indicator (a.k.a., Bernoulli, a.k.a. Boolean) random variable can take only the values 0 or 1. If \\(A\\) is an event then the corresponding indicator random variable \\(\\textrm{I}_A\\) is defined as \\[\n\\textrm{I}_A(\\omega) =\n\\begin{cases}\n1, & \\omega \\in A,\\\\\n0, & \\omega \\notin A\n\\end{cases}\n\\] That is, \\(\\textrm{I}_A\\) equals 1 if event \\(A\\) occurs, and \\(\\textrm{I}_A\\) equals 0 if event \\(A\\) does not occur.\n\nIndicators provide the bridge between events (sets) and random variables (functions). Any event either occurs or not; a realization of any event is either true (\\(\\omega \\in A\\)) or false (\\(\\omega \\notin A\\)). An indicator random variable just translates “true” or “false” into numbers, 1 for “true” and 0 for “false”.\n\n\n\n\n\n\n\nExample 2.22 Recall the sample space from Example 2.2 for the matching problem with \\(n=4\\). Let the random variable \\(X\\) count the number of objects that are placed in the correct spot. Let \\(I_1\\) be equal to 1 if object 1 is placed (correctly) in spot 1, and define \\(I_2, I_3, I_4\\) similarly.\n\nConstruct a table identifying the value of \\(X, I_1, \\ldots, I_4\\) for each outcome in the sample space.\nIdentify the possible values of \\(X\\).\nWhat is the relationship between \\(I_3\\) and event \\(A_3\\) from Example 2.10?\nHow can you express \\(X\\) in terms of \\(I_1, \\ldots, I_4\\)?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.22. \n\nSee Table 2.9. Each random variable corresponds to a different column in the table.\n\\(X\\) can take values 0, 1, 2, and 4, but 3 is not a possible value of \\(X\\).\n\\(I_3\\) is equal to 1 only for outcomes that satisfy \\(A_3\\), the event that object 3 is placed in spot 3; \\(I_3\\) is equal 0 for outcomes that do not satisfy event \\(A_3\\). In this way, the value of the random variable \\(I_3\\) indicates whether or not the event \\(A_3\\) occurs; that is, \\(I_3\\) is the indicator random variable of event \\(A_3\\), \\(I_3 = \\textrm{I}_{A_3}\\).\nFor every outcome (row), the value of \\(X\\) is equal to the sum of the values of \\(I_1\\), \\(I_2\\), \\(I_3\\), \\(I_4\\). That is, \\(X = I_1+I_2+I_3+I_4\\). For example, for outcome 2134, \\(X\\) is equal to 2, \\(I_1\\) and \\(I_2\\) are equal to 0, and \\(I_3\\) and \\(I_4\\) are equal to 1, and \\(2 = 0 + 0 + 1 + 1\\). The relationship \\(X = I_1+I_2+I_3+I_4\\) is true for every outcome (row). The spot-by-spot indicators provide a way to incrementally count the total number of matches.\n\n\n\n\n\n\n\n\n\nTable 2.9: Total number of matches and indicator random variables for each item in the matching problem with \\(n=4\\).\n\n\n\n\n\n\nOutcome\n$X$\n$I_1$\n$I_2$\n$I_3$\n$I_4$\n\n\n\n\n1234\n4\n1\n1\n1\n1\n\n\n1243\n2\n1\n1\n0\n0\n\n\n1324\n2\n1\n0\n0\n1\n\n\n1342\n1\n1\n0\n0\n0\n\n\n1423\n1\n1\n0\n0\n0\n\n\n1432\n2\n1\n0\n1\n0\n\n\n2134\n2\n0\n0\n1\n1\n\n\n2143\n0\n0\n0\n0\n0\n\n\n2314\n1\n0\n0\n0\n1\n\n\n2341\n0\n0\n0\n0\n0\n\n\n2413\n0\n0\n0\n0\n0\n\n\n2431\n1\n0\n0\n1\n0\n\n\n3124\n1\n0\n0\n0\n1\n\n\n3142\n0\n0\n0\n0\n0\n\n\n3214\n2\n0\n1\n0\n1\n\n\n3241\n1\n0\n1\n0\n0\n\n\n3412\n0\n0\n0\n0\n0\n\n\n3421\n0\n0\n0\n0\n0\n\n\n4123\n0\n0\n0\n0\n0\n\n\n4132\n1\n0\n0\n1\n0\n\n\n4213\n1\n0\n1\n0\n0\n\n\n4231\n2\n0\n1\n1\n0\n\n\n4312\n0\n0\n0\n0\n0\n\n\n4321\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\nEven though they seem simple, indicator random variables are very useful. In the matching problem, it is not feasible to enumerate the outcomes and count when there is a large number \\(n\\) of items and spots. Using indicators allows you to count incrementally—is just this item in the correct spot?— rather than all at once. Representing a count as a sum of indicator random variables is a very common and useful strategy, especially in problems that involve “find the expected number of…”\nHere is a little story that illustrates the idea of incremental counting with indicators. Imagine a dad and his young child are reading a picture book. They come to a page that has twenty pictures of fruits, of which seven are bananas. The following conversation ensues.\n\nDad: Can you count all the bananas? Let’s see! How many bananas have we counted so far?\nKid: We haven’t started counting yet!\nDad: Right, so how many bananas have we counted so far?\nKid: Zero.\nDad: That’s right! We’ve counted zero bananas so far. (Dad points to a banana.) Is that a banana?\nKid: Yes!\nDad: So how many more bananas did we just count?\nKid: One more.\nDad: So how many bananas have we counted so far?\nKid: One.\nDad: Great job! We’ve counted one banana so far. (Dad points to a different banana.) Is that a banana?\nKid: Yes!\nDad: So how many more bananas did we just count?\nKid: We counted one more banana.\nDad: So how many bananas have we counted so far?\nKid: Two.\nDad: Great job! We’ve counted two bananas so far. (Dad points to a different banana.) Is that a banana?\nKid: Yes!\nDad: So how many more bananas did we just count?\nKid: We counted one more banana.\nDad: So how many bananas have we counted so far?\nKid: Three.\nDad: Great job! We’ve counted three bananas so far. (Dad points to an orange14.) Is that a banana?\nKid: No, that’s an orange!\nDad: So how many more bananas did we just count?\nKid: Zero. It was not a banana!\nDad: So how many bananas have we counted so far?\nKid: Still three.\nDad: Great job! We’ve counted three bananas so far. (Continues in this manner until Dad points to the twentieth and last fruit on the page, a banana.) Almost done. We’ve counted six bananas so far. Is that a banana?\nKid: Yes!\nDad: So how many more bananas did we just count?\nKid: We counted one more banana.\nDad: So how many bananas have we counted so far?\nKid: Seven.\nDad: We looked at each fruit on the page. How many were bananas?\nKid: Seven.\nDad: Great job! Now you know how indicator random variables can be used to count.\n\nIn the story, the kid counted the bananas by examining each object, determining whether or not it was a banana, and then incrementing the banana counter by 1 for each object that was a banana (and by 0 for the objects that were not bananas). The kid essentially created an indicator (of “banana”) variable for each object on the page (\\(I_{B_1}=1\\), \\(I_{B_2}=1\\), \\(I_{B_3}=1\\), \\(I_{B_4}=0\\ldots\\), \\(I_{B_{20}}=1\\)) and then summed these indicators to obtain the total count of bananas. This strategy gives a way of breaking down a complicated counting problem into smaller pieces and counting incrementally.\n\n\n\n\n\n\n\nExample 2.23 Continuing Example 2.22, interpret each of the following random variables.\n\n\\(1 - \\textrm{I}_3\\)\n\\(\\textrm{I}_1 \\textrm{I}_2\\), that is, the product of \\(\\textrm{I}_1\\) and \\(\\textrm{I}_2\\)\n\\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.23. \n\n\\(1 - \\textrm{I}_3\\) is 1 if \\(\\textrm{I}_3 = 0\\), which occurs when object 3 is not in spot 3, and \\(1 - \\textrm{I}_3\\) is 0 otherwise. So \\(1 - \\textrm{I}_3\\) is the indicator that object 3 is not placed in spot 3; \\(1-\\textrm{I}_3 = \\textrm{I}_{A_3^c}\\).\n\\(\\textrm{I}_1 \\textrm{I}_2\\) is 1 if both \\(\\textrm{I}_1\\) and \\(\\textrm{I}_2\\) are 1, which occurs when objects 1 and 2 are in the correct spots; otherwise, \\(\\textrm{I}_1 \\textrm{I}_2\\) is 0. Therefore \\(\\textrm{I}_1 \\textrm{I}_2\\) is the indicator that object 1 is placed in spot 1 and object 2 is placed in spot 2; \\(\\textrm{I}_1\\textrm{I}_2 = \\textrm{I}_{A_1 \\cap A_2}\\).\n\\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2\\) is 1 if: object 1 is in spot 1 but object 2 is not in spot 2 (1 + 0 - 0), object 1 is not in spot 1 but object 2 is in spot 2 (0 + 1 - 0), or if both object 1 is in spot 1 and object 2 is in spot 2 (1 + 1 - 1). \\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2\\) is 0 only if object 1 is not in spot 1 and object 2 is not in spot 2. Therefore \\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2\\) is the indicator that object 1 is placed in spot 1 or object 2 is placed in spot 2; \\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2 = \\textrm{I}_{A_1 \\cup A_2}\\).\n\n\n\n\n\nExample 2.23 illustrates that for two events \\(A\\) and \\(B\\) \\[\\begin{align*}\n\\textrm{I}_{A^c} & = 1 - \\textrm{I}_A & & \\\\\n\\textrm{I}_{A \\cap B} & = \\textrm{I}_A \\textrm{I}_B & & =\\min(\\textrm{I}_A, \\textrm{I}_B)\\\\\n\\textrm{I}_{A \\cup B} & = \\textrm{I}_A + \\textrm{I}_B - \\textrm{I}_{A \\cap B} & & = \\max(I_A, I_B)\n\\end{align*}\\]\nIn particular, the indicator of an intersection is the product of the indicators of each event. The \\(\\min, \\max\\), and product formulas work for more than two events, but the addition formula is more complicated15.\n\n\n2.3.5 Events involving random variables\nMany events of interest involve random variables. The event “tomorrow’s high temperature is above 75°F” involves the random variable “tomorrow’s high temperature”. Each possible outcome of tomorrow’s weather conditions will correspond to a value of high temperature, but only some of these outcomes will result in values of high temperature above 75 °F.\n\n\n\n\n\n\n\nExample 2.24 Continuning Example 2.8. For the team that wins the top pick in the lottery, let\n\n\\(X\\) be the number of previous championships won by the team that wins the top pick in the lottery\n\\(Y\\) be the number of wins in the 2022-2023 season\n\\(Z\\) be the points per game in the 2022-2023 season\n\\(I\\) be the indicator random variable that the team is in the Western Conference\n\nIdentify and interpret the following events.\n\n\\(\\{I=1\\}\\)\n\\(\\{X = 0\\}\\)\n\\(\\{Y &lt; 25\\}\\)\n\\(\\{Z &gt; 115\\}\\)\n\\(\\{I = 1, X = 0\\}\\)\n\\(\\{I = 1, X = 0, Y &lt; 25\\}\\)\n\\(\\{I = 1\\}\\cup \\{X = 0\\}\\)\n\\(\\{X \\ge 1\\}\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.24. These events are the same as those in Example 2.24 just with different notation.\n\n\\(\\{I = 1\\} = \\{\\text{Houston, San Antonio, Portland, Utah, Dallas, Oklahoma City, New Orleans}\\}\\) is the event that the team is in the Western Conference.\n\\(\\{X = 0\\} = \\{\\text{Charlotte, Orlando, Indiana, Utah, New Orleans}\\}\\) is the event that the team has never won a championship.\n\\(\\{Y &lt; 25\\} = \\{\\text{Detroit, Houston, San Antonio}\\}\\) is the event that the team won fewer than 25 games in the 2022-2023 season\n\\(\\{Z &gt; 115\\} = \\{\\text{Indiana, Utah, Oklahoma City}\\}\\) is the event that the team scored over 115 points per game in the 2022-2023 season\n\\(\\{I = 1, X = 0\\} = \\{\\text{Utah, New Orleans}\\}\\) is the event that the team is in the Western Conference and has won no previous championships.\n\\(\\{I = 1, X = 0, Y &lt; 25\\}=\\{\\text{Utah}\\}\\) is the event that the team is in the Western Conference, has won no previous championships, and scored over 115 points per game in the 2022-2023 season.\n\\(\\{I = 1\\}\\cup \\{X = 0\\}=\\{\\text{Charlottle, Houston, San Antonio, Portland, Orlando, Indians, Utah, Dallas, Oklahoma City, New Orleans}\\}\\) is the event that the team is in the Western Conference or has won no previous championships.\n\\(\\{X \\ge 1\\}=\\{\\text{Detroit, Houston, San Antonio, Portland, Washington, Dallas, Chicago, Oklahoma City, Toronto}\\}\\) is the event that the team has won at least one previous championship.\n\n\n\n\n\nThe expressions \\(X=x\\) or \\(\\{X=x\\}\\) are shorthand for the event that the random variable \\(X\\) takes the value \\(x\\). Remember that any event is a collection of outcomes that satisfy some criteria, a subset of the sample space. So objects like \\(\\{X=x\\}\\) are sets representing the outcomes for which the value of the random variable \\(X\\) is equal to the number \\(x\\). Remember to think of the capital letter \\(X\\) as a label standing in for a formula like “the sum of two rolls of a four-sided die” and \\(x\\) as a dummy variable standing in for a particular value like 3.\n\n\n\n\n\n\n\nExample 2.25 Roll a four-sided die twice, and record the result of each roll in sequence. Recall the sample space from Example 2.1. Let \\(X\\) be the sum of the two dice, and let \\(Y\\) be the larger of the two rolls (or the common value if both rolls are the same). Identify and interpret each of the following.\n\n\\(\\{X = 4\\}\\).\n\\(\\{X = 3\\}\\).\n\\(\\{X \\le 3\\}\\).\n\\(\\{Y = 4\\}\\).\n\\(\\{Y = 3\\}\\).\n\\(\\{Y \\le 3\\}\\).\n\\(\\{X = 4, Y = 3\\}\\) (that is, \\(\\{X = 4\\}\\cap \\{Y = 3\\}\\)).\n\\(\\{X = 4, Y \\le 3\\}\\).\n\\(\\{X = 3, Y = 3\\}\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.25. Notice we encountered many of these events in Example 2.9, but now we are denoting the events in terms of random variables.\n\n\\(\\{X = 4\\}\\), which consists of the outcomes (1, 3), (2, 2), (3, 1), is the event that the sum of the two dice is 4. Recalling Example 2.9, \\(A = \\{X = 4\\}\\).\n\\(\\{X = 3\\}\\), which consists of outcomes (1, 2) and (2, 1), is the event that the sum of the two dice is 3.\n\\(\\{X \\le 3\\}\\), which consists of outcomes (1, 1), (1, 2), and (2, 1), is the event that the sum of the two dice is at most 3. Recalling Example 2.9, \\(B = \\{X \\le 3\\}\\).\n\\(\\{Y = 4\\}=\\{(1, 4), (2, 4), (3, 4), (4, 4), (4, 1), (4, 2), (4,3)\\}\\) is the event that the larger of the two rolls is 4.\n\\(\\{Y = 3\\}=\\{(1, 3), (2, 3), (3, 3), (3, 1), (3, 2)\\}\\) is the event that the larger of the two rolls is 3. Recalling Example 2.9, \\(C = \\{Y = 3\\}\\).\n\\(\\{Y \\le 3\\}=\\{(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)\\}\\) is the event that the larger of the two rolls is at most 3. Notice that since in this example \\(Y\\) can only take values 1, 2, 3, 4, we have \\(\\{Y\\le 3\\} = \\{Y=4\\}^c\\).\n\\(\\{X = 4, Y = 3\\} \\equiv \\{X = 4\\}\\cap \\{Y = 3\\}=\\{(1, 3), (3, 1)\\}\\) is the event that both the sum of the two dice is 4 and the larger of the two rolls is 3. Even though this involves two random variables, it is a single event (that is, a single subset of the sample space). There are only two outcomes for which both the sum of the two dice is 4 and the larger of the two dice is 3.\n\\(\\{X = 4, Y \\le 3\\} \\equiv \\{X = 4\\}\\cap \\{Y \\le 3\\}=\\{(1, 3), (2, 2), (3, 1)\\}\\) is the event that both the sum of the two dice is 4 and the larger of the two rolls is at most 3. Notice that since in this example \\(\\{X=4\\} \\subset \\{Y\\le 3\\}\\), we have \\(\\{X = 4, Y \\le 3\\} = \\{X=4\\}\\). If the sum is 4 we know the larger roll must be at most 3.\n\\(\\{X = 3, Y = 3\\} \\equiv \\{X = 3\\}\\cap \\{Y = 3\\}=\\emptyset\\), since there are no outcomes for which both the sum is 3 and the larger of the two dice is 3. (If the the larger of the two dice is 3, then the sum must be at least 4.)\n\n\n\n\n\n\n\n\n\nTable 2.10: Table representing the sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die. The event \\(X = 4\\) is highlighted in orange.\n\n\n\n\n\n\nOutcome (First roll, second roll)\nX (sum)\nY (max)\n\n\n\n\n(1, 1)\n2\n1\n\n\n(1, 2)\n3\n2\n\n\n(1, 3)\n4\n3\n\n\n(1, 4)\n5\n4\n\n\n(2, 1)\n3\n2\n\n\n(2, 2)\n4\n2\n\n\n(2, 3)\n5\n3\n\n\n(2, 4)\n6\n4\n\n\n(3, 1)\n4\n3\n\n\n(3, 2)\n5\n3\n\n\n(3, 3)\n6\n3\n\n\n(3, 4)\n7\n4\n\n\n(4, 1)\n5\n4\n\n\n(4, 2)\n6\n4\n\n\n(4, 3)\n7\n4\n\n\n(4, 4)\n8\n4\n\n\n\n\n\n\n\n\nWhen dealing with probabilities, it is common to write \\(X=3\\) instead of16 \\(\\{X=3\\}\\), and \\(X = 4, Y = 3\\) instead of \\(\\{X = 4\\}\\cap \\{Y = 3\\}\\); read the comma in \\(X = 4, Y = 3\\) as “and”. But keep in mind that an expression like “\\(X=3\\)” really represents an event \\(\\{X=3\\}\\), a subset of outcomes of the sample space.\n\n\n\n\n\n\n\nExample 2.26 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. Recall the sample space from Example 2.3. Let \\(R\\) be the random variable representing Regina’s arrival time (minutes after noon), and \\(Y\\) for Cady. Interpret each of the following in words and draw a picture representing it.\n\n\\(\\{R &gt; Y\\}\\).\n\\(\\{\\min(R, Y) &lt; 30\\}\\).\n\\(\\{Y&lt;R&lt;Y+15\\}\\).\n\\(\\{R &lt; 24\\}\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.26. The parts of this problem are almost identical to those in Example 2.11. The main difference is in notation; we are now denoting events in terms of random variables.\n\nSee Figure 2.7 for pictures. \\(\\{R&gt;Y\\}\\)is the event that Regina arrives after Cady (event \\(A\\) from Example 2.11).\n\\(\\{\\min(R, Y)&lt;30\\}\\), is the event that the earlier of the two arrival times is before 12:30 (event \\(B\\) from Example 2.11). This event can also be written as \\(\\{R &lt; 30\\}\\cup \\{Y &lt; 30\\}\\), the event that either Regina or Cady arrives before 12:30.\n\\(\\{Y&lt;R&lt;Y+15\\}\\) is the event that Cady arrives first and Regina arrives at most 15 minutes after Cady (event \\(C\\) from Example 2.11).\n\\(\\{R &lt; 24\\} = \\{(\\omega_1, \\omega_2): \\omega_1&lt;24\\}\\) is the event that Regina arrives before 12:24 (event \\(D\\) from Example 2.11).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.7: Illustration of the events in Example 2.26. The square represents the possible values of \\((R, Y)\\), the random vector representing the arrival times of Regina and Cady.\n\n\n\n\n\n\n\n2.3.6 Outcomes, events, and random variables\nOutcomes, events, and random variables are some of the main objects of probability. While they are related, these are distinct objects. Thinking in terms of a spreadsheet, an outcome is a row, an event is a subset of rows, and a random variable is a column. Mathematically, an outcome is a point, an event is a set, and a random variable is a function which outputs a number. As such, different operations are valid depending on what you’re dealing with. Don’t confuse operations like \\(\\cap\\) that operate on sets (events, “and”) with operations like \\(+\\) that operate on numbers and functions (random variables, “plus” meaning addition).\n\n\n\n\n\n\n\nExample 2.27 At various points in his homework, Donny Don’t writes the following. Explain to Donny why each of the following symbols is nonsense, both mathematically and intuitively using a simple example (like tomorrow’s weather). Below, \\(A\\) and \\(B\\) represent events, \\(X\\) and \\(Y\\) represent random variables.\n\n\\(A = 0.5\\)\n\\(A + B\\)\n\\(X = A\\)\n\\(X + A\\)\n\\(X \\cap Y\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.27. We’ll respond to Donny using tomorrow’s weather as an example, with \\(A\\) representing the event that it rains tomorrow, \\(X\\) tomorrow’s high temperature (degrees F), \\(B=\\{X&gt;80\\}\\) the event that tomorrow’s high temperature is above 80 degrees, and \\(Y\\) tomorrow’s rainfall (inches).\n\n\\(A\\) is a set and 0.5 is a number; it doesn’t make mathematical sense to equate them. It doesn’t make sense to say “it rains tomorrow equals 0.5”.\n\\(A\\) and \\(B\\) are sets; it doesn’t make mathematical sense to add them. It doesn’t make sense to say “the sum of (it rains tomorrow) and (tomorrow’s high temperature is above 80 degrees F)”. If we want “(it rains tomorrow) OR (tomorrow’s high temperature is above 80 degrees F)”, then we need \\(A\\cup B\\). Union is an operation on sets; addition is an operation on numbers.\n\\(X\\) is a random variable (a function) and \\(A\\) is an event (a set), and it doesn’t make sense to equate these two different mathematical objects. It doesn’t make sense to say “tomorrow’s high temperature equals the event that it rains tomorrow”.\n\\(X\\) is a random variable (a function) and \\(A\\) is an event (a set), and it doesn’t make sense to add these two different mathematical objects. It doesn’t make sense to say “the sum of (tomorrow’s high temperature) and (the event that it rains tomorrow)”.\n\\(X\\) and \\(Y\\) are random variables (functions) and intersection is an operation on sets. \\(X \\cap Y\\) is attempting to say “tomorrow’s high temperature in degrees F and the amount of rainfall in inches tomorrow”. If we’re talking about a random vector containing these two variables, we would write \\((X, Y)\\) not \\(X \\cap Y\\). If we’re interested in an event involving \\(X\\) and \\(Y\\), we’re missing qualifying information to define a valid event. We could write \\(X &gt;80, Y &lt; 2\\) or \\(\\{X &gt; 80\\} \\cap \\{Y &lt; 2\\}\\) to represent “the event that (tomorrow’s high temperature is greater than 80 degrees F) AND (the amount of rainfall tomorrow is less than 2 inches)”.\n\n\n\n\n\n\n\n2.3.7 Exercises\n\nExercise 2.5 Consider the outcome of a sequence of 4 flips of a coin. One random variable is \\(X\\), the number of heads flipped.\n\nExplain why \\(X\\) is a random variable.\nEvaluate each of the following: \\(X(HHHH), X(HTHT), X(TTHH)\\).\nIdentify the possible values of \\(X\\). Why not let the sample space just consist of this set of possible values?\nWhat does \\(4-X\\) represent?\nWhat does \\(X/4\\) represent?\n\n\n\nExercise 2.6 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\nThe sample space consists of 27 outcomes, listed in the table below.\n\n\n\n\n111\n112\n113\n121\n122\n123\n131\n132\n133\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n211\n212\n213\n221\n222\n223\n231\n232\n233\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n311\n312\n313\n321\n322\n323\n331\n332\n333\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the table above and evaluate \\(X\\) and \\(Y\\) for each of the outcomes.\nIdentify the possible values of \\(X\\).\nIdentify the possible values of \\(Y\\).\nIdentify the possible \\((X, Y)\\) pairs.\nIdentify and interpret \\(\\{X = 1\\}\\).\nIdentify and interpret \\(\\{X = 2\\}\\).\nIdentify and interpret \\(\\{X = 3\\}\\).\nIdentify and interpret \\(\\{Y = 0\\}\\).\nIdentify and interpret \\(\\{Y = 1\\}\\).\nIdentify and interpret \\(\\{Y = 2\\}\\).\nIdentify and interpret \\(\\{Y = 3\\}\\).\nIdentify and interpret \\(\\{X = 2, Y = 1\\}\\).\nIdentify and interpret \\(\\{X = Y\\}\\).\nLet \\(I_1\\) be the indicator random variable that prize 1 is obtained (in at least one of the three packages). Identify and intepret \\(\\{I_1 = 0\\}\\).\nLet \\(I_2\\) be the indicator random variable that prize 2 is obtained (in at least one of the three packages), and similarly \\(I_3\\) for prize 3. What is the relationship between \\(X\\) and \\(I_1, I_2, I_3\\)?\nHow can you write \\(Y\\) in terms of indicator random variables?\n\n\n\nExercise 2.7 Katniss throws a dart at a circular dartboard with radius 1 foot. (Assume that Katniss’s dart never misses the dartboard.) Let \\(X\\) be the distance (inches) from the location of the dart to the center of the dartboard.\n\nIdentify (with a picture) and interpret \\(\\{X \\le 1\\}\\)\nIdentify (with a picture) and interpret \\(\\{1 &lt; X &lt; 2\\}\\)\nIdentify (with a picture) and interpret \\(\\{X &gt; 11\\}\\)\nIdentify (with a picture) and interpret \\(\\{X = 0\\}\\)\nIdentify (with a picture) and interpret \\(\\{X = 1\\}\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-probspace",
    "href": "language-probability.html#sec-probspace",
    "title": "2  The Language of Probability",
    "section": "2.4 Probability spaces",
    "text": "2.4 Probability spaces\nIn this chapter we have defined outcomes, events, and random variables, the main mathematical objects associated with a random phenomenon. But we haven’t actually computed any probabilities yet! So far we have only been concerned with what is possible. You might have noticed that the examples often did not include any assumptions like the “die is fair”, “each object is equally likely to be put in any spot”, or “Regina is more likely to arrive late and Cady is more likely to arrive early”. Now we will start to incorporate assumptions of the random phenomenon to determine how probable various events are.\n\n2.4.1 Probability measures\nAs we saw in Section 1.3, there are some basic logical consistency requirements that probabilities must satisfy, which are formalized in three “axioms”.\n\nDefinition 2.6 A probability measure, typically denoted \\(\\textrm{P}\\), assigns probabilities to events to quantify their relative likelihoods, plausibilities, or degrees of uncertainty according to the assumptions of the model of the random phenomenon. The probability of event17 \\(A\\) is denoted \\(\\textrm{P}(A)\\).\nAny valid probability measure must satisfy the following axioms.\n\n\nFor any event \\(A\\), \\(0 \\le \\textrm{P}(A) \\le 1\\).\nIf \\(\\Omega\\) represents the sample space then \\(\\textrm{P}(\\Omega) = 1\\).\nCountable additivity. If \\(A_1, A_2, A_3, \\ldots\\) are disjoint events (recall Definition 2.3), then \\[\n\\textrm{P}(A_1 \\cup A_2 \\cup A_2 \\cup \\cdots) = \\textrm{P}(A_1) + \\textrm{P}(A_2) +\\textrm{P}(A_3) + \\cdots\n\\]\n\nAn event \\(A\\) is something that can happen or can be true; \\(\\textrm{P}(A)\\) quantifies how likely it is that \\(A\\) will happen or how plausible it is that \\(A\\) is true. Probabilities are always defined for events (sets) but remember than many events are defined in terms of random variables. For example, if \\(X\\) is tomorrow’s high temperature (degrees F) we might be interested in \\(\\textrm{P}(\\{X&gt;80\\})\\), the probability of the event that tomorrow’s high temperature is above 80 degrees F. If \\(Y\\) is the amount of rainfall tomorrow (inches) we might be interested in \\(\\textrm{P}(\\{X &gt; 80\\}\\cap \\{Y &lt; 2\\})\\), the probability of the event that tomorrow’s high temperature is above 80 degrees F and the amount of rainfall is less than 2 inches. To simplify notation, it is common to write \\(\\textrm{P}(X&gt;80)\\) instead of \\(\\textrm{P}(\\{X&gt;80\\})\\), or \\(\\textrm{P}(X &gt; 80, Y &lt; 2)\\) instead of \\(\\textrm{P}(\\{X &gt; 80\\}\\cap \\{Y &lt; 2\\})\\). Read the comma in \\(\\textrm{P}(X &gt; 80, Y &lt; 2)\\) as “and”. But keep in mind that an expression like “\\(X&gt;80\\)” really represents an event \\(\\{X&gt;80\\}\\).\nThe three axioms require that probabilities of different events must fit together in a logically coherent way.\nThe requirement \\(0\\le \\textrm{P}(A)\\le 1\\) makes sense in light of the relative frequency interpretation: an event \\(A\\) can not occur on more than 100% of repetitions or less than 0% of repetitions of the random phenomenon.\nThe requirement that \\(\\textrm{P}(\\Omega)=1\\) just ensures that the sample space accounts for all of the possible outcomes. Basically, \\(\\textrm{P}(\\Omega)=1\\) says that on any repetition of the random phenomenon, “something has to happen”. Roughly, \\(\\textrm{P}(\\Omega)=1\\) implies that all outcomes taken together need to account for 100% of the probability. If \\(\\textrm{P}(\\Omega)\\) were less than 1, then the sample space hasn’t accounted for all of the possible outcomes.\nEvent \\(A_1 \\cup A_2 \\cup \\cdots\\) is the event that \\(A_1\\) occurs OR \\(A_2\\) occurs OR… In other words, \\(A_1 \\cup A_2 \\cup \\cdots\\) is the event that at least one of the \\(A_i\\)’s occur. Countable additivity says that as long as events share no outcomes in common, then the probability that at least one of the events occurs is equal to the sum of the probabilities of the individual events. In Example 1.7, the events \\(B\\)=“the Braves win the 2023 World Series” and \\(A\\)=“the Rays win the 2023 World Series” are disjoint, \\(A\\cap B = \\emptyset\\); in a single World Series, both teams cannot win. If \\(\\textrm{P}(B) = 0.19\\) and \\(\\textrm{P}(A) = 0.16\\), then the probability of \\(A\\cup B\\), the event that either the Rays or the Braves win, must be \\(\\textrm{P}(A\\cup B)=0.29\\).\nCountable additivity can be understood through a diagram with areas representing probabilities, as in the figure below which represents two events (yellow / and blue \\). On the left, there is no “overlap” between areas so the total area is the sum of the two pieces; this depicts countable additivity for two disjoint events. On the right, there is overlap between the two areas, so simply adding the two areas “double counts” the intersection (green \\(\\times\\)) and does not result in the correct total area. Countable additivity applies to any countable number18 of events, as long as there is no “overlap”.\n\n\n\n\n\n\n\n\nFigure 2.8: Illustration of countable additivity for two events. The events in the picture on the left are disjoint, but not on the right.\n\n\n\n\n\nThe three axioms of a probability measure are simply minimal logical consistency requirements that must be satisfied by any probability model to ensure that probabilities fit together in a coherent way. There are also many physical aspects of the random phenomenon or assumptions (e.g. “fairness”, independence, conditional relationships) that must be considered when determining a reasonable probability measure for a particular situation. Sometimes \\(\\textrm{P}(A)\\) is defined explicitly for an event \\(A\\) via a formula. But it is much more common for a probability measure to be defined only implicitly through modeling assumptions; probabilities of events then follow from the axioms and related properties.\n\n\n2.4.2 Some probability measures for a four-sided die\n\n\n\n\n\n\nCaution\n\n\n\nThis section concerns a single roll of a fair four-sided die. Don’t confuse this scenario with many other examples that involve two rolls. This section also discusses all possible events (beyond just all possible outcomes). We encourage you to review Section 2.2.1 before reading this section.\n\n\nConsider a single roll of a four-sided die. The sample space consists of four possible outcomes, \\(\\Omega = \\{1, 2, 3, 4\\}\\). Events concern what might happen on a single roll. For example, if \\(A\\) is the event that we roll an odd number then \\(A = \\{1, 3\\}\\); “roll an odd number” occurs if we roll a 1 so 1 is an \\(A\\), or “roll an odd number” occurs if we roll a 3 so 3 is in \\(A\\). Table 2.6 lists the collection of all events.\n\n\n\n\n\n\nCaution\n\n\n\nWe usually think of a table as a list of all possible outcomes, with one row for each outcome. Table 2.6 and the tables in this section (Table 2.11, Table 2.12, Table 2.13) are different kinds of tables. Each row of these tables is an event, and the tables list the collection of all events.\n\n\n\n\n\n\n\n\n\nExample 2.28 Let’s first assume that the die is fair. Let \\(\\textrm{P}\\) denote the probability measure corresponding to a single roll of a fair four-sided die.\n\nWhat is the probability that a single roll lands on 1? 2? 3? 4?\nCompute the probability of each of the events in Table 2.6.\nSpecify a general formula for \\(\\textrm{P}(A)\\) for any event of interest \\(A\\) in this example.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.28. \n\nAssuming the die is fair implies that all four outcomes are equally likely, each with probability19 1/4.\nGiven the probability of each outcome20, we can find the probability of an event via countable additivity—sum the probabilities of the distinct outcomes that comprise the event. For example, if \\(A=\\{1, 3\\}\\) is the event that the die lands on an odd number, then \\[\n\\textrm{P}(A) = \\textrm{P}(\\{1, 3\\}) = \\textrm{P}(\\{1\\}\\cup \\{3\\}) = \\textrm{P}(\\{1\\}) + \\textrm{P}(\\{3\\}) = 1/4+ 1/4 = 2/4.\n\\] Table 2.11 lists all the possible events, and their probabilities according to the probability measure \\(\\textrm{P}\\).\nSince there are four equally likely outcomes, the probability of any event is \\[\n\\textrm{P}(A) = \\frac{\\text{number of outcomes that satisfy $A$}}{4}, \\qquad{\\text{$\\textrm{P}$ assumes a fair four-sided die}}\n\\]\n\n\n\n\n\n\n\n\nTable 2.11: All possible events associated with a single roll of a four-sided die, and their probabilities assuming the die is fair.\n\n\n\n\n\n\n\n\n\n\nEvent\nDescription\nProbability of event assuming a fair die\n\n\n\n\n\\(\\emptyset\\)\nRoll nothing (not possible)\n0\n\n\n\\(\\{1\\}\\)\nRoll a 1\n1/4\n\n\n\\(\\{2\\}\\)\nRoll a 2\n1/4\n\n\n\\(\\{3\\}\\)\nRoll a 3\n1/4\n\n\n\\(\\{4\\}\\)\nRoll a 4\n1/4\n\n\n\\(\\{1, 2\\}\\)\nRoll a 1 or a 2\n2/4\n\n\n\\(\\{1, 3\\}\\)\nRoll a 1 or a 3\n2/4\n\n\n\\(\\{1, 4\\}\\)\nRoll a 1 or a 4\n2/4\n\n\n\\(\\{2, 3\\}\\)\nRoll a 2 or a 3\n2/4\n\n\n\\(\\{2, 4\\}\\)\nRoll a 2 or a 4\n2/4\n\n\n\\(\\{3, 4\\}\\)\nRoll a 3 or a 4\n2/4\n\n\n\\(\\{1, 2, 3\\}\\)\nRoll a 1, 2, or 3 (a.k.a. do not roll a 4)\n3/4\n\n\n\\(\\{1, 2, 4\\}\\)\nRoll a 1, 2, or 4 (a.k.a. do not roll a 3)\n3/4\n\n\n\\(\\{1, 3, 4\\}\\)\nRoll a 1, 3, or 4 (a.k.a. do not roll a 2)\n3/4\n\n\n\\(\\{2, 3, 4\\}\\)\nRoll a 2, 3, or 4 (a.k.a. do not roll a 1)\n3/4\n\n\n\\(\\{1, 2, 3, 4\\}\\)\nRoll something\n1\n\n\n\n\n\n\nWhen outcomes are equally likely, we find the probability of an event by counting the number of outcomes that satisfy the event.\nThe probability measure \\(\\textrm{P}\\) in Example 2.28 satisfies all the axioms and so it is a valid probability measure. However, assuming that the outcomes are equally likely is a much stricter condition than the basic logical consistency requirements of the axioms. There are many other possible probability measures, like in the following.\n\n\n\n\n\n\n\nExample 2.29 Now consider a single roll of a four-sided die, but suppose the die is weighted so that the outcomes are no longer equally likely. Suppose that the probability of event \\(\\{2, 3\\}\\) is 0.5, of event \\(\\{3, 4\\}\\) is 0.7, and of event \\(\\{1, 2, 3\\}\\) is 0.6. Let \\(\\textrm{Q}\\) denote the probability measure corresponding to a single roll of this weighted four-sided die.\n\nIn what particular way is the die weighted? That is, what is the probability of each the four possible outcomes?\nComplete a table, like Table 2.11, listing the probability of each event for this particular weighted die.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.29. \n\nSince the probability of event \\(\\{1, 2, 3\\}\\)—that is, not rolling a 4—is 0.6, the probability of rolling a 4 must be21 0.4. Since the probability of rolling a 3 or 4 is 0.7 and the probability of rolling a 4 is 0.4, the probability of rolling a 3 must be 0.3. Similarly, the probability of rolling a 2 must be 0.2, and the probability of rolling a 1 must be 0.1.\nGiven the probability of each outcome we can find the probability of an event by summing the probabilities of the distinct outcomes that comprise the event. For example, the probability that a single roll of this die lands on an odd number is \\[\n\\textrm{Q}(\\{1, 3\\}) = \\textrm{Q}(\\{1\\}\\cup \\{3\\}) = \\textrm{Q}(\\{1\\}) + \\textrm{Q}(\\{3\\}) = 0.1+ 0.3 = 0.4.\n\\] We can similarly find the probabilities of all possible events for this particular weighted die, displayed in Table 2.12.\n\n\n\n\n\n\n\n\nTable 2.12: All possible events associated with a single roll of a four-sided die, and their probabilities assuming the die is weighted: roll a 1 with probability 0.1, 2 with probability 0.2, 3 with probability 0.3, 4 with probability 0.4.\n\n\n\n\n\n\n\n\n\n\nEvent\nDescription\nProbability of event assuming a particular weighted die\n\n\n\n\n\\(\\emptyset\\)\nRoll nothing (not possible)\n0\n\n\n\\(\\{1\\}\\)\nRoll a 1\n0.1\n\n\n\\(\\{2\\}\\)\nRoll a 2\n0.2\n\n\n\\(\\{3\\}\\)\nRoll a 3\n0.3\n\n\n\\(\\{4\\}\\)\nRoll a 4\n0.4\n\n\n\\(\\{1, 2\\}\\)\nRoll a 1 or a 2\n0.3\n\n\n\\(\\{1, 3\\}\\)\nRoll a 1 or a 3\n0.4\n\n\n\\(\\{1, 4\\}\\)\nRoll a 1 or a 4\n0.5\n\n\n\\(\\{2, 3\\}\\)\nRoll a 2 or a 3\n0.5\n\n\n\\(\\{2, 4\\}\\)\nRoll a 2 or a 4\n0.6\n\n\n\\(\\{3, 4\\}\\)\nRoll a 3 or a 4\n0.7\n\n\n\\(\\{1, 2, 3\\}\\)\nRoll a 1, 2, or 3 (a.k.a. do not roll a 4)\n0.6\n\n\n\\(\\{1, 2, 4\\}\\)\nRoll a 1, 2, or 4 (a.k.a. do not roll a 3)\n0.7\n\n\n\\(\\{1, 3, 4\\}\\)\nRoll a 1, 3, or 4 (a.k.a. do not roll a 2)\n0.8\n\n\n\\(\\{2, 3, 4\\}\\)\nRoll a 2, 3, or 4 (a.k.a. do not roll a 1)\n0.9\n\n\n\\(\\{1, 2, 3, 4\\}\\)\nRoll something\n1\n\n\n\n\n\n\nThe symbol \\(\\textrm{P}\\) is more than just shorthand for the word “probability”. \\(\\textrm{P}\\) denotes the underlying probability measure, which represents all the assumptions about the random phenomenon. Changing assumptions results in a change of the probability measure and a different probability model. We often consider several probability measures for the same sample space and collection of events; these several measures represent different sets of assumptions or available information and different probability models.\nThe probability measure \\(\\textrm{P}\\) in Example 2.28 corresponds to the assumption of a fair die (equally likely outcomes). With this measure \\(\\textrm{P}(A) = 2/4=0.5\\) for \\(A = \\{1, 3\\}\\). But under the probability measure \\(\\textrm{Q}\\) corresponding to the weighted die in Example 2.29, \\(\\textrm{Q}(A) = 0.4\\). The outcomes and events are the same in both scenarios, because both scenarios involve a four sided-die. What is different is the probability measure that assigns probabilities to the events. One scenario assumes the die is fair while the other assumes the die has a particular weighting, resulting in two different probability measures.\nBoth probability measures \\(\\textrm{P}\\) and \\(\\textrm{Q}\\) can be written as explicit set functions: for an event \\(A\\)\n\\[\\begin{align*}\n\\textrm{P}(A) & = \\frac{\\text{number of outcomes that satisfy $A$}}{4}, & & {\\text{a fair four-sided die}}\n\\\\\n\\textrm{Q}(A) & = \\frac{\\text{sum of elements in $A$}}{10}, & & {\\text{a specific weighted four-sided die}}\n\\end{align*}\\]\nWe provide the above descriptions to illustrate that a probability measure operates on sets. However, in many situations there does not exist a simple closed form expression for the set function defining the probability measure which maps events to probabilities.\n\n\n\n\n\n\n\nExample 2.30 Consider again a single roll of a weighted four-sided die. Suppose that\n\nRolling a 1 is twice as likely as rolling a 4\nRolling a 2 is three times as likely as rolling a 4\nRolling a 3 is 1.5 times as likely as rolling a 4\n\nLet \\(\\tilde{\\textrm{Q}}\\) be the probability measure corresponding to this die.\n\nIn what particular way is the die weighted? That is, what is the probability of each the four possible outcomes?\nCompute \\(\\tilde{\\textrm{Q}}(A)\\) for each event in Table 2.11.\nWeighting a die in a particular way might be hard to conceptualize and even harder to achieve in practice. Construct a circular spinner to represent this weighted die.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.30. \n\nLet \\(q = \\tilde{\\textrm{Q}}(\\{4\\})\\) denote the probability of rolling a 4. Then \\(\\tilde{\\textrm{Q}}(\\{1\\}) = 2q\\), \\(\\tilde{\\textrm{Q}}(\\{2\\}) = 3q\\), and \\(\\tilde{\\textrm{Q}}(\\{3\\}) = 1.5q\\). Since these probabilities must sum to 1, we have \\(2q + 3q + 1.5q + q = 1\\) so \\(q = 2/15\\). Therefore, the probability of rolling a 1 is 4/15, a 2 is 6/15, a 3 is 3/15, and a 4 is 2/15. (We could have also solved this without algebra similiar to how we solved Example 1.8.)\nGiven the probability of each outcome we can find the probability of an event by summing the probabilities of the distinct outcomes that comprise the event. For example, the probability of rolling an odd number is \\[\n\\tilde{\\textrm{Q}}(\\{1, 3\\}) = \\tilde{\\textrm{Q}}(\\{1\\}\\cup \\{3\\}) = \\tilde{\\textrm{Q}}(\\{1\\}) + \\tilde{\\textrm{Q}}(\\{3\\}) = 4/15+ 3/15 = 7/15 \\approx 0.467.\n\\]\nWe can similarly find the probabilities of all possible events for this particular weighted die, displayed in Table 2.13. Note this probability measure does not have a simple closed formula for \\(\\tilde{\\textrm{Q}}(A)\\).\nConstruct a spinner with four sectors of area 4/15, 6/15, 3/15, and 2/15 representing, respectively, the values 1, 2, 3, and 4. See Figure 2.9 (c).\n\n\n\n\n\n\n\n\nTable 2.13: All possible events associated with a single roll of a four-sided die, and their probabilities assuming the die is weighted: roll a 1 with probability 4/15, 2 with probability 6/15, 3 with probability 3/15, 4 with probability 2/15.\n\n\n\n\n\n\n\n\n\n\nEvent\nDescription\nProbability of event assuming a particular weighted die\n\n\n\n\n\\(\\emptyset\\)\nRoll nothing (not possible)\n0\n\n\n\\(\\{1\\}\\)\nRoll a 1\n4/15\n\n\n\\(\\{2\\}\\)\nRoll a 2\n6/15\n\n\n\\(\\{3\\}\\)\nRoll a 3\n3/15\n\n\n\\(\\{4\\}\\)\nRoll a 4\n2/15\n\n\n\\(\\{1, 2\\}\\)\nRoll a 1 or a 2\n10/15\n\n\n\\(\\{1, 3\\}\\)\nRoll a 1 or a 3\n7/15\n\n\n\\(\\{1, 4\\}\\)\nRoll a 1 or a 4\n6/15\n\n\n\\(\\{2, 3\\}\\)\nRoll a 2 or a 3\n9/15\n\n\n\\(\\{2, 4\\}\\)\nRoll a 2 or a 4\n8/15\n\n\n\\(\\{3, 4\\}\\)\nRoll a 3 or a 4\n5/15\n\n\n\\(\\{1, 2, 3\\}\\)\nRoll a 1, 2, or 3 (a.k.a. do not roll a 4)\n13/15\n\n\n\\(\\{1, 2, 4\\}\\)\nRoll a 1, 2, or 4 (a.k.a. do not roll a 3)\n12/15\n\n\n\\(\\{1, 3, 4\\}\\)\nRoll a 1, 3, or 4 (a.k.a. do not roll a 2)\n9/15\n\n\n\\(\\{2, 3, 4\\}\\)\nRoll a 2, 3, or 4 (a.k.a. do not roll a 1)\n11/15\n\n\n\\(\\{1, 2, 3, 4\\}\\)\nRoll something\n1\n\n\n\n\n\n\nThe die rolling example is not the most exciting or practical scenario. But the example does illustrate the idea of several probability measures, each corresponding to a different set of assumptions about the random phenomenon. If it’s difficult to imagine how to physically weight a die in these particular ways, consider the spinners (like from a kids game) in Figure 2.9).\n\n\n\n\n\n\n\n\n\n\n\n(a) A fair die\n\n\n\n\n\n\n\n\n\n\n\n(b) The weighted die of Example 2.29\n\n\n\n\n\n\n\n\n\n\n\n(c) The weighted die of Example 2.30\n\n\n\n\n\n\n\nFigure 2.9: Three possible spinners corresponding to the roll of a four-sided die.\n\n\n\n\n\n\n\n\n\n\nExample 2.31 Using the set up of this section, the event \\(A = \\{1, 3\\}\\), and the spinners from Figure 2.9,\n\nInterpret each of \\(\\textrm{P}(A) = 0.5\\), \\(\\textrm{Q}(A) = 0.4\\), and \\(\\tilde{\\textrm{Q}}(A) = 7/15\\) as a long run relative frequency.\nInterpret each of \\(\\textrm{P}(A) = 0.5\\), \\(\\textrm{Q}(A) = 0.4\\), and \\(\\tilde{\\textrm{Q}}(A) = 7/15\\) in terms of a relative degree of likelihood.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.31. \n\nUse the spinners from Figure 2.9.\n\n\\(\\textrm{P}(A) = 0.5\\): Spin the spinner on the left many times; it will land on an odd number on about 50% of spins.\n\\(\\textrm{Q}(A) = 0.4\\): Spin the spinner in the middle many times; it will land on an odd number on about 40% of spins.\n\\(\\tilde{\\textrm{Q}}(A) = 7/15\\): Spin the spinner on the right many times; it will land on an odd number on about 46.67% of spins.\n\nUse the spinners from Figure 2.9.\n\n\\(\\textrm{P}(A) = 0.5\\): The spinner on the left is equally likely to land on an odd number or an even number\n\\(\\textrm{Q}(A) = 0.4\\): The spinner in the middle is 1.5 times more likely to land on an even number than on an odd number.\n\\(\\tilde{\\textrm{Q}}(A) = 7/15\\): The spinner on the right is \\(8/7\\approx 1.14\\) times more likely to land on an even number than on an odd number.\n\n\n\n\n\n\nIt is usually reasonable to assume that dice are fair, but most real world situations are not as simple as rolling dice. Just because a situation has 16 possible outcomes doesn’t mean the outcomes have to be equally likely. For example, there might be 12 contestants on your favorite reality competition show, but that doesn’t mean that all of the 12 contestants are equally likely to win the season.\n\n\n2.4.3 Some probability measures in the meeting problem\nRecall the meeting problem. The general problem involves multiple people, but we’ll first consider the arrival time of just a single person, who we’ll call Han22.\n\n\n\n\n\n\nCaution\n\n\n\nSome of the examples in this section involve just a single person arriving, while other examples involve two people.\n\n\nSuppose that Han’s arrival time will definitely be between noon and 1:00, so that the sample space—with time measured in minutes after noon, including fractions of a minute—is \\(\\Omega = [0, 60]\\).\n\n\n\n\n\n\n\nExample 2.32 Suppose that Han arrives “uniformly at random” at a time in \\([0, 60]\\). Use your intuition to provide your best guess for each of the following probabilities.\n\nThe probability that Han arrives before 12:30.\nThe probability that Han arrives before 12:15.\nThe probability that Han arrives after 12:45.\nThe probability that Han arrives between 12:15 and 12:45.\nThe probability that Han arrives before 12:05.\nThe probability that Han arrives between 12:15 and 12:20.\nLet \\(\\textrm{P}\\) denote the corresponding probability measure. Suggest a general formula for \\(\\textrm{P}([a, b])\\), the probability that Han arrives between \\(a\\) and \\(b\\) minutes after noon for \\(0\\le a&lt;b\\le 60\\) (e.g., \\(a=15, b=20\\) for “between 12:15 and 12:20” or \\(a = 0, b=5\\) for “before 12:05”).\nFind the probability that Han’s arrival time, truncated to the nearest minute, is 0 minutes after noon; that is, find the probability that Han arrives between 12:00 and 12:01.\nContinue to find the probability that Han’s arrival time truncated23 to the nearest minute is \\(1, 2, 3, \\ldots, 59\\), and sketch a plot with arrival time (truncated minutes after noon) on the horizontal axis and probability on the vertical axis. Is the plot what you would expect for arriving “uniformly at random”?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.32. “Uniformly at random” means that in some sense Han is “equally likely” to arrive at any time between noon and 1:00.\n\n0.5. It seems that Han should be as likely to arrive before 12:30 as after.\n0.25. The time interval before 12:15 is 0.25 of the total noon to 1:00 time interval, so if he is “equally likely” to arrive at any time, the probability that he arrives in a 15 minute interval is \\(15/60 = 0.25\\).\n0.25. Similar to the previous part.\n0.5. This 30 minute interval makes up half of the total noon to 1:00 time interval.\n\\(1/12 = 0.083\\). The time interval before 12:05 is \\(5/60=1/12\\) of the total noon to 1:00 time interval, so if he is “equally likely” to arrive at any time, the probability that he arrives in a 5 minute interval is \\(5/60 = 1/12=0.083\\).\n1/12, similar to the previous part.\nIt seems reasonable that if Han arrives uniformly at random within the 60 minute time interval, the probability that he arrives within any time interval \\([a, b]\\) (in \\([0, 60]\\)) is \\(\\textrm{P}([a, b]) = (b-a)/60\\), the length of the time interval of interest divided by the length of the total time interval.\nThe probability that Han arrives in the one minute interval between 12:00 and 12:01 is \\(1/60\\approx 0.0167\\).\nThe probability that Han arrives in any one minute interval is \\(1/60\\approx 0.0167\\). See Figure 2.10.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.10: Probability of Han arriving at each minute between noon (0) and 1:00 (60), truncated to the nearest minute, for the uniform probability measure in Example 2.32).\n\n\n\n\n\nExample 2.28 illustrated that for a finite sample space with equally likely outcomes, computing the probability of an event reduces to counting the number of outcomes that satisfy the event and dividing by the total number of possible outcomes. The continuous analog of equally likely outcomes is a uniform probability measure. When the sample space is uncountable, size is measured continuously (length, area, volume) rather that discretely (counting).\n\\[\n\\textrm{P}(A) = \\frac{\\text{size of } A}{\\text{size of } \\Omega} \\qquad \\text{if $\\textrm{P}$ is a uniform probability measure}\n\\]\nThe uniform probability measure in Example 2.32 is just one probability measure for Han’s arrival, reflecting an assumption that Han is “equally likely” to arrive at any time between noon and 1:00. Now we’ll model Han’s arrival time with a non-uniform probability measure which reflects that he is more likely to arrive near certain times than others.\n\n\n\n\n\n\n\nExample 2.33 Assume that the probability that Han arrives between \\(a\\) and \\(b\\) minutes after noon is \\((b/60)^2 - (a/60)^2\\) (for \\(0\\le a&lt;b\\le 60\\)) . Let \\(\\textrm{Q}\\) denote the corresponding probability measure; notice that \\(\\textrm{Q}([0, 60]) = (60/60)^2 - (0/60)^2 = 1\\). (We will see where such a probability measure might come from later. For now, we’ll just use it to compute probabilities and observe that it is a non-uniform measure.) Compute the following probabilities and compare your answers to the corresponding parts from Example 2.32.\n\nThe probability that Han arrives before 12:30.\nThe probability that Han arrives before 12:15.\nThe probability that Han arrives after 12:45.\nThe probability that Han arrives between 12:15 and 12:45.\nFind the probability Han’s arrival time, truncated to the nearest minute, is 0 minutes after noon; that is, find the probability that Han arrives between 12:00 and 12:01.\nContinue to find the probability that Han’s arrival time truncated to the nearest minute is \\(1, 2, 3, \\ldots, 59\\), and sketch a plot with arrival time (truncated minutes after noon) on the horizontal axis and probability on the vertical axis. What assumptions about Han’s arrival time does this probability measure reflect?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.33. \n\nThe probability Han arrives before 12:30 is \\(\\textrm{Q}([0, 30]) = (30/60)^2 - (0/60)^2 =0.5^2 =0.25\\). Han is 3 times more likely to arrive after 12:30 than before 12:30. (Han is now less likely to arrive before 12:30 than in the uniform case.)\nThe probability Han arrives before 12:15 is \\(\\textrm{Q}([0, 15)) = (15/60)^2 - (0/60)^2 =0.25^2 = 0.0625\\); \\(\\textrm{Q}([0, 15)) = 0.0625\\). Han is 15 times more likely to arrive after 12:15 than before 12:15. (Han is now less likely to arrive within 15 minutes of noon than in the uniform case.)\nThe probability Han arrives before 12:45 is \\(\\textrm{Q}([0, 45)) = (45/60)^2 - (0/60)^2 =0.75^2 = 0.5625\\). Therefore, the probability that Hans arrives after 12:45 is \\(\\textrm{Q}([45, 60]) = 1 - 0.5625 = 0.4375\\). Han is 7 times more likely to arrive within 15 minutes of 1:00 than within 15 minutes of noon. (Han is now more likely to arrive with 15 minutes of 1:00 than in the uniform case.)\nThe probability that Han arrives between 12:15 and 12:45 is \\(\\textrm{Q}((15, 45)) = (45/60)^2-(15/60)^2 = 0.5\\). (This probability happens to be the same as in the uniform case.)\n\\(\\textrm{Q}([0, 1]) = (1/60)^2 - (0/60)^2 = 1/3600 = 0.000278\\) is the probability that Han arrives within 1 minute of noon. (This probability is less than what it was in the uniform case.)\nContinue as in the previous part. For example, \\(\\textrm{Q}([1, 2]) = (2/60)^2 - (1/60)^2 = 3/3600 = 0.000833\\) is the probability that Han arrives between 12:01 and 12:02; \\(\\textrm{Q}([2, 3]) = (3/60)^2 - (2/60)^2 = 5/3600 = 0.000833\\) is the probability that Han arrives between 12:01 and 12:02; \\(\\textrm{Q}([59, 60]) = (60/60)^2 - (59/60)^2 = 119/3600 = 0.033\\) is the probability that Han arrives within 1 minute of 1:00. In general, \\(\\textrm{Q}([a, a+1]) = ((a+1)/60)^2 - (a/60)^2 = (2a+1)/3600\\) for \\(a = 0, 1, \\ldots, 59\\). See Figure 2.10. This probability measure assumes that Han is more likely to arrive closer to 1:00 than to noon.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.11: Probability of Han arriving at each minute between noon (0) and 1:00 (60), truncated to the nearest minute, for a uniform probability measure (blue) and the probability measure in Example 2.33 (orange).\n\n\n\n\n\nThe probability measure in Example 2.33 is a non-uniform measure. Han is much more likely to arrive between 12:45 and 1:00 than between 12:00 and 12:15, even though both these intervals have the same length.\n\n\n\n\n\n\nWarning\n\n\n\nBe careful when reading Figure 2.11! For example, the probability that the arrival time truncated to the nearest minute is 0 is 1/60 for the uniform measure in Example 2.32 and 1/3600 for the non-uniform measure in Example 2.33; these probabilities represent the probability that Han arrives within one minute of noon rather than the probability that Han arrives exactly at noon. Likewise, the probability that the arrival time truncated to the nearest minute is 59 is 0.0167 = 60/3600 for the uniform measure in Example 2.32 and 0.033 = 119/3600 for the non-uniform measure in Example 2.33; these probabilities represent the probability that Han arrives within one minute of 1:00 rather than the probability that Han arrives exactly at 1:00. All of the dots in Figure 2.11 correspond to one-minute intervals, not exact time points.\n\n\n\n\n\n\n\n\n\nExample 2.34 Continuing with the uniform probability measure of Example 2.32.\n\nFind the probability that Han arrives between 12:00 and 12:01, within 1 minute after noon.\nFind the probability that Han arrives between 12:00:00 and 12:00:01, within 1 second after noon.\nFind the probability that Han arrives between 12:00:00.000 and 12:01:00.001, within 1 millisecond after noon.\nFind the probability that Han arrives at the exact time 12:00:00.00000… (with infinite precision).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.34. For the uniform probability measure, the probability of arriving in any interval is the length of the time interval divided by the length of the total interval. With time measured in minutes, a one minute interval has length 1, a one second interval has length \\(1/60\\), and a one millisecond interval has length \\(1/60000\\).\n\n\\(1/60 = 0.0167\\) is Han’s probability of arriving in this 1 minute interval.\n\\((1/60)/60 = 0.000278\\) is Han’s probability of arriving in this 1 second interval.\n\\((1/60000)/60 = 0.000000278\\) is Han’s probability of arriving in this 1 millisecond interval\nThe exact time 12:00:00.0000 represents a single point the sample space, an interval of length 0. The probability that Han arrives at the exact time 12:00:00000 (with infinite precision) is 0; \\(\\textrm{P}(\\{0\\}) = 0\\).\n\n\n\n\n\nThe last part in Example 2.34 might seem counterintuitive at first. There was nothing special about 12:00; pick any precise time in the continuous interval from noon to 1:00, and the probability that Han arrives at that exact time, with infinite precision, is 0. This idea can be understood as a limit. The probability that Han arrives within one minute of the specified time is small, within one second of the specified time is even smaller, within one millisecond of the specified time is even smaller still; with infinite precision these time increments can get smaller and smaller indefinitely. Of course, infinite precision is not practical, but assuming the possible arrival times are represented by a continuous interval provides a reasonable mathematical model. Even though any particular time has probability 0 of being the precise arrival time, intervals of time still have positive probability of containing the arrival time. When we ask a question like “what is the probability that Han arrives at noon”, “at noon” really means “within 1 minute of noon” or “within 1 second of noon” or within whatever degree of precision is good enough for our practical purposes, and such intervals have non-zero probability.\n\n\n\n\n\n\n\nExample 2.35 Continuing with the non-uniform probability measure of Example 2.33.\n\nFind the probability that Han arrives between 12:00 and 12:01, within 1 minute after noon.\nFind the probability that Han arrives between 12:00:00 and 12:00:01, within 1 second after noon.\nFind the probability that Han arrives between 12:00:00.000 and 12:01:00.001, within 1 millisecond after noon.\nFind the probability that Han arrives at the exact time 12:00:00.00000… (with infinite precision).\nFind the probability that Han arrives between 12:59 and 1:00, within 1 minute before 1:00.\nFind the probability that Han arrives between 12:59:59 and 1:00:00, within 1 second before 1:00.\nFind the probability that Han arrives between 12:59:59.999 and 1:00:00.000, within 1 millisecond before 1:00.\nFind the probability that Han arrives at the exact time 1:00:00.00000… (with infinite precision).\nWhich is more likely: that Han arrives “at noon” or “at 1:00”? Explain.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.35. With time measured in minutes, one minute is 1, one second is \\(1/60\\), and one millisecond is \\(1/60000\\).\n\n\\((1/60)^2 - 0 = 0.000278\\) is Han’s probability of arriving within 1 minute of noon.\n\\(((1/60)/60)^2 - 0 = 0.000000077\\) is Han’s probability of arriving within 1 second of noon.\n\\(((1/60000)/60)^2 - 0= 0.000000000000077\\) is Han’s probability of arriving within 1 millisecond of noon.\nThe exact time 12:00:00.0000 represents a single point the sample space, an interval of length 0. The probability that Han arrives at the exact time 12:00:00000 (with infinite precision) is 0; \\(\\textrm{Q}(\\{0\\}) = 0\\).\n\\(1-((60 - 1)/60)^2 = 0.033\\) is Han’s probability of arriving within 1 minute of 1:00.\n\\(1-((60 - 1/60)/60)^2  = 0.00055\\) is Han’s probability of arriving within 1 second of 1:00.\n\\(1-((60 - 1/60000)/60)^2  = 0.00000055\\) is Han’s probability of arriving within 1 millisecond of 1:00.\nThe exact time 1:00:00.0000 represents a single point the sample space, an interval of length 0. The probability that Han arrives at the exact time 1:00:00000 (with infinite precision) is 0; \\(\\textrm{Q}(\\{60\\}) = 0\\).\nThe probabilities of arriving precisely at noon or 1:00 are both 0. However, the probability of arriving “close to” 1:00 is greater than the probability of arriving “close to” noon, regardless of how “close to” is defined (within 1 minute, within 1 second, etc). In practice, “at” is probably best interpreted as “close to”, and in this sense Han is more likely to arrive “at 1:00” than “at noon”.\n\n\n\n\n\nContinuous sample spaces introduce some complications that we didn’t encounter when dealing with discrete sample spaces. For a continuous sample space, the probability of any particular outcome24 is 0. However, Example 2.35 illustrates that in some sense certain outcomes can be more likely than others; Han is more likely to arrive close to 1:00 than close to noon. For continuous sample spaces it makes more sense to consider “close to” probabilities rather than “equals to” probabilities. We will investigate related ideas in much more detail as we go.\nNow we’ll return to the two-person (Regina, Cady) meeting problem from Example 2.3, with sample space depicted in Figure 2.2. We will use pictures to represent a few probability measures corresponding to different assumptions about the arrival times. In the pictures below, lighter colors represent regions of outcomes that are more likely; darker colors, less likely.\nFigure 2.12 corresponds to a uniform probability measure under which all outcomes are “equally likely”. This probability measure would be appropriate if we assume that Regina and Cady each arrive at a time uniformly at random between noon and 1, independently of each other.\n\n\n\n\n\n\n\n\nFigure 2.12: A uniform probability measure in the (Regina, Cady) meeting problem.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.36 Assume the uniform probability measure \\(\\textrm{P}\\) represented by Figure 2.12. Hint: when finding probabilities below, recall Example 2.11 and Figure 2.13.\n\nFind the probability that Regina arrives after Cady.\nFind the probability that either Regina or Cady arrives before 12:30.\nFind the probability that Cady arrives first and Regina arrives at most 15 minutes after Cady.\nFind the probability that Regina arrives before 12:24.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.36. For a uniform probability measure, the probability of an event is the size of the event divided by the size of the sample space. Since the sample space is \\([0, 60]\\times[0, 60]\\), a continuous two-dimensional region, size is measured by area. The sample space has area 3600.\nSee Figure 2.13 for pictures of the events of interest.\n\nThe triangular region corresponding to the event that Regina arrives after Cady has area 3600/2 = 1800. So the probability that Regina arrives after Cady is \\(1800/3600=0.5\\).\nThe L-shaped region corresponding to the event that Regina or Cady arrives before 12:30 has area \\((0.75)(3600)\\), so the probability is 0.75.\nThe trapezoidal region corresponding to the event that that Regina arrives at most 15 minutes after Cady (and Cady arrives first) has area \\((7/32)(3600) = (0.21875)(3600)\\). (It’s easiest to find the area of the two unshaded triangles and subtract from the total area of 3600: \\(3600 - 0.5(3600) - (3600)(1-0.25)^2/2=7/32(3600)\\).) So the probability that Regina arrives at most 15 minutes after Cady (and Cady arrives first) is 0.21875.\nThe rectangular region corresponding to the event that that Regina arrives before 12:24 has area (0.4)(3600), so the probability is 0.4.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.13: Illustration of the events in Exercise Example 2.36. The square represents the sample space. With a uniform probability measure, the areas of the shaded regions relative to the whole represent their probabilities.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.37 Continuing Example 2.36\n\nFind the probability that Cady arrives first and Regina arrives at most 1 minute after Cady.\nFind the probability that Cady arrives first and Regina arrives at most 1 second after Cady.\nFind the probability that Cady arrives first and Regina arrives at most 1 millisecond after Cady.\nFind the probability that Regina and Cady arrive at exactly the same time, with infinite precision.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.37. \n\nSimilar to part 3 of Example 2.36, the probability that Regina arrives at most 1 minute after Cady (and Cady arrives first) is \\(1 - 0.5 - (1-1/60)^2/2=0.0165\\).\nThe probability that Regina arrives at most 1 second after Cady (and Cady arrives first) is \\(1 - 0.5 - (1-1/3600)^2/2=0.000278\\).\nThe probability that Regina arrives at most 1 millisecond after Cady (and Cady arrives first) is \\(1 - 0.5 - (1-1/3600000)^2/2=0.000000278\\).\nThe event that Regina and Cady arrive at exactly the same time, with infinite precision, corresponds to the “Regina = Cady” line segment. The area of this line segment is 0, so the probability that Regina and Cady arrive at exactly the same time, with infinite precision, is 0.\n\n\n\n\n\nExample 2.37 and Example 2.34 illustrate similar ideas. Regardless of the precise time in the continuous interval \\([0, 60]\\) at which Regina arrives, the probability that Cady arrives at that exact time, with infinite precision, is 0. In practice, if we’re interested in “the probability that Regina at Cady arrive at the same time”, we really mean “close enough to the same time”, where “close enough” could be within one minute or one second or whatever degree of precision is good enough for practical purposes.\nMost random phenomenon do not involve equally likely outcomes or uniform probability measures. Even when the underlying outcomes are equally likely, the values of related random variables are usually not. Therefore, most interesting probability problems involve “non-uniform” probability measures.\nFigure 2.14 corresponds to one non-uniform probability measure for the two-person meeting problem; certain outcomes are more likely than others. (Lighter colors represent regions of outcomes that are more likely; darker colors, less likely.) Such a probability measure would be appropriate if we assume that Regina and Cady each are more likely to arrive around 12:30 than noon or 1:00, independently of each other. Switching from the uniform probability measure represented by Figure 2.12 to the non-uniform one represented by Figure 2.14 would change the probability of the events in Example 2.36 and Example 2.37. (We’ll see how to compute probabilities for non-uniform measures later.)\n\n\n\n\n\n\n\n\nFigure 2.14: A non-uniform probability measure in the two person meeting problem. Lighter colors represent regions of outcomes that are more likely; darker colors, less likely.\n\n\n\n\n\nFigure 2.15 corresponds to another “non-uniform” probability measure. Such a probability measure would be appropriate if we assume that Regina and Cady each are more likely to arrive around 12:30 than noon or 1:00, but they coordinate their arrivals so they are more likely to arrive around the same time.\n\n\n\n\n\n\n\n\nFigure 2.15: Another non-uniform probability measure in the two person meeting problem. Lighter colors represent regions of outcomes that are more likely; darker colors, less likely. Notice how the probability is concentrated along the \\(R=Y\\) line\n\n\n\n\n\nThere are many other probability measures for the meeting problem, representing different sets of assumptions. Each probability measure assigns a probability to events like “Cady arrives first”, “both arrive before 12:20”, and “the first person to arrive has to wait less than 15 minutes for the second to arrive”, and these probabilities can differ between models.\n\n\n2.4.4 Some properties of probability measures\nMany other properties follow from the axioms, some of which we state below. Don’t let notation or names like the “complement rule” confuse you. We have already successfully used all of the properties below intuitively when working with two-way tables. All that is new in this section is mathematical formalism. Yes, getting comfortable with proper notation is part of learning the language of probability. But don’t let formality get in the way of your intuition. Continue to use the ideas from Chapter 1, including tools like two-way tables.\nThe main “meat” of the axioms is countable additivity. Thus, the key to many proofs of probability properties is to express relevant events in terms of unions of disjoint events. (Proof are included in the footnotes.)\n\nLemma 2.2 (Complement rule) For any event25 \\(A\\), \\(\\textrm{P}(A^c) = 1 - \\textrm{P}(A)\\).\n\nThe complement rule follows from the fact that an event either happens or it doesn’t. We’ll see that it is sometimes more convenient to compute directly the probability that an event does not happen and then use the complement rule.\n\n\n\n\n\n\nWarning\n\n\n\nSubtracting a computed probability from 1 seems like a small computational step, but it’s an important one. If you’re taking a test, a 0.9 probability of getting a question correct is much different than a 0.1 probability. Unfortunately, the complement rule step is often overlooked when doing probability calculations. It’s a good idea to ask yourself if the probability you are computing should be greater than or less than 0.5. If your computed value seems to be on the wrong side of 0.5, check your calculations to see if you have forgotten (or misapplied) the complement rule.\n\n\n\nLemma 2.3 (Subset rule) If \\(A \\subseteq B\\) then26 \\(\\textrm{P}(A) \\le \\textrm{P}(B)\\).\n\nThe subset rule says that if every outcome that satisfies event \\(A\\) also satisfies event \\(B\\) then the probability of event \\(B\\) must be at least as large as the probability of event \\(A\\). We saw an application of the subset rule in Example 1.9.\n\nLemma 2.4 (Addition rule for two events) If \\(A\\) and \\(B\\) are any two events then27\n\n\\[\\begin{align*}\n    \\textrm{P}(A\\cup B) = \\textrm{P}(A) + \\textrm{P}(B) - \\textrm{P}(A \\cap B)\n\\end{align*}\\]\n\n\n\n\n\n\n\nExample 2.38 Donny Don’t says: “Wait a minute. You said unions are inclusive; \\(\\textrm{P}(A\\cup B)\\) means the probability of \\(A\\) or \\(B\\) OR BOTH. So \\(\\textrm{P}(A\\cup B)\\) should just be \\(\\textrm{P}(A)+\\textrm{P}(B)\\).” Explain to Donny his mistake, using the picture on the right in Figure 2.8 as an example.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.38. \\(A\\cup B\\) is inclusive so we do want to count the possibility of both, \\(A\\cap B\\). The problem with simply adding \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) is that their sum double counts \\(A \\cap B\\). We do want to count the outcomes that satisfy both \\(A\\) and \\(B\\), but we only want to count them once. Subtracting \\(\\textrm{P}(A \\cap B)\\) in the general addition rule for two events corrects for the double counting.\nFor example, consider the picture on the right in Figure 2.8. Suppose each rectangular cell represents a distinct outcome; there are 16 outcomes in total. Assume the outcomes are equally likely, each with probability \\(1/16\\). Let \\(A\\) represent the yellow / event which has probability \\(4/16\\) and let \\(B\\) represent the blue \\ event which has probability 4/16. (Remember, green represents outcomes that satisfy both blue and yellow.) Then \\(\\textrm{P}(A\\cup B) = 6/16\\), since there are 6 outcomes which satisfy either event \\(A\\) or \\(B\\) (or both). However, simply adding \\(\\textrm{P}(A)+\\textrm{P}(B)\\) yields \\(8/16\\) because the two outcomes that satisfy the green event \\(A\\cap B\\) are counted both in \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\). So to correct for this double counting, we subtract out \\(\\textrm{P}(A\\cap B)\\): \\[\n\\textrm{P}(A)+\\textrm{P}(B)-\\textrm{P}(A\\cap B) = 4/16 + 4/16 -2/16 = 6/16 = \\textrm{P}(A\\cup B)\n\\]\n\n\n\n\nThe addition rule for more than two events is complicated28 (unless the events are disjoint). For example, the addition rule for three events is \\[\\begin{align*}\n    \\textrm{P}(A\\cup B\\cup C) & = \\textrm{P}(A) + \\textrm{P}(B) + \\textrm{P}(C)\\\\\n    & \\qquad - \\textrm{P}(A\\cap B) - \\textrm{P}(A \\cap C) - \\textrm{P}(B \\cap C)\\\\\n    & \\qquad + \\textrm{P}(A \\cap B \\cap C).\n\\end{align*}\\]\nMany problems involve finding the “probability of at least one…” On the surface such problems involve unions (“at least one of events \\(A_1, A_2, \\ldots\\) occur if event \\(A_1\\) occurs OR event \\(A_2\\) occurs OR…”) Since the general addition rule for multiple events is complicated, unless the events are disjoint it is usually more convenient to use the complement rule and compute “the probability of at least one…” as one minus “the probability of none…” The “probability of none…” involves intersections (“none of the events \\(A_1, A_2, \\ldots\\) occur if event \\(A_1\\) does not occur AND event \\(A_2\\) does not occur AND…”). We will see more about probabilities of intersections later.\n\nLemma 2.5 (Law of total probability) If \\(C_1, C_2, C_3\\ldots\\) are disjoint events with \\(C_1\\cup C_2 \\cup C_3\\cup \\cdots =\\Omega\\), then29\n\n\\[\\begin{align*}\n    \\textrm{P}(A) & = \\textrm{P}(A \\cap C_1) + \\textrm{P}(A \\cap C_2) + \\textrm{P}(A \\cap C_3) + \\cdots\n\\end{align*}\\]\nSince \\(C\\) and \\(C^c\\) are disjoint with \\(C \\cup C^c = \\Omega\\), a special case is\n\\[\\begin{align*}\n    \\textrm{P}(A) & = \\textrm{P}(A \\cap C) + \\textrm{P}(A \\cap C^c)\n\\end{align*}\\]\nIn the law of total probability the events \\(C_1, C_2, C_3, \\ldots\\), which represent “cases”, form a partition of the sample space; each outcome in the sample space satisfies exactly one of the cases \\(C_i\\). The law of total probability says that we can compute the “overall” probability \\(\\textrm{P}(A)\\) by breaking \\(A\\) down into pieces and then summing the case-by-case probabilities \\(\\textrm{P}(A\\cap C_i)\\). We use the law of total probability intuitively when we sum across rows and columns in two-way tables. (Later we will see a different and more useful expression of the law of total probability, involving conditional probabilities.)\nThe following example is one we have basically covered before, Example 1.15, but now we use mathematical notation and properties. However, the ideas are the same as we discussed in Example 1.15.\nThe following example involves randomly selecting a U.S. household. Note that while “randomly select” is commonly used terminology, it is not the best wording. Remember that “random” simply means uncertain, so technically “randomly select” just means selecting in a way that the outcome is uncertain. Suppose I want to “randomly select” one of two households, A or B. I could put 10 tickets in a hat, with 9 labeled A and 1 labeled B, and then draw a ticket; this is random selection because the outcome of the draw is uncertain. However, what is often meant by “randomly select” is selecting in a way that each outcome is equally likely. To give households A and B the same chance of being selected, I would put a single ticket for each in the hat. Randomly selecting in a way that each outcome is equally likely could be described more precisely as “selecting uniformly at random”. (We will discuss equally likely outcomes in more detail later.)\n\n\n\n\n\n\n\nExample 2.39 Recall Example 1.15. Suppose that the probability that a randomly selected U.S. household has a pet dog is 0.47, and that the probability that a randomly selected U.S. household has a pet cat is 0.25.\n\nDefine the sample space and two events of interest in words.\nRepresent these probabilities using proper notation.\nDonny Don’t says: “the probability that a randomly selected U.S. household has a pet dog OR a pet cat is \\(0.47 + 0.25=0.72\\).” Do you agree? What must be true for Donny to be correct? Explain.\nWhat is the largest possible value of the probability that a randomly selected U.S. household has a pet dog OR a pet cat? Describe the (unrealistic) situation in which this extreme case would occur.\nWhat is the smallest possible value of the probability that a randomly selected U.S. household has a pet dog OR a pet cat? Describe the (unrealistic) situation in which this extreme case would occur.\nDonny Don’t says: “I remember hearing once that in probability OR means add and AND means multiply. So the probability that a randomly selected U.S. household has a pet dog AND a pet cat is \\(0.47 \\times 0.25=0.1175\\).” Do you agree? Explain.\nSuppose that the probability that a randomly selected U.S. household has a pet dog AND a pet cat is \\(0.14\\). Compute the probability that a randomly selected U.S. household has a pet dog OR a pet cat.\nCompute and interpret \\(\\textrm{P}(C \\cap D^c)\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.39. \n\nThe sample space consists of U.S. households. Let \\(C\\) be the event that the household has a pet cat, and let \\(D\\) be the event that the household has a pet dog.\nLet \\(\\textrm{P}\\) be the probability measure corresponding to randomly selecting a U.S. household. The probability measure corresponds to however the random selection is done; though not specified, it’s assumed to be uniformly at random. Then \\(\\textrm{P}(C) = 0.25\\) and \\(\\textrm{P}(D) = 0.47\\).\nDonny would only be correct if the events \\(C\\) and \\(D\\) were disjoint, which would only be true if no households had both a pet cat and a pet dog. This is an unrealistic scenario so \\(\\textrm{P}(C \\cup D)\\) is less than 0.72.\nUsing the addition rule, \\(\\textrm{P}(C \\cup D) = \\textrm{P}(C) + \\textrm{P}(D) - \\textrm{P}(C \\cap D) = 0.25 + 0.47 - \\textrm{P}(C\\cap D).\\) So \\(\\textrm{P}(C\\cup D)\\) is the largest it can be when \\(\\textrm{P}(C \\cap D)\\) is the smallest it can be. The smallest \\(\\textrm{P}(C \\cap D)\\) can possibly30 be is 0, and hence the largest \\(\\textrm{P}(C\\cup D)\\) can be is 0.72, which would only be true if no households had both a pet cat and a pet dog.\n\\(\\textrm{P}(C \\cup D) = \\textrm{P}(C) + \\textrm{P}(D) - \\textrm{P}(C \\cap D) = 0.25 + 0.47 - \\textrm{P}(C\\cap D)\\). \\(\\textrm{P}(C\\cup D)\\) is the smallest it can be when \\(\\textrm{P}(C \\cap D)\\) is the largest it can be. The probability that the household has both a pet cat and a pet dog can not be larger than either of the two component probabilities; that is, by the subset rule, \\(\\textrm{P}(C\\cap D)\\le \\textrm{P}(C) = 0.25\\) and \\(\\textrm{P}(C\\cap D)\\le \\textrm{P}(D) = 0.47\\). The largest \\(\\textrm{P}(C \\cap D)\\) can be is 0.25, and hence the smallest \\(\\textrm{P}(C\\cup D)\\) can be is 0.47, which would only be true if every household that has a pet cat also has a pet dog.\nTell Donny to check the axioms of probability. There is no requirement that the probability of an intersection must be the product of the probabilities. The two previous parts show that \\(0\\le \\textrm{P}(C \\cap D) \\le 0.25\\), but without further information we can’t determine the value of \\(\\textrm{P}(C\\cap D)\\). We discussed this idea in Example 1.15, and we will explore probabilities of intersections in more detail later.\n\\(\\textrm{P}(C \\cup D) = \\textrm{P}(C) + \\textrm{P}(D) - \\textrm{P}(C \\cap D) = 0.25 + 0.47 - 0.14 = 0.58.\\) Notice that this is between the logical extremes of 0.47 and 0.72. Also notice that the actual \\(\\textrm{P}(C \\cap D)\\) is between the logical extremes of 0 and 0.25, but it is not equal to the product of 0.25 and 0.47. The moral is that we are not able to compute probabilities involving both events (\\(\\textrm{P}(C\\cup D)\\), \\(\\textrm{P}(C^c \\cap D\\))) based on the probability of each event alone.\nThe law of total probability implies that \\(\\textrm{P}(D) = \\textrm{P}(D \\cap C) + \\textrm{P}(D \\cap C^c)\\) so \\(\\textrm{P}(D \\cap C^c) = \\textrm{P}(D) - \\textrm{P}(D \\cap C) = 0.47 - 0.14 = 0.33\\). This might look complicated, but all it says is that we can add across and down in the two-way table. A household either has a cat or not (the two cases, \\(C, C^c\\)); if 14% of households have both a dog and a cat and 33% of households have a dog but no cat, then 47% of households have a dog.\n\n\n\n\n\nProbabilities involving multiple events, such as \\(\\textrm{P}(A \\cap B)\\) or \\(\\textrm{P}(X&gt;80, Y&lt;2)\\), are often called joint probabilities. Note that the axioms do not specify any direct requirements on probabilities of intersections. In particular, is not necessarily true that \\(\\textrm{P}(A\\cap B)\\) equals \\(\\textrm{P}(A)\\textrm{P}(B)\\). It is true that probabilities of intersections can be obtained by multiplying, but the product generally involves at least one conditional probability that reflects any association between the events involved. In general, joint probabilities (\\(\\textrm{P}(A \\cap B)\\)) can not be computed based on the individual probabilities (\\(\\textrm{P}(A)\\), \\(\\textrm{P}(B)\\)) alone. We will explore this topic in more depth later.\n\n\n2.4.5 Probability models\nA probability model (or probability space) puts all the objects we have seen so far in this chapter together in a model for the random phenomenon. Think of a probability model31 as the collection of all outcomes, events, and random variables associated with a random phenomenon along with the probabilities of all events of interest (and distributions of random variables) under the assumptions of the model.\nThere will be many probability measures that satisfy the logical consistency requirements of the probability axioms. Which one is most appropriate depends on the assumptions about the random phenomenon. We will study a variety of commonly used probability models throughout the book.\nPerhaps the concept of multiple potential probability measures is easier to understand in a subjective probability situation. For example, each model that is used to forecast the 2024-2025 NFL season corresponds to a probability measure which assigns probabilities to events like “the Eagles win the 2025 Superbowl”. Different sets of assumptions and models can assign different probabilities for the same events. As another example, the weather forecaster on one local news station might report that the probability of rain tomorrow is 0.6, while an online source might report it as 0.5. Each weather forecasting model corresponds to a different probability measure which encodes a set of assumptions about the random phenomenon.\nBefore moving on, we want to reiterate: Most random phenomenon do not involve equally likely outcomes or uniform probability measures. Even when the underlying outcomes are equally likely, the values of related random variables are usually not. Equally like outcomes or uniform probability measures are the simplest probability measures, and therefore are the ones we typically encounter first. But don’t let that fool you; most interesting probability problems involve non-equally likely outcomes or non-uniform probability measures.\nIt’s easy to get confused between things like events, random variables, and probabilities, and the symbols that represent them. But a strong understanding of these fundamental concepts will help you solve probability problems. Examples like the following do more than encourage proper use of notation. Explaining to Donny why he is wrong will help you better understand the objects that symbols represent, how they are different from one another, and how they connect to real-world contexts.\n\n\n\n\n\n\n\nExample 2.40 At various points in his homework, Donny Don’t writes the following. Explain to Donny why each of the following symbols is nonsense, both mathematically and intuitively using a simple example (like tomorrow’s weather). Try to guess what Donny intends to say, and help him write it properly. Below, \\(A\\) and \\(B\\) represent events, \\(X\\) and \\(Y\\) represent random variables.\n\n\\(\\textrm{P}(A = 0.5)\\)\n\\(\\textrm{P}(A + B)\\)\n\\(\\textrm{P}(A) \\cup \\textrm{P}(B)\\)\n\\(\\textrm{P}(X)\\)\n\\(\\textrm{P}(X = A)\\)\n\\(\\textrm{P}(X \\cap Y)\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.40. We’ll respond to Donny using tomorrow’s weather as an example, with \\(A\\) representing the event that it rains tomorrow, \\(X\\) tomorrow’s high temperature (degrees F), \\(B=\\{X&gt;80\\}\\) the event that tomorrow’s high temperature is above 80 degrees, and \\(Y\\) tomorrow’s rainfall (inches).\n\n\\(A\\) is a set and 0.5 is a number; it doesn’t make mathematical sense to equate them. It doesn’t make sense to say “it rains tomorrow equals 0.5”. Donny probably means “the probability that it rains tomorrow equals 0.5” which he should write as \\(\\textrm{P}(A) = 0.5\\).\n\\(A\\) and \\(B\\) are sets; it doesn’t make mathematical sense to add them. The symbol \\(A + B\\) would represent “it rains tomorrow plus tomorrow’s high temperature is above 80 degrees F,” where “plus” literally means addition. Donny might mean “the probability that (it rains tomorrow) or (tomorrow’s high temperature is above 80 degrees),” which he should write as \\(\\textrm{P}(A \\cup B)\\). Donny might have meant to write \\(\\textrm{P}(A) + \\textrm{P}(B)\\), which is valid expression since \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) are numbers. However, he should keep in mind that \\(\\textrm{P}(A) + \\textrm{P}(B)\\) is not necessarily a probability of anything; this sum could even be greater than one. In particular, since there are some rainy days with high temperatures above 80 degrees—that is, \\(A\\) and \\(B\\) are not disjoint—\\(\\textrm{P}(A) + \\textrm{P}(B)\\) is greater than \\(\\textrm{P}(A\\cup B)\\). Donny might also mean “the probability that (it rains tomorrow) and (tomorrow’s high temperature is above 80 degrees),” which he should write as \\(\\textrm{P}(A \\cap B)\\).\n\\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) are numbers; union is an operation on sets, and it doesn’t make mathematical sense to take a union of numbers. See the previous part for related discussion.\n\\(X\\) is a random variable, and probabilities are assigned to events. \\(P(X)\\) reads “the probability that tomorrow’s high temperature in degrees F”, a subject in need of a predicate; the phrase is missing any qualifying information that could define an event. We assign probabilities to things that might happen (events) like “tomorrow’s high temperature is above 80 degrees,” which has probability \\(\\textrm{P}(X &gt; 80)\\).\n\\(X\\) is a random variable (a function) and \\(A\\) is an event (a set), and it doesn’t make sense to equate these two different mathematical objects. It doesn’t make sense to say “tomorrow’s high temperature in degrees F equals the event that it rains tomorrow”. We’re not sure what Donny was thinking here.\n\\(X\\) and \\(Y\\) are random variables (functions) and intersection is an operation on sets. \\(X \\cap Y\\) is attempting to say “tomorrow’s high temperature in degrees F and the amount of rainfall in inches tomorrow”, but this is still missing qualifying information to define a valid event for which a probability can be assigned. We could say \\(\\textrm{P}(X &gt; 80, Y &lt; 2)\\) to represent “the probability that (tomorrow’s high temperature is greater than 80 degrees F) AND (the amount of rainfall tomorrow is less than 2 inches)”. (Remember,“\\(X &gt; 80, Y &lt; 2\\)” is short for the event \\(\\{X &gt; 80\\} \\cap \\{Y &lt; 2\\}\\).) If we want to say something like “we measure tomorrow’s high temperature in degrees F and the amount of rainfall in inches tomorrow” we would write \\((X, Y)\\).\n\n\n\n\n\n\n\n2.4.6 Exercises\n\nExercise 2.8 Consider the matching problem with \\(n=4\\): objects labeled 1, 2, 3, 4, are placed at random in spots labeled 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. Recall the sample space from Table 2.2. Let the random variable \\(X\\) count the number of objects that are put back in the correct spot; recall Table 2.9. Let \\(\\textrm{P}\\) denote the probability measure corresponding to the assumption that the objects are equally likely to be placed in any spot, so that the 24 possible placements are equally.\n\n\nCompute and interpret \\(\\textrm{P}(X=0)\\).\nCompute and interpret \\(\\textrm{P}(X \\ge 1)\\).\nLet \\(C_1\\) be the event that object 1 is put correctly in spot 1. Find \\(\\textrm{P}(C_1)\\).\nLet \\(C_2\\) be the event that object 2 is put correctly in spot 2. Find \\(\\textrm{P}(C_2)\\).\nDefine \\(C_3\\), and \\(C_4\\) similarly. Represent the event \\(\\{X \\ge 1\\}\\) in terms of \\(C_1, C_2, C_3, C_4\\).\nFind and interpret \\(\\textrm{P}(C_1\\cap C_2 \\cap C_3 \\cap C_4)\\).\nDonny Don’t says: \\(\\textrm{P}(C_1 \\cup C_2 \\cup C_3 \\cup C_4)\\) is equal to \\(\\textrm{P}(C_1)+\\textrm{P}(C_2)+\\textrm{P}(C_3)+\\textrm{P}(C_4)\\).” Explain to Donny his mistake.\nDonny Don’t says: “ok, the events are not disjoint so then by the general addition rule \\(\\textrm{P}(C_1 \\cup C_2 \\cup C_3 \\cup C_4)\\) is equal to \\(\\textrm{P}(C_1)+\\textrm{P}(C_2)+\\textrm{P}(C_3)+\\textrm{P}(C_4)-\\textrm{P}(C_1\\cap C_2 \\cap C_3 \\cap C_4)\\).” Explain to Donny his mistake.\n\n\nExercise 2.9 Consider the outcome of a sequence of 4 flips of a coin. Assume that the coin is fair so that all 16 possible outcomes are equally likely, and let \\(\\textrm{P}\\) be the corresponding probability measure. Let \\(X\\) be the number of heads flipped and let \\(Y=4-X\\).\n\nCompute \\(\\textrm{P}(X=1)\\).\nCompute \\(\\textrm{P}(X = x)\\) for each \\(x = 0, 1, 2, 3, 4\\).\nCompute \\(\\textrm{P}(Y=1)\\).\nCompute \\(\\textrm{P}(Y = y)\\) for each \\(y = 0, 1, 2, 3, 4\\).\nCompute \\(\\textrm{P}(X = Y)\\).\n\n\n\nExercise 2.10 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Suppose that each package is equally likely to contain any of the 3 prizes, regardless of the contents of other packages, so that there are 27 equally likely outcomes, and let \\(\\textrm{P}\\) be the corresponding probability measure.\n\nLet \\(A_1\\) be the event that prize 1 is obtained—that is, at least one of the packages contains prize 1—and define \\(A_2, A_3\\) similarly for prize 2, 3.\nLet \\(B_1\\) be the event that only prize 1 is obtained—that is, all three packages contain prize 1—and define \\(B_2, B_3\\) similarly for prize 2, 3.\n\n\nCompute \\(\\textrm{P}(A_1)\\)\nCompute \\(\\textrm{P}(B_1)\\)\nInterpret the values from parts 1 and 2 as long run relative frequencies.\nInterpret the values from parts 1 and 2 as relative likelihoods.\nCompute \\(\\textrm{P}(A_1 \\cap A_2 \\cap A_3)\\)\nCompute \\(\\textrm{P}(A_1 \\cup A_2 \\cup A_3)\\)\nCompute \\(\\textrm{P}(B_1 \\cap B_2 \\cap B_3)\\)\nCompute \\(\\textrm{P}(B_1 \\cup B_2 \\cup B_3)\\)\n\n\n\nExercise 2.11 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Suppose that each package is equally likely to contain any of the 3 prizes, regardless of the contents of other packages, so that there are 27 equally likely outcomes, and let \\(\\textrm{P}\\) be the corresponding probability measure.\nLet \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\nThe sample space consists of 27 outcomes, listed in the table below.\n\n\n\n\n111\n112\n113\n121\n122\n123\n131\n132\n133\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n211\n212\n213\n221\n222\n223\n231\n232\n233\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n311\n312\n313\n321\n322\n323\n331\n332\n333\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompute \\(\\textrm{P}(X = 1)\\).\nCompute \\(\\textrm{P}(X = 2)\\).\nCompute \\(\\textrm{P}(X = 3)\\).\nInterpret the values in parts 1 through 3 as long run relative frequencies.\nInterpret the values in parts 1 through 3 as relative likelihoods.\nCompute \\(\\textrm{P}(Y = y)\\) for each possible value \\(y\\).\nCompute \\(\\textrm{P}(X = 2, Y = 1)\\).\nCompute \\(\\textrm{P}(X = Y)\\).\n\n\n\nExercise 2.12 Katniss throws a dart at a circular dartboard with radius 1 foot. Suppose that the dart lands uniformly at random anywhere on the dartboard, and let \\(\\textrm{P}\\) be the corresponding probability measure.\n\nCompute \\(\\textrm{P}(A)\\), where \\(A\\) is the event that Katniss’s dart lands within 1 inch of the center of the dartboard.\nCompute \\(\\textrm{P}(B)\\), where \\(B\\) is the event that Katniss’s dart lands more than 1 inch but less than 2 inches away from the center of the dartboard.\nCompute \\(\\textrm{P}(E)\\), where \\(E\\) is the event that Katniss’s dart lands within 1 inch of the outside edge of the dartboard.\nInterpret the previous probabilities as long run relative frequencies.\nInterpret the previous probabilities as relative likelihoods.\n\n\n\nExercise 2.13 Katniss throws a dart at a circular dartboard with radius 1 foot. Suppose that the dart lands uniformly at random anywhere on the dartboard, and let \\(\\textrm{P}\\) be the corresponding probability measure.\nLet \\(X\\) be the distance (inches) from the location of the dart to the center of the dartboard.\n\nCompute \\(\\textrm{P}(X \\le 1)\\)\nCompute \\(\\textrm{P}(1 &lt; X &lt; 2)\\)\nCompute \\(\\textrm{P}(X &gt; 11)\\)\n\n\n\nExercise 2.14 Katniss throws a dart at a circular dartboard with radius 1 foot. Suppose that the dart lands uniformly at random anywhere on the dartboard, and let \\(\\textrm{P}\\) be the corresponding probability measure.\nLet \\(X\\) be the distance (inches) from the location of the dart to the center of the dartboard.\n\nCompute \\(\\textrm{P}(X \\le 0.1)\\)\nCompute \\(\\textrm{P}(X \\le 0.01)\\)\nCompute \\(\\textrm{P}(X = 0)\\)\nCompute \\(\\textrm{P}(X \\ge 11.9)\\)\nCompute \\(\\textrm{P}(X \\ge 11.99)\\)\nCompute \\(\\textrm{P}(X = 12)\\)\nWhich is more likely: the dart lands exactly in the center or the darts lands exactly on the edge? Discuss.\nWhich is more likely: the dart lands close to the center or the darts lands close to the edge? Discuss.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-dist-intro",
    "href": "language-probability.html#sec-dist-intro",
    "title": "2  The Language of Probability",
    "section": "2.5 Distributions of random variables (a brief introduction)",
    "text": "2.5 Distributions of random variables (a brief introduction)\nEven when outcomes of a random phenomenon are equally likely, values of related random variable are usually not. The probability distribution of a random variable describes the possible values that the random variable can take and their relative likelihoods or plausibilities. We will see several ways of summarizing and describing distributions throughout the book; this section only provides a brief introduction.\n\n\n\n\n\n\n\nExample 2.41 Roll a four-sided die twice; recall the sample space in Example 2.17 and Table 2.7. One choice of probability measure \\(\\textrm{P}\\) corresponds to assuming that the die is fair and that the 16 possible outcomes are equally likely. Let \\(X\\) be the sum of the two dice, and let \\(Y\\) be the larger of the two rolls (or the common value if both rolls are the same).\n\nCompute \\(\\textrm{P}(E_1)\\), where \\(E_1\\) is the event that the first roll lands on 1.\n\nCompute \\(\\textrm{P}(X = 6)\\).\nInterpret \\(\\textrm{P}(X = 6)\\) as a long run relative frequency.\nInterpret \\(\\textrm{P}(X = 6)\\) as a relative degree of likelihood. (Hint: compare to \\(\\textrm{P}(X \\neq 6)\\).)\nConstruct a table displaying \\(\\textrm{P}(X = x)\\) for each possible value \\(x\\) of \\(X\\), and sketch a corresponding plot.\nConstruct a table displaying \\(\\textrm{P}(Y = y)\\) for each possible value \\(y\\) of \\(Y\\), and sketch a corresponding plot.\nConstruct a table displaying \\(\\textrm{P}(X = x, Y= y)\\) for each possible \\((x, y)\\) pair, and sketch a corresponding plot.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.41. \n\nSince \\(\\textrm{P}\\) corresponds to equally likely outcomes, we simply need to count the number of outcomes that satisfy the event and divide by the total number of outcomes. There are 16 equally likely outcomes, of which 4 satisfy event \\(E_1\\). (Remember, the sample space corresponds to pairs of rolls, and there are 4 pairs for which the first roll is 1.) So \\(\\textrm{P}(E_1) = 4 / 16 = 1/4\\), which makes sense if we’re assuming the die is fair.\nThere are 16 equally likely outcomes, 3 of which satisfy the event that the sum is 6. So \\(\\textrm{P}(X = 6) = 3 / 16 = 0.1875\\).\nOver many pairs of rolls of a fair four-sided die, around 18.75% of pairs will yield a sum of 6.\n\\(\\textrm{P}(X\\neq 6) = 13/16 = 0.8125\\). The ratio of \\(\\textrm{P}(X \\neq 6)\\) to \\(\\textrm{P}(X = 6)\\) is \\(13/3 \\approx 4.3\\). If you roll a fair four-sided die twice, it is 4.3 times more likely for the sum to be something other than 6 than for it to be 6.\nThe possible values of \\(X\\) are \\(2, 3, 4, 5, 6, 7, 8\\). Find the probability of each value by counting the corresponding outcomes using Table 2.7. For example, \\(\\textrm{P}(X = 3) = \\textrm{P}(\\{(1, 2), (2, 1)\\}) = 2/16\\). See Table 2.14. Figure 2.16 displays an “impulse” plot with the possible values of \\(X\\) on the horizontal axis and the corresponding probabilities on the vertical axis.\nThe possible values of \\(Y\\) are \\(1, 2, 3, 4\\). See Table 2.15 and Figure 2.17 for probabilities. For example, \\(\\textrm{P}(Y = 3) = \\textrm{P}(\\{(1, 3), (2, 3), (3, 1), (3, 2), (3, 3)\\}) = 5/16\\).\nSimilar to the previous parts, we can first construct a table with each row corresponding to a possible \\((X, Y)\\) pair, and then find the probabilities of the corresponding outcomes. For example, there are two pairs of rolls that result in \\(X=4\\) and \\(Y=3\\)—\\((1, 3), (3,1)\\)—so \\(\\textrm{P}((X, Y) = (4, 3))=\\textrm{P}(X = 4, Y=3) = \\textrm{P}(\\{(1, 3), (3, 1)\\}) = 2/16\\). See Table 2.16 for probabilities. Table 2.17 reorganizes Table 2.16 into a two-way table with rows corresponding to possible values of \\(X\\) and columns corresponding to possible values of \\(Y\\). Figure 2.18 displays the distribution of \\((X, Y)\\) pairs in a 3d impulse plot, and Figure 2.19 displays the distribution in a “tile” plot where lighter colors represent larger probabilities.\n\n\n\n\n\n\n\n\n\nTable 2.14: The marginal distribution of \\(X\\), the sum of two rolls of a fair four-sided die.\n\n\n\n\n\n\nx\nP(X=x)\n\n\n\n\n2\n0.0625\n\n\n3\n0.1250\n\n\n4\n0.1875\n\n\n5\n0.2500\n\n\n6\n0.1875\n\n\n7\n0.1250\n\n\n8\n0.0625\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.16: The marginal distribution of \\(X\\), the sum of two rolls of a fair four-sided die.\n\n\n\n\n\n\n\n\n\nTable 2.15: The marginal distribution of \\(Y\\), the larger (or common value if a tie) of two rolls of a fair four-sided die.\n\n\n\n\n\n\ny\nP(Y=y)\n\n\n\n\n1\n0.0625\n\n\n2\n0.1875\n\n\n3\n0.3125\n\n\n4\n0.4375\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.17: The marginal distribution of \\(Y\\), the larger (or common value if a tie) of two rolls of a fair four-sided die.\n\n\n\n\n\n\n\n\n\nTable 2.16: Table representing the joint distribution of sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die\n\n\n\n\n\n\n(x, y)\nP(X = x, Y = y)\n\n\n\n\n(2, 1)\n0.0625\n\n\n(3, 2)\n0.1250\n\n\n(4, 2)\n0.0625\n\n\n(4, 3)\n0.1250\n\n\n(5, 3)\n0.1250\n\n\n(5, 4)\n0.1250\n\n\n(6, 3)\n0.0625\n\n\n(6, 4)\n0.1250\n\n\n(7, 4)\n0.1250\n\n\n(8, 4)\n0.0625\n\n\n\n\n\n\n\n\n\n\n\nTable 2.17: Two-way table representation of the joint distribution of \\(X\\) and \\(Y\\), the sum and the larger (or common value if a tie) of two rolls of a fair four-sided die. Possible values of \\(X\\) are in the leftmost column; possible values of \\(Y\\) are in the top row.\n\n\n\n\n\n\\(x\\) \\ \\(y\\)\n1\n2\n3\n4\n\n\n2\n1/16\n0\n0\n0\n\n\n3\n0\n2/16\n0\n0\n\n\n4\n0\n1/16\n2/16\n0\n\n\n5\n0\n0\n2/16\n2/16\n\n\n6\n0\n0\n1/16\n2/16\n\n\n7\n0\n0\n0\n2/16\n\n\n8\n0\n0\n0\n1/16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.18: 3D Impulse plot representing the joint distribution of the sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.19: Tile plot representing the joint distribution of the sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die.\n\n\n\n\n\nThe above tables and plots represent the joint and marginal distributions of the random variables \\(X\\) and \\(Y\\) in Example 2.41 according to the probability measure \\(\\textrm{P}\\), which reflects the assumption that the die is fair and the rolls are independent.\nTable 2.17, Table 2.16, Figure 2.18 and Figure 2.19 represent the joint distribution of the sum and larger of two rolls of a fair four-sided die.. The joint distribution of two random variables summarizes the possible pairs of values and their relative likelihoods or plausibilities.\nIn the context of multiple random variables, the distribution of any one of the random variables is called a marginal distribution. Table 2.14 and Figure 2.16 represent the marginal distribution of the sum and larger of two rolls of a fair four-sided die. Table 2.15 and Figure 2.17 represent the marginal distribution of the larger of two rolls of a fair four-sided die.\n\n\n\n\n\n\n\nExample 2.42 Continuing Example 2.41, suppose that instead of a fair die, the weighted die in Example 2.29 is rolled twice. Answer the following without doing any computations.\n\nAre the possible values of \\(X\\) the same as in Table 2.14? Is the distribution of \\(X\\) the same as in Table 2.14?\nAre the possible values of \\((X, Y)\\) the same as in Table 2.16? Is the joint distribution of \\((X, Y)\\) the same as in Table 2.16?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.42. In both parts, the possible values are the same. There are still 16 possible outcomes and the random variables are still measuring the same quantities as before. But the distributions are all different. With the weighted die some outcomes are more or less likely than others, and some values of the random variables are more or less likely than when the die is fair. For example, the probabilities of the events \\(\\{X = 8\\}\\), \\(\\{Y=4\\}\\), and \\(\\{X = 8, Y=4\\}\\) are larger with the weighted die than with the fair die, because each roll of the weighted die is more likely to result in a 4 than the fair die.\n\n\n\n\nDistributions of random variables depend on the underlying probability measure. Changing the probability measure can change distributions.\nIn Example 2.41, we first specified the probability space of 16 equally likely outcomes then derived the distribution. However, in many problems we often assume or identify distributions directly, without any mention of the underlying sample space or probability measure. Recall the brown bag analogy in Section 2.3.2. The probability space corresponds to the random selection of fruits to put in the bag. The random variable is weight. The distribution of weight can be obtained by randomly selecting fruits to put in the bag, weighing the bag, and then repeating this process many times to observe many weights. For example, maybe 10% of bags have weights less than 5 pounds, 75% of bags have weights less than 20 pounds, etc. We can observe the distribution of weights even if we don’t observe the actual fruits in the bag or fully specify the random phenomenon and its sample space.\nExample 2.41 involved two discrete random variables. We will introduce distributions of continuous random variables later.\n\n2.5.1 Marginal distributions do not determine the joint distribution\nIn Example 2.41, we can obtain the marginal distributions from the joint distribution by summing rows and columns: think of adding a total column (for \\(X\\)) and a total row (for \\(Y\\)) in the “margins” of the table. It is always possible to obtain marginal distributions of the random variables in a collection from their joint distribution. However, in general the marginal distributions alone are not enough to determine the joint distribution.\n\n\n\n\n\n\n\nExample 2.43 Suppose \\(X\\) and \\(Y\\) are random variables whose joint distribution is represented by Table 2.18.\n\nFind the marginal distribution of \\(X\\).\nFind the marginal distribution of \\(Y\\).\nAre the marginal distributions of \\(X\\) and \\(Y\\) in this example the same as those in Example 2.41?\nIs the joint distribution of \\(X\\) and \\(Y\\) the same as the one in Example 2.41?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.43. \n\nThe possible values of \\(X\\) are 2, 3, 4, 5, 6, 7, 8. Add a total column to the joint distribution table to find the probabilities of each possible \\(x\\) value, which are, respectively, 16/256, 32/356, 42/256, 64/256, 42/256, 32/356, 16/256, or 1/16, 2/16, 3/16, 4/16, 3/16, 2/16, 1/16.\nThe possible values of \\(Y\\) are 1, 2, 3, 4. Add a total row to the joint distribution table to find the probabilities of each possible \\(y\\) value, which are, respectively, 16/256, 48/356, 80/256, 112/256, or 1/16, 3/16, 5/16, 7/16.\nYes, the marginal distributions of \\(X\\) and \\(Y\\) are the same as in Example 2.41, represented by Table 2.14 and Table 2.15.\nNo, this is a different joint distribution than the one in Table 2.17. For example, in Table 2.17 some of the \\((X, Y)\\) pairs aren’t even possible, but the joint distribution in Table 2.18 assigns positive probability to all \\((X, Y)\\) pairs.\n\n\n\n\n\n\n\n\nTable 2.18: The joint distribution for Example 2.43\n\n\n\n\n\n\\(x\\) \\ \\(y\\)\n1\n2\n3\n4\n\n\n2\n1/256\n3/256\n5/256\n7/256\n\n\n3\n2/256\n6/256\n10/256\n14/256\n\n\n4\n3/256\n9/256\n15/256\n21/256\n\n\n5\n4/256\n12/256\n20/256\n28/256\n\n\n6\n3/256\n9/256\n15/256\n21/256\n\n\n7\n2/256\n6/256\n10/256\n14/256\n\n\n8\n1/256\n3/256\n5/256\n7/256\n\n\n\n\n\n\nTable 2.17 and Table 2.18 provide an illustration of two different joint distributons with the same marginal distributions. When representing the joint distribution of two discrete random variables in a table, just because you know the row and column totals doesn’t mean you know all the values of the interior cells.\nA joint distribution represents all of the probabilistic behavior of a collection of random variables. It is always possible to obtain marginal distributions of the random variables in a collection from their joint distribution.\nHowever, in general you cannot determine the joint distribution based on the marginal distributions alone. Marginal distributions only reflect how each random variable behaves in isolation. The joint distribution goes further and fully represents relationships between the random variables. Just because you know how each random variable behaves individually, you don’t necessarily know how they behave in relationship with each other.\n\n\n\n\n\n\nWarning\n\n\n\nIn general, marginal distributions alone are not enough to determine a joint distribution.\n\n\nThe exception to this warning is when random variables are independent, which we’ll discuss later. But you shouldn’t simply assume random variables are independent without sufficient justification.\n\n\n2.5.2 Interpretations of distributions\nDistributions can be thought of as collections of probabilities of events involving random variables. As for probabilities, we can interpret probability distributions of random variables as:\n\nlong run relative frequency distributions: what pattern of values would emerge if we repeated the random process many times and observed many values of the random variables?\n\nsubjective probability distributions: which potential values of these uncertain quantities are relatively more plausible than others?\n\nThe long run relative frequency interpretation is natural for Example 2.41. We can roll a pair of fair four-sided dice and measure the sum of the rolls and the larger of the rolls. If we repeat this process many times, we would expect about 6.25% of repetitions to result in a sum of 2, 12.5% of repetitions to result in a sum of 3, 6.25% of repetitions to result in a larger roll of 1, 18.75% of repetitions to result in a larger roll of 3, 6.25% of repetitions to result in both a sum of 2 and a larger roll of 1, 12.5% of repetitions to result in both a sum of 3 and a larger roll of 2, etc. If we summarize the results of many repetitions—which we will do in the next chapter—we would expect the patterns to look like those in the tables and plots in this section.\nIn other situations the subjective distribution interpretation is more natural. For example, the total number of points scored in the next Superbowl will be one and only one number, but since we don’t know what that number is we can treat it as a random variable. Treating the number of points as a random variable allows us to quantify our uncertainty about it through probability statements like “there is a 0.6 probability that at most 45 points will be scored in the next Superbowl”. A subjective probability distribution for the number of points describes which possible values are relatively more plausible than others.\nAs with probabilities, the mathematics of distributions work the same way regardless of which interpretation is used, so we will use the two interpretations interchangeably.\n\n\n2.5.3 Expected value\nThe distribution of a random variable specifies its possible values and the probability of any event that involves the random variable. It is also useful to summarize some key features of a distribution. Recall that in Section 1.7 we introduced the idea of a “probability-weighted average value”. We also saw how this value can be interpreted as a “long run average value”.\n\n\n\n\n\n\n\nExample 2.44 Continuing Example 2.41, recall the marginal distributions of \\(X\\) and \\(Y\\) from Table 2.14 and Table 2.15.\n\nCompute the probability-weighted average value of \\(X\\).\nInterpret the value from the previous part as a long run average value in context.\nCompute the probability-weighted average value of \\(Y\\).\nCompute the probability that \\(Y\\) is equal to the value from the previous part.\nIs the value from part 3 the value we would expect for \\(Y\\) when we roll the dice? If not, explain in what sense the value from part 3 is “expected”.\nSuppose that instead of rolling a fair die we rolled the weighted die from Example 2.29) represented by the spinner Figure 2.9 (b). How would the probability-weighted average values of \\(X\\) and \\(Y\\) for the weighted die relate to those for the fair die?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.44. \n\nMultiply each possible of \\(X\\) by its probability and sum \\[\n\\small{\n2\\times 0.0625 + 3 \\times 0.1250 + 4 \\times 0.1875 + 5 \\times 0.2500 + 6 \\times 0.1875 + 7 \\times 0.1250 + 8 \\times 0.0625 = 5\n}\n\\]\nWe can roll a pair of fair four-sided dice and measure the sum of the rolls. If we repeat this process many times and average the values of the sum, we would expect the average to be around 5.\nMultiply each possible of \\(Y\\) by its probability and sum \\[\n1\\times 0.0625 + 3 \\times 0.1875 + 5 \\times 0.3125 + 7 \\times 0.4375  = 3.125\n\\]\n\\(\\textrm{P}(Y = 3.125) = 0\\).\nIt’s not possible for the sum of two rolls of a fair four-sided die to be 3.125, so it’s certainly not expected. Over many pairs of rolls of a fair four-sided die, we would expect the average of the values of the larger roll in the pair to be around 3.125.\nThis weighted die is more likely to return large values than small values so we would expect the long run averages of \\(X\\) and \\(Y\\) to be greater with this weighted die than with the fair die.\n\n\n\n\n\nIn Example 2.44, 5 is the expected value of \\(X\\), denoted \\(\\textrm{E}(X)\\). Likewise, \\(\\textrm{E}(Y) = 3.125\\). As we discussed in Section 1.7 the term “expected value” is somewhat of a misnomer. The expected value of \\(X\\) is not necessarily the value of \\(X\\) we expect to see when the random phenomenon is observed, but rather the value of \\(X\\) we would expect to see on average in the long run over many observations of the random phenomenon.\nThe distribution of a random variable and hence its expected value depend on the probability measure. If the probability measure changes (e.g., from representing a fair die to a weighted die) then distributions and expected values of random variables can change.\nExample 2.44 involved two discrete random variables. We will introduce expected values of continuous random variables later.\nExpected value is just one feature of a distribution. We are also interested in other features, such as percentiles or the overall degree of variability. Usually there are multiple random variables of interest and we are interested in summarizing relationships between them. We will explore distributions of random variables and related concepts such as expected value, variance, and correlation in much more detail in the remaining chapters.\n\n\n2.5.4 Exercises\n\nExercise 2.15 Consider the matching problem with \\(n=4\\): objects labeled 1, 2, 3, 4, are placed at random in spots labeled 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. Recall the sample space from Table 2.2. Let the random variable \\(X\\) count the number of objects that are put back in the correct spot; recall Table 2.9. Let \\(\\textrm{P}\\) denote the probability measure corresponding to the assumption that the objects are equally likely to be placed in any spot, so that the 24 possible placements are equally.\n\n\nFind the distribution of \\(X\\) by creating an appropriate table and plot.\nFind the probability-weighted average value of \\(X\\).\nIs the value from part 2 the most likely value of \\(X\\)? Explain.\nIs the value from part 2 the value that we would “expect” to see for \\(X\\) in a single repetition of the phenomenon? Explain.\nExplain in what sense the value from part 2 is “expected”.\n\n\nExercise 2.16 Continuing Exercise 2.6.\nThe latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1. Suppose that each package is equally likely to contain any of the 3 prizes, regardless of the contents of other packages. There are 27 possible, equally likely outcomes\n\nConstruct a two-way table representing the joint distribution of \\(X\\) and \\(Y\\).\nSketch a plot representing the joint distribution of \\(X\\) and \\(Y\\).\nIdentify the marginal distribution of \\(X\\), and sketch a plot of it.\nIdentify the marginal distribution of \\(Y\\), and sketch a plot of it.\nCompute and interpret \\(\\text{E}(X)\\).\nCompute and interpret \\(\\text{E}(Y)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-cond",
    "href": "language-probability.html#sec-cond",
    "title": "2  The Language of Probability",
    "section": "2.6 Conditioning",
    "text": "2.6 Conditioning\nAll probabilities are conditional on some information. Conditioning concerns how probabilities of events or distributions of random variables are influenced by information about the occurrence of events or the values of random variables. We discussed some ideas related to conditioning in Section 1.5. This section—really a chapter within a chapter—explores conditioning in more detail, introducing some of the notation and math.\n\n2.6.1 Conditional probability\nA probability quantifies the likelihood or degree of uncertainty of an event. A conditional probability revises this value to reflect any newly available information about the outcome of the underlying random phenomenon.\n\n\n\n\n\n\n\nExample 2.45 The probability32 that a randomly selected American adult (18+) uses Snapchat is 0.24.\n\nSuppose the randomly selected adult is age 18-29. Do you think the probability that a randomly selected adult who is age 18-29 uses Snapchat is 0.24? What if the adult is age 65+? Explain.\nThe probability33 that a randomly selected American adult is age 18-29 is 0.20. Is the probability that a randomly selected American adult both (1) is age 18-29, and (2) uses Snapchat equal to \\(0.20\\times 0.24\\)? Explain.\nWithout further information, provide a range of “logically possible” values for the probability in the previous part. (“Logically possible” means they satisfy the rules of probability, even though they might not be realistic in context.)\nSuppose that the probability that a randomly selected American adult both is age 18-29 and uses Snapchat is 0.13. Construct an appropriate two-way table.\nFind the probability that a randomly selected American adult who is age 18-29 uses Snapchat.\nHow can the probability in the previous part be written in terms of the probabilities provided earlier?\nFind the probability that a randomly selected American adult who uses Snapchat is age 18-29.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.45. \n\nThe value 0.24 represents adults of all ages (18+). We might expect Snapchat use to vary with age, with younger adults more likely to use Snapchat than older adults. We might expect the probability that a randomly selected adult who is age 18-29 uses Snapchat to be greater than 0.24, while the probability that a randomly selected adult who is age 65+ uses Snapchat to be less than 0.24.\nNo. This would only be true if the probability that a randomly selected adult who is age 18-29 uses Snapchat is 0.24. But as we mentioned in the previous part we expect this probability to be greater than 0.24.\nWe could make a table like in the following part and see what values produce valid tables. If \\(A\\) is the event that the selected adult is age 18-29, \\(C\\) is the event that the selected adult uses Snapchat, and \\(\\textrm{P}\\) corresponds to randomly selecting an American adult, then \\(\\textrm{P}(A) = 0.20\\) and \\(\\textrm{P}(C) = 0.24\\). By the subset rule \\(\\textrm{P}(A\\cap C)\\le \\min(\\textrm{P}(A), \\textrm{P}(C)) = 0.20\\). The largest \\(\\textrm{P}(A\\cap C)\\) can be is 0.20, which corresponds to all adults age 18-29 using Snapchat. The smallest \\(\\textrm{P}(A \\cap C)\\) can be is 0, which corresponds to no adults age 18-29 using Snapchat. The extremes are not realistic, but without knowing more information, we do not know where \\(\\textrm{P}(A\\cap C)\\) lies in \\(0\\le \\textrm{P}(A \\cap C) \\le 0.20\\).\n\nIf \\(\\textrm{P}(A \\cap C)= 0.13\\), then the two-way table of probabilities34 is\n\n\n\n\n\\(A\\)\n\\(A^c\\)\nTotal\n\n\n\n\n\\(C\\)\n0.13\n0.11\n0.24\n\n\n\\(C^c\\)\n0.07\n0.69\n0.76\n\n\nTotal\n0.20\n0.80\n1.00\n\n\n\n\\(\\frac{0.13}{0.20}=0.65\\) is the probability that a randomly selected American adult who is age 18-29 uses Snapchat. Imagine a group of 100 hypothetical adults; we would expect 20 to be age 18-29 of whom 13 use Snapchat, so 65% of adults age 18-29 use Snapchat.\n\\(0.65= \\frac{0.13}{0.20}=\\frac{\\textrm{P}(A\\cap C)}{\\textrm{P}(A)}\\). The probability that a randomly selected American adult who is age 18-29 uses Snapchat is the probability that an adult both uses Snapchat and is age 18-29 divided by the probability that an adult is age 18-29.\nThe probability that a randomly selected American adult who uses Snapchat is age 18-29 is \\(\\frac{\\textrm{P}(A\\cap C)}{\\textrm{P}(C)} = \\frac{0.13}{0.24} = 0.5417\\). Note that the numerator is the same as in the previous part but now the denominator is the probability that an adult uses Snapchat. Imagine a group of 100 hypothetical adults; we would expect 24 to use Snapchat of whom 13 are age 18-29, so 54.17% of adults who use Snapchat are age 18-29.\n\n\n\n\n\n\nDefinition 2.7 The conditional probability of event \\(A\\) given event \\(B\\), denoted \\(\\textrm{P}(A|B)\\), is defined as (provided35 \\(\\textrm{P}(B)&gt;0\\)):\n\n\\[\n\\textrm{P}(A|B) = \\frac{\\textrm{P}(A\\cap B)}{\\textrm{P}(B)}\n\\]\nThe conditional probability \\(\\textrm{P}(A|B)\\) represents the likelihood, plausibility, or degree of uncertainty of event \\(A\\) reflecting information that event \\(B\\) has occurred. The event to the left of the vertical bar, \\(A\\) in \\(\\textrm{P}(A|B)\\), is the event we are evaluating the probability of. The unconditional probability \\(\\textrm{P}(A)\\) is often called the prior probability (a.k.a., base rate) of \\(A\\) (prior to observing \\(B\\)). The event to the right of the vertical bar, \\(B\\) in \\(\\textrm{P}(A|B)\\), is the event being conditioned on—how does the probability of \\(A\\) change given that event \\(B\\) occurs? The conditional probability \\(\\textrm{P}(A|B)\\) is the posterior probability of \\(A\\) after observing \\(B\\). Read the vertical bar \\(|\\) in \\(\\textrm{P}(A | B)\\) as “given”.\nIn Example 2.45, \\(\\textrm{P}(C|A) = 0.65\\) is the conditional probability that an adult uses Snapchat given that they are age 18-29, and \\(\\textrm{P}(A|C) = 0.5417\\) is the conditional probability that an adult is age 18-29 given that they use Snapchat.\nAll of the ideas from Section 1.5 still apply. We’ll remind you of a few, using our new notation. Remember that, in general, knowing whether or not event \\(B\\) occurs influences the probability of event \\(A\\); that is, \\[\n\\text{In general, } \\textrm{P}(A|B) \\neq \\textrm{P}(A)\n\\] Also remember that order is essential in conditioning; that is, \\[\n\\text{In general, } \\textrm{P}(A|B) \\neq \\textrm{P}(B|A)\n\\] Lastly, remember to always ask “probability of what?” Thinking of a conditional probability as a fraction, the event being conditioned on identifies the total/baseline group which corresponds to the denominator.\n\n\n2.6.2 Joint, conditional, and marginal probabilities\nWhen dealing with multiple events, probabilities can be joint, conditional, or marginal. In the context of two events \\(A\\) and \\(B\\):\n\nJoint: unconditional probability involving both events, \\(\\textrm{P}(A \\cap B)\\).\nConditional: conditional probability of one event given the other, \\(\\textrm{P}(A | B)\\), \\(\\textrm{P}(B | A)\\).\nMarginal: unconditional probability of a single event \\(\\textrm{P}(A)\\), \\(\\textrm{P}(B)\\).\n\nThe relationship \\(\\textrm{P}(A|B) = \\textrm{P}(A\\cap B)/\\textrm{P}(B)\\) can be stated generically as \\[\n\\text{conditional} = \\frac{\\text{joint}}{\\text{marginal}}\n\\] We will see several versions of this general relationship in the remaining chapters.\nIn Example 2.45, we were provided the marginal probabilities (\\(\\textrm{P}(A) = 0.20\\), \\(\\textrm{P}(C) = 0.24\\)) and a joint probability (\\(\\textrm{P}(A \\cap C) = 0.13\\)) and we computed conditional probabilities (\\(\\textrm{P}(C|A) = 0.65\\), \\(\\textrm{P}(A|C) = 0.5417\\)). In many problems some conditional probabilities are provided or can be determined directly.\n\n\n\n\n\n\n\nExample 2.46 Continuing Example 2.45, suppose that\n\n65% of American adults age 18-29 use Snapchat\n24% of American adults age 30-49 use Snapchat\n12% of American adults age 50-64 use Snapchat\n2% of American adults age 65+ use Snapchat\n\nAlso suppose that\n\n20% of American adults are age 18-29\n33% of American adults are age 30-49\n25% of American adults are age 50-64\n22% of American adults are age 65+\n\n\nIf the probability measure \\(\\textrm{P}\\) corresponds to randomly selecting an American adult, write all the percentages above as probabilities using proper notation.\nCompute and identify with proper notation the probability that a randomly selected American adult is age 18-29 and uses Snapchat.\nCompute and identify with proper notation the probability that a randomly selected American adult is age 30-49 and does not use Snapchat.\nCompute an appropriate two-way table.\nCompute and identify with proper notation the probability that a randomly selected American adult uses Snapchat.\nCompute and identify with proper notation the probability that a randomly selected American adult is age 18-29 given that they use Snapchat.\nRepeat the previous part for each of the age groups. How do the conditional probabilities that the selected adult is in each group given that they use Snapchat compare to the prior probabilities?\nNow suppose the randomly selected adult does not use Snapchat. Compute the conditional probability that the selected adult is in age group. How do the conditional probabilities compare to the prior probabilities?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.46. \n\nLet \\(C\\) denote the event that the selected adult uses Snapchat, and let \\(A_1\\), \\(A_2\\), \\(A_3\\), \\(A_4\\) denote the events that the selected adult is in the age group 18-29, 30-49, 50-64, 65+, respectively. Then the marginal probabilities that the selected adult is in each age group are \\[\\begin{align*}\n\\textrm{P}(A_1) & = 0.20\\\\\n\\textrm{P}(A_2) & = 0.33\\\\\n\\textrm{P}(A_3) & = 0.25\\\\\n\\textrm{P}(A_4) & = 0.22\n\\end{align*}\\] The conditional probabilities that the selected adult uses Snapchat given that the adult is in each of the age groups are \\[\\begin{align*}\n\\textrm{P}(C|A_1) & = 0.65\\\\\n\\textrm{P}(C|A_2) & = 0.24\\\\\n\\textrm{P}(C|A_3) & = 0.12\\\\\n\\textrm{P}(C|A_4) & = 0.02\n\\end{align*}\\]\n\\(\\textrm{P}(C|A_1) = \\frac{\\textrm{P}(A_1 \\cap C)}{\\textrm{P}(A_1)}\\) so \\(\\textrm{P}(A_1 \\cap C) = \\textrm{P}(C|A_1)\\textrm{P}(A_1) = 0.65\\times 0.20 = 0.13\\) is the probability that a randomly selected American adult is age 18-29 and uses Snapchat. (This value was provided to us directly in Example 2.45.)\n\\(\\textrm{P}(C^c|A_2) = 1 - \\textrm{P}(C|A_2) = 1 - 0.24 = 0.76\\) is the probability that the selected adult does not use Snapchat given that they are in the 30-49 age group. Then \\(\\textrm{P}(A_2 \\cap C^c) = \\textrm{P}(C^c|A_2)\\textrm{P}(A_2) = 0.76 \\times 0.33 = 0.2508\\) is the probability that a randomly selected American adult is age 30-49 and does not use Snapchat.\nMultiply as in the previous parts to complete the table.\n\n\n\n\n\n\n\n\n\n\n\\(C\\) (uses Snapchat)\n\\(C^c\\) (does not use Snapchat)\nTotal\n\n\n\n\n\\(A_1\\) (age 18-29)\n0.1300\n0.0700\n0.2000\n\n\n\\(A_2\\) (age 30-49)\n0.0792\n0.2508\n0.3300\n\n\n\\(A_3\\) (age 50-64)\n0.0300\n0.2200\n0.2500\n\n\n\\(A_4\\) (age 65+)\n0.0044\n0.2156\n0.2200\n\n\nTotal\n0.2436\n0.7564\n1.0000\n\n\n\n\\(\\textrm{P}(C) = 0.2436\\) is the marginal probability36 that a randomly selected American adult uses Snapchat. We will discuss this value in further detail below.\n\\(\\textrm{P}(A_1|C) = \\frac{0.13}{0.2436} = 0.5337\\) is the conditional probability37 that a randomly selected American adult is age 18-29 given that they use Snapchat.\nCompute38 the conditional probabilities similar to the previous part \\[\\begin{align*}\n\\textrm{P}(A_1|C) & = \\frac{0.1300}{0.2436} = 0.5337\\\\\n\\textrm{P}(A_2|C) & = \\frac{0.0792}{0.2436} = 0.3251\\\\\n\\textrm{P}(A_3|C) & = \\frac{0.0300}{0.2436} = 0.1232\\\\\n\\textrm{P}(A_4|C) & = \\frac{0.0044}{0.2436} = 0.0181\n\\end{align*}\\] Given that the adult uses Snapchat, we see the probability shift towards the younger ages. For example, the posterior probability (0.5337) that the adult is age 18-29 given that they use Snapchat is much greater than the prior probability (0.20), while the posterior probability (0.0181) that the adult is age 65+ given that they use Snapchat is much less than the prior probability (0.22).\nCompute similar to the previous part \\[\\begin{align*}\n\\textrm{P}(A_1|C^c) & = \\frac{0.0700}{0.7564} = 0.0925\\\\\n\\textrm{P}(A_2|C^c) & = \\frac{0.2508}{0.7564} = 0.3316\\\\\n\\textrm{P}(A_3|C^c) & = \\frac{0.2200}{0.7564} = 0.2909\\\\\n\\textrm{P}(A_4|C^c) & = \\frac{0.2156}{0.7564} = 0.2850\n\\end{align*}\\] Given that the adult does not use Snapchat, we see the probability shift towards the older ages. For example, the posterior probability (0.0925) that the adult is age 18-29 given that they do not use Snapchat is less than the prior probability (0.20), while the posterior probability (0.2850) that the adult is age 65+ given that they do not use Snapchat is greater than the prior probability (0.22). However, the shift from prior to posterior given that the adult does not use Snapchat is less dramatic than given that the adult uses Snapchat. See Figure 2.20.\n\n\n\n\n\nA mosaic plot provides a nice visual of joint, marginal, and one-way conditional probabilities. The mosaic plot in Figure 2.20 (a) represents conditioning on age group. The vertical bars represent the conditional probabilities of using/not using Snapchat for each group. The widths of the vertical bars are scaled in proportion to the marginal probabilities for the age groups; the bar for 30-49 is a little wider than the others. The area of each rectangle represents a joint probability; the rectangle for “age 18-29 and uses Snapchat” represents 13% of the total area. The single vertical bar on the right displays the marginal probabilities of using/not using Snapchat.\nFigure 2.20 (b) represents conditioning on Snapchat use. Now the widths of the vertical bars represent the probabilities of using/not using Snapchat, the heights within the bars represent conditional probabilities of each age group given Snapchat use, and the single bar to the right represents the marginal probabilities of age group.\n\n\n\n\n\n\n\n\n\n\n\n(a) Conditioning on age group\n\n\n\n\n\n\n\n\n\n\n\n(b) Conditioning on Snapchat use\n\n\n\n\n\n\n\nFigure 2.20: Mosaic plots for Example 2.46\n\n\n\n\n\n2.6.3 Multiplication rule\nIn Example 2.46 we were given marginal probabilities of age groups and conditional probabilities of Snapchat use given age groups, and we computed joint probabilities. For example:\n\n20% of adults are age 18-29\n65% of adults age 18-29 use Snapchat\nSo 13% of adults are age 18-29 and use Snapchat, \\(0.13 = 0.20\\times 0.65\\).\n\nIn fraction terms,\n\\[\n\\scriptsize{\n\\frac{\\text{adults age 18-29 who use Snapchat}}{\\text{adults}} = \\left(\\frac{\\text{adults age 18-29}}{\\text{adults}}\\right)\\left(\\frac{\\text{adults age 18-29 who use Snapchat}}{\\text{adults age 18-29}}\\right)\n}\n\\]\nThis calculation is an application of the following multiplication rule which we have already applied intuitively in several examples.\n\nLemma 2.6 (Multiplication rule) The probability that two events \\(A\\) and \\(B\\) both occur is\n\n\\[\n\\begin{aligned}\n\\textrm{P}(A \\cap B) & = \\textrm{P}(A|B)\\textrm{P}(B)\\\\\n& = \\textrm{P}(B|A)\\textrm{P}(A)\n\\end{aligned}\n\\]\nThe multiplication rule is just a rearranging of the definition of the conditional probability of one event given another. The multiplication rule says that you should think “multiply” when you see “and”. However, be careful about what you are multiplying: to find a joint probability you need an unconditional probability and an appropriate conditional probability. You can condition either on \\(A\\) or on \\(B\\), provided you have the appropriate marginal probability; often, conditioning one way is easier than the other based on the available information. Be careful: the multiplication rule does not say that \\(\\textrm{P}(A\\cap B)\\) is equal to \\(\\textrm{P}(A)\\textrm{P}(B)\\).\nGenerically, the multiplication rule says \\[\n\\text{joint} = \\text{conditional}\\times\\text{marginal}\n\\] We will see several versions of this general relationship in the remaining chapters.\nThe multiplication rule is useful in situations where conditional probabilities are easier to obtain directly than joint probabilities.\n\n\n\n\n\n\n\nExample 2.47 A standard deck of playing cards has 52 cards, 13 cards (2 through 10, jack, king, queen, ace) in each of 4 suits (hearts, diamonds, clubs, spades). Shuffle a deck and deals cards one at a time without replacement.\n\nCompute the probability that the first card dealt is a heart.\nIf the first card dealt is a heart, determine the conditional probability that the second card is a heart.\nCompute the probability that the first two cards dealt are hearts.\nCompute the probability that the first two cards dealt are hearts and the third card dealt is a diamond.\nShuffle the deck and deal cards one at a time until an ace is dealt, and then stop. Compute the probability that more than 4 cards are dealt. (Hint: consider the first 4 cards dealt.)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.47. \n\nIf the cards are well shuffled, then any of the cards in the deck is equally likely to be the first card dealt. There are 13 hearts out of 52 cards in the deck, so the probability that the first card is a heart is 13/52 = 1/4 = 0.25.\nIf the first card dealt is a heart, there are 51 cards left in the deck, 12 of which are hearts (and all the remaining cards in the deck are equally likely to be the next one drawn). So the conditional probability that the second card is a heart given that the first card is a heart is 12/51 = 0.235.\nUse the multiplication rule: the probability the both cards are hearts is the product of the probability that the first card is a heart and the conditional probability that the second card is a heart given that the first card is a heart, (13/52)(12/51) = 0.0588. If we imagine 132600 repetitions (a convenient choice given these fractions), then we would expect the first card to be a heart in 33150=132600(13/52) repetitions, and among these 33150 repetitions we would expect the second card to be a heart in 7800=33150(12/51) repetitions, so the proportion of repetitions in which both cards are hearts is 7800/132600 = 0.0588.\nThe third card adds a third “stage” but the multiplication rule extends naturally. The probability the first two cards dealt are hearts and the third card dealt is a diamond is (13/52)(12/51)(13/50)= 0.0153, the product of:\n\n13/52, the probability that the first card is a heart,\n12/51, the conditional probability that the second card is a heart given that the first card is a heart, and\n13/50, the conditional probability that the third card is a diamond given that the first two cards are hearts. (If the first two cards are hearts, then there are 50 cards remaining in the deck, of which 13 are diamonds.) Continuing the simulation from the previous part, among the 7800 repetitions in which the first two cards are hearts, we would expect the third card will be a diamond in 2028 = 7800(13/50) repetitions, so the proportion of repetitions in which the first two cards are hearts and the third is a diamond is 2028/132600 = 0.0153.\n\nThe key is to recognize that in this scenario more than 4 cards are needed to obtain the first ace if and only if the first four cards dealt are not aces. The probability that the first 4 cards are not aces is \\((48/52)(47/51)(46/50)(45/49) = 0.719\\).\n\n\n\n\n\nThe multiplication rule extends naturally to more than two events (though the notation gets messy). For three events, we have\n\\[\n\\textrm{P}(A_1 \\cap A_2 \\cap A_3) = \\textrm{P}(A_1)\\textrm{P}(A_2|A_1)\\textrm{P}(A_3|A_1\\cap A_2)\n\\]\nAnd in general, \\[\n\\textrm{P}(A_1\\cap A_2 \\cap A_3 \\cap A_4 \\cap \\cdots) = \\textrm{P}(A_1)\\textrm{P}(A_2|A_1)\\textrm{P}(A_3|A_1\\cap A_2)\\textrm{P}(A_4|A_1\\cap A_2 \\cap A_4)\\cdots\n\\]\nThe multiplication rule is useful for computing probabilities of events that can be broken down into component “stages” where conditional probabilities at each stage are readily available. At each stage, condition on the information about all previous stages.\n\n\n\n\n\n\n\nExample 2.48 The birthday problem concerns the probability that at least two people in a group of \\(n\\) people have the same birthday39. Ignore multiple births and February 29 and assume that the other 365 days are all equally likely40.\n\nIf \\(n=30\\), what do you think the probability that at least two people share a birthday is: 0-20%, 20-40%, 40-60%, 60-80%, 80-100%? How large do you think \\(n\\) needs to be in order for the probability that at least two people share a birthday to be larger than 0.5? Just make your best guesses before proceeding to calculations.\nNow consider \\(n=3\\) people, labeled 1, 2, and 3. What is the probability that persons 1 and 2 have different birthdays?\nWhat is the probability that persons 1, 2, and 3 all have different birthdays given that persons 1 and 2 have different birthdays?\nWhat is the probability that persons 1, 2, and 3 all have different birthdays?\nWhen \\(n = 3\\), what is the probability that at least two people share a birthday?\nNow consider \\(n=4\\). What is the probability that 4 people all have different birthdays?\nWhen \\(n = 4\\), what is the probability that at least two people share a birthday?\nFor \\(n=30\\), compute the probability that none of the people have the same birthday.\nFor \\(n=30\\), compute the probability that at least two people have the same birthday.\nWrite a clearly worded sentence interpreting the probability in the previous part as a long run relative frequency.\nWhen \\(n=30\\), how much more likely than not is it for at least two people to have the same birthday?\nProvide an expression of the probability for a general \\(n\\) and find the smallest value of \\(n\\) for which the probability is over 0.5. (You can just try different values of \\(n\\).)\nWhen \\(n=100\\) the probability is about 0.9999997. If you are in a group of 100 people and no one shares your birthday, should you be surprised? Discuss.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.48. \n\nYour guesses are whatever they are. But many people who have never encountered this problem before say that the probability is 0-20%, and it takes \\(n\\) over at least 100 to get to a probability greater than 0.5.\nWhatever person 1’s birthday is, the probability that person 2 has the same birthday41 is 1/365, so the probability that person 2 has a different birthday than person 1 is 364/365.\nGiven that person 1 and person 2 are born on different days, the probability that person 3 is also born on a different day is 363/365. Notice the importance of the conditioning; if persons 1 and 2 share the same birthday, then the probability that person 3 is born on a different day is 364/365.\nUse the multiplication rule: \\((364/365)(363/365) = 0.992\\), the probability that all three are born on different days, is the product of the probability that persons 1 and 2 are born on different days, and the conditional probability that person 3 is also born on a different day given that the first two are.\nExactly one of the following must be true: (1) all 3 people are born on different days, or (2) at least two people share a birthday. Use the complement rule: when \\(n=3\\), the probability that at least two people share a birthday is \\(1-(364/365)(363/365) = 0.008\\).\nNow consider \\(n=4\\). In order for all 4 people to have different birthdays, the first three people must have different birthdays and the fourth also has to be different from theirs.\n\nThe probability that the first three people have different birthdays is \\((364/365)(363/365)\\) (from a previous part).\nGiven that the first three people have different birthdays, the conditional probability that the fourth person’s birthday is also different is 362/365. Notice the importance of the conditioning; if for example, persons 1 and 2 and 3 all shared the same birthday, then the probability that person 4 is born on a different day is 364/365.\nUsing the multiplication rule, the probability that the first three people have different birthdays and the fourth is also different from theirs is \\((364/365)(363/365)(362/365) = 0.983\\)\n\nExactly one of the following must be true: (1) all 4 people are born on different days, or (2) at least two people share a birthday. Use the complement rule: when \\(n=4\\), the probability that at least two people share a birthday is \\(1-(364/365)(363/365)(362/365) = 0.016\\).\nWe can use the method for \\(n=3\\) and \\(n=4\\). Imagine lining the 30 people up in some order. Let \\(A_2\\) be the event that the first two people have different birthdays, \\(A_3\\) be the event that the first three people have different birthdays, and so on, until \\(A_{30}\\), the event that all 30 people have different birthdays. Notice \\(A_{30}\\subseteq A_{29} \\subseteq \\cdots \\subseteq A_3 \\subseteq A_2\\), so \\(\\textrm{P}(A_{30}) = \\textrm{P}(A_2 \\cap A_3 \\cap \\cdots \\cap A_{30})\\).\n\nThe first person’s birthday can be any one of 365 days. In order for the second person’s birthday to be different, it needs to be on one of the remaining 364 days. So the probability that the second person’s birthday is different from the first is \\(\\textrm{P}(A_2)=\\frac{364}{365}\\).\nNow if the first two people have different birthdays, in order for the third person’s birthday to be different it must be on one of the remaining 363 days. So \\(\\textrm{P}(A_3|A_2) = \\frac{363}{365}\\). Notice that this is a conditional probability. (If the first two people had the same birthday, then the probability that the third person’s birthday is different would be \\(\\frac{364}{365}\\).)\nIf the first three people have different birthdays, in order for the fourth person’s birthday to be different it must be on one of the remaining 362 days. So \\(\\textrm{P}(A_4|A_2\\cap A_3) = \\frac{362}{365}\\).\nAnd so on. If the first 29 people have different birthdays, in order for the 30th person’s birthday to be different it must be on one of the remaining 365-29=336 days. Then using the multiplication rule \\[\\begin{align*}\n\\textrm{P}(A_{30}) & = \\textrm{P}(A_{2}\\cap A_3 \\cap \\cdots \\cap A_{30})\\\\\n& = \\textrm{P}(A_2)\\textrm{P}(A_3|A_2)\\textrm{P}(A_4|A_2\\cap A_3)\\textrm{P}(A_5|A_2\\cap A_3 \\cap A_4)\\cdots \\textrm{P}(A_{30}|A_2\\cap \\cdots \\cap A_{29})\\\\\n& = \\left(\\frac{364}{365}\\right)\\left(\\frac{363}{365}\\right)\\left(\\frac{362}{365}\\right)\\left(\\frac{361}{365}\\right)\\cdots \\left(\\frac{365-30 + 1}{365}\\right)\\approx 0.294\n\\end{align*}\\]\n\n\nBy the complement rule, the probability that at least two people have the same birthday is \\(1-0.294=0.706\\), since either (1) none of the people have the same birthday, or (2) at least two of the people have the same birthday.\nIn about 70% of groups of 30 people at least two people in the group will have the same birthday. For example, if Cal Poly classes all have 30 students, then in about 70% of your classes at least two people in the class will share a birthday.\n\\(0.706 / 0.294 = 2.4.\\) In a group of \\(n=30\\) people it is about 2.4 times more likely to have at least two people with the same birthday than not.\nFor a general \\(n\\), the probability that at least two people have the same birthday is \\[\n1 - \\left(\\frac{364}{365}\\right)\\left(\\frac{363}{365}\\right)\\left(\\frac{362}{365}\\right)\\left(\\frac{361}{365}\\right)\\cdots \\left(\\frac{365-n + 1}{365}\\right)\n\\] See Figure 2.21 which plots this probability as a function of \\(n\\). When \\(n=23\\) this probability is 0.507.\nMaybe, but not because of the 0.999997. 0.999997 is the probability that at least two people in the group of 100 share a birthday. It is NOT the probability that someone shares YOUR birthday. The probability that no one shares your birthday is about \\(0.76\\)—we’ll see how to compute this later—so it’s about 3.1 times more likely than not that someone in a group of 100 people shares your birthday.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.21: Probability of at least one birthday match as a function of the number of people in the room in Example 2.48. For 23 people, the probability of at least one birthday match is 0.507.\n\n\n\n\n\nThat only 23 people are needed to have a better than 50% chance of a birthday match is surprising to many people, because 23 doesn’t seem like a lot of people. But when determining if there is a birthday match, we need to consider every pair of people in the group. In a group of 23 people, there are \\(23(22)/2 = 253\\) different pairs of people, and each one of these pairs has a chance of sharing a birthday.\n\n\n2.6.4 Law of total probability\nThe law of total probability says that a marginal probability can be thought of as a weighted average of “case-by-case” conditional probabilities, where the weights are determined by the likelihood or plausibility of each case.\n\n\n\n\n\n\n\nExample 2.49 Continuing Example 2.46.\n\nDonny Don’t says: “The average of the probabilities of using Snapchat for each age group—0.65, 0.24, 0.12, and 0.02—is 0.2575. Why isn’t \\(\\textrm{P}(C)\\), the probability of using Snapchat equal to 0.2575 (instead of 0.2436)?” Can you answer Donny’s question? (Hint: consider an extreme case; for example, if everyone were age 18-29 what would \\(\\textrm{P}(C)\\) be?)\nShow how \\(\\textrm{P}(C) = 0.2436\\) can be written as a weighted average of the values 0.65, 0.24, 0.12, and 0.02.\nShow how \\(\\textrm{P}(A_1)\\) can be written as a weighted average—what probabilities are being averaged and what are they weights?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.49. \n\nIf all adults were age 18-29 then the overall probability of using Snapchat would be 0.65; if all adults were age 65+ the overall probability of using Snapchat would be 0.02. The overall probability of using Snapchat depends on the age group breakdown. The marginal probabilities of the age groups differ, partly because the age groups cover different numbers of ages.\nWe can write our two-way table calculation of \\(\\textrm{P}(C)\\) in Example 2.46 in formulas as \\[\\begin{align*}\n\\textrm{P}(C) & = \\textrm{P}(C \\cap A_1) + \\textrm{P}(C \\cap A_2) + \\textrm{P}(C \\cap A_3) + \\textrm{P}(C \\cap A_4)\\\\\n& = \\textrm{P}(C|A_1)\\textrm{P}(A_1) + \\textrm{P}(C|A_2)\\textrm{P}(A_2) + \\textrm{P}(C|A_3)\\textrm{P}(A_3) +\\textrm{P}(C|A_4)\\textrm{P}(A_4)\\\\\n& = 0.65\\times 0.20 + 0.24\\times 0.33 + 0.12 \\times 0.25 + 0.02\\times 0.22\\\\\n& = 0.2436\n\\end{align*}\\] The above shows that the overall probability of using Snapchat, \\(\\textrm{P}(C) = 0.2436\\), is a weighted average of the conditional probabilities of using Snapchat for each of the age groups—\\(\\textrm{P}(C|A_1) = 0.65\\), \\(\\textrm{P}(C|A_2) = 0.24\\), \\(\\textrm{P}(C|A_3) = 0.12\\), \\(\\textrm{P}(C|A_4) = 0.02\\)—where the weights are the marginal probabilities of the age groups, \\(\\textrm{P}(A_1) = 0.20\\), \\(\\textrm{P}(A_2) = 0.33\\), \\(\\textrm{P}(A_3) = 0.25\\), \\(\\textrm{P}(A_4) = 0.22\\).\nNow we break down the probability into two cases, using/not using Snapchat. \\[\\begin{align*}\n\\textrm{P}(A_1) & = \\textrm{P}(A_1\\cap C) + \\textrm{P}(A_1 \\cap C^c)\\\\\n& = \\textrm{P}(A_1 | C)\\textrm{P}(C) + \\textrm{P}(A_1 | C^c)\\textrm{P}(C^c)\\\\\n& = 0.5337\\times 0.2436 + 0.0925 \\times (1 - 0.2436)\\\\\n& = 0.20\n\\end{align*}\\] The above shows that the overall probability of being age 18-29, \\(\\textrm{P}(A_1) = 0.20\\), is a weighted average of the conditional probabilities of being age 18-29 for each Snapchat use case—\\(\\textrm{P}(A_1|C) = 0.5337\\), \\(\\textrm{P}(A_1|C^c) = 0.0925\\)—where the weights are the marginal probabilities of the Snapchat use cases, \\(\\textrm{P}(C) = 0.2436\\), \\(\\textrm{P}(C^c) = 1-0.2436 = 0.7564\\). Since the overall probability of not using Snapchat is about 3 times greater than the overall probability of using Snapchat, the conditional probability of being age 18-29 given the adult does not use Snapchat (0.0925) gets about 3 times more weight in the average than the conditional probability of being age 18-29 given the adult does uses Snapchat (0.5337). This is why the overall probability of being age 18-29 (0.20) is closer to 0.0925 than to 0.5337.\n\n\n\n\n\nThe previous example illustrates another version of the law of total probability.\n\nLemma 2.7 (Law of total probability) If \\(C_1, C_2, C_3\\ldots\\) are disjoint events with \\(C_1\\cup C_2 \\cup C_3\\cup \\cdots =\\Omega\\), then42\n\n\\[\\begin{align*}\n    \\textrm{P}(A) & = \\textrm{P}(A |C_1)\\textrm{P}(C_1) + \\textrm{P}(A | C_2)\\textrm{P}(C_2) + \\textrm{P}(A | C_3)\\textrm{P}(C_3) + \\cdots\n\\end{align*}\\]\nThe events \\(C_1, C_2, C_3, \\ldots\\), which represent the “cases”, form a partition of the sample space; each outcome \\(\\omega\\in\\Omega\\) lies in exactly one of the \\(C_i\\). The law of total probability says that we can interpret the unconditional probability \\(\\textrm{P}(A)\\) as a probability-weighted average of the case-by-case conditional probabilities \\(\\textrm{P}(A|C_i)\\) where the weights \\(\\textrm{P}(C_i)\\) represent the probability of encountering each case.\nFor an illustration of the law of total probability, consider the mosaic plots in Figure 2.20. In Figure 2.20 (a), the heights of the orange bars for each age group correspond to the conditional probabilities of using Snapchat given age group (0.65, 0.24, 0.12, 0.02). The widths of these bars are scaled in proportion to the marginal probabilities of the age groups; the width of the bar for age 30-49 is 1.65 (0.33/0.20) times wider than the width for age 18-29. The height of the orange part of the single vertical bar on the right represents the marginal probability of using Snapchat (0.2436), and this is the weighted average of the heights of the the other orange bars (the conditional probabilities of using Snapchat given the age groups), with the weights given by the widths of the other bars (the marginal probabilities of the age groups).\nThe influence of the weighting is even more apparent in the mosaic plot in Figure 2.20 (b). Since the marginal probability of not using Snapchat is greater than the marginal probability of using Snapchat, the marginal probabilities of the age groups are closer to those for the conditional probabilities of the age groups given the adult does not use Snapchat than those given that the adult uses Snapchat.\nConditioning and using the law of probability is an effective strategy in solving many problems, even when the problem doesn’t seem to involve conditioning. For example, when a problem involves iterations or steps it is often useful to condition on the result of the first step.\n\n\n\n\n\n\n\nExample 2.50 You and your friend are playing the “lookaway challenge”.\nThe game consists of possibly multiple rounds. In the first round, you point in one of four directions: up, down, left or right. At the exact same time, your friend also looks in one of those four directions. If your friend looks in the same direction you’re pointing, you win! Otherwise, you switch roles and the game continues to the next round—now your friend points in a direction and you try to look away. As long as no one wins, you keep switching off who points and who looks. The game ends, and the current “pointer” wins, whenever the “looker” looks in the same direction as the pointer.\nSuppose that each player is equally likely to point/look in each of the four directions, independently from round to round. What is the probability that you, starting as the pointer, win the game?\n\nWhy might you expect the probability to not be equal to 0.5?\nIf you start as the pointer, what is the probability that you win in the first round?\nIf \\(p\\) denotes the probability that the player who starts as the pointer wins the game, what is the probability that the player who starts as the looker wins the game? (Note: \\(p\\) is the probability that the person who starts as pointer wins the whole game, not just the first round.)\nLet \\(A\\) be the event that the person who starts as the pointer wins the game, and \\(B\\) be the event that the person who starts as the pointer wins in the first round. What is \\(\\textrm{P}(A|B)\\)?\nFind a simple expression for \\(\\textrm{P}(A | B^c)\\) in terms of \\(p\\). The key is to consider this question: if the player who starts as the pointer does not win in the first round, how does the game behave from that point forward?\nCondition on the result of the first round and set up an equation to solve for \\(p\\).\nInterpret the probability from the previous part as a long run relative frequency.\nHow much more likely is the player who starts as the pointer to win than the player who starts as the looker?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.50. \n\nThe player who starts as the pointer has the advantage of going first; that player can win the game in the first round, but cannot lose the game in the first round. So we might expect the player who starts as the pointer to be more likely to win than the player who starts as the looker.\n1/4. Whichever direction the pointer points, the probability that the looker looks in the same direction is 1/4.Alternatively, if we represent an outcome in the first round as a pair (point, look) then there are 16 possible equally likely outcomes, of which 4 represent pointing and looking in the same direction.\n\\(1-p\\), since the game keeps going until someone wins.\n\\(\\textrm{P}(A|B)=1\\) since if the person who starts as the pointer wins the first round then they win the game.\nThe key is to recognize that if the person who starts as the pointer does not win in the first round, it is like the game starts over with the roles reversed. That is, the player who originally started as the pointer, having not won the first round, is now starting as the looker, and the probability that the player who starts as the looker wins the game is \\(1-p\\). That is, \\(\\textrm{P}(A|B^c) = 1-p\\).\nHere is where we use conditioning and the law of total probability. We condition on what happens in the first round: either the person who starts as the pointer wins the first round and the game ends (event \\(B\\)), or the person who starts as the pointer does not win the the first round and the game continues with the other player becoming the pointer for the next round (event \\(B^c\\)). By the law of total probability \\[\n\\textrm{P}(A) = \\textrm{P}(A|B)\\textrm{P}(B) + \\textrm{P}(A|B^c)\\textrm{P}(B^c)\n\\] From previous parts \\(\\textrm{P}(A)=p\\), \\(\\textrm{P}(B)=1/4\\), \\(\\textrm{P}(B^c)=3/4\\), \\(\\textrm{P}(A|B) = 1\\), and \\(\\textrm{P}(A|B^c)=1-p\\). Therefore \\[\np = (1)(1/4)+ (1-p)(3/4)\n\\] Solve to find \\(p=4/7= 0.571\\).\nOver many games of the lookaway challenge, the player who starts as the pointer wins about 57.1% of games.\nThe player who starts as the pointer is about \\((4/7)/(3/7) = 4/3= 1.33\\) times more likely to win the game than the player who starts as the looker.\n\n\n\n\n\nThe game in Example 2.50 could potentially last any number of rounds (1, 2, 3, …) However, the law of total probability allowed us to take advantage of the iterative nature of the game, and consider only one round rather than enumerating all the possibilities of what might happen over many potential rounds.\n\n\n2.6.5 Conditioning is “slicing and renormalizing”\n\n\n\n\n\n\n\nExample 2.51 Continuing Example 2.46.\n\nHow many times more likely is it for an American adult to be a Snapchat user and age 18-29 than to be:\n\na Snapchat user and age 30-49?\na Snapchat user and age 50-64?\na Snapchat user and age 65+?\n\nHow many times more likely is it for an American adult who uses Snapchat to be age 18-29 than to be:\n\nage 30-49?\nage 50-64?\nage 65+?\n\nWhat do you notice about the answers to the two previous parts?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.51. \n\nUse the joint probabilities we computed in Example 2.46; see the “uses Snapchat” column of the two-way table in the solution to part 4. The joint probability that an American adult is a Snapchat user and age 18-29 is:\n\n\\(\\frac{0.1300}{0.0792} = 1.64\\) times greater than the joint probability that an American adult is a Snapchat user and age 30-49\n\\(\\frac{0.1300}{0.0300} = 4.33\\) times greater than the joint probability that an American adult is a Snapchat user and age 50-64\n\\(\\frac{0.1300}{0.0044} = 29.55\\) times greater than the joint probability that an American adult is a Snapchat user and age 65+\n\nUse the conditional probabilities we computed in Example 2.46; see the solution to part 7. The conditional probability that an American adult is age 18-29 given that they use Snapchat is:\n\n\\(\\frac{0.5337}{0.3251} = \\frac{0.1300/0.2436}{0.0792/0.2436} = 1.64\\) times greater than the conditional probability that an American adult is age 30-49 given that they use Snapchat.\n\\(\\frac{0.5337}{0.1232} = \\frac{0.1300/0.2436}{0.0300/0.2436}= 4.33\\) times greater than the conditional probability that an American adult is age 50-64 given that they use Snapchat.\n\\(\\frac{0.5337}{0.0181} = \\frac{0.1300/0.2436}{0.0044/0.2436} = 29.55\\) times greater than The conditional probability that an American adult is age 65+ given that they use Snapchat.\n\nThe ratios are the same43! Conditioning on using Snapchat zooms in on the “slice” of adults who use Snapchat in the two-way table of joint probabilities. The ratios within this slice are determined by the joint probabilities for adults, as in part 1. The conditional probabilities given Snapchat use that we used to compute ratios in part 2 are simply rescaled versions of the joint probabilities for the “use Snapchat slice”; rescaled so that the slice represents 100% of the probability given that the adult uses Snapchat.\n\n\n\n\n\nThe process of conditioning can be thought of as “slicing and renormalizing”.\n\nExtract the “slice” corresponding to the event being conditioned on (and discard the rest). For example, a slice might correspond to a particular row or column of a two-way table, or a section of a plot.\n\n“Renormalize” the values in the slice so that corresponding probabilities add up to 1.\n\nSlicing determines shape; renormalizing determines scale. Slicing determines relative probabilities; renormalizing just makes sure they add up to 1.\nConsider the mosaic plot in Figure 2.20 (b), where the areas of rectangles represent joint probabilities. The areas of the rectangles in the “uses Snapchat” column represent the joint probabilities we used in part 1 of Example 2.46. Imagine taking the rectangles in this column and unstacking them to make a bar plot with heights determined by the joint probabilities of being in each age group and using Snapchat, as in Figure 2.22 (a). The “slice” determines the shape of the bar plot: The bar for age 18-29 is 1.64 times higher than the bar for age 30-49, 4.33 times higher than the bar for age 50-64, and 29.55 times higher than the bar for age 65+.\nSumming the joint probabilities in Figure 2.22 (a) over the age groups yields 0.2436, the marginal probability that an adult uses Snapchat. Given that the adult uses Snapchat, we want the conditional probabilities of the age groups to sum to 1. Thus we “renormalize” the joint probabilities on the vertical axis—by dividing each by 0.2436—so that they sum to 1 to obtain the conditional probabilities of each age group given that the adult uses Snapchat, displayed in Figure 2.22 (b). Renormalizing only changes the absolute scale of the plot; compare the values on the vertical axes in Figure 2.22, which correspond to joint probabilities on the left and conditional probabilities on the right. Both plots have the same relative shape: the bar for age 18-29 is 1.64 times higher than the bar for age 30-49, 4.33 times higher than the bar for age 50-64, and 29.55 times higher than the bar for age 65+.\n\n\n\n\n\n\n\n\n\n\n\n(a) Joint probability of each age group and Snapchat use for the uses Snapchat slice\n\n\n\n\n\n\n\n\n\n\n\n(b) Renormalized, conditional probability of each age group given that the adult uses Snapchat.\n\n\n\n\n\n\n\nFigure 2.22: Illustration of slicing and renormalizing for Example 2.51\n\n\n\n\n\n\n\n\n\n\nExample 2.52 Each of the three Venn diagrams below represents a sample space with 16 equally likely outcomes. Let \\(A\\) be the yellow / event, \\(B\\) the blue \\ event, and their intersection \\(A\\cap B\\) the green \\(\\times\\) event. Suppose that areas represent probabilities, so that for example \\(\\textrm{P}(A) = 4/16\\).\nFind \\(\\textrm{P}(A|B)\\) for each of the scenarios. Be sure to indicate what represents the “slice” in each scenario.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.23: Three sample spaces with 16 equally outcomes\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.52. In each case we’re conditioning on event \\(B\\), so the slice represents the 4 blue outcomes. Imagine zooming in on the blue (including green) area of each plot: remove the slice with the 4 blue outcomes (and erase the rest) and then magnify (renormalize) the slice so that it is the size of the original rectangle.\n\nLeft: \\(\\textrm{P}(A|B)=0\\). After conditioning on \\(B\\), there are now 4 equally likely outcomes, of which none satisfy \\(A\\).\nMiddle: \\(\\textrm{P}(A|B) = 2/4=1/2\\). After conditioning on \\(B\\), there are now 4 equally likely outcomes, of which 2 satisfy \\(A\\). The green part represents 1/2 of the area of the blue slice.\nRight: \\(\\textrm{P}(A|B) = 1/4\\). After conditioning on \\(B\\), there are now 4 equally likely outcomes, of which 1 satisfies \\(A\\). The green part represents 1/4 of the area of the blue slice.\n\n\n\n\n\nWe will see that “slicing and renormalizing” is a helpful way to conceptualize conditioning, especially when dealing with conditional distributions of random variables.\n\n\n2.6.6 Bayes rule\nBayes’ rule describes how to update uncertainty in light of new information, evidence, or data. We’ll introduce it in the context of two-way tables.\n\n\n\n\n\n\n\nExample 2.53 A recent survey of American adults asked: “Based on what you have heard or read, which of the following two statements best describes the scientific method?”\n\n70% selected “The scientific method produces findings meant to be continually tested and updated over time”. (We’ll call this the “iterative” opinion.)\n14% selected “The scientific method identifies unchanging core principles and truths”. (We’ll call this the “unchanging” opinion).\n16% were not sure which of the two statements was best.\n\nHow does the response to this question change based on education level? Suppose education level is classified as: high school or less (HS), some college but no Bachelor’s degree (college), Bachelor’s degree (Bachelor’s), or postgraduate degree (postgraduate). The education breakdown is\n\nAmong those who agree with “iterative”: 31.3% HS, 27.6% college, 22.9% Bachelor’s, and 18.2% postgraduate.\nAmong those who agree with “unchanging”: 38.6% HS, 31.4% college, 19.7% Bachelor’s, and 10.3% postgraduate.\nAmong those “not sure”: 57.3% HS, 27.2% college, 9.7% Bachelor’s, and 5.8% postgraduate\n\n\nUse the information to construct an appropriate two-way table.\nOverall what percentage of adults have a postgraduate degree? How is this related to the values 18.2%, 10.3%, and 5.8%?\nWhat percent of those with a postgraduate degree agree that the scientific method is “iterative”? How is this related to the values provided?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.53. \n\nSuppose there are 100000 hypothetical American adults. Of these 100000, \\(100000\\times 0.7 = 70000\\) agree with the “iterative” statement. Of the 70000 who agree with the “iterative” statement, \\(70000\\times 0.182 = 12740\\) also have a postgraduate degree. Continue in this way to complete Table 2.19\nOverall 15.11% of adults have a postgraduate degree (15110/100000 in the table). The overall percentage is a weighted average of the three percentages; 18.2% gets the most weight in the average because the “iterative” statement has the highest percentage of people that agree with it compared to “unchanging” and “not sure”. \\[\n0.1511 = (0.70)(0.182) + (0.14)(0.103) + (0.16)(0.058)  \n\\]\nOf the 15110 who have a postgraduate degree 12740 agree with the “iterative” statement, and \\(12740/15110 = 0.843\\). 84.3% of those with a graduate degree agree that the scientific method is “iterative”. The value 0.843 is equal to the product of (1) 0.70, the overall proportion who agree with the “iterative” statement, and (2) 0.182, the proportion of those who agree with the “iterative” statement that have a postgraduate degree; divided by 0.1511, the overall proportion who have a postgraduate degree. \\[\n0.843 = \\frac{0.182 \\times 0.70}{0.1511}\n\\]\n\n\n\n\n\n\n\n\n\nTable 2.19: Two-way table for Example 2.53\n\n\n\n\n\n\nhypothesis\nHS\nCollege\nBachelors\nPostgrad\nTotal\n\n\n\n\niterative\n21910\n19320\n16030\n12740\n70000\n\n\nunchanging\n5404\n4396\n2758\n1442\n14000\n\n\nnot sure\n9168\n4352\n1552\n928\n16000\n\n\nTotal\n36482\n28068\n20340\n15110\n100000\n\n\n\n\n\n\n\n\n\nLemma 2.8 (Bayes rule for events) Bayes’ rule for events44 specifies how a prior probability \\(P(H)\\) of event \\(H\\) is updated in response to the evidence \\(E\\) to obtain the posterior probability \\(P(H|E)\\). \\[\nP(H|E) = \\frac{P(E|H)P(H)}{P(E)}\n\\]\n\n\nEvent \\(H\\) represents a particular hypothesis45 (or model or case)\nEvent \\(E\\) represents observed evidence (or data or information)\n\\(P(H)\\) is the unconditional or prior probability of \\(H\\) (prior to observing evidence \\(E\\))\n\\(P(H|E)\\) is the conditional or posterior probability of \\(H\\) after observing evidence \\(E\\).\n\\(P(E|H)\\) is the likelihood of evidence \\(E\\) given hypothesis (or model or case) \\(H\\)\n\n\n\n\n\n\n\n\nExample 2.54 Continuing Example 2.53. Randomly select an American adult.\n\nConsider the conditional probability that a randomly selected American adult agrees that the scientific method is “iterative” given that they have a postgraduate degree. Identify the hypothesis, prior probability, evidence, likelihood, and posterior probability, and use Bayes’ rule to compute the posterior probability.\nCompute the conditional probability that a randomly selected American adult with a postgraduate degree agrees that the scientific method is “unchanging”.\nCompute the conditional probability that a randomly selected American adult with a postgraduate degree is not sure about which statement is best.\nHow many times more likely is it for an American adult to have a postgraduate degree and agree with the “iterative” statement than to have a postgraduate degree and agree with the “unchanging” statement?\nHow many times more likely is it for an American adult with a postgraduate degree to agree with the “iterative” statement than to agree with the “unchanging” statement?\nWhat do you notice about the answers to the two previous parts?\nHow many times more likely is it for an American adult to agree with the “iterative” statement than to agree with the “unchanging” statement?\nHow many times more likely is it for an American adult to have a postgraduate degree when the adult agrees with the “iterative” statement than when the adult agree with the “unchanging” statement?\nHow many times more likely is it for an American adult with a postgraduate degree to agree with the “iterative” statement than to agree with the “unchanging” statement?\nHow are the values in the three previous parts related?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.54. \n\nThis is essentially the same question as the last part of Example 2.53, just with different terminology.\n\nThe hypothesis is \\(H_1\\), the event that the randomly selected adult agrees with the “iterative” statement.\nThe prior probability is \\(\\textrm{P}(H_1) = 0.70\\), the overall or unconditional probability that a randomly selected American adult agrees with the “iterative” statement.\nThe given “evidence” \\(E\\) is the event that the randomly selected adult has a postgraduate degree. The marginal probability of the evidence is \\(\\textrm{P}(E)=0.1511\\), which can be obtained by the law of total probability as in Example 2.53.\nThe likelihood is \\(\\textrm{P}(E | H_1) = 0.182\\), the conditional probability that the adult has a postgraduate degree (the evidence) given that the adult agrees with the “iterative” statement (the hypothesis).\nThe posterior probability is \\(\\textrm{P}(H_1 |E)=0.843\\), the conditional probability that a randomly selected American adult agrees that the scientific method is “iterative” given that they have a postgraduate degree. By Bayes rule \\[\n\\textrm{P}(H_1 | E) = \\frac{\\textrm{P}(E | H_1) \\textrm{P}(H_1)}{\\textrm{P}(E)} = \\frac{0.182 \\times 0.70}{0.1511} = 0.843\n\\]\n\nLet \\(H_2\\) be the event that the randomly selected adult agrees with the “unchanging” statement; the prior probability is \\(\\textrm{P}(H_2) = 0.14\\). The evidence \\(E\\) is still “postgraduate degree” but now the likelihood of this evidence is \\(\\textrm{P}(E | H_2) = 0.103\\) under the “unchanging” hypothesis. The conditional probability that a randomly selected adult with a postgraduate degree agrees that the scientific method is “unchanging” is \\[\n\\textrm{P}(H_2 | E) = \\frac{\\textrm{P}(E | H_2) \\textrm{P}(H_2)}{\\textrm{P}(E)} = \\frac{0.103 \\times 0.14}{0.1511} = 0.095\n\\]\nLet \\(H_3\\) be the event that the randomly selected adult is “not sure”; the prior probability is \\(\\textrm{P}(H_3) = 0.16\\). The evidence \\(E\\) is still “postgraduate degree” but now the likelihood of this evidence is \\(\\textrm{P}(E | H_3) = 0.058\\) under the “not sure” hypothesis. The conditional probability that a randomly selected adult with a postgraduate degree is “not sure” is \\[\n\\textrm{P}(H_3 | E) = \\frac{\\textrm{P}(E | H_3) \\textrm{P}(H_3)}{\\textrm{P}(E)} = \\frac{0.058 \\times 0.16}{0.1511} = 0.061\n\\]\nThe probability that an American adult has a postgraduate degree and agrees with the “iterative” statement is \\(\\textrm{P}(E \\cap H_1) = \\textrm{P}(E|H_1)\\textrm{P}(H_1) = 0.182\\times 0.70 = 0.1274\\). The probability that an American adult has a postgraduate degree and agrees with the “unchanging” statement is \\(\\textrm{P}(E \\cap H_2) = \\textrm{P}(E|H_2)\\textrm{P}(H_2) = 0.103\\times 0.14 = 0.01442\\). Since \\[\n\\frac{\\textrm{P}(E \\cap H_1)}{\\textrm{P}(E \\cap H_2)} = \\frac{0.182\\times 0.70}{0.103\\times 0.14} = \\frac{0.1274}{0.01442} = 8.835\n\\] an American adult is 8.835 times more likely to have a postgraduate degree and agree with the “iterative” statement than to have a postgraduate degree and agree with the “unchanging” statement.\nThe conditional probability that an American adult with a postgraduate degree agrees with the “iterative” statement is \\(\\textrm{P}(H_1 | E) = \\textrm{P}(E|H_1)\\textrm{P}(H_1)/\\textrm{P}(E) = 0.182\\times 0.70/0.1511 = 0.843\\). The conditional probability that an American adult with a postgraduate degree agrees with the “unchanging” statement is \\(\\textrm{P}(H_2|E) = \\textrm{P}(E|H_2)\\textrm{P}(H_2)/\\textrm{P}(E) = 0.103\\times 0.14/0.1511 = 0.09543\\). Since \\[\n\\frac{\\textrm{P}(H_1 | E)}{\\textrm{P}(H_2 | E)} = \\frac{0.182\\times 0.70/0.1511}{0.103\\times 0.14/0.1511} = \\frac{0.84315}{0.09543} = 8.835\n\\] an American adult with a postgraduate degree is 8.835 times more likely to agree with the “iterative” statement than to agree with the “unchanging” statement.\nThe ratios are the same! Conditioning on having a postgraduate degree just “slices” out the Americans who have a postgraduate degree. The ratios are determined by the overall probabilities for Americans. The conditional probabilities, given postgraduate degree, simply rescale the probabilities for Americans who have a postgraduate degree to add up to 1 (by dividing by 0.1511).\nThis is a ratio of prior probabilities: 0.70 / 0.14 = 5. An American adult is 5 times more likely to agree with the “iterative” statement than to agree with the “unchanging” statement.\nThis is a ratio of likelihoods: 0.182 / 0.103 = 1.767. An American adult is 1.767 times more likely to have a postgraduate degree when the adult agrees with the iterative statement than when the adult agree with the unchanging statement.\nThis is a ratio of posterior probabilities: 0.8432 / 0.0954 = 8.835. An American adult with a postgraduate degree is 8.835 times more likely to agree with the “iterative” statement than to agree with the “unchanging” statement.\nThe ratio of the posterior probabilities is equal to the product of the ratio of the prior probabilities and the ratio of the likelihoods: \\(8.835 = 5 \\times 1.767\\). The posterior is proportional to the product of prior and likelihood.\n\n\n\n\n\nBayes rule is often used when there are multiple hypotheses or cases. Suppose \\(H_1,H_2, \\ldots\\) is a series of distinct hypotheses which together account for all possibilities, and \\(E\\) is any event (evidence). Then Bayes’ rule implies that the posterior probability of any particular hypothesis \\(H_j\\) satisfies \\[\n\\textrm{P}(H_j |E) = \\frac{\\textrm{P}(E|H_j)\\textrm{P}(H_j)}{\\textrm{P}(E)}\n\\]\nThe marginal probability of the evidence, \\(\\textrm{P}(E)\\), in the denominator can be calculated using the law of total probability \\[\n\\textrm{P}(E) = \\textrm{P}(E|H_1) \\textrm{P}(H_1) + \\textrm{P}(E|H_2) \\textrm{P}(H_2) + \\textrm{P}(E|H_3) \\textrm{P}(H_3) + \\cdots\n\\] Since \\(\\textrm{P}(E)\\) is the sum of the terms \\(\\textrm{P}(E|H_j)\\textrm{P}(H_j)\\) over all the hypotheses, Bayes rule implies that \\(\\textrm{P}(H_j |E)\\) is proportional to46 \\(\\textrm{P}(E|H_j)\\textrm{P}(H_j)\\) \\[\\begin{align*}\n\\textrm{P}(H_j |E) & = \\frac{\\textrm{P}(E|H_j)\\textrm{P}(H_j)}{\\textrm{P}(E)}\\\\\n\\textrm{P}(H_j |E) & \\propto \\textrm{P}(E|H_j)\\textrm{P}(H_j)\n\\end{align*}\\]\nIn short, Bayes’ rule says that a posterior probability of a hypothesis is proportional to the product of the prior probability of the hypothesis and the likelihood of the evidence if the hypothesis were true.\n\\[\n\\textbf{posterior} \\propto \\textbf{prior} \\times \\textbf{likelihood}\n\\]\nBayes rule calculations are often organized in a Bayes’ table like Table 2.20 which illustrates “posterior is proportional to likelihood times prior”. The table has one row for each hypothesis and columns for\n\nprior probability: column sum is 1\nlikelihood of the evidence given each hypothesis\n\nlikelihood depends on the evidence; if the evidence changes, the likelihood column changes\nthe sum of the likelihood column is a meaningless number and can be any value\n\nproduct of prior and likelihood: column sum is the marginal probability of the evidence\nposterior probability: column sum is 1\n\n\n\n\n\nTable 2.20: Bayes table representation of the posterior probabilities of each opinion about the scientific method (the hypotheses) given a postgraduate degree (the evidence) in Example 2.54\n\n\n\n\n\n\nhypothesis\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\niterative\n0.70\n0.182\n0.1274\n0.8432\n\n\nunchanging\n0.14\n0.103\n0.0144\n0.0954\n\n\nnot sure\n0.16\n0.058\n0.0093\n0.0614\n\n\nTotal\n1.00\n0.343\n0.1511\n1.0000\n\n\n\n\n\n\n\n\nThe likelihood column in a Bayes table depends on the evidence. In Table 2.20 the evidence is that the American has a postgraduate degree; the likelihood column contains the probability of the same event, \\(E\\) = “the American has a postgraduate degree”, under each of the distinct hypotheses:\n\n\\(\\textrm{P}(E |H_1) = 0.182\\), given the American agrees with the “iterative” statement\n\\(\\textrm{P}(E |H_2) = 0.103\\), given the American agrees with the “unchanging” statement\n\\(\\textrm{P}(E |H_3) = 0.058\\), given the American is “not sure”\n\nSince each of these probabilities is computed under a different case, these values do not need to add up to anything in particular. The sum of the likelihoods is meaningless.\nThe “product” column contains the product of the values in the prior and likelihood columns. In Table 2.20 the product of prior and likelihood for “iterative” (0.1274) is 8.835 (0.1274/0.0144) times higher than the product of prior and likelihood for “unchanging” (0.0144). Therefore, Bayes rule implies that the conditional probability that an American with a postgraduate degree agrees with “iterative” should be 8.835 times higher than the conditional probability that an American with a postgraduate degree agrees with “unchanging”. Similarly, the conditional probability that an American with a postgraduate degree agrees with “iterative” should be \\(0.1274 / 0.0093 = 13.73\\) times higher than the conditional probability that an American with a postgraduate degree is “not sure”, and the conditional probability that an American with a postgraduate degree agrees with “unchanging” should be \\(0.0144 / 0.0093 = 1.55\\) times higher than the conditional probability that an American with a postgraduate degree is “not sure”. The last column just translates these relative relationships into probabilities that sum to 1.\nThe sum of the “product” column is \\(\\textrm{P}(E)\\), the marginal probability of the evidence or “average likelihood”. The sum of the product column represents the result of the law of total probability calculation. However, for the purposes of determining the posterior probabilities, it isn’t really important what \\(P(E)\\) is. Rather, it is the ratio of the values in the “product” column that determine the posterior probabilities. \\(\\textrm{P}(E)\\) is whatever it needs to be to ensure that the posterior probabilities sum to 1 while maintaining the proper ratios.\nBayes rule is just another application of conditioning as “slicing and renormalizing”.\n\nExtract the “slice” corresponding to the event being conditioned on (and discard the rest). For example, a slice might correspond to a particular row or column of a two-way table.\n\n“Renormalize” the values in the slice so that corresponding probabilities add up to 1.\n\nIn Bayes rule, the product of prior and likelihood determines the shape of the slice. Slicing determines relative probabilities; renormalizing just makes sure they “add up” to 1 while maintaining the proper ratios.\n\n\n\n\n\n\n\nExample 2.55 Continuing Example 2.53. Randomly select an American adult. Now suppose we want to compute the posterior probabilities for an American adult’s perception of the scientific method given that the randomly selected American adult has some college but no Bachelor’s degree (“College”).\n\nBefore computing, make an educated guess for the posterior probabilities. In particular, will the changes from prior to posterior be more or less extreme given the American has some college but no Bachelor’s degree than when given the American has a postgraduate degree? Why?\nConstruct a Bayes table and compute the posterior probabilities. Compare to the posterior probabilities given postgraduate degree from the previous examples.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.55. \n\nWe start with the same prior probabilities as before: 0.70 for iterative, 0.14 for unchanging, 0.16 for not sure. Now the evidence is that the American has some college but no Bachelor’s degree. The likelihood of the evidence (“college”) is 0.276 under the iterative hypothesis, 0.314 under the unchanging hypothesis, and 0.272 under the not sure hypothesis. The likelihood of the evidence does not change as much across the different hypotheses when the evidence is “college” than when the evidence was “postgraduate degree”. Therefore, the changes from prior to posterior should be less extreme when the evidence is “college” than when the evidence was “postgraduate degree”. Furthermore, since the likelihood doesn’t vary much across hypotheses when the evidence is “college” we expect the posterior probabilities to be close to the prior probabilities.\nSee Table 2.21 As expected, the posterior probabilities are closer to the prior probabilities when the evidence is “college” than when the evidence is “postgraduate degree”.\n\n\n\n\n\n\n\n\n\nTable 2.21: Bayes table representation of the posterior probabilities of each opinion about the scientific method (the hypotheses) given a college degree (the evidence) in Example 2.55\n\n\n\n\n\n\nhypothesis\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\niterative\n0.70\n0.276\n0.1932\n0.6883\n\n\nunchanging\n0.14\n0.314\n0.0440\n0.1566\n\n\nnot sure\n0.16\n0.272\n0.0435\n0.1551\n\n\nTotal\n1.00\n0.862\n0.2807\n1.0000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.56 True story: On a camping trip in Vermont, my wife and I were driving when a very large, hairy, black animal ran across the road in front of us and into the woods on the other side. It happened very quickly, and at first I said “It’s a gorilla!” But then after some thought, and much derision from my wife, I said “it was probably a bear.”\nI think this story provides an anecdote about Bayesian reasoning, albeit bad reasoning at first but then good. Put the story in a Bayesian context by identifying hypotheses, prior, evidence, and likelihood. What was the mistake I made initially?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.56. “Type of animal running across the road in Vermont” is playing the role of the hypothesis. It could be a gorilla or a bear, but it could also be a cow, deer, dog, rabbit, squirrel, etc.\nThat the animal is “very large, hairy, black, and running” is the evidence.\nThe likelihood is the probability of being “very large, hairy, black, and running” given each of the animals.\n\nThe likelihood of a gorilla being “very large, hairy, black, and running” is relatively high; a high percentage of gorillas are “very large, hairy, and black” and they can run.\nThe likelihood of a bear being “very large, hairy, black, and running” is also relatively high; a high percentage of bears are “very large, hairy, and black” and they can also run.\nThe likelihood of a dog being “very large, hairy, black, and running” is more middling; some dogs are “very large, hairy, and black” but many aren’t.\nThe likelihood of a squirrel being “very large, hairy, black, and running” is basically 0; thankfully, squirrels are not very large.\nThe likelihood of a deer being “very large, hairy, black, and running” is also very small, because most deer are not black.\n\nWe have identified hypotheses, evidence, and likelihood. Did you notice the important element that we skipped? The mistake I made initially was to neglect the base rates and not consider my prior probabilities. For a moment, let’s say the likelihood is 1 for both gorilla and bear and 0 for all other animals47. Then based solely on these likelihoods, the posterior probability would be 50/50 for gorilla and bear, which maybe is why I guessed gorilla.\nAfter my initial reaction, I paused to think about my prior probabilities for the animal crossing the road, which considering I was in Vermont should assign much higher probability to a bear than a gorilla. My prior probabilities should also have given even higher probability to animals such as deer and squirrels; maybe even cows and dogs would have a higher probability than a bear.\nBy combining prior and likelihood in the appropriate way, the posterior probability is\n\nvery high for a bear, due to high likelihood and not-too-small prior\nclose to 0 for a gorilla, due to the essentially 0 prior (even though the likelihood is basically 1)\nvery low for a squirrel or deer because of the essentially 0 likelihood, even if the prior is large.\n\nAfter considering both prior and likelihood, the posterior probability is essentially 0 for a gorilla and relatively high for a bear, so it was good that I revised my conclusion from gorilla to bear48.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nPosterior probabilities can be highly influenced by the original prior probabilities (a.k.a., base rates). Example 2.56 illustrates that ignoring prior probabilities can lead to wildly inaccurate conclusions. Don’t neglect the prior probabilities when evaluating posterior probabilities!\n\n\nLike the scientific method, applying Bayes rule is often an iterative process.\n\n\n\n\n\n\n\nExample 2.57 Suppose that you are presented with six boxes, labeled 0, 1, 2, \\(\\ldots\\), 5, each containing five marbles. Box 0 contains 0 green and 5 gold marbles, box 1 contains 1 green and 4 gold, and so on with box \\(i\\) containing \\(i\\) green and \\(5-i\\) gold. One of the boxes is chosen uniformly at random (perhaps by rolling a fair six-sided die), and then you will randomly select marbles from that box, without replacement. Imagine the boxes appear identical and you can’t see inside; all you observe is the color of the marbles you select. Based on the colors of the marbles selected, you will update the probabilities of which box had been chosen.\n\nSuppose that a single marble is selected and it is green. Which box do you think is the most likely to have been chosen? Make a guess for the posterior probabilities for each box. Then construct a Bayes table to compute the posterior probabilities. How do they compare to the prior probabilities?\nNow suppose a second marble is selected from the same box, without replacement, and its color is gold. Which box do you think is the most likely to have been chosen given these two marbles? Make a guess for the posterior probabilities for each box. Then construct a Bayes table to compute the posterior probabilities, using the posterior probabilities from the previous part after the selection of the green marble as the new prior probabilities before seeing the gold marble.\nNow construct a Bayes table corresponding to the original prior probabilities (1/6 each) and the combined evidence that the first ball selected was green and the second was gold. How do the posterior probabilities compare to the previous part?\nIn the previous part, the first ball selected was green and the second was gold. Suppose you only knew that in a sample of two marbles, 1 was green and 1 was gold. That is, you didn’t know which was first or second. How would the previous part change? Should knowing the order matter? Construct the Bayes table and compute the posterior probabilities, and compare to the previous part.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.57. \n\nSince the prior probability is the same for each box, the posterior probability will be greatest for the box for which the likelihood of selecting a green marble (the evidence) is greatest, i.e., box 5 which has a likelihood of drawing a green marble of 1. See Table 2.22. The likelihood column provides the probability of drawing a green marble from each of the boxes, which is \\(i/5\\) for box \\(i\\). (The likelihood of drawing a green marble is 0 for box 0, so box 0 will have a posterior probability of 0.) Since the prior is “flat” the posterior probabilities are proportional to the likelihoods.\nThe posterior probabilities above quantify our uncertainty about the box after observing a single randomly selected marble is green. These probabilities serve as the prior probabilities before drawing any additional marbles. After drawing a green marble without replacement, each box has 4 marbles and 1 less green marble than before, and the likelihood of observing a second marble which is gold is computed for each of the 4-marble boxes. For example, after drawing a green marble, box 2 now contains 1 green marble and 3 gold marbles, so the likelihood of drawing a gold marble from box 2 is 3/4. (The likelihood for box 0 is technically undefined because the probability of drawing a green marble first from box 0 is 0. But since the prior probability for box 0 is 0, the posterior probability for box 0 will be 0 regardless of the likelihood.) See Table 2.23. Since we have observed green and gold in equal proportion in our sample, the posterior probabilities are highest for the boxes with closest to equal proportions of green and gold (box 2 and box 3).\nIn the previous part we updated the posterior probabilities after the first marble and again after selecting the second. What if we start with equally likely prior probabilities and only update the posterior probabilities after selecting both marbles? The likelihood now represents the probability of drawing a green and then a gold marble, without replacement, from each of the boxes. For example, for box 2, the probability of drawing a green marble first is 2/5 and the conditional probability of then drawing a gold marble is 3/4, so the probability of drawing green and then gold is (2/5)(3/4) = 0.3. See Table 2.24. Notice that the posterior probabilities are the same as in the previous part! It doesn’t matter if we sequentially update our probabilities after each draw as in the previous part, or only once after the entire sample is drawn. The posterior probabilities are the same either way.\nWhat if we know the sample contains 1 green and 1 gold marble, but we don’t know which was drawn first? It seems that knowing the order shouldn’t matter in terms of our posterior probabilities. Technically, the likelihood does change since there are two ways to get a sample with 1 green and 1 gold: green followed by gold or gold followed by green. Therefore, each likelihood will be two times larger than in the previous part. For example, for box 2, the probability of green then gold is (2/5)(3/4) and the probability of gold then green is (3/5)(2/4), so the probability of 1 green and 1 gold is (2/5)(3/4) + (3/4)(2/5) = 2(0.3). However, the ratios of the likelihoods have not changed; since each likelihood is twice as large as it was in the previous part, the likelihood from this part is proportional to the likelihood from the previous part. Therefore, since the prior probabilities are the same as in the previous part and the likelihoods are proportionally the same as in the previous part, the posterior probabilities will also be the same as in the previous part. See Table 2.25.\n\n\n\n\n\n\n\n\n\nTable 2.22: Bayes table given a single green marble in Example 2.57\n\n\n\n\n\n\nGreen\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\n0\n0.1667\n0.0\n0.0000\n0.0000\n\n\n1\n0.1667\n0.2\n0.0333\n0.0667\n\n\n2\n0.1667\n0.4\n0.0667\n0.1333\n\n\n3\n0.1667\n0.6\n0.1000\n0.2000\n\n\n4\n0.1667\n0.8\n0.1333\n0.2667\n\n\n5\n0.1667\n1.0\n0.1667\n0.3333\n\n\nsum\n1.0000\nNA\n0.5000\n1.0000\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2.23: Bayes table given the second marble is gold in Example 2.57, using the posterior given a single green marble as the prior\n\n\n\n\n\n\nGreen\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\n0\n0.0000\n1.00\n0.0000\n0.0\n\n\n1\n0.0667\n1.00\n0.0667\n0.2\n\n\n2\n0.1333\n0.75\n0.1000\n0.3\n\n\n3\n0.2000\n0.50\n0.1000\n0.3\n\n\n4\n0.2667\n0.25\n0.0667\n0.2\n\n\n5\n0.3333\n0.00\n0.0000\n0.0\n\n\nsum\n1.0000\nNA\n0.3333\n1.0\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2.24: Bayes table given one green then one gold marble in Example 2.57\n\n\n\n\n\n\nGreen\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\n0\n0.1667\n0.0\n0.0000\n0.0\n\n\n1\n0.1667\n0.2\n0.0333\n0.2\n\n\n2\n0.1667\n0.3\n0.0500\n0.3\n\n\n3\n0.1667\n0.3\n0.0500\n0.3\n\n\n4\n0.1667\n0.2\n0.0333\n0.2\n\n\n5\n0.1667\n0.0\n0.0000\n0.0\n\n\nsum\n1.0000\nNA\n0.1667\n1.0\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2.25: Bayes table given one green and one gold marble in Example 2.57\n\n\n\n\n\n\nGreen\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\n0\n0.1667\n0.0\n0.0000\n0.0\n\n\n1\n0.1667\n0.4\n0.0667\n0.2\n\n\n2\n0.1667\n0.6\n0.1000\n0.3\n\n\n3\n0.1667\n0.6\n0.1000\n0.3\n\n\n4\n0.1667\n0.4\n0.0667\n0.2\n\n\n5\n0.1667\n0.0\n0.0000\n0.0\n\n\nsum\n1.0000\nNA\n0.3333\n1.0\n\n\n\n\n\n\n\n\nLike the scientific method, Bayesian analysis is often an iterative process. Posterior probabilities are updated after observing some information or data. These probabilities can then be used as prior probabilities before observing new data. Posterior probabilities can be sequentially updated as new data becomes available, with the posterior probabilities after the previous stage serving as the prior probabilities for the next stage. The final posterior probabilities only depend upon the cumulative data. It doesn’t matter if we sequentially update the posterior after each new piece of data or only once after all the data is available; the final posterior probabilities will be the same either way. Also, the final posterior probabilities are not impacted by the order in which the data are observed.\n\n\n\n\n\n\n\nExample 2.58 Continuing Example 2.57. Imagine we haven’t selected the box or any marbles yet.\n\nIf one of the boxes is selected uniformly at random and a marble is selected at random from the box, what is the probability that the first marble we select from the box is green? Hint: the answer is a single number.\nWe select a box, select a marble, and observe that it is green. what is the probability that the next marble we select from the box will be green? Hint: use the result of part 1 of Example 2.57.\nWe select a box, select two marbles, and observe that they are both green. what is the probability that the next marble we select from the box will be green?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.58. \n\nThe conditional probability that the selected marble is green depends on which box is selected: 0, 1/5, 2/5, 3/5, 4/5, 1 for boxes 0, 1, 2, 3, 4, 5, respectively. To compute the unconditional probability that the selected marble we using, we use the law of total probability, conditioning on the different boxes. Since prior to observing any marbles the boxes are equally likely, the probability of selecting a green marble is just the average of the six conditional probabilities. \\[\n(0)(1/6) + (1/5)(1/6) + (2/5)(1/6) + (3/5)(1/6) + (4/5)(1/6) + (1)(1/6) = 0.5\n\\] The probability that the selected marble is green is 0.5.\nThis is similar to the previous part. But now the probability of each box being the one selected has changed based on observing a green marble from the box. We use the law of total probability, but now the weights are the posterior probabilities given a green marble which we computed in part 1 of Example 2.57. \\[\n(0)(0) + (1/5)(1/15) + (2/5)(2/15) + (3/5)(3/15) + (4/5)(4/15) + (1)(5/15) = 0.7333\n\\] The probability that the next marble selected is green is given that the first marble selected is green is 0.7333.\nAgain we will use the law of total probability, but now we need to find the posterior probability for each box given that the first two marbles are green. We didn’t do this in Example 2.57, but it’s similar to how we computed the posterior probabilities after one green and one gold marble; see Table 2.26. Using the posterior probabilities for the boxes given the two marbles selected are green from Table 2.26, the law of total probability calculation is now \\[\n(0)(0) + (1/5)(0) + (2/5)(0.05) + (3/5)(0.15) + (4/5)(0.3) + (1)(0.5) = 0.85\n\\] The probability that the next marble selected is green is given that the first two marbles selected are green is 0.85. As we draw more green marbles, our posterior probability that the box had a lot of green marbles to begin with increases, which increases the probability that the next marble selected will be green.\n\n\n\n\n\n\n\n\n\nTable 2.26: Bayes table given two green marbles in Example 2.57. The likelihood is the probability of selecting two green marbles given each of the boxes.\n\n\n\n\n\n\nGreen\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\n0\n0.1667\n0.0\n0.0000\n0.00\n\n\n1\n0.1667\n0.0\n0.0000\n0.00\n\n\n2\n0.1667\n0.1\n0.0167\n0.05\n\n\n3\n0.1667\n0.3\n0.0500\n0.15\n\n\n4\n0.1667\n0.6\n0.1000\n0.30\n\n\n5\n0.1667\n1.0\n0.1667\n0.50\n\n\nsum\n1.0000\nNA\n0.3333\n1.00\n\n\n\n\n\n\n\n\nThe probabilities we computed in Solution 2.58 are examples of “predictive probabilities”; the value is part 1 is a prior predictive probability and the values in parts 2 and 3 are posterior predictive probabilities. Recall that prior or posterior probabilities assess the uncertainty of the different hypotheses or cases either before (prior) or after (posterior) observing some data. On the other hand, prior or posterior predictive probabilities assess the probability of potential data—while also accounting for the uncertainty of the hypotheses or cases—either before (prior predictive) or after (posterior predictive) observing some data.\n\n\n2.6.7 Conditional probabilities are probabilities\nConditioning on an event \\(E\\) can be viewed as a change in the probability measure49 on \\(\\Omega\\), from \\(\\textrm{P}(\\cdot)\\) to \\(\\textrm{P}(\\cdot|E)\\). That is, the original probability measure \\(\\textrm{P}(\\cdot)\\) assigns probability \\(\\textrm{P}(A)\\), a number, to event \\(A\\), while the conditional probability measure \\(\\textrm{P}(\\cdot |E)\\) assigns probability \\(\\textrm{P}(A|E)\\), a possibly different number, to event \\(A\\). Switching to \\(\\textrm{P}(\\cdot |E)\\) resembles the following.\n\nOutcomes50 in \\(E^c\\) are assigned probability 0 under \\(\\textrm{P}(\\cdot|E)\\). If \\(A\\) consists only of outcomes not in \\(E\\), i.e., if \\(A\\subseteq E^c\\), then \\(\\textrm{P}(A\\cap E)=0\\) so \\(\\textrm{P}(A|E)=0\\).\nThe probabilities of outcomes in \\(E\\) are rescaled so that they comprise 100% of the probability conditional on \\(E\\), i.e. so that \\(\\textrm{P}(E|E)=1\\). This is the effect of dividing by \\(\\textrm{P}(E)\\). For example, if \\(A, B\\subseteq E\\) and \\(\\textrm{P}(A)=2\\textrm{P}(B)\\), then also \\(\\textrm{P}(A|E)=2\\textrm{P}(B|E)\\). That is, if event \\(A\\) is twice as likely as event \\(B\\) according to \\(\\textrm{P}(\\cdot)\\), then the same will be true according to \\(\\textrm{P}(\\cdot|E)\\) provided that the probabilities of none of the outcomes satisfying the events has been zeroed out due to conditioning on \\(E\\).\n\nConditional probabilities are probabilities. Given an event \\(E\\), the function \\(\\textrm{P}(\\cdot|E)\\) defines a valid probability measure. Analogous versions of probability rules hold for conditional probabilities, just condition on event \\(E\\) everywhere.\n\n\\(0 \\le \\textrm{P}(A|E) \\le 1\\) for any event \\(A\\).\n\\(\\textrm{P}(\\Omega|E)=1\\). Moreover, \\(\\textrm{P}(E|E) = 1\\).\nIf events \\(A_1, A_2, \\ldots\\) are disjoint (i.e. \\(A_i \\cap A_j = \\emptyset, i\\neq j\\)) then \\[\n\\textrm{P}(A_1 \\cup A_2 \\cup \\cdots |E) = \\textrm{P}(A_1|E) + \\textrm{P}(A_2|E) + \\cdots\n\\]\n\\(\\textrm{P}(A^c|E) = 1-\\textrm{P}(A|E)\\). (Be careful! Do not confuse \\(\\textrm{P}(A^c|E)\\) with \\(\\textrm{P}(A|E^c)\\).)\n\\(\\textrm{P}(A|E) = \\textrm{P}(A |C_1\\cap E)\\textrm{P}(C_1| E) + \\textrm{P}(A | C_2\\cap E)\\textrm{P}(C_2|E) + \\textrm{P}(A | C_3\\cap E)\\textrm{P}(C_3|E) + \\cdots\\)\n\nAll probabilities are conditional on some information. The probability measure \\(\\textrm{P}\\) assigns probabilities that reflect all assumptions and information about the random phenomenon. When new information becomes available we revise our probabilities. The probability measure \\(\\textrm{P}(\\cdot |E)\\) assigns probabilities that reflect all assumptions and information about the random phenomenon, including the information that event \\(E\\) occurs. Our revised probabilities must still satisfy the logical consistency conditions required by the probability axioms, so \\(\\textrm{P}(\\cdot |E)\\) must be a valid probability measure.\nLike probabilities, conditional probabilities can be interpreted as long run relative frequencies or subjective probabilities. Imagine repeating the random phenomenon a large number of times. The unconditional probability \\(\\textrm{P}(A)\\) can be interpreted as the proportion of repetitions where event \\(A\\) occurs. The conditional probability \\(\\textrm{P}(A|E)\\) can be interpreted as the proportion of repetitions on which event \\(E\\) occurs where event \\(A\\) occurs. From the subjective viewpoint, \\(\\textrm{P}(A)\\) represents the relative plausibility of event \\(A\\), while \\(\\textrm{P}(A|E)\\) represents the relative plausibility of event \\(A\\) given that event \\(E\\) occurs.\n\n\n2.6.8 Conditional distributions (a brief introduction)\nThe probability distribution of a random variable describes the possible values that the random variable can take and the relative likelihoods or plausibilities of these values. A conditional distribution revises this description to reflect newly available information.\n\n\n\n\n\n\n\nExample 2.59 Continuing Example 2.41. Roll a fair four-sided die twice and let \\(X\\) be the sum of the two rolls, and let \\(Y\\) be the larger of the two rolls. We have previously found the joint and marginal distributions of \\(X\\) and \\(Y\\), displayed in Table 2.27; marginal probabilities of \\(X\\) values are in the “Total” column, and marginal probabilities of \\(Y\\) values are in the “Total” row.\n\nCompute and interpret in context \\(\\textrm{P}(X=6|Y=4)\\).\nInterpret \\(\\textrm{P}(X=6|Y=4)\\) as a long run relative frequency.\nConstruct a table and plot to represent the conditional distribution of \\(X\\) given \\(Y=4\\) by “slicing and renormalizing”.\nInterpret the the conditional distribution of \\(X\\) given \\(Y=4\\) as a long run relative frequency distribution.\nConstruct a table and plot to represent the conditional distribution of \\(X\\) given \\(Y=3\\).\nConstruct a table and plot to represent the conditional distribution of \\(X\\) given \\(Y=2\\).\nConstruct a table and plot to represent the conditional distribution of \\(X\\) given \\(Y=1\\).\nCompute and interpret \\(\\textrm{P}(Y=4|X=6)\\).\nConstruct a table and plot to represent the distribution of \\(Y\\) given \\(X=6\\).\nConstruct a table and plot to represent the distribution of \\(Y\\) given \\(X=5\\).\nConstruct a table and plot to represent the distribution of \\(Y\\) given \\(X=4\\).\n\n\n\n\n\n\n\n\nTable 2.27: Two-way table representation of joint and marginal distributions of \\(X\\) and \\(Y\\), the sum and the larger (or common value if a tie) of two rolls of a fair four-sided die. Possible values of \\(X\\) are in the leftmost column; possible values of \\(Y\\) are in the top row.\n\n\n\n\n\n\\((x, y)\\)\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\nTotal\n\n\n2\n1/16\n0\n0\n0\n1/16\n\n\n3\n0\n2/16\n0\n0\n2/16\n\n\n4\n0\n1/16\n2/16\n0\n3/16\n\n\n5\n0\n0\n2/16\n2/16\n4/16\n\n\n6\n0\n0\n1/16\n2/16\n3/16\n\n\n7\n0\n0\n0\n2/16\n2/16\n\n\n8\n0\n0\n0\n1/16\n1/16\n\n\nTotal\n1/16\n3/16\n5/16\n7/16\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.59. \n\nRemember that \\(\\{X=6\\}\\) and \\(\\{Y=4\\}\\) are events, so we use the definition of conditional probability for events. \\[\n\\textrm{P}(X = 6 | Y = 4) =\\frac{\\textrm{P}(X = 6, Y = 4)}{\\textrm{P}(Y=4)} = \\frac{2/16}{7/16} = 2/7 =0.286\n\\] The conditional probability that the sum of the rolls is 6 given that the larger roll is 4 is 2/7.\nWe can roll a pair of fair four-sided dice and measure the sum and larger of the rolls. If we repeat this process many times then we would expect the sum to be 6 on 28.6% of the repetitions for which the larger roll is 4. That is, among pairs of rolls of a fair four-sided die that result in a larger roll of 4, the sum of the rolls is 6 in 28.6% of these pairs.\nWe could find \\(\\textrm{P}(X= x|Y=4)\\) as in the previous part for each of the possible values of \\(x\\). We can also slice the column of the joint distribution table corresponding to \\(Y=4\\), and then renormalize. If \\(Y = 4\\) then \\(X\\) is either 5, 6, 7, or 8; \\(Y\\) is equally likely to be 5, 6, or 7, and each of those values is twice as likely as 8. That is, the joint probabilities in the \\(Y=4\\) column (slice) are in a 2:2:2:1 ratio for the values 5, 6, 7, 8, and renormalizing yields probabilities of 2/7, 2/7, 2/7, 1/7. The table below displays the conditional distribution of \\(X\\) given \\(Y=4\\). Note well that this is a distribution of values of \\(X\\).\n\n\n\n\\(x\\)\n\\(\\textrm{P}(X = x|Y = 4)\\)\n\n\n\n\n5\n2/7\n\n\n6\n2/7\n\n\n7\n2/7\n\n\n8\n1/7\n\n\n\nWe can roll a pair of fair four-sided dice and measure the sum and larger of the rolls. If we repeat this process many times then among only the repetitions for which the larger roll is 4 we would expect the sum to be 5 on 28.6%, 6 on 28.6%, 7 on 28.6%, and 8 on 14.3% of these repetitions.\nSlice the column of the joint distribution table corresponding to \\(Y=3,\\) and then renormalize. Given \\(Y=3,\\) \\(X\\) is equally likely to be either 4 or 5, and each of those values is twice as likely as 6. Note that changing the condition from \\(\\{Y=4\\}\\) to \\(\\{Y=3\\}\\) changes the possible values of \\(X\\), along with their probabilities.\n\n\n\n\\(x\\)\n\\(\\textrm{P}(X = x | Y = 3)\\)\n\n\n\n\n4\n2/5\n\n\n5\n2/5\n\n\n6\n1/5\n\n\n\nSlice the column of the joint distribution table corresponding to \\(Y=2,\\) and then renormalize. Given \\(Y=2,\\) \\(X\\) is twice as likely to be 3 than 4.\n\n\n\n\\(x\\)\n\\(\\textrm{P}(X = x | Y = 2)\\)\n\n\n\n\n3\n2/3\n\n\n4\n1/3\n\n\n\nGiven \\(Y=1,\\) \\(X\\) is equal to 2 with probability 1: \\(\\textrm{P}(X = 2 | Y = 1)=1\\).\nRemember that \\(\\textrm{P}(X = 6 | Y = 4)\\) and \\(\\textrm{P}(Y = 4 | X = 6)\\) measure different probabilities. \\[\n\\textrm{P}(Y = 4 | X = 6) =\\frac{\\textrm{P}(X = 6, Y = 4)}{\\textrm{P}(X=6)} = \\frac{2/16}{3/16} = 2/3 =0.667\n\\] The conditional probability that the larger roll is 4 given that the sum of the rolls is 6 given is 2/3.\nWe could find \\(\\textrm{P}(Y=y|X = 6)\\) for each possible value of \\(Y\\) as in the previous part. We can also slice the row of the joint distribution table corresponding to \\(X=6\\), and then renormalize. If \\(X = 6\\) then \\(Y\\) is either 3 or 4, and \\(Y\\) is twice as likely to be 4 than 3. The table below represents the conditional distribution of \\(Y\\) given \\(X = 6\\). Note that this is a distribution of values of \\(Y\\).\n\n\n\n\\(y\\)\n\\(\\textrm{P}(Y = y | X = 6)\\)\n\n\n\n\n3\n1/3\n\n\n4\n2/3\n\n\n\nSlice the row of the joint distribution table corresponding to \\(X=5\\), and then renormalize. If \\(X=5\\) then \\(Y\\) is equally likely to be 3 or 4.\n\n\n\n\\(y\\)\n\\(\\textrm{P}(Y = y | X = 5)\\)\n\n\n\n\n3\n1/2\n\n\n4\n1/2\n\n\n\nSlice the row of the joint distribution table corresponding to \\(X=4\\), and then renormalize. If \\(X=4\\) then \\(Y\\) is twice as likely to be 3 than 2. Note that changing the condition from \\(\\{X=5\\}\\) to \\(\\{X=4\\}\\) changes the possible values of \\(Y\\), along with their probabilities.\n\n\n\n\\(y\\)\n\\(\\textrm{P}(Y = y | X = 5)\\)\n\n\n\n\n2\n1/3\n\n\n3\n2/3\n\n\n\n\n\n\n\n\nThe conditional distribution of \\(Y\\) given \\(X=x\\) is the distribution of \\(Y\\) values over only those outcomes for which \\(X=x\\). It is a distribution on values of \\(Y\\) only; treat \\(x\\) as a fixed constant when conditioning on the event \\(\\{X=x\\}\\).\nConditional distributions can be obtained from a joint distribution by slicing and renormalizing. The conditional distribution of \\(Y\\) given \\(X=x\\), where \\(x\\) represents a particular number, can be thought of as:\n\nthe slice of the joint distribution corresponding to \\(X=x\\), a distribution on values of \\(Y\\) alone with \\(X=x\\) fixed\nrenormalized so that the slice accounts for 100% of the probability over the possible values of \\(Y\\)\n\nThe shape of the conditional distribution of \\(Y\\) given \\(X=x\\) is determined by the shape of the slice of the joint distribution over values of \\(Y\\) for the fixed \\(x\\).\nFor example, consider the joint distribution of \\(X\\) and \\(Y\\) in Example 2.59, depicted in Figure 2.18. To find the conditional distribution of \\(X\\) given \\(Y=4\\), remove the slice corresponding to \\(y=4\\) in Figure 2.18, and then renormalize to obtain the plot in the bottom right of Figure 2.24.\nFor each fixed \\(x\\), the conditional distribution of \\(Y\\) given \\(X=x\\) is a different distribution on values of the random variable \\(Y\\). There is not one “conditional distribution of \\(Y\\) given \\(X\\)”, but rather a family of conditional distributions of \\(Y\\) given different values of \\(X\\). In Example 2.59, Figure 2.25 depicts the conditional distribution of \\(Y\\) given \\(X=x\\) for each value \\(x\\) of \\(X\\), and Figure 2.24 depicts the conditional distribution of \\(X\\) given \\(Y=y\\) for each value \\(y\\) of \\(Y\\). Notice how each conditional distribution corresponds to a renormalized slice of the joint distribution depicted in Figure 2.18. We can also think of conditioning as slicing (and renormalizing) the joint distribution depicted in the tile plot in Figure 2.19, just remember that color represents probability in the tile plot.\n\n\n\n\n\n\n\n\nFigure 2.24: Impulse plots representing the family of conditional distributions of \\(X\\) given \\(Y\\) in Example 2.59. Each plot represents a conditional distribution of \\(X\\) given \\(Y=y\\) for a particular value of \\(y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.25: Impulse plots representing the family of conditional distributions of \\(Y\\) given \\(X\\) in Example 2.59). Each plot represents a conditional distribution of \\(Y\\) given \\(X=x\\) for a particular value of \\(x\\)\n\n\n\n\n\nWe can also depict families of conditional distributions in mosaic plots; see Figure 2.26. A mosaic plot represents a family of conditional distributions where color represents the possible values of one variable and area represents probability.\n\n\n\n\n\n\nWarning\n\n\n\nBe careful to distinguish between mosaic plots (like Figure 2.26) and tile plots (like Figure 2.19). A tile plot represents a joint distribution and color represents probability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Conditional distributions of \\(Y\\) given each value of \\(X\\); color represents values of \\(Y\\).\n\n\n\n\n\n\n\n\n\n\n\n(b) Conditional distributions of \\(X\\) given each value of \\(Y\\); color represents values of \\(X\\).\n\n\n\n\n\n\n\nFigure 2.26: Mosaic plots for Example 2.59, where \\(X\\) is the sum and \\(Y\\) is the max of two rolls of a fair four-sided die.\n\n\n\n\n\n\n\n\n\n\nExample 2.60 Continuing Example 2.59.\n\nCompute the probability-weighted average value of \\(X\\) given \\(Y=4\\).\nInterpret the value from the previous part as a long run average value in context.\nWithout doing any calculations, determine if the probability-weighted average value of \\(X\\) given \\(Y=3\\) is greater than, less than, or equal to the value from part 1.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.60. \n\nMultiply each possible of \\(X\\) by its conditional probability given \\(Y=4\\) and sum \\[\n\\small{\n5 \\times 2/7 + 6 \\times 2/7 + 7 \\times 2/7 + 8 \\times 1/7 = 44/7 = 6.286\n}\n\\]\nWe can roll a pair of fair four-sided dice and measure the sum and larger of the rolls. If we repeat this process many times and average the values of the sum for repetitions with a larger roll of 4 we would expect the average to be around 6.286.\nThe probability-weighted average value of \\(X\\) given \\(Y=3\\) is less than the probability-weighted average value of \\(X\\) given \\(Y=4\\) is greater than. Compare the conditional distributions; \\(X\\) tends to be larger if \\(Y=4\\) than if \\(Y=3\\).\n\n\n\n\n\nEach conditional distribution is a distribution, so we can summarize its characteristics, such as expected value. The value in part 1 of Example 2.60 is the conditional expected value of \\(X\\) given \\(Y=4\\), denoted \\(\\textrm{E}(X|Y=4)\\). The conditional expected value of \\(Y\\) given \\(X=x\\) represents the long run average of values of \\(Y\\) over only \\((X, Y)\\) pairs with \\(X=x\\). Since each value of \\(x\\) typically corresponds to a different conditional distribution of \\(Y\\) given \\(X=x\\), the conditional expected value will typically be a function of \\(x\\).\nWe will explore conditioning in more detail throughout the book, including conditional distributions when continuous random variables are involved. We will also see how to use conditioning as a problem-solving tool.\n\n\n2.6.9 Exercises\n\nExercise 2.17 Each question on a multiple choice test has four options. You know with certainty the correct answers to 70% of the questions. For 20% of the questions, you can eliminate two of the incorrect choices with certainty, but you guess at random among the remaining two options. For the remaining 10% of questions, you have no idea and guess one of the four options at random.\nRandomly select a question from this test. What is the probability that you answer the question correctly?\n\nConstruct an appropriate twoway table and use it to find the probability of interest.\nFor any given question on the exam, your probability of answering it correctly is either 1, 0.5, or 0.25, depending on if you know it, can eliminate two choices, or are just guessing. How does your probability of correcting answering a randomly selected question relate to these three values? Which value — 1, 0.5, or 0.25 —is the overall probability closest to, and why?\n\n\n\nExercise 2.18 Imagine a light that flashes every few seconds51. The light randomly flashes green with probability 0.75 and red with probability 0.25, independently from flash to flash.\n\nWrite down a sequence of G’s (for green) and R’s (for red) to predict the colors for the next 40 flashes of this light. Before you read on, please take a minute to think about how you would generate such a sequence yourself.\nMost people produce a sequence that has 30 G’s and 10 R’s, or close to those proportions, because they are trying to generate a sequence for which each outcome has a 75% chance for G and a 25% chance for R. That is, they use a strategy in which they predict G with probability 0.75, and R with probability 0.25. How well does this strategy do? Compute the probability of correctly predicting any single item in the sequence using this strategy.\nDescribe a better strategy. (Hint: can you find a strategy for which the probability of correctly predicting any single flash is 0.75?)\n\n\n\nExercise 2.19 The ELISA test for HIV was widely used in the mid-1990s for screening blood donations. As with most medical diagnostic tests, the ELISA test is not perfect. If a person actually carries the HIV virus, experts estimate that this test gives a positive result 97.7% of the time. (This number is called the sensitivity of the test.) If a person does not carry the HIV virus, ELISA gives a negative (correct) result 92.6% of the time (the specificity of the test). Estimates at the time were that 0.5% of the American public carried the HIV virus.\nSuppose that a randomly selected American tests positive; we are interested in the conditional probability that the person actually carries the virus.\n\nBefore proceeding, make a guess for the probability in question.\nDenote the probabilities provided in the setup using proper notation\nConstruct an appropriate two-way table and use it to compute the probability of interest.\nConstruct a Bayes table and use it to compute the probability of interest.\nExplain why this probability is small, compared to the sensitivity and specificity.\nBy what factor has the probability of carrying HIV increased, given a positive test result, as compared to before the test?\nNow suppose that 5% of individuals in a high-risk group carry the HIV virus. Consider a randomly selectd person from this group who takes the test. Given that the test is positive, how many times more likely is it for the person not to have HIV than to have it? Answer without first computing a two-way or Bayes table.\nUsing the result from the previous part, compute the conditional probability that a person in this risk group who tests positive has HIV.\nIs the posterior probability influenced by the prior probability? Discuss.\n\n\n\nExercise 2.20 Consider three tennis players A, B, and C52. One of these players is better than the other two, who are equally good/bad. When the best player plays either of the others, she has a 2/3 probability of winning the match. When the other two players play each other, each has a 1/2 probability of winning the match. But you do not know which player is the best. Based on watching the players warm up, you start with subjective probabilities of 0.5 that A is the best, 0.35 that B is the best, and 0.15 that C is the best. (Note: the fact that these are subjective probabilities doesn’t change at all how you would solve the problems.) A and B will play the first match.\n\nSuppose that A beats B in the first match. Compute your posterior probability that each of A, B, C is best given that A beats B in the first match.\nCompare the posterior probabilities from the previous part to the prior probabilities. Explain how your probabilities changed, and why that makes sense.\nSuppose instead that B beats A in the first match. Compute your posterior probability that each of A, B, C is best given that B beats A in the first match.\nCompare the posterior probabilities from the previous part to the prior probabilities. Explain how your probabilities changed, and why that makes sense.\nNow suppose again that A beats B in the first match, and also that A beats C in the second match.\nCompute your posterior probability that each of A, B, C is best given the results of the first two matches. (Hint: use as the prior your posterior probabilities from the previous part.) Explain how your probabilities changed, and why that makes sense.\n\n\n\nExercise 2.21 Continuing Exercise 2.20. Suppose A will play B in the first match.\n\nBefore any matches, if you had to choose the one player you think is best, who would you choose? What is your subjective probability that your choice is correct? (This should be a short answer, not requiring any calculations. The main reason to think about this is to compare to the last part.)\nCompute your subjective probability that A will beat B in the first match.\nIf A beats B in the first match, you will update your subjective probabilities so they are: 0.6349 that A is the best, 0.2222 that B is the best, and 0.1429 that C is the best. (See Exercise 2.20.) Suppose that A beats B in the first match. If you had to choose the one player you think is best based on your updated subjective probabilities, who would you choose? What is your subjective probability that your choice is correct given that A beats B in the first match?\nIf B beats A in the first match, you will update your subjective probabilities so they are: 0.3509 that A is the best, 0.4912 that B is the best, and 0.1579 that C is the best. (See Exercise 2.20.) Suppose that B beats A in the first match. If you had to choose the one player you think is best based on your updated subjective probabilities, who would you choose? What is your subjective probability that your choice is correct given that B beats A in the first match?\nAfter the first match you make your choice of who you think is the best player. Compute your subjective probability that your choice is correct. (Hint: this should be a single number, but you need to consider the two cases.) Compare to the first part; what is the “value” of observing the winner of the first match?\n\n\n\nExercise 2.22 Continuing Exercise 2.16.\nThe latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1. Suppose that each package is equally likely to contain any of the 3 prizes, regardless of the contents of other packages. There are 27 possible, equally likely outcomes\n\nFind the conditional distribution of \\(Y\\) given \\(X=x\\) for each possible value of \\(x\\) of \\(X\\).\nCompute and interpret \\(\\text{E}(Y|X=x)\\) for each possible value of \\(x\\) of \\(X\\).\nFind the conditional distribution of \\(X\\) given \\(Y=y\\) for each possible value of \\(y\\) of \\(Y\\).\nCompute and interpret \\(\\text{E}(X|Y=y)\\) for each possible value of \\(y\\) of \\(Y\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-independence",
    "href": "language-probability.html#sec-independence",
    "title": "2  The Language of Probability",
    "section": "2.7 Independence",
    "text": "2.7 Independence\nWe revise probabilities of events and distributions of random variables when new information becomes available. In this section we investigate situations where conditioning on information does not change probabilities or distributions.\n\n2.7.1 Independence of two events\nIn general, the conditional probability of event \\(A\\) given some other event \\(B\\) is usually different from the unconditional probability of \\(A\\); that is, in general \\(\\textrm{P}(A | B) \\neq \\textrm{P}(A)\\). Knowledge of the occurrence of event \\(B\\) typically influences the probability of event \\(A\\), and vice versa. If so, we say that events \\(A\\) and \\(B\\) are dependent.\nHowever, in some situations knowledge of the occurrence of one event does not influence the probability of another. For example, if a coin is flipped twice then knowing that the first flip landed on heads does not change the probability that the second flips lands on heads. In such situations we say the events are independent.\n\n\n\n\n\n\n\nExample 2.61 Consider the following hypothetical data.\n\n\n\n\n\n\n\n\n\n\nDemocrat (\\(D\\))\nNot Democrat (\\(D^c\\))\nTotal\n\n\n\n\nLoves puppies (\\(L\\))\n180\n270\n450\n\n\nDoes not love puppies (\\(L^c\\))\n20\n30\n50\n\n\nTotal\n200\n300\n500\n\n\n\nSuppose a person is selected uniformly at random from this group. Let \\(L\\) be the event that the selected person loves puppies and let \\(D\\) be the event that the selected person is a Democrat.\n\nCompute and interpret \\(\\textrm{P}(L)\\).\nCompute and interpret \\(\\textrm{P}(L|D)\\).\nCompute and interpret \\(\\textrm{P}(L|D^c)\\).\nWhat do you notice about \\(\\textrm{P}(L)\\), \\(\\textrm{P}(L|D)\\), and \\(\\textrm{P}(L|D^c)\\)?\nCompute and interpret \\(\\textrm{P}(D)\\).\nCompute and interpret \\(\\textrm{P}(D|L)\\).\nCompute and interpret \\(\\textrm{P}(D|L^c)\\).\nWhat do you notice about \\(\\textrm{P}(D)\\), \\(\\textrm{P}(D|L)\\), and \\(\\textrm{P}(D|L^c)\\)?\nCompute and interpret \\(\\textrm{P}(D \\cap L)\\).\nWhat is the relationship between \\(\\textrm{P}(D \\cap L\\)) and \\(\\textrm{P}(D)\\) and \\(\\textrm{P}(L)\\)?\nWhen randomly selecting a person from this particular group, would you say that events \\(D\\) and \\(L\\) are independent? Why?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.61. \n\nThe probability that the randomly selected person loves puppies is \\(\\textrm{P}(L)=450/500=0.9\\).\nThe conditional probability that the randomly selected person loves puppies given that the person is a Democrat is \\(\\textrm{P}(L|D)=180/200=0.9\\).\nThe conditional probability that the randomly selected person loves puppies given that the person is not a Democrat is \\(\\textrm{P}(L|D^c)=270/300=0.9\\).\n\\(\\textrm{P}(L)=\\textrm{P}(L|D)=\\textrm{P}(L|D^c)=0.9\\). Regardless of whether or not the person is a Democrat the probability that they love puppies is 0.9, the overall probability that a person loves puppies.\nThe probability that the randomly selected person is a Democrat is \\(\\textrm{P}(D)=200/500=0.4\\).\nThe conditional probability that the randomly selected person is a Democrat given that the person loves puppies is \\(\\textrm{P}(D|L)=180/450=0.4\\).\nThe conditional probability that the randomly selected person is a Democrat given that the person does not love puppies is \\(\\textrm{P}(D|L^c)=20/50=0.4\\).\n\\(\\textrm{P}(D)=\\textrm{P}(D|L)=\\textrm{P}(D|L^c)=0.4\\). Regardless of whether or not the person loves puppies the probability that the person is a Democrat is 0.4, the overall probability that a person is a Democrat.\nThe probability that the randomly selected person is a Democrat and loves puppies is \\(\\textrm{P}(D \\cap L)=180/500=0.36\\).\n\\(\\textrm{P}(D \\cap L) = 0.36 = (0.4)(0.9)=\\textrm{P}(D)\\textrm{P}(L)\\). In this case, the joint probability is a product of the marginal probabilities.\nYes, the events \\(D\\) and \\(L\\) are independent. Knowing whether or not the person is a Democrat does not change the probability that the person loves puppies, and vice versa.\n\n\n\n\n\n\nDefinition 2.8 For a probability space with probability measure \\(\\textrm{P}\\), two events \\(A\\) and \\(B\\) are53 independent if \\(\\textrm{P}(A \\cap B) = \\textrm{P}(A)\\textrm{P}(B)\\).\n\nIn general, the multiplication rule says \\[\\begin{align*}\n\\textrm{P}(A \\cap B) & = \\textrm{P}(A|B)\\textrm{P}(B)\\\\\n\\text{Joint} & = \\text{Conditional}\\times\\text{Marginal}\n\\end{align*}\\] For independent events, the multiplication rule simplifies \\[\\begin{align*}\n\\text{If $A$ and $B$ are independent then } && \\textrm{P}(A \\cap B) & = \\textrm{P}(A)\\textrm{P}(B)\\\\\n\\text{If independent then } && \\text{Joint} & = \\text{Product of Marginals}\n\\end{align*}\\]\n\n\n2.7.2 Interpreting independence\nIntuitively, events \\(A\\) and \\(B\\) are independent if the knowing whether or not one occurs does not change the probability of the other. The following lemma54 formalizes this idea.\n\nLemma 2.9 (Equivalent conditions for independence of two events) For a probability space with probability measure \\(\\textrm{P}\\) the following statements are equivalent55 for events \\(A\\) and \\(B\\) (with \\(0&lt;\\textrm{P}(A)&lt;1\\) and \\(0&lt;\\textrm{P}(B)&lt;1\\)).\n\n\\[\\begin{align*}\n\\text{$A$ and $B$} & \\text{ are independent} & &\\\\\n\\textrm{P}(A \\cap B) & = \\textrm{P}(A)\\textrm{P}(B) & & \\\\\n\\textrm{P}(A|B) & = \\textrm{P}(A) & & \\\\\n\\textrm{P}(A|B) & = \\textrm{P}(A|B^c) & & \\\\\n\\textrm{P}(B|A) & = \\textrm{P}(B) & & \\\\\n\\textrm{P}(B|A) & = \\textrm{P}(B|A^c) & &\\\\\n\\textrm{P}(A^c \\cap B) & = \\textrm{P}(A^c)\\textrm{P}(B) & & \\text{that is, $A^c$ and $B$ are independent}\\\\\n\\textrm{P}(A \\cap B^c) & = \\textrm{P}(A)\\textrm{P}(B^c) & & \\text{that is, $A$ and $B^c$ are independent}\\\\\n\\textrm{P}(A^c \\cap B^c) & = \\textrm{P}(A^c)\\textrm{P}(B^c) & & \\text{that is, $A^c$ and $B^c$ are independent}\n\\end{align*}\\]\n\n\n\n\n\n\n\nExample 2.62 Figure 2.27 displays four mosaic plots, each representing probabilities corresponding to two events \\(A\\) and \\(B\\). Which of the mosaic plots represent independent events?\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.27: Four different mosaic plots for two events \\(A\\) and \\(B\\). Example 2.62 discusses which plots represent independent events.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.62. The bottom two plots represent independent events. In these situations \\(\\textrm{P}(B|A) = \\textrm{P}(B|A^c) = \\textrm{P}(B)\\).\n\n\n\n\n\n\n\n\n\n\n\nExample 2.63 Continuing Example 2.52. In which of the three scenarios represented in Figure 2.23 are events \\(A\\) and \\(B\\) independent? Try your intuition first, and then determine which scenarios represent independence by computing and comparing appropriate probabilities.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.63. We can check any one of the conditions for independence in Lemma 2.9. We’ll compute and compare \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(A |B)\\) for each scenario. In each case, \\(\\textrm{P}(A)=4/16\\). Condition on event \\(B\\) by zooming in on the blue slice, and see if \\(\\textrm{P}(A|B)\\) is the same as \\(\\textrm{P}(A)\\).\n\nLeft: \\(\\textrm{P}(A|B)=0\\neq 4/16 = \\textrm{P}(A)\\). Therefore, events \\(A\\) and \\(B\\) are not independent.\nMiddle: \\(\\textrm{P}(A|B) = 2/4\\neq 4/16 = \\textrm{P}(A)\\). Therefore, events \\(A\\) and \\(B\\) are not independent.\nRight: \\(\\textrm{P}(A|B) = 1/4= 4/16 = \\textrm{P}(A)\\). Therefore, events \\(A\\) and \\(B\\) are independent. The ratio of yellow to total is the same as the ratio of the yellow (green) part of blue to blue. If we zoom into the blue part of the picture (slice) and then resize it to the size of the original picture (renormalize), then the yellow (green) part takes up 1/4 of the area just as the yellow part did in the original picture.\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nDo not confuse “disjoint” with “independent”. Disjoint means two events do not “overlap”. Independence means two events “overlap in just the right way”. You can pretty much forget “disjoint” exists; you will naturally apply the addition rule for disjoint events correctly without even thinking about it. Independence is much more important and useful, but also requires more care.\n\n\n\n\n\n\n\n\n\nExample 2.64 Roll two fair four-sided dice, one green and one gold. There are 16 total possible outcomes (roll on green, roll on gold), all equally likely. Consider the event \\(E=\\{\\text{the green die lands on 1}\\}\\). Answer the following questions by computing and comparing appropriate probabilities.\n\nConsider \\(A=\\{\\text{the gold die lands on 4}\\}\\). Are \\(A\\) and \\(E\\) independent?\nConsider \\(B=\\{\\text{the sum of the dice is 3}\\}\\). Are \\(B\\) and \\(E\\) independent?\nConsider \\(C=\\{\\text{the sum of the dice is 5}\\}\\). Are \\(C\\) and \\(E\\) independent?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.64. \\(\\textrm{P}(E)=4/16=1/4\\) since there 4 out of 16 equally likely outcomes satisfy event \\(E\\): \\(E=\\{(1, 1), (1, 2), (1, 3), (1, 4)\\}\\).\n\nThere are 4 outcomes which satisfy event \\(A=\\{(1, 4), (2, 4), (3, 4), (4, 4)\\}\\), all equally likely, only one, (1, 4), of which also satisfies event \\(E\\). \\(\\textrm{P}(E|A) = 1/4 = 4/16 = \\textrm{P}(E)\\), so events \\(A\\) and \\(E\\) are independent. Intuitively, the ratio of the \\(E\\) part of \\(A\\) to \\(A\\) is equal to the ratio of \\(E\\) to the sample space.\nThere is only 1 outcome which satisfies event \\(B=\\{(1, 1)\\}\\) and it also satisfies event \\(E\\). \\(\\textrm{P}(E|B) = 1 \\neq 4/16 = \\textrm{P}(E)\\), so events \\(A\\) and \\(E\\) are not independent. If you know the sum of the dice is 2, then the green die must have landed on 1.\nThere are 4 outcomes which satisfy event \\(C=\\{(1, 4), (2, 3), (3, 2), (4, 1)\\}\\), all equally likely, only one, (1, 4), of which also satisfies event \\(E\\). \\(\\textrm{P}(E|C) = 1/4 = 4/16 = \\textrm{P}(E)\\), so events \\(C\\) and \\(E\\) are independent. The ratio of the \\(E\\) part of \\(C\\) to \\(C\\) is the ratio of \\(E\\) to the sample space.\n\n\n\n\n\nIndependence concerns whether or not the occurrence of one event affects the probability of the other. Conditioning involves slicing and renormalizing; independence concerns whether the renormalized slice matches the original picture. Given two events it is not always obvious whether or not they are independent. When there is any doubt, be sure to check directly if one of the equivalent conditions for independence is true (that is, the directly compute the left side and right side and see if they’re equal).\n\n\n2.7.3 Independence is an assumption\nIndependence is often a reasonable assumption based on the physical properties of the random phenomenon. But remember that it is an assumption, which might or might not match reality.\n\n\n\n\n\n\n\nExample 2.65 You have just been elected president (congratulations!) and you need to choose one of four people to sing the national anthem at your inauguration: Alicia, Ariana, Beyonce, or Billie. You write their names on some cards—each name on possibly a different number of cards—shuffle the cards, and draw one. Let \\(A\\) be the event that either Alicia or Ariana is selected, and \\(B\\) be the event that either Alicia or Beyonce is selected.\nThe following questions ask you to specify probability models satisfying different conditions. You can specify the model by identifying how many cards each person’s name is written on. For each model, find the probabilities of \\(A\\), \\(B\\), and \\(A\\cap B\\), and verify whether or not events \\(A\\) and \\(B\\) are independent according to the model.\n\nSpecify a probability model according to which the events \\(A\\) and \\(B\\) are independent.\nSpecify a different probability model according to which the events \\(A\\) and \\(B\\) are independent.\nSpecify a probability model according to which the events \\(A\\) and \\(B\\) are not independent.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.65. Note that \\(A \\cap B\\) is the event that Alicia is selected.\n\nWrite each person’s name on exactly one card, so the 4 outcomes are equally likely. Let \\(\\textrm{P}\\) represent this probability measure. Then \\(\\textrm{P}(A \\cap B) = 1/4 = (2/4)(2/4)=\\textrm{P}(A)\\textrm{P}(B)\\), so \\(A\\) and \\(B\\) are independent.\n\nThe previous part involves a situation where \\((1/2)(1/2)=1/4=(2/4)(2/4)\\). We try to construct a situation where \\((1/3)(1/3)=1/9=(3/9)(3/9)\\). Suppose there are 9 cards, with Alicia on 1, Ariana and Beyonce on 2 each, and Billie on 4.\n\n\n\nOutcome\nAlicia\nAriana\nBeyonce\nBillie\n\n\n\n\nNumber of cards\n1\n2\n2\n4\n\n\nProbability\n1/9\n2/9\n2/9\n4/9\n\n\n\nLet \\(\\textrm{Q}\\) represent this probability measure. Then \\(\\textrm{Q}(A \\cap B) = 1/9 = (3/9)(3/9)=\\textrm{Q}(A)\\textrm{Q}(B)\\), so events \\(A\\) and \\(B\\) are independent. Elaborating,\n\nThere are 3 cards that satisfy \\(A\\) and 6 that don’t so \\(A\\) is 3/6 = 1/2 as likely to occur than not.\nIf \\(B\\) occurs, then it’s either Alicia (satisfies \\(A\\), 1 card) or Beyonce (does not satisfy \\(A\\), 2 cards), so given that \\(B\\) occurs then \\(A\\) is 1/2 times as likely to occur than not.\nIf \\(B\\) does not occur, then it’s either Ariana (satifies \\(A\\), 2 cards) or Billie (does not satisfy \\(A\\), 4 cards), so given that \\(B\\) does not occur then \\(A\\) is 2/4 = 1/2 times as likely to occur than not.\n\nKnowing whether or not \\(B\\) occurs doesn’t change the chance of \\(A\\) occurring, so \\(A\\) and \\(B\\) are independent according to this probability model.\nIndependence requires probabilities to overlap in just the right way. Aside from equally likely situations, if we blindly write down numbers that sum to 1 we will probably not luck into a probability measure where the events are independent. For example,\n\n\n\nOutcome\nAlicia\nAriana\nBeyonce\nBillie\n\n\n\n\nNumber of cards\n1\n2\n3\n4\n\n\nProbability\n0.1\n0.2\n0.3\n0.4\n\n\n\nLet \\(\\tilde{\\textrm{Q}}\\) represent this probability measure. Then \\(\\tilde{\\textrm{Q}}(A \\cap B) = 0.1 \\neq (0.3)(0.4)=\\tilde{\\textrm{Q}}(A)\\tilde{\\textrm{Q}}(B)\\), so events \\(A\\) and \\(B\\) are not independent. Elaborating,\n\nThere are 3 cards that satisfy \\(A\\) and 7 that don’t so \\(A\\) is 3/7 as likely to occur than not.\nIf \\(B\\) occurs, then it’s either Alicia (satisfies \\(A\\), 1 card) or Beyonce (does not satisfy \\(A\\), 3 cards), so given that \\(B\\) occurs then \\(A\\) is 1/3 times as likely to occur than not.\nIf \\(B\\) does not occur, then it’s either Ariana (satifies \\(A\\), 2 cards) or Billie (does not satisfy \\(A\\), 4 cards), so given that \\(B\\) does not occur then \\(A\\) is 2/4 = 1/2 times as likely to occur than not.\n\nKnowing whether or not \\(B\\) occurs changes the chance of \\(A\\) occurring, so \\(A\\) and \\(B\\) are not independent according to this probability model.\n\n\n\n\n\nRemember, independence is a statement about probabilities, not outcomes themselves. Given two events it is not always obvious whether or not they are independent.\nIndependence is determined by the probability measure. Events that are independent under one probability measure might not be independent under another. The probability measure represents all the assumptions about the random phenomenon. We often incorporate independence assumptions when specifying the probability measure. However, whether or not independence is a valid assumption depends on the underlying random phenomenon.\nBe sure to make a distinction between assumption and observation. For example, flip a coin some number of times. It might be reasonable to assume the coin is fair and flips are independent. In this case, the probability that the next flip lands on heads is 1/2 regardless of what you observed on the previous flips. However, if you flip a coin twenty times and it lands on heads each time, this might cast doubt on your assumption that the coin is fair.\n\n\n2.7.4 Independence of multiple events\n\n\n\n\n\n\n\nExample 2.66 Flip a fair coin twice. Let\n\n\\(A\\) be the event that the first flip lands on heads\n\\(B\\) be the event that the second flip lands on heads,\n\\(C\\) be the event that both flips land on the same side.\n\n\nAre the two events \\(A\\) and \\(B\\) independent?\nAre the two events \\(A\\) and \\(C\\) independent?\nAre the two events \\(B\\) and \\(C\\) independent?\nAre the three events \\(A\\), \\(B\\), and \\(C\\) independent?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.66. There are four equally likely outcomes \\(\\{HH, HT, TH, TT\\}\\).\n\n\\(A = \\{HH, HT\\}\\), so \\(\\textrm{P}(A) = 2/4\\)\n\\(B = \\{HH, TH\\}\\), so \\(\\textrm{P}(B) = 2/4\\)\n\\(C = \\{HH, TT\\}\\), so \\(\\textrm{P}(C) = 2/4\\)\n\n\nYes, events \\(A\\) and \\(B\\) are independent. \\(A\\cap B=\\{HH\\}\\), \\(\\textrm{P}(A\\cap B)=1/4\\), and \\(\\textrm{P}(A\\cap B)=\\textrm{P}(A)\\textrm{P}(B)\\).\nYes, events \\(A\\) and \\(C\\) are independent. \\(A\\cap C=\\{HH\\}\\), \\(\\textrm{P}(A\\cap C)=1/4\\), and \\(\\textrm{P}(A\\cap C)=\\textrm{P}(A)\\textrm{P}(C)\\).\nYes, events \\(B\\) and \\(C\\) are independent. \\(B\\cap C=\\{HH\\}\\), \\(\\textrm{P}(B\\cap C)=1/4\\), and \\(\\textrm{P}(B\\cap C)=\\textrm{P}(B)\\textrm{P}(C)\\).\nNo, even though each pair of events is independent, the collection of the three events is not. If \\(A\\) and \\(B\\) occur then we know event \\(C\\) occurs. That is, \\(\\textrm{P}(C|A \\cap B)=1\\) but \\(\\textrm{P}(C) = 1/2\\).\n\n\n\n\n\nEvents \\(A_1, A_2, A_3, \\ldots\\) are independent if:\n\nany pair of events \\(A_i, A_j, (i \\neq j)\\) satisfies \\(\\textrm{P}(A_i\\cap A_j)=\\textrm{P}(A_i)\\textrm{P}(A_j)\\),\nand any triple of events \\(A_i, A_j, A_k\\) (distinct \\(i,j,k\\)) satisfies \\(\\textrm{P}(A_i\\cap A_j\\cap A_k)=\\textrm{P}(A_i)\\textrm{P}(A_j)\\textrm{P}(A_k)\\),\nand any quadruple of events \\(A_i, A_j, A_k, A_\\ell\\) (distinct \\(i,j,k,\\ell\\)) satisfies \\(\\textrm{P}(A_i\\cap A_j\\cap A_k \\cap A_\\ell)=\\textrm{P}(A_i)\\textrm{P}(A_j)\\textrm{P}(A_k)\\textrm{P}(A_\\ell)\\),\nand so on.\n\nIntuitively, a collection of events is independent if knowing whether or not any combination of the events in the collection occur does not change the probability of any other event in the collection.\nIn particular, three events \\(A\\), \\(B\\), \\(C\\) are independent if and only if all of the following are true \\[\n\\scriptsize{\n\\textrm{P}(A\\cap B) = \\textrm{P}(A)\\textrm{P}(B), \\quad  \\textrm{P}(A\\cap C) = \\textrm{P}(A)\\textrm{P}(C),\\quad  \\textrm{P}(B\\cap C) = \\textrm{P}(B)\\textrm{P}(C),\\quad \\textrm{P}(A\\cap B\\cap C) = \\textrm{P}(A)\\textrm{P}(B)\\textrm{P}(C)\n}\n\\]\nEquivalently, it can be shown that three events \\(A\\), \\(B\\), \\(C\\) are independent if and only if all of the following56 are true.\n\\[\\begin{align*}\n& \\textrm{P}(A| B) = \\textrm{P}(A), \\quad \\textrm{P}(A| C) = \\textrm{P}(A), \\quad \\textrm{P}(B|A) = \\textrm{P}(B), \\quad \\textrm{P}(B| C) = \\textrm{P}(B), \\quad \\textrm{P}(C|A) = \\textrm{P}(C),\\\\\n& \\textrm{P}(C|B) = \\textrm{P}(C), \\quad\n\\textrm{P}(A| B\\cap C) = \\textrm{P}(A), \\quad \\textrm{P}(B|A\\cap C) = \\textrm{P}(B), \\quad \\textrm{P}(C|A\\cap B) = \\textrm{P}(C)\n\\end{align*}\\]\n\n\n2.7.5 Independence of random variables\nWe have focused on independence of events, but random variables can also be independent.\n\n\n\n\n\n\n\nExample 2.67 Continuing Example 2.59. Let \\(U_1\\) be the result of the first roll.\n\nAre the events \\(\\{U_1 = 1\\}\\) and \\(\\{X = 5\\}\\) independent?\nDo you think the random variables \\(U_1\\) and \\(X\\) are independent? Support your answer by computing and comparing appropriate probabilities.\nSuggest a random variable in this context—not \\(X\\) or \\(Y\\)—that is independent of \\(U_1\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.67. \n\nYes the events \\(\\{U_1 = 1\\}\\) and \\(\\{X = 5\\}\\). See the solution to part 3 of Example 2.64).\nIntuitively, \\(U_1\\) and \\(X\\) are not independent. But remember that independence is a statement about probabilities, so we need to compare appropriate probabilities. For example, \\(\\textrm{P}(X = 8 | U_1 = 1) = 0\\) but \\(\\textrm{P}(X = 8) = 1/16\\). Knowing that \\(U_1=1\\) changes the distribution of \\(X\\).\nIf \\(U_2\\) is the result of the second roll, then intuitively \\(U_1\\) and \\(U_2\\) are independent. \\(U_2\\) is equally likely to be 1, 2, 3, or 4, regardless of the value of \\(U_1\\).\n\n\n\n\n\nTwo random variables are independent if any event involving one of the random variables is independent of any event involving the other. Roughly, two random variables are independent if knowing the value of one does not change the distribution of the other.\n\n\n\n\n\n\n\nExample 2.68 Suppose \\(X\\) and \\(Y\\) are random variables whose joint distribution is represented by Table 2.18. Recall that we found the marginal distributions in Example 2.43.\n\nHow is \\(\\textrm{P}(X = 2, Y=1)\\) related to \\(\\textrm{P}(X = 2)\\) and \\(\\textrm{P}(Y=1)\\)? What does this imply?\nHow is the joint distribution of \\(X\\) and \\(Y\\) related to the marginal distributions of \\(X\\) and \\(Y\\)?\nCompute the conditional distribution of \\(Y\\) given \\(X=2\\). How does it compare to the marginal distribution of \\(Y\\)?\nCompute the conditional distribution of \\(Y\\) given \\(X=x\\) for each possible \\(x\\). What do you notice?\nCompute the conditional distribution of \\(X\\) given \\(Y=1\\). How does it compare to the marginal distribution of \\(X\\)?\nCompute the conditional distribution of \\(X\\) given \\(Y=y\\) for each possible \\(y\\). What do you notice?\nAre the random variables \\(X\\) and \\(Y\\) independent?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.68. \n\nThe joint probability is the product of the marginal probabilities, \\(\\textrm{P}(X = 2, Y=1)= 1/256 = (1/16)(1/16) = \\textrm{P}(X = 2) \\textrm{P}(Y=1)\\), so the events \\(\\{X=2\\}\\) and \\(\\{Y=1\\}\\) are independent.\nFor each possible value \\(x\\) of \\(X\\) and \\(y\\) of \\(Y\\), \\(\\textrm{P}(X = x, Y=y)= \\textrm{P}(X = x) \\textrm{P}(Y=y)\\). In short, the joint distribution of \\(X\\) and \\(Y\\) is the product of their marginal distributions.\nSlice and renormalize: the possible values of \\(Y\\) are 1, 2, 3, 4 with respective probabilities 1/6, 3/16, 5/16, 7/16. The conditional distribution of \\(Y\\) given \\(X=2\\) is the same as the marginal distribution of \\(Y\\).\nAlong each possible \\(x\\) slice, the possible values of \\(Y\\) are 1, 2, 3, 4 with respective probabilities 1/6, 3/16, 5/16, 7/16. For every possible value \\(x\\) of \\(X\\), the conditional distribution of \\(Y\\) given \\(X=x\\) is the same as the marginal distribution of \\(Y\\).\nSlice and renormalize: the possible values of \\(X\\) are 2, 3, 4, 5, 6, 7, 8 with respective probabilities 1/16, 2/16, 3/16, 4/16, 3/16, 2/16, 1/16. The conditional distribution of \\(X\\) given \\(Y=1\\) is the same as the marginal distribution of \\(X\\).\nAlong each possible \\(y\\) slice, the possible values of \\(X\\) are 2, 3, 4, 5, 6, 7, 8 with respective probabilities 1/16, 2/16, 3/16, 4/16, 3/16, 2/16, 1/16. For every possible value \\(y\\) of \\(Y\\), the conditional distribution of \\(X\\) given \\(Y=y\\) is the same as the marginal distribution of \\(X\\).\nYes, the random variables \\(X\\) and \\(Y\\) independent. For every possible value \\(x\\) of \\(X\\) and \\(y\\) of \\(Y\\) the events \\(\\{X=x\\}\\) and \\(\\{Y=y\\}\\) are independent. Knowing the value of one variable does not change the distribution of the other.\n\n\n\n\n\nRoughly, two random variables \\(X\\) and \\(Y\\) are independent if and only if:\n\nTheir joint distribution is the product of their marginal distributions\nThe conditional distribution of \\(X\\) given the value of \\(Y\\) is equal to the marginal distribution of \\(X\\).\nThe conditional distribution of \\(Y\\) given the value of \\(X\\) is equal to the marginal distribution of \\(Y\\).\n\nFigure 2.28 displays mosaic plots of the distributions of the two independent discrete random variables of Example 2.68. Notice that the conditional distribution of \\(X\\) is the same for each value of \\(Y\\), and vice versa.\n\n\n\n\n\n\n\n\n\n\n\n(a) Conditioning on values of \\(X\\); color represents values of \\(Y\\).\n\n\n\n\n\n\n\n\n\n\n\n(b) Conditioning on values of \\(Y\\); color represents values of \\(X\\)\n\n\n\n\n\n\n\nFigure 2.28: Mosaic plots for two independent discrete random variables \\(X\\) and \\(Y\\).\n\n\n\n\n\n2.7.6 Using independence\nRemember the general multiplication rule involves successive conditional probabilities \\[\n\\textrm{P}(A_1\\cap A_2 \\cap A_3 \\cap A_4 \\cap \\cdots) = \\textrm{P}(A_1)\\textrm{P}(A_2|A_1)\\textrm{P}(A_3|A_1\\cap A_2)\\textrm{P}(A_4|A_1\\cap A_2 \\cap A_4)\\cdots\n\\] In problems with complicated relationships, determining joint and conditional probabilities can be difficult.\nBut when events are independent, the multiplication rule simplifies greatly. \\[\n\\textrm{P}(A_1 \\cap A_2 \\cap A_3 \\cap \\cdots) = \\textrm{P}(A_1)\\textrm{P}(A_2)\\textrm{P}(A_3)\\cdots \\quad \\text{if $A_1, A_2, A_3, \\ldots$ are independent}\n\\]\nWhen a problem involves independence, you will want to take advantage of it. Work with “and” events whenever possible in order to use the multiplication rule. For example, for problems involving “at least one” (an “or” event) take the complement to obtain “none” (an “and” event).\n\n\n\n\n\n\n\nExercise 2.23 A certain system consists of four identical components. Suppose that the probability that any particular component fails is 0.1, and failures of the components occur independently of each other. Find the probability that the system fails if:\n\nThe components are connected in parallel: the system fails only if all of the components fail.\nThe components are connected in series: the system fails whenever at least one of the components fails.\nDonny Don’t says the answer to the previous part is \\(0.1 + 0.1 + 0.1 + 0.1 = 0.4\\). Explain the error in Donny’s reasoning.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.69. Let \\(F\\) be the event the system fails, and \\(F_i\\) the event that component \\(i\\) fails.\n\nIf the components are connected in parallel, \\(F=F_1 \\cap F_2 \\cap F_3 \\cap F_4\\). \\[\\begin{align*}\n\\textrm{P}(F) & = \\textrm{P}(F_1\\cap F_2\\cap F_3 \\cap F_4) & & \\\\\n& = \\textrm{P}(F_1)\\textrm{P}(F_2)\\textrm{P}( F_3)\\textrm{P}(F_4) & & \\text{independence}\\\\\n& = (0.1)(0.1)(0.1)(0.1) = 0.0001\n\\end{align*}\\]\n“At least one fails” is an “or” event: \\(F= F_1 \\cup F_2 \\cup F_3 \\cup F_4\\). With independence you want “and” events. Use the complement rule \\[\\begin{align*}\n\\textrm{P}(F) & = \\textrm{P}(\\text{at least one fails}) & & \\\\\n& = 1 - \\textrm{P}(\\text{none fails})\\ & & \\\\\n& = 1 - \\textrm{P}(F_1^c\\cap F_2^c \\cap F_3^c\\cap F_4^c) & & \\\\\n& = 1 - \\textrm{P}(F_1^c)\\textrm{P}(F_2^c)\\textrm{P}( F_3^c)\\textrm{P}(F_4^c) & & \\text{independence}\\\\\n& = 1-(0.9)(0.9)(0.9)(0.9) = 0.3439\n\\end{align*}\\]\nDonny is assuming that the component failures are disjoint, but that’s not true since multiple components could fail. Simply adding the probabilities double counts outcomes where multiple components fail. Don’t confuse “disjoint” and “independent”. It is almost always better to work with “and” events and multiplying rather than “or” events.\n\n\n\n\n\nThe complement rule is often useful in probability problems that involve finding “the probability of at least one…,” which on the surface involves unions (OR). It usually more convenient to use the complement rule and compute “the probability of at least one…” as one minus “the probability of none…”; the latter probability involves intersections (AND). Don’t forget to actually use the complement rule to get back to the original probability of interest!\n\n\n\n\n\n\nWarning\n\n\n\nWhen using the complement rule, subtracting a computed probability from 1 seems like a small computational step, but it’s an important one. Getting 90% correct on a test is very different than getting 10% correct! Unfortunately, the complement rule step is often overlooked when doing probability calculations. It’s a good idea to ask yourself if the probability you are computing should be greater than or less than 50%. If your computed value seems to be on the wrong side of 50%, check your calculations to see if you have forgotten (or misapplied) the complement rule.\n\n\n\n\n\n\n\n\n\nExample 2.69 In the Powerball lottery, a player picks five different whole numbers between 1 and 69, and another whole number between 1 and 26 that is called the Powerball.\nIn the drawing, the 5 numbers are drawn without replacement from a “hopper” with balls labeled 1 through 69, but the Powerball is drawn from a separate hopper with balls labeled 1 through 26. The player wins the jackpot if both the first 5 numbers match those drawn, in any order, and the Powerball is a match. Under this set up, there are 292,201,338 possible winning numbers.\n\nWhat is the probability the next winning number is 6-7-16-23-26, plus the Powerball number, 4.\nWhat is the probability the next winning number is 1-2-3-4-5, plus the Powerball number, 6.\nThe Powerball drawing happens twice a week. Suppose you play the same Powerball number, twice a week, every week for over 50 years. Let’s say you purchase a ticket for 6000 drawings in total. What is the probability that you win at least once?\nInstead of playing for 50 years, you decide only to play one lottery, but you buy 6000 tickets, each with a different Powerball number. What is the probability that at least one of your tickets wins? How does this compare to the previous part? Why?\nEach ticket costs 2 dollars, but the jackpot changes from drawing to drawing. Suppose you buy 6000 tickets for a single drawing. How large does the jackpot need to be for your “expected” profit to be positive? To be $100,000? (We’re ignoring inflation, taxes, transaction costs, and any changes in the rules.)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.70. \n\nEach of the possible winning numbers is equally likely, so the probability is \\(1/292,201,338\\approx 3\\times 10^{-9}\\). See Example 1.22 and the discussion following it.\nEach of the possible winning numbers is equally likely. Remember, don’t confuse a general event with a specific outcome; see Example 1.22.\nThe probability that you lose in any single drawing is \\((1-1/292201338)\\). The drawings are independent so the probability that you lose all 6000 is \\((1-1/292201338)^{6000}\\). The probability that you win at least once is \\(1 - (1-1/292201338)^{6000}\\approx 0.00002\\). If many people each play 6000 drawings, about 2 in every 100,000 people win will at least once.\nIf you play 6000 different numbers, the events that each different number wins are disjoint. So the probability you win at least once is \\(6000/292201338\\approx 0.00002\\). This is about the same as the probability in the previous part. When you play 6000 different independent drawings, there is a possibility that you win multiple times, so the events of winning in each different drawing are not disjoint. But the probability of winning multiple lotteries is so small that it’s negligible. The probability of winning any single drawing is about 1 in 300 million. The probability of winning twice in any two drawings is about 1 in 85 quadrillion.\nYou pay $12,000 in total. Let \\(w\\) be the value of the jackpot. You win either 0 or \\(w\\) so your “expected” profit is \\(w(6000/292201338)-12000\\). But this not what you expect in a single repetition. Rather, it is the profit you would expect to see on average in the long run. You probably won’t be buying 6000 tickets for a large number of drawings, so your long run average isn’t really relevant. In any case, we must have \\(w&gt;584,402,676\\) for the expected profit to be positive. Sometimes, but not often, the jackpot does get this high; even so, this just guarantees that your expected profit is positive. In order for your expected long run average profit to be greater than just $100,000, the jackpot must be over 5 billion dollars, and the largest jackpot ever was 1.6 billion. The moral: there are better things to do with $12,000 dollars.\n\n\n\n\n\n\n\n2.7.7 Exercises\n\nExercise 2.24 Maya is a basketball player who makes 40% of her three point field goal attempts. Suppose that at the end of every practice session, she attempts three pointers until she makes one and then stops. Let \\(X\\) be the total number of shots she attempts in a practice session. Assume shot attempts are independent, each with probability of 0.4 of being successful.\n\nWhat are the possible values that \\(X\\) can take? Is \\(X\\) discrete or continuous?\nCompute and interpret \\(\\text{P}(X=1)\\).\nCompute and interpret \\(\\text{P}(X=2)\\).\nCompute and interpret \\(\\text{P}(X=3)\\).\nCompute \\(\\text{P}(X&gt;3)\\) without summing the values from the previous parts. Hint: what needs to be true about the first 3 attempts for \\(X &gt; 3\\)?\n\n\n\nExercise 2.25 A very large petri dish starts with a single microorganism. After one minute, the microorganism either splits into two with probability \\(s\\), or dies. All subsequent microorganisms behave in the same way — splitting into two or dying after each minute — independently of each other.\n\nIf \\(s=3/4\\), what is the probability that the population eventually goes extinct? (Hint: condition on the first step.)\nCompute the probability that the population eventually goes extinct as a function of \\(s\\). For what values of \\(s\\) is the extinction probability 1?\n\n\n\nExercise 2.27 Consider a “best-of-5” series of games between two teams: games are played until one of the teams has won 3 games (requiring at most 5 games total). Suppose one team, team A, is better than the other, having a 0.55 probability of winning any particular game. Assume the results of the games are independent (and ignore advantage, etc). Let \\(X\\) represent the number of games played in the series. Hint: It’s helpful to first construct a two-way table of probabilities with the number of games played and which team wins, and then use it to answer the following questions. It will also help to list some outcomes, like AABA (team A wins game 1, 2, and 4, and B wins game 3).\n\nCompute the probability that team A wins the series in 3 games.\nCompute the probability that the series ends in 3 games.\nCompute the probability that team A wins the series.\nAre the events “team A wins the series” and “the series ends in 3 games” independent? Explain by comparing relevant probabilities.\nLet \\(X\\) represent the number of games played in the series. Find the distribution of \\(X\\).\n\n\nExercise 2.26 Continuing Exercise 2.20. Now we’ll consider multiple matches. Assume that the results of matches are conditionally independent given the best player.\n\nSuppose that A beats B in the first match, and also that A beats C in the second match. Construct a Bayes table to compute your posterior probability that each of A, B, C is best given the results of the first two matches. Use as the prior your posterior probabilities from part 1 of Exercise 2.20. Explain how your probabilities changed, and why that makes sense.\nNow suppose that after A beats B in the first match and A beats C in the second match, then B beats C in the third match. Construct a Bayes table to compute your posterior probability that each of A, B, C is best given the results of the first three matches. Use as the prior your posterior probabilities from the previous part. Explain how your probabilities changed, and why that makes sense.\nIn the previous parts we updated posterior probabilities after each match. What if we waited until the results of all three matches? Construct a Bayes table to find your posterior probability that each of A, B, C is best given the results of the first three matches (A beats B, A beats C, B beats C). Use your original prior probabilities from Exercise 2.20 (0.5 for A, 0.35 for B, 0.15 for C). The likelihood should now reflect the results of the three matches.\n\n\n\n2.8 Chapter exercises",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#chapter-exercises",
    "href": "language-probability.html#chapter-exercises",
    "title": "2  The Language of Probability",
    "section": "2.8 Chapter exercises",
    "text": "2.8 Chapter exercises",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#footnotes",
    "href": "language-probability.html#footnotes",
    "title": "2  The Language of Probability",
    "section": "",
    "text": "Why four-sided? Simply to make the number of possibilities a little more manageable. Rolling a four-sided die twice yields 16 possible pairs, while rolling a six-sided die yields 36 possible pairs.↩︎\nThere is no one set of universally agreed on notation, but \\(\\Omega\\) is commonly used. It is also common practice to use uppercase and lowercase letters to denote different objects, like \\(\\Omega\\) versus \\(\\omega\\).↩︎\nWe could have written the sample space as the Cartesian product \\(\\Omega = \\{1, 2, 3, 4\\} \\times\\{1, 2, 3, 4\\}\\), where the first \\(\\{1, 2, 3, 4\\}\\) set in the product represents the result of the first roll (and similarly for the second). But this Cartesian product still represents a single set of ordered pairs, and it is that single set which is the sample space corresponding to outcomes of the pair of rolls.↩︎\nWhy have we started with [0, 1] and not some other continuous interval? Because probabilities take values in \\([0, 1]\\). We will see why this is useful in more detail later.↩︎\nMathematically we can write the sample space as \\([0,60]\\times [0,60]=[0,60]^2\\), the Cartesian product \\(\\{(x, y): x \\in [0, 60], y \\in [0, 60]\\}\\), the set of ordered pairs whose components take values in \\([0, 60]\\).↩︎\nWe could also try \\([0, m]\\) where \\(m\\) is some large dollar amount providing an upper bound on the maximum possible salary. But we would need to be sure that \\(m\\) is large enough so that all possible outcomes are in the sample space \\([0, m]\\). Without knowing this bound in advance, it is convenient to just choose the unbounded interval \\([0, \\infty)\\). There is really no harm in making the sample space bigger than it needs to be, but you can run into problems if you make it too small.↩︎\nMathematically this sample space can be written as \\(\\Omega=\\{1, 2, 3\\}^\\infty\\).↩︎\na.k.a., jimmies↩︎\nTechnically, \\(\\mathcal{F}\\) is a \\(\\sigma\\)-field of subsets of \\(\\Omega\\): \\(\\mathcal{F}\\) contains \\(\\Omega\\) and is closed under countably many elementary set operations (complements, unions, intersections). This requirement ensures that if \\(A\\) and \\(B\\) are “events of interest”, then so are \\(A\\cup B\\), \\(A\\cap B\\), and \\(A^c\\). While this level of technical detail is not needed, we prefer to introduce the idea of a “collection of events” now since a probability measure is a function whose input is an event (set) rather than an outcome (point).↩︎\nA \\(d\\)-dimensional random vector \\(V\\) maps sample space outcomes to \\(d\\)-dimensional vectors, \\(V:\\Omega \\mapsto \\mathbb{R}^d\\). The output of a random vector is a vector (or tuple) of numbers.↩︎\nThroughout, we use \\(g\\) to denote a generic function, and reserve \\(f\\) to represent a probability density function (which we will encounter later). Likewise, we represent a generic function argument (or “dummy variable”) with \\(u\\), since \\(x\\) is often used to represent possible values of a random variable \\(X\\). In the context of a random variable, \\(x\\) typically represents the output of the function \\(X\\) rather than the input (which is a sample space outcome \\(\\omega\\).)↩︎\nIn Example 2.17 sample space outcomes are pairs of rolls. If we denote a generic outcome as \\(\\omega = (\\omega_1, \\omega_2)\\) then \\(X(\\omega) = X((\\omega_1, \\omega_2)) = \\omega_1 + \\omega_1\\). Similarly, \\(Y(\\omega) = Y((\\omega_1, \\omega_2)) = \\max(\\omega_1, \\omega_2)\\). But we don’t need this level of technical detail; defining \\(X\\) and \\(Y\\) in words is sufficient.↩︎\n\\(Y(\\omega) = g(X(\\omega))\\) so \\(Y\\) maps \\(\\Omega\\) to \\(\\mathbb{R}\\) via the composition of the functions \\(g\\) and \\(X\\); that is, \\(Y=g\\circ X\\) where \\((g\\circ X):\\Omega\\mapsto \\mathbb{R}\\)↩︎\nOrange you glad I didn’t say banana?↩︎\nSee the inclusion-exclusion principle↩︎\nAnd \\(\\{X = 3\\}\\) itself is short for \\(\\{\\omega\\in\\Omega:X(\\omega) = x\\}\\).↩︎\nA probability measure is a set function; its input is a set and its output is a number.↩︎\nIt’s the number of events that must be countable. The events themselves can be uncountable sets like intervals.↩︎\nThat the probability of each outcome must be 1/4 when there are four equally likely outcomes follows from the axioms, by writing \\(\\{1, 2, 3, 4\\} = \\{1\\}\\cup\\{2\\}\\cup \\{3\\}\\cup \\{4\\}\\), a union of disjoint sets, and applying countable additivity and \\(\\textrm{P}(\\Omega)=1\\). But we don’t need this level of technical detail; our intuition tells us the probability of each four equally likely outcomes is 1/4.↩︎\nProbabilities are always defined for events (sets). When we say loosely “the probability of an outcome \\(\\omega\\)” we really mean the probability of the event \\(\\{\\omega\\}\\) consisting of the single outcome \\(\\omega\\). In this example \\(\\textrm{P}(\\{1\\})=\\textrm{P}(\\{2\\})=\\textrm{P}(\\{3\\})=\\textrm{P}(\\{4\\})=1/4\\).↩︎\n\\(\\Omega = \\{1, 2, 3\\} \\cup \\{4\\}\\), a union of disjoint events, so \\(1 = \\textrm{Q}(\\Omega) = \\textrm{Q}(\\{1, 2, 3\\}) + \\textrm{Q}(\\{4\\})\\).↩︎\nBecause he’s solo.↩︎\nIt doesn’t really matter if we round or truncate to the nearest minute, but we’re truncating so we don’t treat 0 differently than the other values (technically only times in the first 30 seconds, not minute, round to 0).↩︎\nThis is one reason why probabilities are defined directly for events and not outcomes.↩︎\nProof. Since \\(\\Omega = A \\cup A^c\\) and \\(A\\) and \\(A^c\\) are disjoint the axioms imply that \\(1=\\textrm{P}(\\Omega) = \\textrm{P}(A \\cup A^c) = \\textrm{P}(A) + \\textrm{P}(A^c)\\).↩︎\nProof. If \\(A \\subseteq B\\) then \\(B = A \\cup (B \\cap A^c)\\). Since \\(A\\) and \\((B \\cap A^c)\\) are disjoint, \\(\\textrm{P}(B) = \\textrm{P}(A) + \\textrm{P}(B \\cap A^c) \\ge \\textrm{P}(A)\\).↩︎\nThe proof is easiest to see by considering a picture like the one in Figure 2.8).↩︎\nSee the inclusion-exclusion principle.↩︎\n\\(A = A\\cap \\Omega = A\\cap(C_1 \\cup C_2 \\cup \\cdots) = (A\\cap C_1)\\cup(A\\cap C_2)\\cup \\cdots\\). The \\(A\\cap C_i\\)’s are disjoint since the \\(C_i\\)’s are, and the result follows from countable additivity.↩︎\nIn this example it is logically possible for \\(\\textrm{P}(C \\cap D)\\) to be 0, but that’s not always true. For example, if \\(\\textrm{P}(A) = 0.9\\) and \\(\\textrm{P}(B) = 0.8\\), then \\(\\textrm{P}(A \\cap B)\\) must be at least 0.7 so that \\(\\textrm{P}(A \\cup B)\\le 1\\).↩︎\nA probability space is usually defined as a triple \\((\\Omega, \\mathcal{F}, \\textrm{P})\\), where \\(\\Omega\\) is the sample space, \\(\\mathcal{F}\\) is a \\(\\sigma\\)-field of subsets of \\(\\Omega\\) representing the collection of events of interest, and \\(\\textrm{P}\\) is a probability measure. Given that many events of interest involve random variables, we also include random variables in the model.↩︎\nThe values in this problem are based on a April, 2021 report by the Pew Research Center.↩︎\nBased on data from the U.S. Census Bureau↩︎\nWe generally encourage you to use two-way tables of whole number counts, but we’re using probabilities here to motivate the definition of conditional probability.↩︎\nWe have seen that “equals to” events involving continuous random variables have probability 0. We will discuss some issues related to conditioning on the value of a continuous random variable later.↩︎\nThe value only differs from the 0.24 in Example 2.46 due to rounding.↩︎\nThe value only differs from the 0.5417 in Example 2.46 due to rounding.↩︎\nIn computing these probabilities we have unconsciously applied “Bayes rule”, which we will discuss in more detail later.↩︎\nYou should really check about this birthday problem demo from The Pudding.↩︎\nWhich isn’t quite true. However, a non-uniform distribution of birthdays only increases the probability that at least two people have the same birthday. To see that, think of an extreme case like if everyone were born in September.↩︎\nSometimes students mistake this for \\((1/365)^2\\), but \\((1/365)^2\\) would be the probability that person 1 and person 2 both have a particular birthday, like the probability that both are born on January 1. There are \\(365^2\\) possible (person 1, person 2) birthday pairs, of which 365 — (Jan 1, Jan 1), (Jan 2, Jan 2), etc — result in the same birthday, so the probability of sharing a birthday is \\(365/365^2 = 1/365\\).↩︎\nProof: start with Lemma 2.5 and use the multiplication rule to write \\(\\textrm{P}(A \\cap C_1)=\\textrm{P}(A|C_1)\\textrm{P}(C_1)\\), etc.↩︎\nThey should be exactly the same; any differences are due to rounding.↩︎\nThis section only covers Bayes’ rule for events. We’ll see Bayes’ rule for distributions of random variables later. But the ideas are analogous.↩︎\nWe’re using “hypothesis” in the sense of a general scientific hypothesis, not necessarily a statistical null or alternative hypothesis.↩︎\nThe symbol \\(\\propto\\) means “is proportional to”.↩︎\nWouldn’t it also be a mistake to not consider other animals like cow? Yes, but that’s also a mistake about prior probabilities. If you forget to include an animal like cow then you’re assigning it a prior probability of 0, so its posterior probability will automatically be 0 regardless of the likelihood.↩︎\nYou still might be thinking: what about cows? Or dogs? Or moose? Or horses? Cows would have a high prior probability, and they are often very large, hair, and black. So it depends on how likely it is for a cow to be running. Depending on the prior probabilities and likelihoods, a cow—or dog or moose or horse—might end up with an even higher posterior probability than a bear. In any case, the point is that a gorilla should have a posterior probability of basically 0. “Tt’s a gorilla” was not a great initial proclamation, but maybe “it’s probably just a cow (or dog/moose/horse)” would have been a fine conclusion.↩︎\nConditioning on event \\(E\\) can also be viewed as a restiction of the sample sample from \\(\\Omega\\) to \\(E\\). However, we prefer to keep the sample space as \\(\\Omega\\) and only view conditioning as a change in probability measure. In this way, we can consider conditioning on various events as representing different probability measures all defined for the same collection of events corresponding to the same sample space.↩︎\nRemember: probabilities are assigned to events, so we are speaking loosely when we say probabilities of outcomes.↩︎\nThanks to Allan Rossman for this example.↩︎\nPlease replace A, B, and C with your favorite names. Possible choices: Ahsoka, Boba, Cassian. Ant-Man, Black Panther, Captain America. Arthur Ashe, Bjorn Borg, Chris Evert.↩︎\nTechnically, we should say “\\(\\textrm{P}\\)-independent”; see Section 2.7.3↩︎\nThe proof follows from the definitions of independence and conditional probability and properties of a probability measure. For example, \\(\\textrm{P}(A) = \\textrm{P}(A\\cap B) + \\textrm{P}(A \\cap B^c)\\) so \\(\\textrm{P}(A \\cap B^c) = \\textrm{P}(A) - \\textrm{P}(A \\cap B)\\). If \\(A\\) and \\(B\\) are independent then \\(\\textrm{P}(A \\cap B^c) = \\textrm{P}(A) - \\textrm{P}(A)\\textrm{P}(B) = \\textrm{P}(A)(1-\\textrm{P}(B)) = \\textrm{P}(A)\\textrm{P}(B^c)\\), so \\(A\\) and \\(B^c\\) are independent.↩︎\nThat is, if one statement is true then they all are true; if one statement is false, then they all are false.↩︎\nSome of these conditions are redundant. For example, \\(\\textrm{P}(A|B)=\\textrm{P}(A)\\) if and only if \\(\\textrm{P}(B|A)=\\textrm{P}(B)\\) so technically only one of those conditions needs to be verified.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-simulation.html",
    "href": "language-simulation.html",
    "title": "3  The Language of Simulation",
    "section": "",
    "text": "3.1 Tactile simulation: Boxes and spinners\nA probability model of a random phenomenon consists of a sample space of possible outcomes, associated events and random variables, and a probability measure which encapsulates the model assumptions and determines probabilities of events and distributions of random variables. We will study strategies for computing probabilities, distributions, expected values, and more, but in many situations explicit computation is difficult. Simulation provides a powerful tool for working with probability models and solving complex problems.\nSimulation involves using a probability model to artificially recreate a random phenomenon, usually using a computer. Given a probability model, we can simulate outcomes, occurrences of events, and values of random variables. Simulation can be used to approximate probabilities of events, distributions of random variables, expected values, and more.\nRecall that the probability of an event can be interpreted as a long run relative frequency. Therefore the probability of an event can be approximated by simulating—according to the assumptions of the probability model—the random phenomenon a large number of times and computing the relative frequency of repetitions on which the event occurs.\nLikewise, the expected value of a random variable can be interpreted as its long run average value, and can be approximated by simulating—according to the assumptions of the probability model—the random phenomenon a large number of times and computing the average value of the random variable over the simulated repetitions.\nIn general, a simulation involves the following steps.\nYou might ask: if we have access to the probability measure, then why do we need simulation to approximate probabilities? Can’t we just compute them? Remember that the probability measure is often only specified indirectly, e.g. “flip a fair coin ten times and count the number of heads”. In most situations the probability measure does not provide an explicit formula for computing the probability of any particular event. And in many cases, it is impossible to enumerate all possible outcomes.\nFor example, a probabilistic model of a particular Atlantic Hurricane does not provide a mathematical formula for computing the probability that the hurricane makes landfall in the U.S. Nor does the model provide a comprehensive list of the uncountably many possible paths of the hurricane. Rather, the model reflects a set of assumptions under which possible paths can be simulated to approximate probabilities of events of interest like those depicted in Figure 3.1.\nIn this chapter we will use simulation to investigate some of the problems introduced in the previous chapter. We can solve many of these problems without simulation. But we like to introduce simulation via simple examples where we know the answers so we can get comfortable with the simulation process and easily check that it works.\nWhile we generally use technology to conduct large scale simulations, it is helpful to first consider how to conduct a simulation by hand using physical objects like coins, dice, cards, or spinners.\nMany random phenomena can be represented in terms of a “box model2”\nIf the draws are made with replacement from a single box, we can think of a single circular “spinner” instead of a box, spun multiple times. For example:\nTable 3.1: Results of 10 repetitions of two rolls of a fair four-sided die. X is the sum of the two rolls, Y is the maximum, and A is the event that the first roll is a 3.\n\n\n\n\n\n\nRepetition\nFirst roll\nSecond roll\nX\nY\nEvent A occurs?\nI[A]\n\n\n\n\n1\n2\n1\n3\n2\nFalse\n0\n\n\n2\n1\n1\n2\n1\nFalse\n0\n\n\n3\n3\n3\n6\n3\nTrue\n1\n\n\n4\n4\n3\n7\n4\nFalse\n0\n\n\n5\n3\n2\n5\n3\nTrue\n1\n\n\n6\n3\n4\n7\n4\nTrue\n1\n\n\n7\n2\n3\n5\n3\nFalse\n0\n\n\n8\n2\n4\n6\n4\nFalse\n0\n\n\n9\n1\n2\n3\n2\nFalse\n0\n\n\n10\n3\n4\n7\n4\nTrue\n1\nNote that we are able to simulate outcomes of the rolls and values of \\(X\\) and \\(Y\\) without defining the probability space in detail. That is, we do not need to list all the possible outcomes and events and their probabilities. Instead, the probability space is defined implicitly via the specification to “roll a fair four-sided die twice” or “draw two tickets with replacement from a box with four tickets labeled 1, 2, 3, 4” or “spin the spinner on the left of Figure 2.9 twice”. The random variables are defined by what is being measured for each outcome, the sum (\\(X\\)) and the max (\\(Y\\)) of the two draws or spins.\nA simulation usually involves many repetitions. When conducting a simulation4 it is important to distinguish between what entails (1) one repetition of the simulation and its output, and (2) the simulation itself and output from many repetitions. When describing a simulation, refrain from making vague statements like “repeat this” or “do it again”, because “this” or “it” could refer to different elements of the simulation. In the dice example, (1) rolling a die is repeated to generate a single \\((X, Y)\\) pair, and (2) the process of generating \\((X, Y)\\) pairs is repeated to obtain the simulation results. That is, a single repetition involves an ordered pair of die rolls, resulting in an outcome \\(\\omega\\), and the values of the sum \\(X(\\omega)\\) and max \\(Y(\\omega)\\) are computed for the outcome \\(\\omega\\). The process described in the previous sentence is repeated many times to generate many outcomes and \\((X, Y)\\) pairs according to the probability model.\nThink of simulation results being organized in a table like Table 3.1, where each row corresponds to a repetition of the simulation, resulting in a possible outcome of the random phenomenon, and each column corresponds to a different random variable or event. Remember that indicators are the bridge between events and random variables. On each repetition of the simulation an event either occurs or not; we could record the occurrence of an event as “true” or “false”, or we could record the value of the corresponding indicator random variable, 1 or 0.\nFigure 3.2 displays two plots summarizing the results in Table 3.1. Each dot represents the results of one repetition. Figure 3.2 (a) displays the simulated \\((X, Y)\\) pairs, Figure 3.2 (b) displays the simulated values of \\(X\\) alon along with their frequencies. While this simulation only consists of 10 repetitions, a larger scale simulation would follow the same process.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-tactile",
    "href": "language-simulation.html#sec-tactile",
    "title": "3  The Language of Simulation",
    "section": "",
    "text": "Imagine a box containing “tickets” with labels. Examples include:\n\nFair coin flip. 2 tickets: 1 labeled H and 1 labeled T\nFree throw attempt of a 90% free throw shooter. 10 tickets: 9 labeled “make” and 1 labeled “miss”\nCard shuffling. 52 cards: each card with a pair of labels (face value, suit).\n\nThe tickets are shuffled in the box and some number are drawn out, either with replacement or without replacement of the tickets before the next draw3.\nIn some cases, the order in which the tickets are drawn matters; in other cases the order is irrelevant. For example,\n\nDealing a 5 card poker hand: Select 5 cards without replacement, order does not matter\nRandom digit dialing: Select 4 cards with replacement from a box with tickets labeled 0 through 9 to represent the last 4 digits of a randomly selected phone number with a particular area code and exchange; order matters, e.g., 805-555-1212 is a different outcome than 805-555-2121.\n\nThen something is done with the tickets to determine which events of interest have occurred or to measure random variables. For example, you might flip a coin 10 times (by drawing from the H/T box 10 times with replacement) and check if there were at least 3 H in a row or count the number of H.\n\n\n\nFair coin flip. Spinner with half of the area corresponding to H and half T\nFree throw attempt of a 90% free throw shooter. Spinner with 90% of the area corresponding to “make” and 10% “miss”. \n\n\n\n\n\n\n\n\nExample 3.1 Consider a box model for rolling a four-sided die.\n\nSet up a box model for simulating a roll of each of the following dice.\n\na fair four-sided die\nthe weighted die in Example 2.29\nthe weighted die in Example 2.30.\n\nRoll a die from the previous part twice and let \\(X\\) be the sum of two rolls and let \\(Y\\) be the larger of the two rolls (or the common value if a tie). Explain how you would use the box models from the previous part to simulate a realization of \\((X, Y)\\).\nLet \\(A\\) be the event that the sum is 3, and let \\(\\textrm{I}_A\\) be the indicator random variable. Explain how you would use the box models to simulate a realization of \\(A\\) and \\(I_A\\).\nIn the previous parts, could you use spinners instead?\nUse a fair four-sided die (or a box or a spinner) to simulate 10 repetitions. (Yes, really do it.) For each repetition, record the results of the first and second rolls (or draws or spins) and the simulated values of \\(X\\), \\(Y\\), \\(A\\), and \\(I_A\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.1. \n\nEach box would have the numbers 1, 2, 3, 4 written on some number of tickets.\n\n4 tickets: labeled 1, 2, 3, 4\n10 tickets: 1 labeled 1, 2 labeled 2, 3 labeled 3, 4 labeled 4\n15 tickets: 4 labeled 1, 6 labeled 2, 3 labeled 3, 2 labeled 4\n\nUse the appropriate box for the die of interest. Draw two tickets with replacement (that is, put the first ticket back in the box and reshuffle before drawing the second ticket). Let \\(X\\) be the sum of the two numbers drawn and \\(Y\\) the larger of the two numbers drawn.\nSimilar to the previous part, but event \\(A\\) either happens or not, so a realization of it is true or false instead of a number. If the first roll is 3 then \\(A\\) is true; otherwise \\(A\\) is false. The indicator random variable \\(\\textrm{I}_A\\) just translates true to 1 and false to 0.\nWe could replace the boxes in part 1 with the spinners in Figure 2.9. Spin the appropriate spinner twice and let \\(X\\) be the sum of the two numbers spun and \\(Y\\) the larger of the two numbers spun, etc.\nSee Table 3.1. Results vary naturally so your simulation results will be different, but the same ideas apply.\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe tables of outcomes in this chapter are a different type than those in Chapter 2. Many tables in Chapter 2, such as Table 2.7, represent the sample space: there is one and only one row for each distinct possible outcome, and each outcome (row) has a corresponding theoretical probability. On the other hand, tables of simulation output—like Table 3.1 and many tables in this chapter—contain one row for each repetition of the simulation. A particular outcome might be repeated several times in a simulation and thus might appear in several rows of the table of simulation output. For example, the outcome (3, 4) appears only once in Table 2.7, but twice in Table 3.1 (in repetitions 6 and 10). We will discuss how to approximate the theoretical probability of a particular outcome using the relative frequency of repetitions of that outcome in the simulation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Simulated \\((X, Y)\\) pairs\n\n\n\n\n\n\n\n\n\n\n\n(b) Simulated values of \\(X\\)\n\n\n\n\n\n\n\nFigure 3.2: Dot plots of the simulation results in Table 3.1 of 10 repetitions of two rolls of a fair four-sided die, where \\(X\\) is the sum and \\(Y\\) is the larger (or common value if a tie) of the two rolls.\n\n\n\n\n\n\n\n\n\n\nExample 3.2 Recall Example 2.2. Consider the matching problem with \\(n=4\\). Label the objects 1, 2, 3, 4, and the spots 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. Let \\(X\\) be the number of objects that are placed in the correct spot, and let \\(C\\) be the event that at least one object is placed in the correct spot. Describe how you would use a box model to simulate a single realization of \\(X\\) and of \\(C\\). Could you use a spinner instead?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.2. Use a box with 4 tickets, labeled 1, 2, 3, 4. Shuffle the tickets and draw all 4 without replacement and record the tickets drawn in order. Let \\(X\\) be the number of tickets that match their spot in order. For example, if the tickets are drawn in the order 2431 then the realized value of \\(X\\) is 1 since only ticket 3 matches its spot in the order. Since \\(C=\\{X \\ge 1\\}\\), event \\(C\\) occurs if \\(X\\ge 1\\) and does not occur if \\(X=0\\). We could record the realization of event \\(C\\) as “true” or “false”. We could also record the realization of \\(\\textrm{I}_C\\), the indicator random variable for event \\(C\\), as 1 if \\(C\\) occurs and 0 if \\(C\\) does not occur.\nSince the tickets are drawn without replacement, we could not simply spin a single spinner, like the one in Figure 2.9 (a), four times. If we really wanted to use the spinner in Figure 2.9 (a), we couldn’t just spin it four times; we would sometimes have to discard spins and try again. For example, suppose the first spin results in 2; then if the second spin results in 2 we would need to discard it and try again. So we would usually need more than four spins to obtain a valid outcome. If we wanted to guarantee a valid outcome in only four spins, we would need a collection of spinners, and which one we use would depend on the results of previous spins. For example, if the first spin results in 2, then we would need to spin a spinner that only lands on 1, 3, 4; if the second spin results in 3, then we would need to spin a spinner that lands only on 1 and 4.\n\n\n\n\n\n3.1.1 Exercises\n\nExercise 3.1 Recall the birthday problem of Example 2.48. Let \\(B\\) be the event that at least two people in a group of \\(n\\) share a birthday.\nDescribe in detail you could use physical objects (coins, cards, spinners, etc) to simulate by hand a single realization of \\(B\\) (that is, simulate whether or not \\(B\\) occurs).\n\n\nExercise 3.2 Maya is a basketball player who makes 40% of her three point field goal attempts. Suppose that at the end of every practice session, she attempts three pointers until she makes one and then stops. Let \\(X\\) be the total number of shots she attempts in a practice session. Assume shot attempts are independent, each with probability of 0.4 of being successful. Describe in detail you could use physical objects (coins, cards, spinners, etc) to simulate by hand a single value of \\(X\\).\n\n\nExercise 3.3 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\nDescribe in detail you could use physical objects (coins, cards, spinners, etc) to simulate by hand a single \\((X, Y)\\) pair.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-language-simulation-tactile-meeting",
    "href": "language-simulation.html#sec-language-simulation-tactile-meeting",
    "title": "3  The Language of Simulation",
    "section": "3.2 Tactile simulation: Meeting problem",
    "text": "3.2 Tactile simulation: Meeting problem\nNow we’ll consider tactile simulation for a continuous sample space. Throughout this section we’ll consider the two-person meeting problem. We’ll continue to measure arrival times in minutes after noon, including fractions of a minute, so that arrival times take values on a continuous scale.\n\n3.2.1 A uniform distribution\n\n\n\n\n\n\n\nExample 3.3 Assume that Regina and Cady each arrive at a time uniformly at random in the continuous time interval between noon and 1, independently of each other.\n\nExplain how you could construct a circular spinner to simulate Regina’s arrival time. In particular, what values go at the “3 o’clock”, “6 o’clock”, and “9 o’clock” points on the spinner’s axis? (Here “3 o’clock” refers to the direction on the “clock” (spinner), and not arrival time.)\nExplain how you could use the spinner from the previous part to simulate an outcome, that is, a pair of arrival times for Regina and Cady.\nWhy could we not simulate this situation with a box model?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.3. \n\nImagine a circular spinner with an infinitely fine needle that after being spun well points to a value on the spinner’s axis uniformly at random. We could label the axis like the spinner like the one in Figure 2.1, but ranging from 0 to 60 instead of 0 to 1; see Figure 3.3, which we’ll call the “Uniform(0, 60)” spinner. (Or we could just use the spinner in Figure 2.1 to get the arrival time as a fraction of the hour, then multiply the result of a spin by 60.) Only selected rounded values are displayed on the circular axis, but in the idealized model the spinner is infinitely precise so that any real number between 0 and 60 is a possible outcome. Assuming the arrival time is uniformly distributed, Regina should have a probability of \\(15/60=0.25\\) of arriving in each of the 15-minutes intervals \\([0, 15]\\), \\([15, 30]\\), \\([30, 45]\\), and \\([45, 60]\\). Therefore, 15 should go at “3 o’clock”, 30 at “6 o’clock”, and 45 at “9 o’clock”, just like the minutes on a regular clock.\nSince the arrival times are independent and follow the same uniform pattern, we can spin the spinner in Figure 3.3 twice to simulate an outcome; the first spin represents Regina’s arrival time, the second Cady’s. The order of the spins matters; for example, the pair (34.89, 12.56) represents Regina arriving at 34.89 minutes after noon, while the pair (12.56, 34.89) represents Regina arriving at 12.56 minutes after noon (and vice versa for Cady).\nAn outcome consists of a pair of values from the continuous interval [0, 60]. Since this interval is uncountable, it’s not possible to write every real number in the interval [0, 60] on a ticket to place in a box. To use a box model, we would have to round arrival times to some desired degree of precision—nearest minute, second, millisecond, etc—and put the rounded values on the tickets. Which is probably fine for practical purposes! But if we really want to create a tactile representation of continuous outcomes, a box model won’t work; we tend to use spinners instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Values at 1 o’clock, 2 o’clock, etc\n\n\n\n\n\n\n\n\n\n\n\n(b) Spinner axis marked at 10 minute intervals\n\n\n\n\n\n\n\nFigure 3.3: A continuous Uniform(0, 60) spinner. Only selected rounded values are displayed, but in the idealized model the spinner is infinitely precise so that any real number between 0 and 60 is a possible outcome.\n\n\n\nNotice that the values on the circular axis in Figure 3.3 are evenly spaced. For example, the intervals [0, 15], [15, 30], [30, 45], and [45, 60], all of length 15, each represent 25% of the spinner area. If we spin the idealized spinner represented by Figure 3.3 10 times, our results might look like those in Table 3.2.\n\n\n\n\nTable 3.2: Results of 10 spins of the Uniform(0, 60) spinner.\n\n\n\n\nResults of 10 spins of the Uniform(0, 60) spinner.\n\n\nSpin\nResult\n\n\n\n\n1\n1.062914\n\n\n2\n17.729239\n\n\n3\n21.610468\n\n\n4\n27.190663\n\n\n5\n36.913450\n\n\n6\n19.604730\n\n\n7\n14.479123\n\n\n8\n25.198875\n\n\n9\n2.805937\n\n\n10\n17.456726\n\n\n\n\n\n\n\n\nNotice the number of decimal places. If the sample space is [0, 60], any value in the continuous interval between 0 and 60 is a distinct possible value: 10.25000000000… is different from 10.25000000001… which is different from 10.2500000000000000000001… and so on.\nFigure 3.4 displays the 10 values in Table 3.2 plotted along a number line. The values are roughly evenly spaced, but there is some natural variability. (Though it’s hard to discern any pattern with only 10 values.)\n\n\n\n\n\n\n\n\nFigure 3.4: Plot of the 10 values simulated from a Uniform(0, 60) model, recorded in Table 3.2\n\n\n\n\n\nTo simulate a (Regina, Cady) pair of arrival times, we would spin the Uniform(0, 60) spinner twice. Let \\(R\\) be the result of the first spin, representing Regina’s arrival time, and \\(Y\\) the second spin for Cady. Also let \\(T=\\min(R, Y)\\) be the time (minutes after noon) at which the first person arrives, and \\(W=|R-Y|\\) be the time (minutes) the first person to arrive waits for the second person to arrive. Table 3.3 displays the values of \\(R\\), \\(Y\\), \\(T\\), \\(W\\) for 10 simulated repetitions, each repetition consisting of a pair of spins of the Uniform(0, 60) spinner.\n\n\n\n\nTable 3.3: Results of 10 repetitions of a simulation of the independent Uniform model in the two-person meeting problem.\n\n\n\n\nResults of 10 repetitions of a simulation of the independent Uniform model in the two-person meeting problem.\n\n\nRepetition\nR\nY\nT\nW\n\n\n\n\n1\n49.50512\n52.748971\n49.505123\n3.243848\n\n\n2\n55.38527\n22.040907\n22.040907\n33.344360\n\n\n3\n7.52414\n9.956804\n7.524140\n2.432664\n\n\n4\n51.33105\n39.636179\n39.636179\n11.694869\n\n\n5\n43.77325\n26.338476\n26.338476\n17.434775\n\n\n6\n42.51350\n28.619413\n28.619413\n13.894083\n\n\n7\n31.15456\n41.117529\n31.154557\n9.962971\n\n\n8\n44.01602\n4.406319\n4.406319\n39.609700\n\n\n9\n35.46720\n8.867082\n8.867082\n26.600122\n\n\n10\n56.58527\n7.784337\n7.784337\n48.800934\n\n\n\n\n\n\n\n\nFigure 3.5 plots the 10 simulated \\((R, Y)\\) pairs in Table 3.3\n\n\n\n\n\n\n\n\nFigure 3.5: Plot of 10 pairs of values, each pair simulated independently from a Uniform(0, 60) model, recorded in Table 3.3. Each dot represents a pair. The components of each pair are marked on the horizontal and vertical axes.\n\n\n\n\n\nNow suppose we keep repeating the process, resulting in many simulated (Regina, Cady) pairs of arrival times. Figure 3.6 displays 1000 simulated pairs of arrival times, resulting from 1000 pairs of spins of the Uniform(0, 60) spinner.\n\n\n\n\n\n\n\n\nFigure 3.6: Plot of 1000 pairs of values, each pair simulated independently from a Uniform(0, 60) model. Each dot represents a pair. The components of each pair are marked on the horizontal and vertical axes.\n\n\n\n\n\nWe see that the pairs are fairly evenly distributed throughout the square with sides [0, 60] representing the sample space (though there is some “clumping” due to natural variability). If we simulated more values and summarized them in an appropriate plot, we would expect to see something like Figure 2.12.\n\n\n3.2.2 A non-uniform distribution\n\n\n\n\n\n\n\nExample 3.4 Imagine we have an unlabeled circular spinner with an infinitely fine needle that after being spun well lands on a point on the spinner’s axis uniformly at random. But now suppose that Regina’s arrival time is not uniformly distributed. How should we label the spinner’s circular axis to reflect assumptions about Regina’s arrival time?\n\nIn particular, suppose that Regina has a probability of 0.25 of arriving in each of the intervals \\([0, 23]\\), \\([23, 30]\\), \\([30, 37]\\), \\([37, 60]\\). Start to label the spinner for simulating Regina’s arrival time; what values should go at the “3 o’clock”, “6 o’clock”, and “9 o’clock” positions on the spinner’s circular axis?\nAlso assume that Regina has a probability of (roughly):\n\n0.025 of arriving in the interval \\([0, 10]\\)\n0.135 of arriving in the interval \\([10, 20]\\)\n0.135 of arriving in the interval \\([40, 50]\\)\n0.025 of arriving in the interval \\([50, 60]\\)\n\nAt what points on the spinner’s circular axis should the values 10, 20, 40, and 50 go? What is the probability that Regina arrives in the interval \\([20, 30]\\)? \\([30, 40]\\)?\nWhat does this spinner say about Regina’s arrival time: is she most likely to arrive near noon, near 12:30, or near 1:00?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.4. \n\nWe can split the spinner into four equal sectors representing the four intervals. Therefore, 23 should go at 3 o’clock, 30 at 6 o’clock, and 37 at 9 o’clock. See Figure 3.7 (a). This part only provides enough information to label 3, 6, and 9 o’clock; we’ll discuss where the other values come from below. (Also, we have rounded values in this example.)\nStarting from 0 and moving clockwise around the spinner\n\n10 goes 2.5% of the way around\n20 goes 16% of the way around, at roughly 2 o’clock (2.5% to get from 0 to 10 then another 13.5% to get from 10 to 20)\n30 goes at 6 o’clock like before\n40 goes 84% of the way around, at roughly 10 o’clock (\\(1 - 0.025 - 0.135 = 0.84\\))\n50 goes 97.5% of the way around (\\(1 - 0.025 = 0.975\\)) Since the probability of arriving in \\([0, 30]\\) is 0.5, the probability of arriving in \\([20, 30]\\) is \\(0.5 - 0.16 = 0.34\\). Similarly, the probability of arriving in \\([30, 40]\\) is 0.34. See Figure 3.7 (b) (We have rounded values a little differently for this example.)\n\nPart 1 shows that Regina is as likely as not to arrive between 12:23 and 12:37. Part 2 shows that Regina has a probability of about 0.68 of arriving withing 10 minutes of 12:30, but only a probability of about 0.05 of arriving within 10 minutes of either noon or 1:00. So under these assumptions she is more likely to arrive near 12:30 than near noon or 1:00.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Values at 1 o’clock, 2 o’clock, etc\n\n\n\n\n\n\n\n\n\n\n\n(b) Spinner axis marked at 10 minute intervals\n\n\n\n\n\n\n\nFigure 3.7: A continuous Normal(30, 10) spinner. The same spinner is displayed on both sides, with different features highlighted on the left and right. Only selected rounded values are displayed, but in the idealized model the spinner is infinitely precise so that any real number is a possible outcome. Notice that the values on the axis are not evenly spaced.\n\n\n\nImagine we have an unlabeled circular spinner with an infinitely fine needle that after being spun well lands on a point on the spinner’s axis uniformly at random. Even though the needle lands uniformly, we can use the spinner to represent non-uniform probability measures by labeling the spinner’s circular axis appropriately. We can “stretch” intervals with higher probability, and “shrink” intervals with lower probability. We have already done this intuitively with discrete spinners; see Figure 1.6 and Figure 2.9. But the same idea applies to continuous spinners.\nFigure 3.7 displays a “Normal(30, 10)” spinner. Only selected rounded values are displayed, but the needle can land—uniformly at random—at any point on the continuous circular axis. But pay close attention to the circular axis; the values are not equally spaced. For example, the bottom half of the spinner corresponds to the interval [23.26, 36.74], with length 13.48 minutes, while the upper half of the spinner corresponds to the intervals [0, 23.26] and [36.74, 60], with total length 46.52 minutes. Compared with the Uniform(0, 60) spinner, in the Normal(30, 10) spinner intervals near 30 are “stretched out” to reflect a higher probability of arriving near 12:30, while intervals near 0 and 60 are “shrunk” to reflect a lower probability of arriving near 12:00 or 1:00. The interval [20, 40] represents about 68% of the spinner area, so if we spin this spinner many times, about 68% of the spins will land in the interval [20, 40]. A person whose arrival time is represented by this spinner has a probability of about 0.68 of arriving within 10 minutes of 12:30 compared to \\(20/60 = 0.33\\) for the Uniform(0, 60) model, and a probability of about 0.05 of arriving with 10 minutes of either noon or 1:00, compared to \\(20/60=0.33\\) in the Uniform(0, 60) model. (The spinner on the left is divided into 12 wedges of equal area, so each wedge represents 8.33% of the probability. Not all values on the axis are labeled, but you can use the wedges to eyeball probabilities.)\nThe particular pattern represented by the spinner in Figure 3.7 is a Normal(30, 10) distribution; that is, a Normal distribution with mean 30 and standard deviation 10. We will see Normal distributions in much more detail later. For now, just know that a Normal(30, 10) model reflects one particular pattern of non-uniform probability5. Table 3.4 compares probabilities of selected intervals under the Uniform(0, 60) and Normal(30, 10) models.\n\n\n\n\n\n\nWarning\n\n\n\nThe parameters in the uniform probability model are different from those in the Normal model. In the Uniform(0, 60) model, 0 is the minimum possible value; in the Normal(30, 10) model, 30 is the average value. In the Uniform(0, 60) model, 60 is the maximum possible value; in the Normal(30, 10) model, 10 is the standard deviation.\n\n\n\n\n\nTable 3.4: Comparison of probabilities for the Uniform(0, 60) and Normal(30, 10) models\n\n\n\n\n\nInterval\nUniform(0, 60) probability\nNormal(30, 10) probability\n\n\n\n\n[0, 10]\n0.167\n0.025\n\n\n[10, 20]\n0.167\n0.136\n\n\n[20, 30]\n0.167\n0.341\n\n\n[30, 40]\n0.167\n0.341\n\n\n[40, 50]\n0.167\n0.136\n\n\n[50, 60]\n0.167\n0.025\n\n\n\n\n\n\nIf we spin the idealized spinner represented by Figure 3.7 10 times, our results might look like those in Table 3.5.\n\n\n\n\nTable 3.5: Results of 10 spins of the Normal(30, 10) spinner.\n\n\n\n\n\n\nSpin\nResult\n\n\n\n\n1\n21.38732\n\n\n2\n50.71937\n\n\n3\n24.08964\n\n\n4\n32.68036\n\n\n5\n54.51060\n\n\n6\n38.11696\n\n\n7\n16.81857\n\n\n8\n22.97995\n\n\n9\n28.86703\n\n\n10\n43.43031\n\n\n\n\n\n\n\n\nFigure 3.8 displays the 10 values in Table 3.5 plotted along a number line. We tend to see more values near 30 than near 0 or 60 (though it’s hard to discern any pattern with only 10 values).\n\n\n\n\n\n\n\n\nFigure 3.8: Plot of the 10 values simulated from a Normal(30, 10) model, recorded in Table 3.5.\n\n\n\n\n\nIf we spin the spinner in Figure 3.7 many times,\n\nAbout half of the simulated values would be below 30 and half above\nBecause axis values near 30 are stretched out, values near 30 would occur with higher frequency than those near 0 or 60.\nThe shape of the distribution would be symmetric about 30 since the axis spacing of values below 30 mirrors that for values above 30. For example, about 34% of values would be between 20 and 30, and also 34% between 30 and 40.\nAbout 68% of values would be between 20 and 40.\nAbout 95% of values would be between 10 and 50.\n\nAnd so on. We could compute percentages for other intervals by measuring the areas of corresponding sectors on the spinner to complete the pattern of variability that values resulting from this spinner would follow. This particular pattern is called a “Normal(30, 10)” distribution, which we will explore in much more detail later (in particular, see ?sec-histogram-to-density).\nNow suppose Regina’s and Cady’s arrival times are each reasonably modeled by a Normal(30, 10) model, independently of each other. To simulate a (Regina, Cady) pair of arrival times, we would spin the Normal(30, 10) spinner twice. Table 3.6 displays the results of 10 repetitions, each repetition resulting in a (Regina, Cady) pair.\n\n\n\n\nTable 3.6: Results of 10 pairs of spins of the Normal(30, 10) spinner.\n\n\n\n\n\n\nRepetition\nRegina's time\nCady's time\n\n\n\n\n1\n31.758630\n50.89160\n\n\n2\n7.842356\n34.23954\n\n\n3\n29.644008\n40.34209\n\n\n4\n25.154312\n26.89845\n\n\n5\n38.011497\n32.04975\n\n\n6\n27.325808\n42.97185\n\n\n7\n44.594399\n38.65448\n\n\n8\n18.557759\n30.99171\n\n\n9\n30.142711\n36.53947\n\n\n10\n26.479249\n30.23044\n\n\n\n\n\n\n\n\nFigure 3.9 plots the 10 simulated pairs in Table 3.6\n\n\n\n\n\n\n\n\nFigure 3.9: Plot of 10 pairs of values, each pair simulated from a Normal(30, 10) model, recorded in Table 3.6. Each dot represents a pair. The components of each pair are marked on the horizontal and vertical axes.\n\n\n\n\n\nFigure 3.10 displays 1000 pairs of (Regina, Cady) arrival times, resulting from 1000 pairs of spins of the Normal(30, 10) spinner. Compared with the simulated pairs from the Uniform(0, 60) spinner (in Figure 3.6), we see many more simulated pairs in the center of the plot (when both arrive near 12:30) than in the corners of the plot (where either arrives near 12:00 or 1:00). If we simulated more values and summarized them in an appropriate plot, we would expect to see something like Figure 2.14.\n\n\n\n\n\n\n\n\nFigure 3.10: Plot of 1000 pairs of values, each pair simulated from a Normal(30, 10) model. Each dot represents a pair. The components of each pair are marked on the horizontal and vertical axes.\n\n\n\n\n\nExample 3.3 and Example 3.4 assumed that Regina’s and Cady’s arrival times individually followed the same model, both Uniform(0, 60) or both Normal(30, 10), so we just spun the same spinner twice to simulate a pair of arrival times. However, we could easily simulate from different models. Suppose Regina’s arrival time follows a Uniform(0, 60) model while Cady’s follows a Normal(30, 10) model, independently of each other. Then we could simulate a pair of arrival times by spinning the Uniform(0, 60) spinner for Regina and the Normal(30, 10) spinner for Cady.\nSo far we have assumed that Regina and Cady arrive independently, but what if they coordinate and their arrival times are related? Recall that Figure 2.15 reflects a model where Regina and Cady each are more likely to arrive around 12:30 than noon or 1:00, and also more likely to arrive around the same time. In such a situation, we could still use spinners to simulate pairs of arrival times, but it’s more involved than just spinning a single spinner twice (or having just one spinner for each person). We’ll revisit using spinners to simulate dependent pairs later.\n\n\n3.2.3 Exercises\n\nExercise 3.4 Katniss throws a dart at a circular dartboard with radius 12 inches. Suppose that the dart lands uniformly at random anywhere on the dartboard, and assume that Katniss’s dart never misses the dartboard. Suppose that the dartboard is on a coordinate plane, with the center of the dartboard at (0, 0) and the north, south, east, and west edges, respectively, at coordinates (0, 12), (0,-12), (12, 0), (-12, 0). When the dart hits the board its \\((X, Y)\\) coordinates are recorded. Let \\(R\\) be the distance (inches) from the location of the dart to the center of the dartboard.\n\nSketch a Uniform(0, 12) spinner.\nDescribe how you could use a fair coin and the Uniform(0, 12) spinner to simulate the \\((X, Y)\\) coordinates of a single throw of the dart and the value of \\(R\\). Hint: you might need to flip the coin and spin the spinner multiple times. What will you do if your simulated coordinates correspond to “off the board”?\nSuppose you want to simulate \\(R\\) directly. Could you just spin the Uniform(0, 12) spinner and record the value? Explain. Hint: see Exercise 2.13.\n\n\n\nExercise 3.5 Continuing Exercise 3.4. Computing like we did in Exercise 2.13, we can show\n\n\n\n\n\nRange\nProbability that $R$ is in range\n\n\n\n\n0 to 1\n0.0069\n\n\n1 to 2\n0.0208\n\n\n2 to 3\n0.0347\n\n\n3 to 4\n0.0486\n\n\n4 to 5\n0.0625\n\n\n5 to 6\n0.0764\n\n\n6 to 7\n0.0903\n\n\n7 to 8\n0.1042\n\n\n8 to 9\n0.1181\n\n\n9 to 10\n0.1319\n\n\n10 to 11\n0.1458\n\n\n11 to 12\n0.1597\n\n\n\n\n\nSketch a spinner that could be used to simulate values of \\(R\\). You should label 12 sectors on the spinner. Hint: the sectors won’t be the same size and the values on the outside axis of the spinner won’t be evenly spaced.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-technology-intro",
    "href": "language-simulation.html#sec-technology-intro",
    "title": "3  The Language of Simulation",
    "section": "3.3 Computer simulation: Dice rolling",
    "text": "3.3 Computer simulation: Dice rolling\nWe will perform computer simulations using the Python package Symbulate. The syntax of Symbulate mirrors the language of probability in that the primary objects in Symbulate are the same as the primary components of a probability model: probability spaces, random variables, events. Once these components are specified, Symbulate allows users to simulate many times from the probability model and summarize the results.\nThis section contains a brief introduction to Symbulate; more examples can be found throughout the text. Symbulate can be installed with pip.\n\npip install git+https://github.com/kevindavisross/symbulate\n\nImport Symbulate during a Python session using the following command.\n\nfrom symbulate import *\n\nWe’ll start with a dice rolling example. Unless indicated otherwise, in this section \\(X\\) represents the sum of two rolls of a fair four-sided die, and \\(Y\\) represents the larger of the two rolls (or the common value if a tie). We have already discussed a tactile simulation; now we’ll carry out the process on a computer.\nThere aren’t many examples for you to work in this section. Instead, we encourage you to open a Python session and copy and run the code as you read. In particular, you can run Python code using this template Colab notebook which includes the code needed to get started with Symbulate.\n\n3.3.1 Simulating outcomes\nThe following Symbulate code defines a probability space6 P for simulating the 16 equally likely ordered pairs of rolls via a box model.\n\nP = BoxModel([1, 2, 3, 4], size = 2, replace = True)\n\nThe above code tells Symbulate to draw 2 tickets (size = 2), with replacement7, from a box with tickets labeled 1, 2, 3, and 4 (entered as the Python list [1, 2, 3, 4]). Each simulated outcome consists of an ordered8 pair of rolls .\nThe sim(r) command simulates r realizations of probability space outcomes (or events or random variables). Here is the result of one repetition.\n\nP.sim(1)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(3, 1)\n        \n        \n      \n    \n\n\nAnd here are the results of 10 repetitions. (We will typically run thousands of repetitions, or more, but in this section we just run a few repetitions for illustration.)\n\nP.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(3, 4)\n        \n        \n        \n          1(3, 2)\n        \n        \n        \n          2(3, 2)\n        \n        \n        \n          3(4, 2)\n        \n        \n        \n          4(3, 3)\n        \n        \n        \n          5(4, 4)\n        \n        \n        \n          6(3, 1)\n        \n        \n        \n          7(3, 3)\n        \n        \n        \n          8(4, 2)\n        \n        ......\n        \n          9(1, 4)\n        \n        \n      \n    \n\n\n\n\n\n\n\n\nWarning\n\n\n\nEvery time .sim() is called, a new simulation is run. When running a simulation, the “simulate” step should be performed with a single call to sim so that all analysis of results corresponds to the same simulated values. We’ll show how to do this below.\n\n\n\n\n3.3.2 Simulating random variables\nA Symbulate RV is specified by the probability space on which it is defined and the mapping function which defines it. Recall that \\(X\\) is the sum of the two dice rolls and \\(Y\\) is the larger (max).\n\nX = RV(P, sum)\nY = RV(P, max)\n\n\n\n\n\n\nThe above code simply defines the random variables. Again, we can simulate values with .sim(). Since every call to sim runs a new simulation, we typically store the simulation results as an object. The following commands simulate 100 values of the random variable X and store the results as x. For consistency with standard probability notation9, the random variable itself is denoted with an uppercase letter X, while the realized values of it are denoted with a lowercase letter x.\n\nx = X.sim(100)\n\nx # this just displays x; only the first few and last values will print\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          06\n        \n        \n        \n          15\n        \n        \n        \n          23\n        \n        \n        \n          35\n        \n        \n        \n          45\n        \n        \n        \n          55\n        \n        \n        \n          66\n        \n        \n        \n          75\n        \n        \n        \n          84\n        \n        ......\n        \n          993\n        \n        \n      \n    \n\n\n\n\n3.3.3 Simulating multiple random variables\nIf we call X.sim(10000) and Y.sim(10000) we get two separate simulations of 10000 pairs of rolls, one which returns the sum of the rolls for each repetition, and the other the max. If we want to study relationships between \\(X\\) and \\(Y\\) we need to compute both \\(X\\) and \\(Y\\) for each pair of rolls in the same simulation.\nWe can simulate \\((X, Y)\\) pairs using10 &. We store the simulation output as x_and_y to emphasize that x_and_y contains pairs of values.\n\nx_and_y = (X & Y).sim(10)\n\nx_and_y # this just displays x_and_y\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(4, 3)\n        \n        \n        \n          1(4, 3)\n        \n        \n        \n          2(5, 4)\n        \n        \n        \n          3(5, 4)\n        \n        \n        \n          4(4, 3)\n        \n        \n        \n          5(3, 2)\n        \n        \n        \n          6(6, 4)\n        \n        \n        \n          7(8, 4)\n        \n        \n        \n          8(5, 3)\n        \n        ......\n        \n          9(6, 4)\n        \n        \n      \n    \n\n\nThink of x_and_y as a table with two columns. We can select columns using brackets []. Remember that Python uses zero-based indexing, so 0 corresponds to the first column, 1 to the second, etc.\n\nx = x_and_y[0]\n\nx\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          04\n        \n        \n        \n          14\n        \n        \n        \n          25\n        \n        \n        \n          35\n        \n        \n        \n          44\n        \n        \n        \n          53\n        \n        \n        \n          66\n        \n        \n        \n          78\n        \n        \n        \n          85\n        \n        ......\n        \n          96\n        \n        \n      \n    \n\n\n\ny = x_and_y[1]\n\ny\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          03\n        \n        \n        \n          13\n        \n        \n        \n          24\n        \n        \n        \n          34\n        \n        \n        \n          43\n        \n        \n        \n          52\n        \n        \n        \n          64\n        \n        \n        \n          74\n        \n        \n        \n          83\n        \n        ......\n        \n          94\n        \n        \n      \n    \n\n\nWe can also select multiple columns.\n\nx_and_y[0, 1]\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(4, 3)\n        \n        \n        \n          1(4, 3)\n        \n        \n        \n          2(5, 4)\n        \n        \n        \n          3(5, 4)\n        \n        \n        \n          4(4, 3)\n        \n        \n        \n          5(3, 2)\n        \n        \n        \n          6(6, 4)\n        \n        \n        \n          7(8, 4)\n        \n        \n        \n          8(5, 3)\n        \n        ......\n        \n          9(6, 4)\n        \n        \n      \n    \n\n\n\n\n3.3.4 Simulating outcomes and random variables\nWhen calling X.sim(10) or (X & Y).sim(10) the outcomes of the rolls are generated in the background but not saved. We can create a RV which returns the outcomes of the probability space11. The default mapping function for RV is the identity function, \\(g(u) = u\\), so simulating values of U = RV(P) below returns the outcomes of the BoxModel P representing the outcome of the two rolls.\n\nU = RV(P)\n\nU.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(4, 3)\n        \n        \n        \n          1(1, 3)\n        \n        \n        \n          2(2, 3)\n        \n        \n        \n          3(2, 3)\n        \n        \n        \n          4(3, 3)\n        \n        \n        \n          5(2, 1)\n        \n        \n        \n          6(1, 1)\n        \n        \n        \n          7(3, 2)\n        \n        \n        \n          8(1, 3)\n        \n        ......\n        \n          9(2, 1)\n        \n        \n      \n    \n\n\nNow we can simulate and display the outcomes along with the values of \\(X\\) and \\(Y\\) using &.\n\n(U & X & Y).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0((4, 3), 7, 4)\n        \n        \n        \n          1((4, 2), 6, 4)\n        \n        \n        \n          2((4, 4), 8, 4)\n        \n        \n        \n          3((1, 1), 2, 1)\n        \n        \n        \n          4((1, 1), 2, 1)\n        \n        \n        \n          5((2, 1), 3, 2)\n        \n        \n        \n          6((1, 3), 4, 3)\n        \n        \n        \n          7((3, 1), 4, 3)\n        \n        \n        \n          8((3, 2), 5, 3)\n        \n        ......\n        \n          9((2, 3), 5, 3)\n        \n        \n      \n    \n\n\nBecause the probability space P returns pairs of values, U = RV(P) above defines a random vector. The individual components12 of U can be “unpacked” as U1, U2 in the following. Here U1 is an RV representing the result of the first roll and U2 the second.\n\nU1, U2 = RV(P)\n(U1 & U2 & X & Y).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(4, 1, 5, 4)\n        \n        \n        \n          1(3, 4, 7, 4)\n        \n        \n        \n          2(2, 3, 5, 3)\n        \n        \n        \n          3(2, 1, 3, 2)\n        \n        \n        \n          4(3, 4, 7, 4)\n        \n        \n        \n          5(1, 3, 4, 3)\n        \n        \n        \n          6(2, 2, 4, 2)\n        \n        \n        \n          7(2, 1, 3, 2)\n        \n        \n        \n          8(2, 1, 3, 2)\n        \n        ......\n        \n          9(2, 4, 6, 4)\n        \n        \n      \n    \n\n\n\n\n3.3.5 Simulating events\nEvents involving random variables can also be defined and simulated. For programming reasons, events are enclosed in parentheses () rather than braces \\(\\{\\}\\). For example, we can define the event that the larger of the two rolls is less than 3, \\(A=\\{Y&lt;3\\}\\), as\n\nA = (Y &lt; 3) # an event\n\nWe can use sim to simulate events. A realization of an event is True if the event occurs for the simulated outcome, or False if not.\n\nA.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0False\n        \n        \n        \n          1True\n        \n        \n        \n          2False\n        \n        \n        \n          3False\n        \n        \n        \n          4False\n        \n        \n        \n          5True\n        \n        \n        \n          6True\n        \n        \n        \n          7True\n        \n        \n        \n          8False\n        \n        ......\n        \n          9False\n        \n        \n      \n    \n\n\nFor logical equality use a double equal sign ==. For example, (Y == 3) represents the event \\(\\{Y=3\\}\\).\n\n(Y == 3).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0True\n        \n        \n        \n          1True\n        \n        \n        \n          2False\n        \n        \n        \n          3False\n        \n        \n        \n          4True\n        \n        \n        \n          5False\n        \n        \n        \n          6False\n        \n        \n        \n          7False\n        \n        \n        \n          8False\n        \n        ......\n        \n          9False\n        \n        \n      \n    \n\n\nIn most situations, events of interest involve random variables. It is much more common to simulate random variables directly, rather than events; see Section 3.12.1 for further discussion. Events are primarily used in Symbulate for conditioning.\n\n\n3.3.6 Simulating transformations of random variables\nTransformations of random variables (defined on the same probability space) are random variables. If X is a Symbulate RV and g is a function, then g(X) is also a Symbulate RV.\nFor example, we can simulate values of \\(X^2\\). (In Python, exponentiation is represented by **; e.g., 2 ** 5 = 32.)\n\n(X ** 2).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          036\n        \n        \n        \n          116\n        \n        \n        \n          29\n        \n        \n        \n          325\n        \n        \n        \n          425\n        \n        \n        \n          525\n        \n        \n        \n          649\n        \n        \n        \n          79\n        \n        \n        \n          816\n        \n        ......\n        \n          936\n        \n        \n      \n    \n\n\nFor many common functions (e.g., sqrt, log, cos), the syntax g(X) is sufficient. Here sqrt(u) is the square root function \\(g(u) = \\sqrt{u}\\).\n\n(X & sqrt(X)).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(5, 2.23606797749979)\n        \n        \n        \n          1(3, 1.7320508075688772)\n        \n        \n        \n          2(3, 1.7320508075688772)\n        \n        \n        \n          3(5, 2.23606797749979)\n        \n        \n        \n          4(6, 2.449489742783178)\n        \n        \n        \n          5(2, 1.4142135623730951)\n        \n        \n        \n          6(5, 2.23606797749979)\n        \n        \n        \n          7(3, 1.7320508075688772)\n        \n        \n        \n          8(7, 2.6457513110645907)\n        \n        ......\n        \n          9(6, 2.449489742783178)\n        \n        \n      \n    \n\n\nFor general functions, including user defined functions, the syntax for defining \\(g(X)\\) is X.apply(g). Here we define the function \\(g(u) = (u-5)^2\\) and then define13 the random variable \\(g(X) = (X - 5)^2\\).\n\n# define a function g; u represents a generic input\ndef g(u):\n  return (u - 5) ** 2\n\n# define the RV g(X)  \nZ = X.apply(g)\n\n# simulate X and Z pairs\n(X & Z).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(4, 1)\n        \n        \n        \n          1(6, 1)\n        \n        \n        \n          2(5, 0)\n        \n        \n        \n          3(2, 9)\n        \n        \n        \n          4(5, 0)\n        \n        \n        \n          5(6, 1)\n        \n        \n        \n          6(5, 0)\n        \n        \n        \n          7(4, 1)\n        \n        \n        \n          8(4, 1)\n        \n        ......\n        \n          9(5, 0)\n        \n        \n      \n    \n\n\nWe can also apply transformations of multiple RVs defined on the same probability space. (We will look more closely at how Symbulate treats this “same probability space” issue later.)\nFor example, we can simulate values of \\(XY\\), the product of \\(X\\) and \\(Y\\).\n\n(X * Y).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          028\n        \n        \n        \n          118\n        \n        \n        \n          22\n        \n        \n        \n          32\n        \n        \n        \n          48\n        \n        \n        \n          518\n        \n        \n        \n          620\n        \n        \n        \n          720\n        \n        \n        \n          818\n        \n        ......\n        \n          96\n        \n        \n      \n    \n\n\nRecall that we defined \\(X\\) via X = RV(P, sum). Defining random variables \\(U_1, U_2\\) to represent the individual rolls, we can define \\(X=U_1 + U_2\\). Recall that we previously defined14 U1, U2 = RV(P).\n\nX = U1 + U2\n\nX.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          05\n        \n        \n        \n          14\n        \n        \n        \n          25\n        \n        \n        \n          37\n        \n        \n        \n          47\n        \n        \n        \n          52\n        \n        \n        \n          65\n        \n        \n        \n          74\n        \n        \n        \n          84\n        \n        ......\n        \n          95\n        \n        \n      \n    \n\n\nUnfortunately max(U1, U2) does not work, but we can use the apply syntax. Since we want to apply max to \\((U_1, U_2)\\) pairs, we must15 first join them together with &.\n\nY  = (U1 & U2).apply(max)\n\nY.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          04\n        \n        \n        \n          14\n        \n        \n        \n          23\n        \n        \n        \n          33\n        \n        \n        \n          44\n        \n        \n        \n          53\n        \n        \n        \n          64\n        \n        \n        \n          72\n        \n        \n        \n          84\n        \n        ......\n        \n          94\n        \n        \n      \n    \n\n\n\n\n3.3.7 Other probability spaces\nSo far we have assumed a fair four-sided die. Now consider the weighted die in Example 2.29: a single roll results in 1 with probability 0.1, 2 with probability 0.2, 3 with probability 0.3, and 4 with probability 0.4. BoxModel assumes equally likely tickets by default, but we can specify non-equally likely tickets using the probs option. The probability space WeightedRoll in the following code corresponds to a single roll of the weighted die; the default size option is 1.\n\nWeightedRoll = BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4])\nWeightedRoll.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          04\n        \n        \n        \n          13\n        \n        \n        \n          23\n        \n        \n        \n          33\n        \n        \n        \n          42\n        \n        \n        \n          54\n        \n        \n        \n          64\n        \n        \n        \n          74\n        \n        \n        \n          84\n        \n        ......\n        \n          94\n        \n        \n      \n    \n\n\nWe could add size = 2 to the BoxModel to create a probability space corresponding to two rolls of the weighted die. Alternatively, we can think of BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4]) as defining the middle spinner in Figure 2.9 that we want to spin two times, which we can do with ** 2.\n\nQ = BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4]) ** 2\nQ.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(4, 2)\n        \n        \n        \n          1(4, 4)\n        \n        \n        \n          2(3, 3)\n        \n        \n        \n          3(4, 2)\n        \n        \n        \n          4(2, 3)\n        \n        \n        \n          5(2, 3)\n        \n        \n        \n          6(2, 3)\n        \n        \n        \n          7(4, 3)\n        \n        \n        \n          8(1, 4)\n        \n        ......\n        \n          9(2, 3)\n        \n        \n      \n    \n\n\nYou can interpret BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4]) as defining the middle spinner in Figure 2.9 and ** 2 as “spin the spinner two times”. In Python, ** represents exponentiation; e.g., 2 ** 5 = 32. So BoxModel([1, 2, 3, 4]) ** 2 is equivalent to BoxModel([1, 2, 3, 4]) * BoxModel([1, 2, 3, 4]). In light of our discussion in Section 2.7, the product * notation should seem natural for independent spins.\nWe could use the product notation to define a probability space corresponding to a pair of rolls, one from a fair die and one from a weighted-die.\n\nMixedRolls = BoxModel([1, 2, 3, 4]) * BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4])\nMixedRolls.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(1, 3)\n        \n        \n        \n          1(4, 4)\n        \n        \n        \n          2(4, 4)\n        \n        \n        \n          3(2, 2)\n        \n        \n        \n          4(4, 2)\n        \n        \n        \n          5(2, 2)\n        \n        \n        \n          6(3, 2)\n        \n        \n        \n          7(2, 1)\n        \n        \n        \n          8(4, 4)\n        \n        ......\n        \n          9(1, 3)\n        \n        \n      \n    \n\n\nNow consider the weighted die from Example 2.30, represented by the spinner in Figure 2.9 (c). We could use the probs option, but we can also imagine a box model with 15 tickets—four tickets labeled 1, six tickets labeled 2, three tickets labeled 3, and two tickets labeled 4—from which a single ticket is drawn. A BoxModel can be specified in this way using the following {label: number of tickets with the label} formulation16. This formulation is especially useful when multiple tickets are drawn from the box without replacement.\n\nQ = BoxModel({1: 4, 2: 6, 3: 3, 4: 2})\nQ.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          01\n        \n        \n        \n          13\n        \n        \n        \n          22\n        \n        \n        \n          31\n        \n        \n        \n          42\n        \n        \n        \n          54\n        \n        \n        \n          61\n        \n        \n        \n          71\n        \n        \n        \n          81\n        \n        ......\n        \n          91\n        \n        \n      \n    \n\n\nWhile many scenarios can be represented by box models, there are also many Symbulate probability spaces other than BoxModel. When tickets are equally likely and sampled with replacement, a Discrete Uniform model can also be used. Think of a DiscreteUniform(a, b) probability space corresponding to a spinner with sectors of equal area labeled with integer values from a to b (inclusive). For example, the spinner in Figure 2.9 (a) corresponds to the DiscreteUniform(1, 4) model. This gives us another way to represent the probability space corresponding to two rolls of a fair-four sided die.\n\nP = DiscreteUniform(1, 4) ** 2\nP.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(3, 1)\n        \n        \n        \n          1(3, 3)\n        \n        \n        \n          2(3, 1)\n        \n        \n        \n          3(4, 4)\n        \n        \n        \n          4(4, 1)\n        \n        \n        \n          5(1, 3)\n        \n        \n        \n          6(2, 3)\n        \n        \n        \n          7(4, 2)\n        \n        \n        \n          8(2, 1)\n        \n        ......\n        \n          9(3, 4)\n        \n        \n      \n    \n\n\nNote that BoxModel is the only probability space with the size argument. For other probability spaces, the product * or exponentiation ** notation must be used to simulate multiple spins.\nThis section has only introduced how to set up a probability model and simulate realizations. We’ll see how to summarize and use simulation output soon.\n\n\n3.3.8 Exercises\n\nExercise 3.6 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\nWrite Symbulate code to define an appropriate probability space and random variables, and simulate a few repetitions. Hint: you’ll need to define a function to define \\(X\\); try len(unique(...))\n\n\nExercise 3.7 Continuing Exercise 3.6. Now suppose that 10% of boxes contain prize 1, 30% contain prize 2, and 60% contain prize 3. Write Symbulate code to define an appropriate probability space and random variables, and simulate a few repetitions.\n\n\nExercise 3.8 Recall the birthday problem of Example 2.48. Let \\(B\\) be the event that at least two people in a group of \\(n\\) share a birthday.\nWrite Symbulate code to define an appropriate probability space, and simulate a few realizations of \\(B\\) (that is, simulate whether or not \\(B\\) occurs).\n\n\nExercise 3.9 Maya is a basketball player who makes 40% of her three point field goal attempts. Suppose that at the end of every practice session, she attempts three pointers until she makes one and then stops. Let \\(X\\) be the total number of shots she attempts in a practice session. Assume shot attempts are independent, each with probability of 0.4 of being successful.\nWrite Symbulate code to define an appropriate probability space and random variable, and simulate a few repetitions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-meeting-sim",
    "href": "language-simulation.html#sec-meeting-sim",
    "title": "3  The Language of Simulation",
    "section": "3.4 Computer simulation: Meeting problem",
    "text": "3.4 Computer simulation: Meeting problem\nNow we’ll introduce computer simulation of the continuous models in Section 3.2. Throughout this section we’ll consider the two-person meeting problem. Let \\(R\\) be the random variable representing Regina’s arrival time (minutes after noon, including fractions of a minute), and \\(Y\\) for Cady. Also let \\(T=\\min(R, Y)\\) be the time (minutes after noon) at which the first person arrives, and \\(W=|R-Y|\\) be the time (minutes) the first person to arrive waits for the second person to arrive.\n\n3.4.1 Independent Uniform model\nFirst consider the situation of Example 3.3 where Regina and Cady each arrive at a time uniformly at random in [0, 60], independently of each other. The following code defines a Uniform(0, 60) spinner17, like in Figure 3.3, which we spin twice to get the (Regina, Cady) pair of outcomes.\n\nP = Uniform(0, 60) ** 2\nP.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(59.20127574288018, 48.80751774592388)\n        \n        \n        \n          1(57.7884254112979, 26.25923132573051)\n        \n        \n        \n          2(0.3555090466949107, 20.79499438753527)\n        \n        \n        \n          3(45.80088112801981, 46.1661137962137)\n        \n        \n        \n          4(18.85876141216116, 39.13440263557181)\n        \n        \n        \n          5(35.730864509401236, 36.64361468453995)\n        \n        \n        \n          6(45.172228113872556, 39.219200356741524)\n        \n        \n        \n          7(44.587575757606686, 17.023489955325466)\n        \n        \n        \n          8(37.392187250918305, 31.991771672384626)\n        \n        ......\n        \n          9(50.52589024925992, 27.371872322440673)\n        \n        \n      \n    \n\n\nNotice (again) the number of decimal places; any value in the continuous interval between 0 and 60 is a distinct possible value\nA probability space outcome is a (Regina, Cady) pair of arrival times. We can define the random variables \\(R\\) and \\(Y\\), representing the individual arrival times, by “unpacking” the outcomes.\n\nR, Y = RV(P)\n\n(R & Y).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(56.21502825995775, 24.75366049836198)\n        \n        \n        \n          1(4.909267723957436, 0.2001045922655198)\n        \n        \n        \n          2(31.898470361821982, 9.768296716645317)\n        \n        \n        \n          3(44.20642723981174, 29.35606518736078)\n        \n        \n        \n          4(17.095670875467416, 8.437075025021546)\n        \n        \n        \n          5(41.186792279788804, 2.923578848574444)\n        \n        \n        \n          6(13.713651414546659, 56.21187974985033)\n        \n        \n        \n          7(55.6648632263129, 27.82847963555161)\n        \n        \n        \n          8(42.995576618427414, 19.377598812014185)\n        \n        ......\n        \n          9(47.38786737028318, 59.564430100869515)\n        \n        \n      \n    \n\n\nWe can define \\(W = |R-Y|\\) using the abs function. In order to define \\(T = \\min(R, Y)\\) we need to use the apply syntax with R & Y.\n\nW = abs(R - Y)\n\nT = (R & Y).apply(min)\n\nNow we can simulate values of \\(R\\), \\(Y\\), \\(T\\), and \\(W\\) with a single call to sim. Each row in the resulting Table 3.7 corresponds to a single simulated outcome (pair of arrival times).\n\n(R & Y & T & W).sim(10)\n\n\n\nTable 3.7\n\n\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(49.90437690076261, 21.332744107710365, 21.332744107710365, 28.571632793052242)\n        \n        \n        \n          1(29.47396589339801, 46.355375034486315, 29.47396589339801, 16.881409141088305)\n        \n        \n        \n          2(24.46845260820188, 24.773840228293743, 24.46845260820188, 0.3053876200918637)\n        \n        \n        \n          3(59.55696091976193, 7.141042713868961, 7.141042713868961, 52.415918205892964)\n        \n        \n        \n          4(29.0437225617224, 27.862385597961836, 27.862385597961836, 1.1813369637605646)\n        \n        \n        \n          5(32.26013895414678, 23.824440363561937, 23.824440363561937, 8.435698590584845)\n        \n        \n        \n          6(13.44813305694434, 2.144762906605393, 2.144762906605393, 11.303370150338946)\n        \n        \n        \n          7(45.959091255159095, 37.37576583245607, 37.37576583245607, 8.583325422703027)\n        \n        \n        \n          8(2.3841658483831574, 4.8390413396404846, 2.3841658483831574, 2.454875491257327)\n        \n        ......\n        \n          9(21.738518672366627, 45.269909369552565, 21.738518672366627, 23.531390697185937)\n        \n        \n      \n    \n\n\n\n\n\nWe can simulate values of \\(R\\) and plot them along a number line in a “rug” plot; compare to Figure 3.4. Notice how we have chained together the sim and plot commands. (We’ll see some more interesting and useful plots later.)\n\nplt.figure()\nR.sim(100).plot('rug')\nplt.show()\n\n\n\n\n\n\n\n\nCalling .plot() (without 'rug') for simulated values of a continuous random variable produces a histogram, which we will discuss in much more detail in ?sec-simulation-marginal-continuous.\n\nplt.figure()\nR.sim(10000).plot()\nplt.show()\n\n\n\n\n\n\n\n\nWe can simulate and plot many \\((R, Y)\\) pairs of arrival times; compare to Figure 3.6 (without the rug).\n\n(R & Y).sim(1000).plot()\n\n\n\n\n\n\n\n\n\n\nWhen plotting simulated pairs, the first component is plotted on the horizontal axis and the second component on the vertical axis. In the following plots, we’ll import matplotlib.pyplot as plt and use plt.xlabel(\"x-axis text\") and plt.ylabel(\"y-axis text\")to label axes.\nWe can also simulate and plot many \\((T, W)\\) pairs. For purposes of illustration, first we simulate all four random variables, then we’ll select the columns corresponding to \\((T, W)\\) and plot the simulated pairs.\n\nimport matplotlib.pyplot as plt\n\nmeeting_sim = (R & Y & T & W).sim(1000)\n\nmeeting_sim[2, 3].plot()\nplt.xlabel(\"T\")\nplt.ylabel(\"W\")\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 Independent Normal model\nNow consider a Normal(30, 10) model, represented by the spinner in Figure 3.7.\n\nNormal(mean = 30, sd = 10).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          019.248376698359177\n        \n        \n        \n          14.488621957485115\n        \n        \n        \n          224.519430518185484\n        \n        \n        \n          326.68767673661839\n        \n        \n        \n          446.68901285526742\n        \n        \n        \n          524.38582988126445\n        \n        \n        \n          627.619100902407663\n        \n        \n        \n          740.632452074292004\n        \n        \n        \n          829.895937307026365\n        \n        ......\n        \n          941.03913825482211\n        \n        \n      \n    \n\n\nWe define a probability space corresponding to (Regina, Cady) pairs of arrival times, by assuming that their arrival times individually follow a Normal(30, 10) model, independently of each other. That is, we spin the Normal(30, 10) spinner twice to simulate a pair of arrival times.\n\nP = Normal(30, 10) ** 2\nP.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(17.220844745940273, 41.73990261558275)\n        \n        \n        \n          1(28.357043746317146, 19.516142529702815)\n        \n        \n        \n          2(46.98275957989102, 41.038521905095905)\n        \n        \n        \n          3(26.785300996580702, 23.46243228654259)\n        \n        \n        \n          4(19.508447310678996, 16.61170695137681)\n        \n        \n        \n          5(32.7785792168998, 40.13111405692695)\n        \n        \n        \n          6(32.063006887924246, 17.280220706209306)\n        \n        \n        \n          7(21.070821122134525, 42.81929212221777)\n        \n        \n        \n          8(29.665484468890774, 36.73238845140908)\n        \n        ......\n        \n          9(23.38165816756268, 24.36160199235167)\n        \n        \n      \n    \n\n\nWe can unpack the individual \\(R\\), \\(Y\\) random variables and define \\(W\\), \\(T\\) as before.\n\nR, Y = RV(P)\n\nW = abs(R - Y)\n\nT = (R & Y).apply(min)\n\nWe can simulate values of \\(R\\) and plot them along a number line in a rug plot; compare to Figure 3.8. (Technically, the Normal(30, 10) assigns small but positive probability to values outside of [0, 60], so we might see some values outside of [0, 60].)\n\nplt.figure()\nR.sim(100).plot('rug')\nplt.show()\n\n\n\n\n\n\n\n\nWe can simulate many values and summarize them in a histogram. We’ll discuss histograms in more detail later, but notice that the histogram conveys that for a Normal(30, 10) distribution values near 30 are more likely than values near 0 or 60.\n\nplt.figure()\nR.sim(10000).plot()\nplt.show()\n\n\n\n\n\n\n\n\nWe can simulate and plot many \\((R, Y)\\) pairs of arrival times; compare to Figure 3.10 (without the rug).\n\n(R & Y).sim(1000).plot()\nplt.xlabel(\"R\");\nplt.ylabel(\"Y\");\n\n\n\n\n\n\n\n\n\n\nWe can also simulate and plot many \\((T, W)\\) pairs. Notice that the plot looks quite different from the one for the independent Uniform(0, 60) model for arrival times.\n\nmeeting_sim = (R & Y & T & W).sim(1000)\n\nmeeting_sim[2, 3].plot()\nplt.xlabel(\"T\");\nplt.ylabel(\"W\");\n\n\n\n\n\n\n\n\n\n\n\n\n3.4.3 Bivariate Normal model\nNow assume that Regina and Cady tend to arrive around the same time. We haven’t yet seen how to construct spinners to reflect dependence, but we’ll briefly introduce a particular model and some code. One way to model pairs of values that have a relationship or correlation is with a BivariateNormal model, like in the following.\n\nP = BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7)\nP.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(21.349047544074764, 32.77381012401626)\n        \n        \n        \n          1(11.562132070247234, 15.118724438149501)\n        \n        \n        \n          2(35.77638776218474, 31.315668720722247)\n        \n        \n        \n          3(25.414827762987073, 35.40764525379387)\n        \n        \n        \n          4(45.02235215885766, 34.48751253626255)\n        \n        \n        \n          5(35.391984880868726, 33.435274412096526)\n        \n        \n        \n          6(30.54164124201556, 9.496263639437917)\n        \n        \n        \n          7(13.692987334356559, 19.616463901560905)\n        \n        \n        \n          8(53.724795977004156, 42.40499833451176)\n        \n        ......\n        \n          9(27.753465965100304, 43.349932280821484)\n        \n        \n      \n    \n\n\nNote that a BivariateNormal probability space returns pairs directly. We can unpack the pairs as before, and plot some simulated values.\n\nR, Y = RV(P)\n\n(R & Y).sim(1000).plot()\nplt.xlabel(\"R\");\nplt.ylabel(\"Y\");\n\n\n\n\n\n\n\n\n\n\nNow we see that Regina and Cady tend to arrive near the same time, similar to Figure 2.15.\nIf we plot \\((T, W)\\) pairs, we expect values of the waiting time \\(W\\) to tend to be closer to 0 than in the independent arrivals models. Compare the scale on the vertical axis, corresponding to \\(W\\), in each of the three plots of \\((T, W)\\) pairs in this section.\n\nW = abs(R - Y)\n\nT = (R & Y).apply(min)\n\nmeeting_sim = (R & Y & T & W).sim(1000)\n\nmeeting_sim[2, 3].plot()\nplt.xlabel(\"T\");\nplt.ylabel(\"W\");\n\n\n\n\n\n\n\n\n\n\nA call to sim always simulates independent repetitions from the model, but be careful about what this means. In the Bivariate Normal model, the \\(R\\) and \\(Y\\) values are dependent within a repetition. However, the \\((R, Y)\\) pairs are independent between repetitions. Thinking in terms of a table, the \\(R, Y\\) columns are dependent, but the rows are independent.\nWe will study specific probability models like Normal and BivariateNormal in much more detail as we go.\n\n\n3.4.4 Exercises\n\nExercise 3.10 Write Symbulate code to conduct the simulation in Exercise 3.4. Caveat: don’t worry about the code to discard repetitions where the dart lands off the board. (We’ll return to this later.)\n\n\nExercise 3.11 Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4). Let \\(X\\) be the sum of the two spins and let \\(Y\\) be the larger of the two spins. Write Symbulate code to define an appropriate probability space and random variables, and simulate a few repetitions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-language-simulation-relative-frequency",
    "href": "language-simulation.html#sec-language-simulation-relative-frequency",
    "title": "3  The Language of Simulation",
    "section": "3.5 Approximating probabilities: Relative frequencies",
    "text": "3.5 Approximating probabilities: Relative frequencies\nWe can use simulation-based relative frequencies to approximate probabilities. That is, the probability of event \\(A\\) can be approximated by simulating—according to the assumptions encoded in the probability measure \\(\\textrm{P}\\)—the random phenomenon a large number of times and computing the relative frequency of \\(A\\).\n\\[\n{\\small\n\\textrm{P}(A) \\approx \\frac{\\text{number of repetitions on which $A$ occurs}}{\\text{number of repetitions}}, \\quad \\text{for a large number of repetitions simulated according to $\\textrm{P}$}\n}\n\\]\nIn practice, many repetitions of a simulation are performed on a computer to approximate what happens in the “long run”. However, we often start by carrying out a few repetitions by hand to help make the process more concrete.\n\n\n\n\n\n\n\nExample 3.5 Recall your simulation results from Example 3.1; ours are in Table 3.1. Based only on your 10 repetitions, how would you approximate the following? (Don’t worry if the approximations are any good yet.)\n\n\\(\\textrm{P}(A)\\), where \\(A\\) is the event that the first roll is 3.\n\\(\\textrm{P}(X=6)\\)\n\\(\\textrm{P}(X \\ge 6)\\)\n\\(\\textrm{P}(Y = 3)\\)\n\\(\\textrm{P}(Y \\ge 3)\\)\n\\(\\textrm{P}(X=6, Y=3)\\)\n\\(\\textrm{P}(X\\ge6, Y \\ge 3)\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.5. See Table 3.1 for the results of our simulation.\n\nApproximate \\(\\textrm{P}(A)\\) by 4/10 = 0.4, the relative frequency of event \\(A\\) in the simulation; that is, the proportion of repetitions where the first roll is 3.\nApproximate \\(\\textrm{P}(X=6)\\) by 2/10 = 0.2, the proportion of repetitions where the sum is 6.\nApproximate \\(\\textrm{P}(X\\ge 6)\\) by 5/10 = 0.5, the proportion of repetitions where the sum is at least 6.\nApproximate \\(\\textrm{P}(Y=3)\\) by 3/10 = 0.3, the proportion of repetitions where the max is 3.\nApproximate \\(\\textrm{P}(Y\\ge 3)\\) by 7/10 = 0.7, the proportion of repetitions where the max is at least 3.\nApproximate \\(\\textrm{P}(X=6, Y = 3)\\) by 1/10 = 0.1, the proportion of repetitions where both the sum is 6 and the max is 3.\nApproximate \\(\\textrm{P}(X\\ge 6, Y \\ge 3)\\) by 5/10 = 0.5, the proportion of repetitions where both the sum is at least 6 and the max is at least 3. (Since \\(X\\ge 6\\) implies \\(Y\\ge 3\\), \\(\\textrm{P}(X\\ge 6, Y\\ge 3) = \\textrm{P}(X\\ge 6)\\).)\n\n\n\n\n\n\n\n\n\n\n\n\nExample 3.6 Continuing Example 3.5.\n\nConstruct a table of the simulated relative frequencies of each possible value \\(x\\) of \\(X\\).\nConstruct a table of the simulated relative frequencies of each possible value \\((x, y)\\) pair of \\((X, Y)\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.6. For discrete random variables like these we can make tables or plots summarizing the observed values of the random variables and their corresponding relative frequencies.\nSummarizing our simulation results from Table 3.1, the observed values of \\(X\\) and corresponding relative frequencies are\n\n\n\n\\(x\\)\nRelative frequency\n\n\n\n\n2\n1/10\n\n\n3\n2/10\n\n\n4\n0\n\n\n5\n2/10\n\n\n6\n2/10\n\n\n7\n3/10\n\n\n8\n0\n\n\n\nThe above table18 represents an approximation of the distribution of \\(X\\), albeit a bad approximation; compare with Table 2.14.\nWe can summarize simulated \\((X, Y)\\) pairs and their relative frequencies, as in the following two-way table; compare with Table 2.17.\n\n\n\n\\(x, y\\)\n1\n2\n3\n4\n\n\n\n\n2\n1/10\n0\n0\n0\n\n\n3\n0\n2/10\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n0\n2/10\n0\n\n\n6\n0\n0\n1/10\n1/10\n\n\n7\n0\n0\n0\n3/10\n\n\n8\n0\n0\n0\n0\n\n\n\n\n\n\n\nYou might have noticed that many of the simulated relative frequencies in Example 3.5 provide terrible estimates of the corresponding probabilities. For example, the true probability that the first roll is a 3 is \\(\\textrm{P}(A) = 0.25\\) while the simulated relative frequency is 0.4. The problem is that the simulation only consisted of 10 repetitions. Probabilities can be approximated by long run relatively frequencies, but 10 repetitions certainly doesn’t qualify as the long run! The more repetitions we perform the better our estimates should be. But how many repetitions is sufficient? And how accurate are the estimates? We will address these issues in Section 3.6.\n\n3.5.1 A few Symbulate commands for summarizing simulation output\nWe’ll continue with the dice rolling example. Recall the setup.\n\nP = DiscreteUniform(1, 4) ** 2\n\nX = RV(P, sum)\n\nY = RV(P, max)\n\nFirst we’ll simulate and store 10 values of \\(X\\).\n\nx = X.sim(10)\nx # displays the simulated values\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          05\n        \n        \n        \n          14\n        \n        \n        \n          26\n        \n        \n        \n          35\n        \n        \n        \n          45\n        \n        \n        \n          56\n        \n        \n        \n          63\n        \n        \n        \n          76\n        \n        \n        \n          86\n        \n        ......\n        \n          95\n        \n        \n      \n    \n\n\nSuppose we want to find the relative frequency of 6. We can count the number of simulated values equal to 6 with count_eq().\n\nx.count_eq(6)\n\n4\n\n\nThe count is the frequency. To find the relative frequency we simply divide by the number of simulated values.\n\nx.count_eq(6) / 10\n\n0.4\n\n\nWe can find frequencies of other events using the “count” functions:\n\ncount_eq(u): count equal to (\\(=\\)) u\ncount_neq(u): count not equal to (\\(\\neq\\)) u\ncount_leq(u): count less than or equal to (\\(\\le\\)) u\ncount_lt(u): count less than (\\(&lt;\\)) u\ncount_geq(u): count greater than or equal to (\\(\\ge\\)) u\ncount_gt(u): count greater than (\\(&gt;\\)) u\ncount: count according to a custom True/False criteria (see examples below)\n\nUsing count() with no inputs to defaults to “count all”, which provides a way to count the total number of simulated values. (This is especially useful when conditioning.)\n\nx.count_eq(6) / x.count()\n\n0.4\n\n\nThe tabulate method provides a quick summary of the individual simulated values and their frequencies.\n\nx.tabulate()\n\n\n  \n    Value\n    Frequency\n  \n  \n    31415464Total10\n  \n\n\n\nBy default, tabulate returns frequencies (counts). Adding the argument19 normalize = True returns relative frequencies (proportions).\n\nx.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    30.140.150.460.4Total1.0\n  \n\n\n\nWe often initially simulate a small number of repetitions to see what the simulation is doing and check that it is working properly. However, in order to accurately approximate probabilities or distribution we simulate a large number of repetitions (usually thousands for our purposes). Now let’s simulate many \\(X\\) values and summarize the results.\n\nx = X.sim(10000)\n\nx.tabulate(normalize = True)\n\n\n\nTable 3.8: Table representing simulation-based approximate distribution of \\(X\\), the sum of two rolls of a fair four-sided die.\n\n\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    20.063330.123340.192650.246160.186970.124580.0633Total1.0\n  \n\n\n\n\n\n\nCompare to Table 2.14; with 10000 repetitions the simulation based approximations are pretty close to the theoretical probabilities.\nGraphical summaries play an important role in analyzing simulation output. We have previously seen rug plots of individual simulated values. Rug plot emphasize that realizations of a random variable are numbers along a number line. However, a rug plot does not adequately summarize relative frequencies. Instead, calling .plot() for simulated values of a discrete random variable produces20 an impulse plot which displays the simulated values and their relative frequencies; see Figure 3.11 and compare to Figure 2.16. Since we stored the simulated values as x, the same simulated values are used to produce Table 3.8 and Figure 3.11.\n\nx.plot()\n\n\n\n\n\n\n\n\n\nFigure 3.11: Impulse plot representing simulation-based approximate distribution of \\(X\\), the sum of two rolls of a fair four-sided die.\n\n\n\n\n\nNow we simulate and summarize a few \\((X, Y)\\) pairs.\n\nx_and_y = (X & Y).sim(10)\nx_and_y \n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(3, 2)\n        \n        \n        \n          1(5, 3)\n        \n        \n        \n          2(3, 2)\n        \n        \n        \n          3(6, 4)\n        \n        \n        \n          4(4, 2)\n        \n        \n        \n          5(4, 3)\n        \n        \n        \n          6(5, 3)\n        \n        \n        \n          7(7, 4)\n        \n        \n        \n          8(4, 2)\n        \n        ......\n        \n          9(4, 2)\n        \n        \n      \n    \n\n\nPairs of values can also be tabulated.\n\nx_and_y.tabulate()\n\n\n  \n    Value\n    Frequency\n  \n  \n    (3, 2)2(4, 2)3(4, 3)1(5, 3)2(6, 4)1(7, 4)1Total10\n  \n\n\n\n\nx_and_y.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    (3, 2)0.2(4, 2)0.3(4, 3)0.1(5, 3)0.2(6, 4)0.1(7, 4)0.1Total1.0\n  \n\n\n\nIndividual pairs can be plotted in a scatter plot, which is a two-dimensional analog of a rug plot.\n\nx_and_y.plot()\n\n\n\n\n\n\n\n\n\n\nThe values can be “jittered” slightly, as below, so that points do not coincide.\n\nx_and_y.plot(jitter = True)\n\n\n\n\n\n\n\n\n\n\nThe two-dimensional analog of an impulse plot is a tile plot. For two discrete variables, the 'tile' plot type produces a tile plot (a.k.a. heat map) where rectangles represent the simulated pairs with their relative frequencies visualized on a color scale.\n\nx_and_y.plot('tile')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustom functions can be used with count to compute relative frequencies of events involving multiple random variables. Suppose we want to approximate \\(\\textrm{P}(X&lt;6, Y \\ge 2)\\). We first define a Python function which takes as an input a pair u = (u[0], u[1]) and returns True if u[0] &lt; 6 and u[1] &gt;= 2.\n\n\ndef is_x_lt_6_and_y_ge_2(u):\n  if u[0] &lt; 6 and u[1] &gt;= 2:\n    return True\n  else:\n    return False\n\nNow we can use this function along with count to find the simulated relative frequency of the event \\(\\{X &lt;6, Y \\ge 2\\}\\). Remember that x_and_y stores \\((X, Y)\\) pairs of values, so the first coordinate x_and_y[0] represents values of \\(X\\) and the second coordinate x_and_y[1] represents values of \\(Y\\).\n\nx_and_y.count(is_x_lt_6_and_y_ge_2) / x_and_y.count()\n\n0.8\n\n\nWe could also count use Boolean logic; basically using indicators and the property \\(\\textrm{I}_{\\{X&lt;6,Y\\ge 2\\}}=\\textrm{I}_{\\{X&lt;6\\}}\\textrm{I}_{\\{Y\\ge 2\\}}\\).\n\n((x_and_y[0] &lt; 6) * (x_and_y[1] &gt;= 2)).count_eq(True) / x_and_y.count()\n\n0.8\n\n\nNow we simulate many \\((X, Y)\\) pairs and summarize their frequencies.\n\nx_and_y = (X & Y).sim(10000)\n\nx_and_y.tabulate()\n\n\n  \n    Value\n    Frequency\n  \n  \n    (2, 1)636(3, 2)1250(4, 2)649(4, 3)1217(5, 3)1191(5, 4)1236(6, 3)638(6, 4)1301(7, 4)1210(8, 4)672Total10000\n  \n\n\n\nHere are the relative frequencies; compare with Table 2.16.\n\nx_and_y.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    (2, 1)0.0636(3, 2)0.125(4, 2)0.0649(4, 3)0.1217(5, 3)0.1191(5, 4)0.1236(6, 3)0.0638(6, 4)0.1301(7, 4)0.121(8, 4)0.0672Total1.0\n  \n\n\n\nWhen there are thousands of simulated pairs, a scatter plot does not adequately display relative frequencies, even with jittering.\n\nx_and_y.plot(jitter = True)\n\n\n\n\n\n\n\n\n\n\nThe tile plot provides a better summary. Notice how the colors represent the relative frequencies in the previous table.\n\nx_and_y.plot('tile')\n\n\n\n\n\n\n\n\n\n\nFinally, we find the simulated relative frequency of the event \\(\\{X &lt;6, Y \\ge 2\\}\\).\n\nx_and_y.count(is_x_lt_6_and_y_ge_2) / x_and_y.count()\n\n0.5543\n\n\n\n\n3.5.2 Approximating probabilities in the meeting problem\n\n\n\n\n\n\n\nExample 3.7 Recall the independent Uniform(0, 60) model for arrival times of Example 3.3. Use the simulation results in Table 3.3 to approximate the following. (Don’t worry if the approximations are any good yet.)\n\n\\(\\textrm{P}(T &lt; 15)\\)\n\\(\\textrm{P}(W &lt; 15)\\)\n\\(\\textrm{P}(T &lt; 15, W &lt; 15)\\)\n\\(\\textrm{P}(R = 20)\\)\n\\(\\textrm{P}(19.5 &lt; R &lt; 20.5)\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.7. \n\nApproximate \\(\\textrm{P}(T &lt; 15)\\) by 3/10 = 0.3, the proportion of repetitions where the first arrival time is less than 15 minutes.\nApproximate \\(\\textrm{P}(W &lt; 15)\\) by 6/10 = 0.6, the proportion of repetitions where the waiting time is less than 15 minutes.\nApproximate \\(\\textrm{P}(T &lt; 15, W &lt; 15)\\) by 2/10 = 0.2, the proportion of repetitions where both the first arrival time and the waiting time are less than 15 minutes.\nApproximate \\(\\textrm{P}(R=20)\\) by 0, the proportion of repetitions where \\(R\\) is equal to 20.\nApproximate \\(\\textrm{P}(19.5 &lt; R &lt; 20.5)\\) by 1/10 = 0.1, the proportion of repetitions where \\(R\\), rounded to the nearest minute, is equal to 20.\n\n\n\n\n\nAn event either happens or not. Regardless of whether an event involves a discrete or continuous random variable, the probability of the event is approximated in the same way. However, the kinds of events we’re interested in differ between those involving discrete and those involving continuous random variables. The probability that a continuous random variable is equal to any particular value is 0, so we’re not interested in approximating “equals to” probabilities for continuous random variables. When dealing with continuous random variables in practice, “equals to” is really “close to”, and we compute approximate “close to” probabilities with relative frequencies are usual. (Later, we’ll see what it means to condition on a continuous random variable being equal to some value.)\nTo get better approximations for the probabilities in Example 3.3 we would need to simulate many more repetitions. But the process of approximating probabilities with simulated relative frequencies is the same as in Example 3.3.\nSimulation can also be used to investigate how sensitive (approximate) probabilities are to changes in assumptions.\n\n\n\n\n\n\n\nExample 3.8 Write Symbulate code to run simulations and use the results to approximate the probability that Regina and Cady arrive with 15 minutes of each other for each of the three models in Section 3.4.\n\nIndependent Uniform model\nIndependent Normal model\nBivariate Normal model\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.8. There are a few ways to code this, but one way is to define the waiting time random variable \\(W=|R-Y|\\) and find simulated relative frequencies of the event \\(\\{W&lt;15\\}\\).\nFirst the independent Uniform model.\n\nP = Uniform(0, 60) ** 2\nR, Y = RV(P)\n\nW = abs(R - Y)\n\nw = W.sim(10000)\n\nw.count_lt(15) / w.count()\n\n0.4392\n\n\nNext the independent Normal model.\n\nP = Normal(30, 10) ** 2\nR, Y = RV(P)\n\nW = abs(R - Y)\n\nw = W.sim(10000)\n\nw.count_lt(15) / w.count()\n\n0.7194\n\n\nFinally, the Bivariate Normal model.\n\nP = BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7)\nR, Y = RV(P)\n\nW = abs(R - Y)\n\nw = W.sim(10000)\n\nw.count_lt(15) / w.count()\n\n0.9483\n\n\nWe see that these changes in assumptions have substantial influence on this probability. The simulations shows that they are roughly 1.7 times more likely to arrive within 15 minutes of each other under the independent Normal model than under the independent Uniform model, and roughly 1.3 times more likely under the Bivariate Normal model than under the independent Normal model.\n\n\n\n\nWe have previously seen rug plots of individual simulated values. Rug plot emphasize that realizations of a random variable are numbers along a number line. However, a rug plot does not adequately summarize the distribution of values. Instead, calling .plot() for simulated values of a continuous random variable produces a histogram.\n\nplt.figure()\nw.plot()\nplt.show()\n\n\n\n\n\n\n\n\nWe will cover histograms and marginal distributions of continuous random variables in much more detail in ?sec-simulation-marginal-continuous.\n\n\n3.5.3 Exercises\n\nExercise 3.12 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\n\nExplain how you could, in principle, conduct a simulation by hand and use the results to approximate\n\n\\(\\textrm{P}(X = 2)\\)\n\\(\\textrm{P}(Y = 1)\\)\n\\(\\textrm{P}(X = 2, Y = 1)\\)\n\nWrite Symbulate code to conduct a simulation and approximate the values in part 1.\nWrite Sybulate code to conduct a simulation and approximate\n\nMarginal distribution of \\(X\\)\nMarginal distribution of \\(Y\\)\nJoint distribution of \\(X\\) and \\(Y\\)\n\n\n\n\nExercise 3.13 Repeat Exercise 3.12, but now assuming that 10% of boxes contain prize 1, 30% contain prize 2, and 60% contain prize 3.\n\n\nExercise 3.14 Maya is a basketball player who makes 40% of her three point field goal attempts. Suppose that at the end of every practice session, she attempts three pointers until she makes one and then stops. Let \\(X\\) be the total number of shots she attempts in a practice session. Assume shot attempts are independent, each with probability of 0.4 of being successful.\n\nExplain in words you could use simulation to approximate the distribution of \\(X\\) and \\(\\textrm{P}(X &gt; 3)\\).\nWrite Symbulate code to approximate the distribution of \\(X\\) and \\(\\textrm{P}(X &gt; 3)\\).\n\n\n\nExercise 3.15 Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4). Let \\(X\\) be the sum of the two spins and let \\(Y\\) be the larger of the two spins.\n\nDescribe in words how you could use simulation to approximate\n\n\\(\\textrm{P}(X &lt; 3.5)\\)\n\\(\\textrm{P}(Y &gt; 2.7)\\)\n\\(\\textrm{P}(X &lt; 3.5, Y &gt; 2.7)\\)\n\nWrite Symbulate code to conduct a simulation to approximate, via plots\n\nthe marginal distribution of \\(X\\)\nthe marginal distribution of \\(Y\\)\nthe joint distribution of \\(X\\) and \\(Y\\)\nThe probabilities from part 1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-moe",
    "href": "language-simulation.html#sec-moe",
    "title": "3  The Language of Simulation",
    "section": "3.6 Approximating probabilities: Simulation margin of error",
    "text": "3.6 Approximating probabilities: Simulation margin of error\nThe probability of an event can be approximated by simulating the random phenomenon a large number of times and computing the relative frequency of the event. After enough repetitions we expect the simulated relative frequency to be close to the true probability, but there probably won’t be an exact match. Therefore, in addition to reporting the approximate probability, we should also provide a margin of error which indicates how close we think our simulated relative frequency is to the true probability.\nSection 1.2.1 introduced the relative frequency interpretation in the context of flipping a fair coin. After many flips of a fair coin, we expect the proportion of flips resulting in H to be close to 0.5. But how many flips is enough? And how “close” to 0.5? We’ll investigate these questions now.\nConsider Figure 3.12 below. Each dot represents a set of 10,000 fair coin flips. There are 100 dots displayed, representing 100 different sets of 10,000 coin flips each. For each set of flips, the proportion of the 10,000 flips which landed on head is recorded. For example, if in one set 4973 out of 10,000 flips landed on heads, the proportion of heads is 0.4973. The plot displays 100 such proportions; similar values have been “binned” together for plotting. We see that 98 of these 100 proportions are between 0.49 and 0.51, represented by the blue dots. So if “between 0.49 and 0.51” is considered “close to 0.5”, then yes, in 10000 coin flips we would expect21 the proportion of heads to be close to 0.5.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.12: Proportion of flips which are heads in 100 sets of 10,000 fair coin flips. Each dot represents a set of 10,000 fair coin flips. In 98 of these 100 sets the proportion of heads is between 0.49 and 0.51 (the blue dots).\n\n\n\nOur discussion of Figure 3.12 suggests that 0.01 might be an appropriate margin of error for a simulation based on 10,000 flips. Suppose we perform a simulation of 10000 flips with 4973 landing on heads. We could say “we estimate that the probability that a coin land on heads is equal to 0.4973”. But such a precise estimate would almost certainly be incorrect, due to natural variability in the simulation. In fact, only 1 sets22 resulted in a proportion of heads exactly equal to the true probability of 0.5.\nA better statement would be “we estimate that the probability that a coin land on heads is 0.4973 with a margin of error23 of 0.01”. This means that we estimate that the true probability of heads is within 0.01 of 0.4973. In other words, we estimate that the true probability of heads is between 0.4873 and 0.5073, an interval whose endpoints are \\(0.4973 \\pm 0.01\\). This interval estimate is “accurate” in the sense that the true probability of heads, 0.5, is between 0.4873 and 0.5073. By providing a margin of error, we have sacrificed a little precision—“equal to 0.4973” versus “within 0.01 of 0.4973”—to achieve greater accuracy.\nLet’s explore this idea of “accuracy” further. Recall that Figure 3.12 displays the proportion of flips which landed on heads for 100 sets of 10000 flips each. Suppose that for each of these sets we form an interval estimate of the probability that the coin lands on heads by adding/subtracting 0.01 from the simulated proportion, as we did for \\(0.4973 \\pm 0.01\\) in the previous paragraph. Figure 3.13 displays the results. Even though the proportion of heads was equal to 0.5 in only 1 sets, in 98 of these 100 sets (the blue intervals) the corresponding interval contains 0.5, the true probability of heads. For almost all of the sets, the interval formed via “relative frequency \\(\\pm\\) margin of error” provides an accurate estimate of the true probability. However, not all the intervals contain the true probability, which is why we often qualify that our margin of error is for “95% confidence” or “95% accuracy”. We will see more about “confidence” soon. In any case, the discussion so far, and the results in Figure 3.12 and Figure 3.13, suggest that 0.01 is a reasonable choice for margin of error when estimating the probability that a coin lands on heads based on 10000 flips.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.13: Interval estimates of the probability of heads based on 100 sets of 10,000 fair coin flips. Each dot represents the proportion of heads in a set of 10,000 fair coin flips. (The sets have been sorted based on their proportion of heads.) For each set an interval is obtained by adding/subtracting the margin of error of 0.01 from the proportion of heads. In 98 of these 100 sets (the blue dots/intervals) the corresponding interval contains the true probability of heads (0.5, represented by the vertical black line).\n\n\n\nWhat if we want to be stricter about what qualifies as “close to 0.5”? That is, what if a margin of error of 0.01 isn’t good enough? You might suspect that with even more flips we would expect to observe heads on even closer to 50% of flips. Indeed, this is the case. Figure 3.14 displays the results of 100 sets of 1,000,000 fair coin flips. The pattern seems similar to Figure 3.12 but pay close attention to the horizontal axis which covers a much shorter range of values than in the previous figure. Now 91 of the 100 proportions are between 0.499 and 0.501. So in 1,000,000 flips we would expect24 the proportion of heads to be between 0.499 and 0.501, pretty close to 0.5. This suggests that 0.001 might be an appropriate margin of error for a simulation based on 1,000,000 flips.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.14: Proportion of flips which are heads in 100 sets of 1,000,000 fair coin flips. Each dot represents a set of 1,000,000 fair coin flips. In 91 of these 100 sets the proportion of heads is between 0.499 and 0.501 (the blue dots).\n\n\n\nWhat about even more flips? In Figure 3.15 each dot represents a set of 100 million flips. The pattern seems similar to the previous figures, but again pay close attention the horizontal access which covers a smaller range of values. Now 96 of the 100 proportions are between 0.4999 and 0.5001. So in 100 million flips we would expect25 the proportion of heads to be between 0.4999 and 0.5001, pretty close to 0.5. This suggests that 0.0001 might be an appropriate margin of error for a simulation based on 100,000,000 flips.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.15: Proportion of flips which are heads in 100 sets of 100,000,000 fair coin flips. Each dot represents a set of 100,000,000 fair coin flips. In 96 of these 100 sets the proportion of heads is between 0.4999 and 0.5001 (the blue dots).\n\n\n\nThe previous figures illustrate that the more flips there are, the more likely it is that we observe a proportion of flips landing on heads close to 0.5. We also see that with more flips we can refine our definition of “close to 0.5”: increasing the number of flips by a factor of 100 (10,000 to 1,000,000 to 100,000,000) seems to give us an additional decimal place of precision (\\(0.5\\pm0.01\\) to \\(0.5\\pm 0.001\\) to \\(0.5\\pm 0.0001\\).)\n\n3.6.1 A closer look at margin of error\nWe will now carry out an analysis similar to the one above to investigate simulation margin of error and how it is influenced by the number of simulated values used to compute the relative frequency. Continuing the dice example, suppose we want to estimate \\(p=\\textrm{P}(X=6)\\), the probability that the sum of two rolls of a fair four-sided equals six. Since there are 16 possible equally likely outcomes, 3 of which result in a sum of 3, the true probability is \\(p=3/16=0.1875\\).\nWe will perform a “meta-simulation”. The process is as follows\n\nSimulate two rolls of a fair four-sided die. Compute the sum (\\(X\\)) and see if it is equal to 6.\nRepeat step 1 to generate \\(N\\) simulated values of the sum (\\(X\\)). Compute the relative frequency of sixes: count the number of the \\(N\\) simulated values equal to 6 and divide by \\(N\\). Denote this relative frequency \\(\\hat{p}\\) (read “p-hat”).\nRepeat step 2 a large number of times, recording the relative frequency \\(\\hat{p}\\) for each set of \\(N\\) values.\n\nBe sure to distinguish between steps 2 and 3. A simulation will typically involve just steps 1 and 2, resulting in a single relative frequency based on \\(N\\) simulated values. Step 3 is the “meta” step; we see how this relative frequency varies from simulation to simulation to help us in determing an appropriate margin of error. The important quantity in this analysis is \\(N\\), the number of independently simulated values used to compute the relative frequency in a single simulation. We wish to see how \\(N\\) impacts margin of error. The number of simulations in step 3 just needs to be “large” enough to provide a clear picture of how the relative frequency varies from simulation to simulation. The more the relative frequency varies from simulation to simulation, the larger the margin of error needs to be.\nWe can combine steps 1 and 2 of the meta-simulation to put it in the framework of the simulations from earlier in this chapter. Namely, we can code the meta-simulation as a single simulation in which\n\nA sample space outcome represents \\(N\\) values of the sum of two fair-four sided dice\nThe main random variable of interest is the proportion of the \\(N\\) values which are equal to 6.\n\nLet’s first consider \\(N=100\\). The following Symbulate code defines the probability space corresponding to 100 values of the sum of two-fair four sided dice. Notice the use of apply which functions much in the same way26 as RV.\n\nN = 100\nP = BoxModel([1, 2, 3, 4], size = 2).apply(sum) ** N\nP.sim(5)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(6, 6, 5, 7, 5, ..., 4)\n        \n        \n        \n          1(5, 5, 2, 6, 3, ..., 4)\n        \n        \n        \n          2(4, 8, 4, 4, 8, ..., 6)\n        \n        \n        \n          3(5, 6, 8, 3, 2, ..., 5)\n        \n        \n        \n          4(4, 5, 6, 5, 5, ..., 7)\n        \n        \n      \n    \n\n\nIn the code above\n\nBoxModel([1, 2, 3, 4], size = 2) simulates two rolls of a fair four-sided die\n.apply(sum) computes the sum of the two rolls\n** N repeats the process N times to generate a set of N independent values, each value representing the sum of two rolls of a fair four-sided die\nP.sim(5) simulates 5 sets, each set consisting of N sums\n\nNow we define the random variable which takes as an input a set of \\(N\\) sums and returns the proportion of the \\(N\\) sums which are equal to six.\n\nphat = RV(P, count_eq(6)) / N\nphat.sim(5)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          00.15\n        \n        \n        \n          10.14\n        \n        \n        \n          20.24\n        \n        \n        \n          30.19\n        \n        \n        \n          40.19\n        \n        \n      \n    \n\n\nIn the code above\n\nphat is an RV defined on the probability space P. Recall that an outcome of P is a set of N sums (and each sum is the sum of two rolls of a fair four-sided die).\nThe function that defines the RV is count.eq(6), which counts the number of values in the set that are equal to 6. We then27 divide by N, the total number of values in the set, to get the relative frequency. (Remember that a transformation of a random variable is also a random variable.)\nphat.sim(5) generates 5 simulated values of the relative frequency phat. Each simulated value of phat is the relative frequency of sixes in N sums of two rolls of a fair four-sided die.\n\nNow we simulate and summarize a large number of values of phat. We’ll simulate 100 values for illustration (as we did in Figure 3.12, Figure 3.14, and Figure 3.15). Be sure not to confuse 100 with N. Remember, the important quantity is N, the number of simulated values used in computing each relative frequency.\n\n\n\n\n\n\n\n\n\n\nphat.sim(100).plot(type = \"impulse\", normalize = False)\nplt.ylabel('Number of simulations');\n\nWe see that the 100 relative frequencies are roughly centered around the true probability 0.1875, but there is variability in the relative frequencies from simulation to simulation. From the range of values, we see that most relative frequencies are within about 0.08 or so from the true probability 0.1875. So a value around 0.08 seems like a reasonable value of the margin of error, but the actual value depends on what we mean by “most”. We can get a clearer picture if we run more simulations. The following plot displays the results of 10000 simulations, each resulting in a value of \\(\\hat{p}\\). Remember that each relative frequency is based on \\(N=100\\) sums of two rolls.\n\n\n\n\n\n\n\n\n\n\nphats = phat.sim(10000)\nphats.plot(type = \"impulse\", normalize = False)\nplt.ylabel('Number of simulations');\n\nLet’s see how many of these 10000 simulated proportions are within 0.08 of the true probability 0.1875.\n\n1 - (phats.count_lt(0.1875 - 0.08) + phats.count_gt(0.1875 + 0.08)) / 10000\n\n0.9609\n\n\nIn roughly 95% or so of simulations, the simulated relative frequency was within 0.08 of the true probability. So 0.08 seems like a reasonable margin of error for “95% confidence” or “95% accuracy”. However, a margin of error of 0.08 yields pretty imprecise estimates, ranging from about 0.10 to 0.27. Can we keep the degree of accuracy at 95% but get a smaller margin of error, and hence a more precise estimate? Yes, if we increase the number of repetitions used to compute the relative frequency.\nNow we repeat the analysis, but with \\(N=10000\\). In this case, each relative frequency is computed based on 10000 independent values, each value representing a sum of two rolls of a fair four-sided die. As before we start with 100 simulated relative frequencies.\n\n\n\n\n\n\n\n\n\n\nN = 10000\nP = BoxModel([1, 2, 3, 4], size = 2).apply(sum) ** N\nphat = RV(P, count_eq(6)) / N\n\nphats = phat.sim(100)\nphats.plot(type = \"impulse\", normalize = False)\nplt.ylabel('Number of simulations');\n\nAgain we see that the 100 relative frequencies are roughly centered around the true probability 0.1875, but there is less variability in the relative frequencies from simulation to simulation for \\(N=10000\\) than for \\(N=100\\). Pay close attention to the horizontal axis. From the range of values, we see that most relative frequencies are now within about 0.008 of the true probability 0.1875.\n\n1 - (phats.count_lt(0.1875 - 0.008) + phats.count_gt(0.1875 + 0.008)) / 100\n\n0.95\n\n\nAs with \\(N=100\\), running more than 100 simulations would give a clearer picture of how much the relative frequency based on \\(N=10000\\) simulated values varies from simulation to simulation. But even with just 100 simulations, we see that a margin of error of about 0.008 is required for roughly 95% accuracy when \\(N=10000\\), as opposed to 0.08 when \\(N=100\\). As we observed in the coin flipping example earlier in this section, it appears that increasing \\(N\\) by a factor of 100 yields an extra decimal place of precision. That is, increasing \\(N\\) by a factor of 100 decreases the margin of error by a factor of \\(\\sqrt{100}\\). In general, the margin of error is inversely related to \\(\\sqrt{N}\\).\n\n\n\n\nTable 3.9: Comparison of margins of error for 95% confidence for the meta-simulations in this section.\n\n\n\n\n\n\nProbability that\nTrue value\n95% m.o.e. (N = 100)\n95% m.o.e. (N = 10000)\n95% m.o.e. (N = 1000000)\n\n\n\n\nA fair coin flip lands H\n0.5000\n0.1000\n0.0100\n0.0010\n\n\nTwo rolls of a fair four-sided die sum to 6\n0.1875\n0.0781\n0.0078\n0.0008\n\n\n\n\n\n\n\n\nThe two examples in this section illustrate that the margin of error also depends somewhat on the true probability. The margin of error required for 95% accuracy is larger when the true probability is 0.5 than when it is 0.1875. It can be shown that when estimating a probability \\(p\\) with a relative frequency based on \\(N\\) simulated repetitions, the margin of error required for 95% confidence28 is \\[\n2\\frac{\\sqrt{p(1-p)}}{\\sqrt{N}}\n\\] For a given \\(N\\), the above quantity is maximized when \\(p\\) is 0.5. Since \\(p\\) is usually unknown—the reason for performing the simulation is to approximate it—we plug in 0.5 for a somewhat conservative margin of error of \\(1/\\sqrt{N}\\).\nFor a fixed \\(N\\), there is a tradeoff between accuracy and precision. The factor 2 in the margin of error formula above corresponds to 95% accuracy. Greater accuracy would require a larger factor, and a larger margin of error, resulting in a wider—that is, less precise—interval. For example, 99% confidence requires a factor of roughly 2.6 instead of 2, resulting in an interval that is roughly 30 percent wider. The confidence level does matter, but the primary influencer of margin of error is \\(N\\), the number of independently simulated repetitions on which the relative frequency is based. Regardless of confidence level, the margin of error is on the order of magnitude of \\(1/\\sqrt{N}\\).\nIn summary, the margin of error when approximating a probability based on a simulated relative frequency is roughly on the order \\(1/\\sqrt{N}\\), where \\(N\\) is the number of independently simulated repetitions used to calculate the relative frequency. Warning: alternative methods are necessary when the actual probability being estimated is very close to 0 or to 1.\nA probability is a theoretical long run relative frequency. A probability can be approximated by a relative frequency from a large number of simulated repetitions, but there is some simulation margin of error. Likewise, the average value of \\(X\\) after a large number of simulated repetitions is only an approximation to the theoretical long run average value of \\(X\\), that is, the expected value of \\(X\\). The margin of error is also on the order of \\(1/\\sqrt{N}\\) where \\(N\\) is the number of independently simulated values used to compute the average, but the degree of variability of the random variable also plays a role. We will explore margins of error for long run averages in more detail later.\nPay attention to what \\(N\\) denotes: \\(N\\) is the number of independently29 simulated repetitions used to calculate the relative frequency. This is not necessarily the number of simulated repetitions. For example, suppose we use simulation to approximate the conditional probability that the larger of two rolls of a fair four-sided die is 4 given that the sum is equal to 6. We might start by simulating 10000 pairs of rolls. But the sum would be equal to 6 in only about 1875 pairs, and it is only these pairs that would be used to compute the relative frequency that the larger roll is 4 to approximate the probability of interest. The appropriate margin of error is roughly \\(1/\\sqrt{1875} \\approx 0.023\\). Compared to 0.01 (based on the original 10000 repetitions), the margin of error of 0.023 for the conditional probability results in intervals that are 130 percent wider. Carefully identifying the number of repetitions used to calculate the relative frequency is especially important when determining appropriate simulation margins of error for approximating conditional probabilities, which we’ll discuss in more detail later.\n\n\n3.6.2 Approximating multiple probabilities\nWhen using simulation to estimate a single probability, the primary influencer of margin of error is \\(N\\), the number of repetitions on which the relative frequency is based. It doesn’t matter as much whether we use, say, 95% versus 99% confidence (either way, it’s an “A”). That is, it doesn’t matter too much whether we compute our margin of error using \\[\n2\\frac{\\sqrt{p(1-p)}}{\\sqrt{N}},\n\\] with a multiple of 2 for 95% confidence, or if we replace 2 by 2.6 for 99% confidence. (Remember, we can plug in 0.5 for the unknown \\(p\\) for a conservative margin of error.) A margin of error based on 95% or 99% (or another confidence level in the neighborhood) provides a reasonably accurate estimate of the probability. However, using simulation to approximate multiple probabilities simultaneously requires a little more care with the confidence level.\nIn the previous section we used simulation to estimate \\(\\textrm{P}(X=6)\\). Now suppose we want to approximate \\(\\textrm{P}(X = x)\\) for each value of \\(x = 2,3,4,5,6,7,8\\). We could run a simulation to obtain results like those in Figure 3.11 and the table before it. Each of the relative frequencies in the table is an approximation of the true probability, and so each of the relative frequencies should have a margin of error, say 0.01 for a simulation based on 10000 repetitions. Thus, the simulation results yield a collection of seven interval estimates, an interval estimate of \\(\\textrm{P}(X = x)\\) for each value of \\(x = 2,3,4,5,6,7,8\\). Each interval in the collection either contains the respective true probability or not. The question is then: In what percent of simulations will every interval in the collection contain the respective true probability?\nFigure 3.16 summarizes the results of 100 simulations. Each simulation consists of 10000 repetitions, with results similar to those in Figure 3.11 and the table before it. Each simulation is represented by a row in Figure 3.16, consisting of seven 95% interval estimates, one for each value of \\(x\\). (The rows have been sorted before plotting; see the next paragraph.) Each panel represents a different value of \\(x\\); for each value of \\(x\\), around 95 out of the 100 simulations yield estimates that contain the true probability \\(\\textrm{P}(X=x)\\), represented by the vertical line.\n\n\n\n\n\n\n\n\nFigure 3.16: Results of 100 simulations. Each simulation yields a collection of seven 95% confidence intervals.\n\n\n\n\n\nHowever, let’s zoom in on the bottom of Figure 3.16. Figure 3.17 displays the results of the 21 simulations at the bottom of Figure 3.16. Look carefully row by row in Figure 3.17; in each of these simulations at least one of the seven intervals in the collection does not contain the true probability. In other words, every interval in the collection contains the respective true probability in only 79 of the 100 simulations (the other simulations in Figure 3.16).) While we have 95 percent confidence in our interval estimate of \\(\\textrm{P}(X = x)\\) for any single \\(x\\), we only have around 79 percent confidence in our approximate distribution of \\(X\\). Our confidence “grade” has gone from “A” range (95 percent) to “C” range (79 percent).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.17: Subset of 21 simulations from Figure 3.16. In each of these simulations, at least one 95% confidence interval does not contain the respective true probability.\n\n\n\nWhen approximating multiple probabilities based on a single simulation, such as when approximating a distribution, margins of error and interval estimates need to be adjusted to obtain simultaneous 95% confidence. The easiest way to do this is to make all of the intervals in the collection wider.\nThere are many procedures for adjusting a collection of interval estimates to achieve simultaneous confidence; we won’t get into any technical details. As a very rough, but simple and typically conservative rule, when approximating many probabilities based on a single simulation, we recommend making the margin of error twice as large as when approximating a single probability. That is, use a margin of error of \\(2/\\sqrt{N}\\) (rather than \\(1/\\sqrt{N}\\)) to achieve simultaneous 95% confidence when approximating many probabilities based on a single simulation.\nFigure 3.18 displays the same simulation results as Figure 3.16, but now the margin of error for each confidence interval is 2 times greater. We can see that all of the original “bad” intervals turn “good” when widened, and now there is (greater than) 95% simultaneous confidence.\n\n\n\n\n\n\n\n\nFigure 3.18: Results of 100 simulations. Each simulation yields a collection of seven 95% confidence intervals. The margin of error has been adjusted to obtain simultaneous confidence.\n\n\n\n\n\n\n\n3.6.3 Beware a false sense of precision\nWhy don’t we always run something like one trillion repetitions so that our margin of error is tiny? There is a cost to simulating and storing more repetitions in terms of computational time and memory. Also, remember that simulating one trillion repetitions doesn’t guarantee that the margin of error is actually based on anywhere close to one trillion repetitions, especially when conditioning on a low probability event.\nMost importantly, keep in mind that any probability model is based on a series of assumptions and these assumptions are not satisfied exactly by the random phenomenon. A precise estimate of a probability under the assumptions of the model is not necessarily a comparably precise estimate of the true probability. Reporting probability estimates out to many decimal places conveys a false sense of precision and should typically be avoided.\nFor example, the probability that any particular coin lands on heads is probably not 0.5 exactly. But any difference between the true probability of the coin landing on heads and 0.5 is likely not large enough to be practically meaningful30. That is, assuming the coin is fair is a reasonable model.\nSuppose we assume that the probability that a coin lands on heads is exactly 0.5 and that the results of different flips are independent. If we flip the coin 1000 times the probability that it lands on heads at most 490 times is 0.2739864. (We will see a formula for computing this value later.) If we were to simulate one trillion repetitions (each consisting of 1000 flips) to estimate this probability then our margin of error would be 0.000001; we could expect accuracy out to the sixth decimal place. However, reporting the probability with so many decimal places is somewhat disingenuous. If the probability that the coin lands on heads were 0.50001, then the probability of at most 490 heads in 1000 flips would be 0.2737757. If the probability that the coin lands on heads were 0.5001, then the probability of at most 490 heads in 1000 flips would be 0.2718834. Reporting our approximate probability as something like 0.2739864 \\(\\pm\\) 0.000001 says more about the precision in our assumption that the coin is fair than it does about the true probability that the coin lands on heads at most 490 times in 1000 flips. A more honest conclusion would result from running 10000 repetitions and reporting our approximate probability as something like 0.27 \\(\\pm\\) 0.01. Such a conclusion reflects more genuinely that there’s some “wiggle room” in our assumptions, and that any probability computed according to our model is at best a reasonable approximation of the “true” probability.\nFor most of the situations we’ll encounter in this book, estimating a probability to within 0.01 of its true value will be sufficient for practical purposes, and so basing approximations on 10000 independently simulated values will be appropriate. Of course, there are real situations where probabilities need to be estimated much more precisely, e.g., the probability that a bridge will collapse. Such situations require more intensive methods.\n\n\n\n\n\n\n\nExample 3.9 Donny Dont runs a simulation to approximate the probability of an event \\(A\\). In 1,000,000 repetitions, event \\(A\\) occurs on 437,952 repetitions. He computes a margin of error (for 95% confidence) of \\(1/\\sqrt{1000000} = 0.001\\). Donny tries a few different ways of reporting his results. Explain to him what is wrong, missing, or could be improved in each of the following.\n\nI estimate that \\(\\textrm{P}(A)\\) is 0.437952.\nI estimate that \\(\\textrm{P}(A)\\) is 43.7952% with a margin of error of 0.1%.\nI estimate that \\(\\textrm{P}(A)\\) is between 0.436952 and 0.438952.\nI estimate with 95% confidence that under these assumptions \\(\\textrm{P}(A)\\) is between 0.437 and 0.439.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.9. \n\nDonny has not provided a margin of error.\nWe’re okay with Donny expressing the proportion as a percent. However, 0.001 is technically a margin of error of 0.1 percentage points. A margin of error of 0.1% implies a percentage change, leading to interval endpoints of \\(0.437952\\times (1 - 0.001) = 0.437514\\) and \\(0.437952\\times (1 + 0.001) = 0.438390\\). With a margin of error of 0.001, the interval endpoints are really \\(0.437952 -  0.001 = 0.436952\\) and \\(0.437952 + 0.001 = 0.438952\\). The numbers are fairly similar in this case, but in general, the margins of error we have discussed are additive and therefore should be reported as percentage points.\nWe don’t know the context, but in many situations reporting estimates to six decimal places as Donny has done is not necessary and could convey a false sense of precision.\nWe like Donny’s statement! He has provided an interval estimate, reported his level of confidence, rounded to an appropriate number of decimal places (in most contexts) so as not to convey a false sense of precision, and drawn attention to to the fact that the estimate of the probability is predicated on the model assumptions. It would have also been fine if he had replaced “is between 0.437 and 0.439” with “is 0.438 with a margin of error of 0.001”. In practice, Donny should replace vague statements like “these assumptions” and “\\(\\textrm{P}(A)\\)” with contextual details, but the general form of his answer is very good.\n\n\n\n\n\n\n\n3.6.4 Exercises\n\nExercise 3.16 Use simulation to approximate the probability that at least two people in a group of \\(n=30\\) share a birthday in Example 2.48. Compute the margin of error and write a clearly worded sentence reporting your approximate probability in context.\n\n\nExercise 3.17 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\nSuppose you simulate 10000 \\((X, Y)\\) pairs and use the results to approximate all of\n\nMarginal distribution of \\(X\\)\nMarginal distribution of \\(Y\\)\nJoint distribution of \\(X\\) and \\(Y\\)\n\nWhat is the approximate margin of error for simultaneous 95% confidence?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-LRA",
    "href": "language-simulation.html#sec-LRA",
    "title": "3  The Language of Simulation",
    "section": "3.7 Approximating expected values: Averages",
    "text": "3.7 Approximating expected values: Averages\nOn any single repetition of a simulation a particular event either occurs or not. Summarizing simulation results for events involves simply counting the number of repetitions on which the event occurs and finding related proportions.\nOn the other hand, random variables typically take many possible values over the course of many repetitions. We are still interested in relative frequencies of events, like \\(\\{X=6\\}\\), \\(\\{Y \\ge 3\\}\\), and \\(\\{X &gt; 5, Y \\ge 3\\}\\). But for random variables we are also interested in their distributions which describe the possible values that the random variables can take and their relative likelihoods. A marginal distribution contains all the information about the pattern of variability of a single random variable alone, and a joint distribution contains all the information about the pattern of variability of a collection of random variables. It is also useful to summarize some key features of the pattern of variability.\nOne summary characteristic of a marginal distribution of a random variable is the expected value. In Section 1.7 and Section 2.5.3 we discussed how an expected value can be interpreted as the long run average value of a random variable. We can approximate the long run average value by simulating many values of the random variable and computing the average (a.k.a. mean) in the usual way: sum all the simulated values and divide by the number of simulated values.\n\n\n\n\n\n\n\nExample 3.10 Let \\(X\\) be the sum of two rolls of a fair four-sided die, and let \\(Y\\) be the larger of the two rolls (or the common value if a tie). Recall your tactile simulation from Example 3.1; see ours in Table 3.1. Based only on the results of your simulation, approximate the long run average value of each of the following. (Don’t worry if the approximations are any good yet.)\n\n\\(X\\)\n\\(Y\\)\n\\(X^2\\)\n\\(XY\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.10. We reproduce the results of our simulation in Table 3.10 with additional columns for \\(X^2\\) and \\(XY\\). Results vary naturally so your simulation results will be different, but the same ideas apply.\n\n\n\n\nTable 3.10: Results of 10 repetitions of two rolls of a fair four-sided die\n\n\n\n\nResults of 10 repetitions of two rolls of a fair four-sided die\n\n\nRepetition\nFirst roll\nSecond roll\nX\nY\nX^2\nXY\n\n\n\n\n1\n2\n1\n3\n2\n9\n6\n\n\n2\n1\n1\n2\n1\n4\n2\n\n\n3\n3\n3\n6\n3\n36\n18\n\n\n4\n4\n3\n7\n4\n49\n28\n\n\n5\n3\n2\n5\n3\n25\n15\n\n\n6\n3\n4\n7\n4\n49\n28\n\n\n7\n2\n3\n5\n3\n25\n15\n\n\n8\n2\n4\n6\n4\n36\n24\n\n\n9\n1\n2\n3\n2\n9\n6\n\n\n10\n3\n4\n7\n4\n49\n28\n\n\n\n\n\n\n\n\n\nApproximate the long run average value of \\(X\\) by summing the 10 simulated values of \\(X\\) and dividing by 10. \\[\n\\frac{3 + 2 + 6 + 7 + 5 + 7 + 5 + 6 + 3 + 7}{10} = 5.1\n\\]\nApproximate the long run average value of \\(Y\\) by summing the 10 simulated values of \\(Y\\) and dividing by 10. \\[\n\\frac{2 + 1 + 3 + 4 + 3 + 4 + 3 + 4 + 2 + 4}{10} = 3\n\\]\nFirst, for each repetition square the value of \\(X\\) to obtain the \\(X^2\\) column. Then approximate the long run average value of \\(X^2\\) by summing the 10 simulated values of \\(X^2\\) and dividing by 10. \\[\n\\frac{9 + 4 + 36 + 49 + 25 + 49 + 25 + 36 + 9 + 49}{10} = 29.1\n\\]\nFirst, for each repetition compute the product \\(XY\\) to obtain the \\(XY\\) column. Then approximate the long run average value of \\(XY\\) by summing the 10 simulated values of \\(XY\\) and dividing by 10. \\[\n\\frac{6 + 2 + 18 + 28 + 15 + 28 + 15 + 24 + 6 + 28}{10} = 17\n\\]\n\nOf course, 10 repetitions is not enough to reliably approximate the long run average value. But whether the average is based on 10 values or 10 million, an average is computed in the usual way: sum the values and divide by the number of values.\n\n\n\n\n\n\n\n\n\n\n\nExample 3.11 Recall Section 3.2.2 where we assumed the arrival time \\(X\\) (minutes after noon) followed a Normal(30, 10) distribution, represented by the spinner in Figure 3.7. Table 3.5 displays 10 simulated values of \\(X\\). Based only on the results of this simulation, approximate the long run average value of \\(X\\). (Don’t worry if the approximation is any good yet.)\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.11. Approximate the long run average value of \\(X\\) by simply computing the average in the usual way: sum the 10 simulated values of \\(X\\) and divide by 10. It’s just that when \\(X\\) is continuous each simulated value will be distinct with lots of decimal places.\n\\[\n{\\scriptscriptstyle\n\\frac{21.387... + 50.719... + 24.09... + 32.68... + 54.511... + 38.117... + 16.819... + 22.98... + 28.867... + 43.43}{10} = 33.36\n}\n\\]\n\n\n\n\nWe have seen a few examples of how to compute expected values for discrete random variables as probability-weighted average values. The computation of expected values for continuous random variables is more complicated. However, expected values can also be interpreted as long run average values for continuous random variables. Therefore, expected values can be approximated in the same way for discrete and continuous random variables: simulate lots of values and compute the average.\nIn the examples in the section we only considered 10 simulated repetitions to emphasize that we’re simply computing an average in the usual way. But to get a good approximation of an expected value, we’ll need to simulate many more values and average. We’ll soon explore what happens to the average as we simulate more values, but first a caution about averages of transformations.\n\n3.7.1 Averages of transformations\n\n\n\n\n\n\n\nExample 3.12 Donny Don’t says: “In Example 3.10, why bother creating columns for \\(X^2\\) and \\(XY\\)? If I want to find the average value of \\(X^2\\) I can just square the average value of \\(X\\). For the average value of \\(XY\\) I can just multiply the average value of \\(X\\) and the average value of \\(Y\\).” Do you agree? (Check to see if this works for your simulation results.) If not, explain why not.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.12. It is easy to check that Donny has made a mistake just by inspecting the simulation results: 5.12 \\(\\neq\\) 29.1, 5.1 \\(\\times\\) 3 \\(\\neq\\) 17.  To see why, suppose we had just performed two repetitions, resulting in the first two rows of Table 3.10.\n\\[\n\\text{Average of $X^2$} = \\frac{3^2 + 2^2}{2} =6.5 \\neq 6.25= \\left(\\frac{3 + 2}{2}\\right)^2=(\\text{Average of $X$})^2\n\\]\nSquaring first and then averaging (which yields 6.5) is not the same as averaging first and then squaring (which yields 6.25), essentially because \\((3+2)^2\\neq 3^2 + 2^2\\).\nSimilarly, \\[\n{\\small\n\\text{Average of $XY$} = \\frac{(3)(2) + (2)(1)}{2} =4 \\neq 3.75= \\left(\\frac{3 + 2}{2}\\right)\\left(\\frac{2 + 1}{2}\\right)=(\\text{Average of $X$})\\times (\\text{Average of $Y$})\n}\n\\] Multiplying first and then averaging (which yields 4) is not the same as averaging first and then multiplying (which yields 3.75), essentially because \\((3)(2)+(2)(1)\\neq(3+2)(2+1)\\).\n\n\n\n\nWe often transform random variables to obtain other random variables, e.g. \\(X\\) to \\(g(X)\\). To obtain the average of the transformed variable, we cannot simply plug the average of the original variable into the transformation formula. Instead, we need to transform the values of the variable first and then average the transformed values. In general the order of transforming and averaging is not interchangeable. Whether in the short run or the long run, in general \\[\\begin{align*}\n\\text{Average of $g(X)$} & \\neq g(\\text{Average of $X$})\\\\\n\\text{Average of $g(X, Y)$} & \\neq g(\\text{Average of $X$}, \\text{Average of $Y$})\n\\end{align*}\\]\nIn terms of expected value, in general \\[\\begin{align*}\n\\textrm{E}(g(X)) & \\neq g(\\textrm{E}(X))\\\\\n\\textrm{E}(g(X, Y)) & \\neq g(\\textrm{E}(X), \\textrm{E}(Y))\n\\end{align*}\\]\n\n\n\n\n\n\nWarning\n\n\n\nBe careful! Many common mistakes in probability result from not heeding this general principle about averages (expected values) of transformations.\n\n\n\n\n3.7.2 Long run averages\nWe have investigated long run relative frequencies; see Section 1.2.1 and Section 3.6 in particular. Now let’s see what happens to averages in the long run. Continuing Example 3.10 let \\(X\\) be the sum of two rolls of a fair four-sided die. Table 3.11 displays the results of 10 pairs of rolls of a fair four-sided die. The first column is the repetition number (first pair, second pair, and so on) and the second column represents \\(X\\), the sum of the two rolls. The third column displays the running sum of \\(X\\) values, and the fourth column the running average of \\(X\\) values. Figure 3.19 displays the running average as a function of the number of repetitions. Of course, the results depend on the particular sequence of rolls. We encourage you to roll the dice and construct your own table and plot.\n\n\n\n\nTable 3.11: Results and running average of \\(X\\), the sum of two rolls of a fair four-sided die.\n\n\n\n\n\n\nRepetition\nValue of X\nRunning sum of X\nRunning average of X\n\n\n\n\n1\n3\n3\n3.000\n\n\n2\n2\n5\n2.500\n\n\n3\n6\n11\n3.667\n\n\n4\n7\n18\n4.500\n\n\n5\n5\n23\n4.600\n\n\n6\n7\n30\n5.000\n\n\n7\n5\n35\n5.000\n\n\n8\n6\n41\n5.125\n\n\n9\n3\n44\n4.889\n\n\n10\n7\n51\n5.100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.19: Running average of \\(X\\) for the 10 pairs of rolls in Table 3.11.\n\n\n\n\n\nNow we’ll perform 90 more repetitions for a total of 100. Figure 3.20 (a) summarizes the results, while Figure 3.20 (b) also displays the results for 3 additional simulations of 100 pairs of rolls. The running average fluctuates considerably in the early stages, but settles down and tends to get closer to 5 as the number of repetitions increases. However, each of the four simulations results in a different average of \\(X\\) after 100 pairs of rolls: 4.85 (gray), 4.9 (orange), 5.25 (blue), 4.79 (green). Even after 100 pairs of rolls the running average of \\(X\\) still fluctuates from simulation to simulation.\n\n\n\n\n\n\n\n\n\n\n\n(a) A single simulation of 100 pairs of rolls\n\n\n\n\n\n\n\n\n\n\n\n(b) Four simulations, each of 100 pairs of rolls\n\n\n\n\n\n\n\nFigure 3.20: Running average of \\(X\\), the sum of two rolls of a fair four-sided die, for four simulations of 100 pairs of rolls.\n\n\n\nNow we’ll add 900 more repetitions for a total of 1000 in each simulation. Figure 3.21 (a) summarizes the results for our original set and Figure 3.21 (b) also displays the results for three additional simulations. Again, the running average of \\(X\\) fluctuates considerably in the early stages, but settles down and tends to get closer to 5 as the number of repetitions increases. Compared to the results after 100 repetitions, there is less variability between simulations in the running average of \\(X\\) after 1000 repetitions: 4.99 (gray), 4.964 (orange), 5.006 (blue), 4.933 (green). Now, even after 1000 repetitions the running average of \\(X\\) isn’t guaranteed to be exactly 5, but we see a tendency for the running average of \\(X\\) to get closer to 5 as the number of repetitions increases.\n\n\n\n\n\n\n\n\n\n\n\n(a) A single simulation of 1000 pairs of rolls\n\n\n\n\n\n\n\n\n\n\n\n(b) Four simulations, each of 1000 pairs of rolls\n\n\n\n\n\n\n\nFigure 3.21: Running average of \\(X\\), the sum of two rolls of a fair four-sided die, for four simulations of 1000 pairs of rolls.\n\n\n\nThe marginal distribution of \\(X\\), depicted in Figure 2.16, shows that 5 is the “balance point” of the distribution. In Example 2.44 we saw that 5 is the probability-weighted average value of \\(X\\), and we interpreted 5 as the value of \\(X\\) we would “expect” to see on average in the long run. In this sense, 5 is the “true” long run average value of \\(X\\), and our simulation results agree. We will discuss later “true” long run average values or “expected values” in much more detail later. For now, we’ll rely on simulation: we can approximate the long run average value of a random variable \\(X\\) by simulating many values of \\(X\\) and finding the average in the usual way.\nRecall that a probability is a theoretical long run relative frequency. A probability can be approximated by a relative frequency from a large number of simulated repetitions, but there is some simulation margin of error.\nLikewise, the average value of \\(X\\) after a large number of simulated repetitions is only an approximation to the theoretical long run average value of \\(X\\), and there is margin of error due to natural variability in the simulation. The margin of error is also on the order of \\(1/\\sqrt{N}\\) where \\(N\\) is the number of independently simulated values used to compute the average. However, the degree of variability of the random variable itself also influences the margin of error when approximating long run averages. In particular, if \\(\\sigma\\) is the standard deviation (see Section 3.8) of the random variable, then the margin of error for the average is on the order of \\(\\sigma / \\sqrt{N}\\).\nRemember that the long run average value is just one feature of a marginal distribution. There is much more to the long run pattern of variability of a random variable than just its average value. We are also interested in percentiles, degree of variability, and quantities that measure relationships between random variables. Two random variables can have the same long run average value but very different distributions. For example, the average temperature in both Phoenix, AZ and Miami, FL is around 75 degrees F, but the distribution of temperatures is not the same.\n\n\n3.7.3 Averages in Symbulate\nContinuing Example 3.10 let \\(X\\) be the sum of two rolls of a fair four-sided die. In Symbulate, we first simulate and store 10000 values of \\(X\\).\n\nP = BoxModel([1, 2, 3, 4], size = 2)\n\nX = RV(P, sum)\n\nx = X.sim(10000)\n\nWe can approximate the long run average value of \\(X\\) by computing the average—a.k.a., mean—of the 10000 simulated values in the usual way: sum the 10000 simulated values stored in x and divide by 10000. Here are a few ways of computing the mean of the simulated values.\n\nx.sum() / 10000\n\n4.9955\n\n\n\nx.sum() / x.count()\n\n4.9955\n\n\n\nx.mean()\n\n4.9955\n\n\nAverages are computed the same way, regardless of whether the variable is discrete or continuous. The following code computes the average of 5 then 10000 simulated values of \\(X\\), a random variable with the Normal(30, 10) distribution from Section 3.2.2.\n\nX = RV(Normal(30, 10))\n\nx = X.sim(5)\n\nx\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          031.68670839475387\n        \n        \n        \n          133.87187025440593\n        \n        \n        \n          235.998634555738434\n        \n        \n        \n          331.32054324394603\n        \n        \n        \n          432.90533358919854\n        \n        \n      \n    \n\n\n\nx.mean()\n\n33.15661800760856\n\n\n\nx = X.sim(10000)\n\nx\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          019.16187708645522\n        \n        \n        \n          125.60101467230118\n        \n        \n        \n          241.098347402911116\n        \n        \n        \n          326.373329950153668\n        \n        \n        \n          428.94756579056211\n        \n        \n        \n          528.265016343859088\n        \n        \n        \n          642.224786540660624\n        \n        \n        \n          742.132411665390705\n        \n        \n        \n          833.801028877556696\n        \n        ......\n        \n          999926.463610210073597\n        \n        \n      \n    \n\n\n\nx.mean()\n\n30.02778962718948\n\n\nOur simulation suggests that the long run average of a random variable with a Normal(30, 10) distribution is approximately 30. In general, one parameter of a Normal distribution represents its expected value, a.k.a., (long run) mean; the other parameter represents its standard deviation, which we will discuss soon (in Section 3.8).\n\n\n3.7.4 Linearity of averages\nNow we’ll introduce a useful properties of averages.\n\n\n\n\n\n\n\nExample 3.13 Recall your tactile simulation from Example 3.5). Let \\(U_1\\) be the result of the first roll, and \\(U_2\\) the result of the second, so the sum is \\(X = U_1 + U_2\\).\n\nDonny Don’t says: “\\(X=U_1+U_2\\), so I can find the average value of \\(X\\) by finding the average value of \\(U_1\\), the average value of \\(U_2\\), and adding the two averages”. Do you agree? Explain.\nDonny Don’t says: “\\(U_1\\) and \\(U_2\\) have the same distribution, so they have the same average value, so I can find the average value of \\(X\\) by multiplying the average value of \\(U_1\\) by 2”. Do you agree? Explain.\nDonny Don’t says: “\\(U_1\\) and \\(U_2\\) have the same distribution, so \\(X=U_1+U_2\\) has the same distribution as \\(2U_1 = U_1 + U_1\\)”. Do you agree? Explain.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.13. \n\nDonny is correct! Our simulation results are in Table 3.10. The average value of \\(U_1\\) is \\[\n\\frac{2 + 1 + 3 + 4 + 3 + 3 + 2 + 2 + 1 + 3}{10} = 2.4\n\\] The average value of \\(U_2\\) is \\[\n\\frac{1 + 1 + 3 + 3 + 2 + 4 + 3 + 4 + 2 + 4}{10} = 2.7\n\\] The sum of these two values is equal to the average value of \\(X\\). To see why, suppose we had just performed two repetitions, resulting in the last two rows of Table 3.10). \\[\n{\\scriptsize\n\\text{Average of $(U_1+U_2)$} = \\frac{(1 + 2) + (3 + 4)}{2} = 5 = 2 + 3= \\left(\\frac{1 + 3}{2}\\right)+\\left(\\frac{2 + 4}{2}\\right) = (\\text{Average of $U_1$}) + (\\text{Average of $U_1$})\n}\n\\] We discuss further below.\nDonny is correct that \\(U_1\\) and \\(U_2\\) have the same distribution, and he has some good ideas about averages. But we should remind Donny that a distribution represents the long run pattern of variability. With only 10 repetitions, the results for \\(U_1\\) will not necessarily follow the same pattern as those for \\(U_2\\). In our simulation, the average value of \\(U_1\\) is 2.4 and the average value of \\(U_2\\) is 2.7. Multiplying neither one of these numbers by 2 yields the average value of \\(X\\). Donny would have been correct if he were talking about long run average values. Since \\(U_1\\) and \\(U_2\\) have the same distribution, the long run average value of \\(U_1\\) is equal to the long run average value of \\(U_2\\), and so the long run average value of \\(X\\) is equal to the long run average value of \\(U_1\\) multiplied by two.\nDonny is not correct. In particular, \\(X\\) and \\(2U_1\\) do not have the same possible values; for example, \\(X\\) can be 3 but \\(2U_1\\) cannot. The long run average value is just one feature of a distribution. Just because \\(X\\) and \\(2U_1\\) have the same long run average value does not necessarily mean they have the same full long run pattern of variability. In particular, relationships between random variables will affect distributions of transformations of them. \\(U_1\\) and \\(U_2\\) have the same marginal distribution, but the joint distribution of \\((U_1, U_2)\\) is not the same as that of \\((U_1, U_1)\\), and so the distribution of \\(U_1+U_2\\) is not the same as that of \\(U_1+U_1\\).\n\n\n\n\n\nIn general the order of transforming and averaging is not interchangeable. However, the order is interchangeable for linear transformations.\n\nTheorem 3.1 (Linearity of averages) If \\(X\\) and \\(Y\\) are random variables and \\(m\\) and \\(b\\) are non-random constants, whether in the short run or the long run,\n\\[\\begin{align*}\n\\text{Average of $(mX+b)$} & = m(\\text{Average of $X$})+b\\\\\n\\text{Average of $(X+Y)$} & = \\text{Average of $X$} +\\text{Average of $Y$}\n\\end{align*}\\]\n\nThe following just restates in terms of long run averages (expected values)\n\nTheorem 3.2 (Linearity of expected value) If \\(X\\) and \\(Y\\) are random variables and \\(m\\) and \\(b\\) are non-random constants,\n\\[\\begin{align*}\n\\textrm{E}(mX+b) & = m\\textrm{E}(X)+b\\\\\n\\textrm{E}(X+Y) & = \\textrm{E}(X) + \\textrm{E}(Y)\n\\end{align*}\\]\n\nFor example, if \\(X\\) measures temperature in degrees Celsius with average 24°C, then \\(1.8X+32\\) measures temperature in degrees Fahrenheit with average 75.2°F.\nAveraging involves adding and dividing. Linear transformations involve only adding/subtracting and multiplying/dividing. The ability to interchange the order of averaging and linear transformations follows simply from basic properties of arithmetic (commutative, associative, distributive).\nNote that the average of the sum of \\(X\\) and \\(Y\\) is the sum of the average of \\(X\\) and the average of \\(Y\\) regardless of the relationship between \\(X\\) and \\(Y\\). We will explore this idea in more detail later.\n\n\n3.7.5 Averages of indicator random variables\nRecall that indicators are the bridge between events and random variables. Indicators are also the bridge between relative frequencies and averages.\n\n\n\n\n\n\n\nExample 3.14 Recall your tactile simulation from Example 3.5. Let \\(A\\) be the event that the first roll is 3 and \\(\\textrm{I}_A\\) the corresponding indicator random variable. Based only on the results of your simulation, approximate the long run average value of each of \\(\\textrm{I}_A\\). What do you notice?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.14. Our simulation results are in Table 3.10). Approximate the long run average value of \\(\\textrm{I}_A\\) by summing the 10 simulated values of \\(\\textrm{I}_A\\) and dividing by 10. \\[\n\\frac{0 + 0 + 1 + 0 + 1 + 1 + 0 + 0 + 0 + 1}{10} = \\frac{4}{10}\n\\] The average of \\(\\textrm{I}_A\\) is the relative frequency of event \\(A\\)! When we sum the 1/0 values of \\(\\textrm{I}_A\\) we count the repetitions on which \\(A\\) occurs. That is, the numerator in the average calculation for \\(\\textrm{I}_A\\) is the frequency of event \\(A\\), and dividing by the number of repetitions yields the relative frequency of event \\(A\\).\n\n\n\n\nIf \\(\\textrm{I}_A\\) is the indicator random variable of an event \\(A\\), whether in the short run or the long run, \\[\n\\text{Average of $\\textrm{I}_A$} = \\text{Relative frequency of $A$}\n\\] In terms of our long run notation, the above long run result is \\[\n\\textrm{E}(\\textrm{I}_A) = \\textrm{P}(A)\n\\]\nIndicators provide a bridge between events and random variables, and between probability and expected value.\n\n\n3.7.6 Exercises\n\nExercise 3.18 Suppose that a total of 350 students at a college are taking a particular statistics course. The college offers five sections of the course, each taught by a different instructor. The class sizes are shown in the following table.\n\n\n\nSection\nA\nB\nC\nD\nE\n\n\nNumber of students\n35\n35\n35\n35\n210\n\n\n\nWe are interested in: What is the average class size?\n\nSuppose we randomly select one of the 5 instructors. Let \\(X\\) be the class size for the selected instructor. Specify the distribution of \\(X\\). (A table is fine.)\nCompute and interpret \\(\\text{E}(X)\\).\nCompute and interpret \\(\\text{P}(X = \\text{E}(X))\\).\nSuppose we randomly select one of the 350 students. Let \\(Y\\) be the class size for the selected student. Specify the distribution of \\(Y\\). (A table is fine.)\nCompute and interpret \\(\\text{E}(Y)\\).\nCompute and interpret \\(\\text{P}(Y = \\text{E}(Y))\\).\nComment on how these two expected values compare, and explain why they differ as they do. Which average would you say is more relevant?\n\n\n\nExercise 3.19 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\n\nExplain how you could, in principle, conduct a simulation by hand and use the results to approximate\n\n\\(\\textrm{E}(X)\\)\n\\(\\textrm{E}(Y)\\)\n\\(\\textrm{E}(X^2)\\)\n\\(\\textrm{E}(XY)\\)\n\nWrite Symbulate code to conduct a simulation and approximate the values in part 1.\n\n\n\nExercise 3.20 Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4). Let \\(X\\) be the sum of the two spins and let \\(Y\\) be the larger of the two spins.\n\nDescribe in words how you could use simulation to approximate\n\n\\(\\textrm{E}(X)\\)\n\\(\\textrm{E}(Y)\\)\n\\(\\textrm{E}(X^2)\\)\n\\(\\textrm{E}(XY)\\)\n\nWrite Symbulate code to conduct a simulation to approximate the quantities in part 1.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-sd",
    "href": "language-simulation.html#sec-sd",
    "title": "3  The Language of Simulation",
    "section": "3.8 Measuring variability: Variance and standard deviation",
    "text": "3.8 Measuring variability: Variance and standard deviation\nThe long run average value is just one feature of a distribution. Random variables vary, and the distribution describes the entire pattern of variability. It is also convenient to measure the overall degree of variability in a single number. Some values of a variable are close to its mean and some are far, so to measure variability in a single number we might ask: how far are the values away from the mean on average? Variance and standard deviation are numbers that address this question.\nConsider again a random variable \\(X\\) that follows a Normal(30, 10) distribution; we’ll assume \\(X\\) is measured in minutes (after noon) as in the meeting problem. Any Normal distribution has two parameters, the mean and the standard deviation; the Normal(30, 10) distribution has mean 30 (minutes) and standard deviation 10 (minutes). In Section 3.7.3 we saw simulation evidence supporting that the mean is 30. Now we’ll investigate the standard deviation, which measures, roughly, the average distance from the mean.\nWe’ll motivate the calculation of standard deviation using using just the 10 simulated values in Table 3.5, reproduced in Table 3.12. For now focus on only the first three columns of Table 3.12. We see how far a value is away from the mean by subtracting the mean, resulting in a “deviation”. Deviations are positive for values that are above the mean and negative for values that are below the mean. For example, the value 21.387 is 11.973 minutes below the mean.\n\n\n\n\nTable 3.12: Calculation of standard deviation based on 10 simulated values\n\n\n\n\n\n\nrepetition\nx\ndeviation\nabsolute_deviation\nsquared_deviation\n\n\n\n\n1\n21.387\n-11.973\n11.973\n143.345\n\n\n2\n50.719\n17.359\n17.359\n301.347\n\n\n3\n24.090\n-9.270\n9.270\n85.940\n\n\n4\n32.680\n-0.680\n0.680\n0.462\n\n\n5\n54.511\n21.151\n21.151\n447.347\n\n\n6\n38.117\n4.757\n4.757\n22.629\n\n\n7\n16.819\n-16.541\n16.541\n273.619\n\n\n8\n22.980\n-10.380\n10.380\n107.746\n\n\n9\n28.867\n-4.493\n4.493\n20.187\n\n\n10\n43.430\n10.070\n10.070\n101.411\n\n\nSum\n333.600\n0.000\n106.674\n1504.033\n\n\nAverage\n33.360\n0.000\n10.667\n150.403\n\n\n\n\n\n\n\n\nWe might try to compute the average deviation from the mean, but this will always be 0. The mean is the balance point—that is, the center of gravity—so the (positive) deviations above the mean will always balance out, in total, with the (negative) deviations below the mean. However, regarding degree of variability, we only care about how far values are away from the mean, not if they’re above or below. So we take the absolute value of each deviation and then find the average. See the fourth column of Table 3.12, resulting in an average absolute deviation of 10.667 minutes.\nTable 3.12 motivates the calculation, but we’re really interested in what happens in the long run, so let’s carry out the calculation for many simulated values.\n\nX = RV(Normal(30, 10))\n\nx = X.sim(10000)\n\nx\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          029.5740328740167\n        \n        \n        \n          129.66440082044776\n        \n        \n        \n          226.659484504103595\n        \n        \n        \n          323.25639654092317\n        \n        \n        \n          418.894836361733816\n        \n        \n        \n          535.08277439845746\n        \n        \n        \n          632.94059974573494\n        \n        \n        \n          725.981559712350478\n        \n        \n        \n          845.707157940360005\n        \n        ......\n        \n          999931.274181540765742\n        \n        \n      \n    \n\n\nThe mean is about 30.\n\nx.mean()\n\n29.87772724678908\n\n\nNow we compute the absolute deviations from the mean.\n\nabs(x - x.mean())\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          00.3036943727723802\n        \n        \n        \n          10.2133264263413217\n        \n        \n        \n          23.2182427426854865\n        \n        \n        \n          36.621330705865912\n        \n        \n        \n          410.982890885055266\n        \n        \n        \n          55.205047151668378\n        \n        \n        \n          63.062872498945861\n        \n        \n        \n          73.8961675344386038\n        \n        \n        \n          815.829430693570924\n        \n        ......\n        \n          99991.3964542939766602\n        \n        \n      \n    \n\n\nThen we average the absolute deviations.\n\nabs(x - x.mean()).mean()\n\n8.089673580372754\n\n\nUnfortunately, the above calculation yields roughly 8 rather than the standard deviation of 10. It turns out that for a Normal(30, 10) distribution the long run average absolute deviation from the mean is about 8. We can conceptualize standard deviation as average distance from the mean, but the actual calculation of standard deviation is a little more complicated. Technically, we must first square all the distances and then average; the result is the variance. Then the square root of the variance is the standard deviation31.\n\\[\\begin{align*}\n\\text{Variance of } X & = \\text{Average of } [(X - \\text{Average of } X)^2]\\\\\n\\text{Standard deviation of } X & = \\sqrt{\\text{Variance of } X}\n\\end{align*}\\]\nReturning to the 10 simulated values in Table 3.12, the fifth column contains the squared deviations. Notice that squaring the deviations has a similar effect to taking the absolute value: a value that is 3 units above the mean has the same squared deviation as a value that is 3 units below the mean (since \\(3^2 = (-3)^2\\)). Now we average the squared deviations to obtain the variance. The average is computed in the usual way: sum all the values and divide by the number of values32. But now each value included in the average is the squared deviation of \\(X\\) from the mean, rather than the value of \\(X\\) itself. The variance of the 10 simulated values is 150.403. This probably seems like a weird number, and it is: because we squared all the deviations before averaging, the measurement units of the variance are minutes2. To get back to the original measurement units, we take the square root of the variance, \\(\\sqrt{150.403}\\), resulting in the standard deviation of 12.264 minutes.\nNow back to the long run, using 10000 simulated values x. The following code shows the “long way” of computing variance and standard deviation. First, find the squared distance between each simulated value and the mean.\n\n(x - x.mean()) ** 2 \n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          00.09223027205360942\n        \n        \n        \n          10.045508164175559356\n        \n        \n        \n          210.357086350847803\n        \n        \n        \n          343.84202031644278\n        \n        \n        \n          4120.62389219303004\n        \n        \n        \n          527.092515851091093\n        \n        \n        \n          69.381187944798864\n        \n        \n        \n          715.180121456413389\n        \n        \n        \n          8250.57087608256526\n        \n        ......\n        \n          99991.9500845951658525\n        \n        \n      \n    \n\n\nThen compute the average squared deviation to get the variance.\n\n((x - x.mean()) ** 2).mean()\n\n102.87728342773268\n\n\nNow take the square root of the variance to get the standard deviation.\n\nsqrt(((x - x.mean()) ** 2).mean())\n\n10.142843951660337\n\n\nWe see that the standard deviation is about 10—as it should be for values simulated from a Normal(30, 10) distribution—and the variance is about \\(10^2 = 100\\). Fortunately, var and sd will carry out these calculations more quickly.\n\nx.var()\n\n102.87728342773268\n\n\n\nx.sd()\n\n10.142843951660337\n\n\n\n\n\n\n\n\n\nExample 3.15 We’ll compare long run average and standard deviation for the Uniform(0, 60) distribution and the Normal(30, 10) distribution.\n\nMake an educated guess for the long run average value of a Uniform(0, 60) distribution.\nWill the standard deviation for a Uniform(0, 60) distribution be greater than, less than, or equal to 10, the standard deviation for a Normal(30, 10) distribution? Explain without doing any calculations. (Hint: It might help to compare the spinners in Section 3.2 or the simulations from Section 3.4.)\nMake an educated guess for the standard deviation of a Uniform(0, 60) distribution.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.15. \n\nIt seems reasonable that the long run average value of a Uniform(0, 60) distribution is 30, the balance point of the distribution.\nWhile the Uniform(0, 60) and Normal(30, 10) distributions have the same mean of 30, the Uniform(0, 60) has a larger standard deviation than the Normal(30, 10) distribution. In comparison to a Normal(30, 10) distribution, a Uniform(0, 60) distribution will give higher probability to ranges of values near the extremes of 0 and 60, as well as lower probability to ranges of values near 30. Thus, there will be more values far from the mean of 30 and fewer values close, and so the average distance from the mean and hence standard deviation will be larger for the Uniform(0, 60) distribution than for the Normal(30, 10) distribution. See Figure 3.22 which compares histograms of simulated values from the two distributions.\nIn a Uniform(0, 60) distribution, values are “evenly spread” from 0 to 60, so distances from the mean are “evenly spread” from 0 (for 30) to 30 (for 0 and 60). We might expect the standard deviation—roughly the average distance from the mean—to be about 15, halfway between 0 and 30. It turns out that the standard deviation is about 17; 15 is the average absolute deviation from the mean. While the “average distance” interpretation helps our conceptual understanding of standard deviation, the process of squaring the distances, then averaging, and then taking the square root makes guessing the actual value of standard deviation difficult.\n\n\n\n\n\n\nU = RV(Uniform(0, 60))\n\nu = U.sim(10000)\n\nplt.figure()\n\nx.plot()\nu.plot()\n\nplt.legend(['Normal(30, 10)', 'Uniform(0, 60)']);\nplt.show()\n\n\n\n\n\n\n\nFigure 3.22: Histograms of many simulated values from each of the Normal(30, 10) and Uniform(0, 60) distributions.\n\n\n\n\n\n\nu.sd()\n\n17.251303525801873\n\n\n\nabs(u - u.mean()).mean()\n\n14.915430185610745\n\n\n\n\n\n\n\n\n\nExample 3.16 The plots below summarize hypothetical distributions of quiz scores in six classes. Each quiz score is a whole number between 0 and 10 inclusive. All plots are on the same scale with quiz scores on the horizontal axis, and probability on the vertical axis.\n\nDonny Dont says that of these six plots, C represents the smallest SD, since there is “no variability in the heights of the bars”. Do you agree that C represents “no variability”? Explain.\nWhat is the smallest possible value the SD of quiz scores could be? What would need to be true about the distribution for this to happen? (This scenario might not be represented by one of these six plots.)\nWithout doing any calculations, identify which of these six classes exhibits the smallest standard deviation of quiz scores.\nWithout doing any calculations, arrange the classes in order based on their standard deviations from smallest to largest.\n\nIn one of the classes, the standard deviation of quiz scores is 5. Which one? Why?\nIs the standard deviation in F greater than, less than, or equal to 1? Why?\nProvide a ballpark estimate of standard deviation in each case.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.23\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.24\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.25\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.26\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.27\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.28\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.16. \n\nWe disagree with Donny. Standard deviation measures variability of the values of the variable, not their probabilities. If we were to simulate values according to the distribution in C, we would observe some 0s, some 1s, some 2s, all the way through some 10s (with roughly equal frequency). So there would certainly be variability in the values of the variable. Remember that values of the variable are along the horizontal axis, so standard deviation measures average distance from the mean horizontally.\nThe smallest possible value of standard deviation is 0, which occurs only if the random variable is a constant (with probability 1). In this context, if every student had the same quiz score, e.g., if 100% of students scored an 8, then the standard deviation would be 0. The distribution plot would have a single spike at a single value.\nRemember that values of the variable are along the horizontal axis, so standard deviation measures average distance from the mean horizontally. The distribution in F represents the smallest standard deviation. The mean is 7, most of the scores are 7, and some of the scores are only 1 unit away from the mean. In all other situations, the probability that the random variable is equal to its mean is smaller, and the probability that the random variables takes a value more than 1 unit away from its mean is larger than in F.\nIn all plots other than F the mean is 5, so the smallest standard deviation occurs where the values tend to be close to 5, and the largest occurs where the values tend to be far from 5. In order from smallest to largest standard deviation: F, E, A, C, B, D.\nIn D, the score takes values 0 and 10 with probability 0.5. The mean is 5, and all deviations are 5 units away from the mean, so the average squared deviation will be \\(5^2\\) and the standard deviation will be 5.\nLess than 1. Don’t forget that there is a high probability of a deviation of 0 in this case. So the average deviation will be somewhere between 0 and 1.\nSome of these are harder than others. In E, many values are 0 units away from mean, many values are 1 unit away, and some values are 2. So the standard deviation in E is maybe around 1. In C, there are values that are 0 units away, and about as many values that are each 1, 2, 3, 4, and 5 units away; we might expect standard deviation to be around 2.5. But remember, while considering the average absolute deviation helps intuition, standard deviation is actually the square root of the average squared deviation so the exact value can be difficult to ascertain without computation. The actual values are: F = 0.45, E = 1.15, A = 2.4, C = 3.1, B = 3.7, D = 5.\n\n\n\n\n\nVariance and standard deviation are both based on average squared deviations from the mean. Variance has some nice mathematical properties (which we’ll see later), but standard deviation is the more “practical” number since it has the same measurement units as the variable. In computations we often work with variances then take the square root at the end to report and interpret standard deviations.\nStandard deviation is the most commonly used single-number measure of variability, but it’s not the only one. Average absolute deviation also measures variability; why not use that? It turns out that squaring deviations, rather than taking absolute values, leads to nicer mathematical properties33. Also, standard deviation is the natural measure of variability for Normal distributions (we’ll investigate why later). While standard deviation is commonly used, there are other, sometimes better, ways to summarize variability. For example, we will see later how percentiles can be used to summarize the pattern of variability.\nThe following definiton states our notion of variance in expected value terms.\n\nDefinition 3.1 (Variance and standard deviation of a random varible) The variance of a random variable \\(X\\) is \\[\n\\textrm{Var}(X) = \\textrm{E}((X-\\textrm{E}(X))^2)\n\\] The standard deviation of a random variable \\(X\\) is \\(\\textrm{SD}(X) = \\sqrt{\\textrm{Var}(X)}\\).\n\nRecall that an expected value is a long run average. Thefore we can interpret \\(\\textrm{E}(\\cdot)\\) as “simulate many values of what’s inside \\((\\cdot)\\) and average”. In this way \\[\n\\textrm{E}((X-\\textrm{E}(X))^2) = \\text{Long Run Average of } [(X - \\text{Long Run Average of } X)^2]\n\\]\nRecall that for discrete random variables we can compute expected values as probability-weighted average values. We can compute variances for discrete random variables in a similar way.\n\n\n\n\n\n\n\nExample 3.17 In the dice rolling problem, let \\(Y\\) be the larger of the two rolls. The marginal distribution of \\(Y\\) is represented by Table 2.15. In Example 2.44 we computed \\(\\textrm{E}(Y) = 3.125\\).\n\nCompute \\(\\textrm{Var}(Y)\\).\nCompute \\(\\textrm{SD}(Y)\\).\nDescribe in detail how \\(\\textrm{Var}(Y)\\) can be simulated via approximation\nWrite Symbulate code to approximate \\(\\textrm{Var}(Y)\\) and \\(\\textrm{SD}(Y)\\) and compare to the values from parts 1 and 2.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.17. \n\n\\(Y\\) takes values 1, 2, 3, 4, and \\(\\textrm{E}(Y)=3.125\\), so \\((Y-\\textrm{E}(Y))^2\\) takes values \\((1-3.125)^2\\), \\((2-3.125)^2\\), \\((3-3.125)^2\\), \\((4-3.125)^2\\), with respective probability 1/16, 3/16, 5/16, 7/16. To compute \\(\\textrm{E}((Y-\\textrm{E}(Y))^2)\\) as a probability-weighted average value, multiply each possible of \\((Y-\\textrm{E}(Y))^2\\) by its probability and sum. \\[\n(1-3.125)^2\\times 0.0625 + (2-3.125)^2 \\times 0.1875 + (3-3.125)^2 \\times 0.3125 + (4-3.125)^2 \\times 0.4375  = 0.8594\n\\] See Table 3.13 for more detail. \\(\\textrm{Var}(Y) = 0.8594\\).\n\\(\\textrm{SD}(Y)=\\sqrt{\\textrm{Var}(Y)} = \\sqrt{0.8594} = 0.9270\\).\nWe have already discussed how to simulate a value of \\(Y\\) in this content. To approximate the variance\n\nSimulate many values of \\(Y\\)\nCompute the average of the simulated values of \\(Y\\) (to approximate \\(\\textrm{E}(Y)\\))\nFrom each simulated value of \\(Y\\) subtract the average, and then square\nCompute the average of the squared deviations from the previous part to approximate the variance\n\nSee below for the code, both the long way and using the var and sd shortcuts. The simulation-based approximations are close to the values from parts 1 and 2.\n\n\n\n\n\n\n\n\n\nTable 3.13: Steps in computing the variance of \\(Y\\) in Example 3.17.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(y\\)\n\\(y - \\textrm{E}(Y)\\)\n\\((y - \\textrm{E}(Y))^2\\)\n\\(\\textrm{P}(Y=y)\\)\n\\((y - \\textrm{E}(Y))^2\\textrm{P}(Y=y)\\)\n\n\n\n\n1\n-2.125\n4.5156\n0.0625\n0.2822\n\n\n2\n-1.125\n1.2656\n0.1875\n0.2373\n\n\n3\n-0.125\n0.0156\n0.3125\n0.0049\n\n\n4\n0.875\n0.7656\n0.4375\n0.3350\n\n\n\n\n\n\n\n\n\nP = BoxModel([1, 2, 3, 4], size = 2)\n\nY = RV(P, max)\n\ny = Y.sim(10000)\n\ny\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          04\n        \n        \n        \n          14\n        \n        \n        \n          23\n        \n        \n        \n          33\n        \n        \n        \n          43\n        \n        \n        \n          51\n        \n        \n        \n          62\n        \n        \n        \n          72\n        \n        \n        \n          84\n        \n        ......\n        \n          99993\n        \n        \n      \n    \n\n\n\ny.mean()\n\n3.1078\n\n\n\ny - y.mean()\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          00.8921999999999999\n        \n        \n        \n          10.8921999999999999\n        \n        \n        \n          2-0.10780000000000012\n        \n        \n        \n          3-0.10780000000000012\n        \n        \n        \n          4-0.10780000000000012\n        \n        \n        \n          5-2.1078\n        \n        \n        \n          6-1.1078000000000001\n        \n        \n        \n          7-1.1078000000000001\n        \n        \n        \n          80.8921999999999999\n        \n        ......\n        \n          9999-0.10780000000000012\n        \n        \n      \n    \n\n\n\n(y - y.mean()) ** 2\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          00.7960208399999998\n        \n        \n        \n          10.7960208399999998\n        \n        \n        \n          20.011620840000000025\n        \n        \n        \n          30.011620840000000025\n        \n        \n        \n          40.011620840000000025\n        \n        \n        \n          54.44282084\n        \n        \n        \n          61.2272208400000002\n        \n        \n        \n          71.2272208400000002\n        \n        \n        \n          80.7960208399999998\n        \n        ......\n        \n          99990.011620840000000025\n        \n        \n      \n    \n\n\n\n((y - y.mean()) ** 2).mean()\n\n0.8711791600000001\n\n\n\ny.var()\n\n0.8711791600000001\n\n\n\ny.sd()\n\n0.9333697873833287\n\n\n\n\n\n\n\n\n\nExample 3.18 Continuing Example 3.17.\n\nCompute \\(\\textrm{E}(Y^2)\\).\nDescribe in detail how \\(\\textrm{E}(Y^2)\\) can be approximated via simulation.\nCompute \\(\\textrm{E}(Y^2) - (\\textrm{E}(Y))^2\\). What do you notice?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.18. \n\n\\(Y\\) takes values 1, 2, 3, 4, so \\(Y^2\\) takes values \\(1^2, 2^2, 3^2, 4^2\\), with respective probability 1/16, 3/16, 5/16, 7/16. To compute \\(\\textrm{E}(Y^2)\\) as a probability-weighted average value, multiply each possible of \\(Y^2\\) by its probability and sum. \\[\n1^2\\times 0.0625 + 2^2 \\times 0.1875 + 3^2 \\times 0.3125 + 4^2 \\times 0.4375  = 10.625\n\\] \\(\\textrm{E}(Y^2) = 10.625\\). Notice this is not the same as \\(\\textrm{E}(Y)^2=3.125^2.\\)\nWe have already discussed how to simulate a value of \\(Y\\) in this content. To approximate \\(\\textrm{E}(Y^2)\\)\n\nSimulate many values of \\(Y\\)\nSquare each simulated value of \\(Y\\)\nCompute the average of the squared values from from the previous part to approximate \\(\\textrm{E}(Y^2)\\). See the Symbulate code below.\n\n\\(\\textrm{E}(Y^2) - (\\textrm{E}(Y))^2 = 10.625 - 3.125^2 = 0.8594\\), which is \\(\\textrm{Var}(Y)\\).\n\n\n\n\n\n\n(y ** 2)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          016\n        \n        \n        \n          116\n        \n        \n        \n          29\n        \n        \n        \n          39\n        \n        \n        \n          49\n        \n        \n        \n          51\n        \n        \n        \n          64\n        \n        \n        \n          74\n        \n        \n        \n          816\n        \n        ......\n        \n          99999\n        \n        \n      \n    \n\n\n\n(y ** 2).mean()\n\n10.5296\n\n\n\n(y ** 2).mean() - (y.mean()) ** 2\n\n0.8711791599999987\n\n\nExample 3.18 illustrates an alternative formula for computing variance. Definition 3.1 represents the concept of variance. However, variance is usually computed using the following equivalent but slightly simpler formula.\n\nLemma 3.1 \\[\n\\textrm{Var}(X) = \\textrm{E}(X^2) - (\\textrm{E}(X))^2\n\\]\n\nThat is, the variance of \\(X\\) is the expected value of the square of \\(X\\) minus the square of the expected value of \\(X\\).\nWe will see that variance has many nice theoretical properties. Whenever you need to compute a standard deviation, first find the variance and then take the square root at the end.\nWe will see how to compute variance for continuous random variables later. But Definition 3.1 and Lemma 3.1 apply for both discrete and continuous random variables. Furthermore, variance can be approximated via simulation in the same way for discrete or continuous random variables: simulate many values of the random variable and compute the average of the squared deviations from the mean.\n\n3.8.1 Standardization\nStandard deviation provides a “ruler” by which we can judge a particular value of a random variable relative to the distribution of values. This idea is particularly useful when comparing random variables with different measurement units but whose distributions have similar shapes.\n\n\n\n\n\n\n\nExample 3.19 SAT scores have, approximately, a Normal distribution with a mean of 1050 and a standard deviation of 200. ACT scores have, approximately, a Normal distribution with a mean of 21 and a standard deviation of 5.5. Darius’s score on the SAT is 1500. Alfred’s score on the ACT is 31. We’ll investigate who scored relatively better on their test.\n\nCompute the deviation from the mean for Darius’s SAT score. How large is this value relative to the standard deviation for SAT scores (which measures, roughly, the average deviation from the mean)?\nCompute the deviation from the mean for Alfred’s ACT score. How large is this value relative to the standard deviation for ACT scores?\nWho scored relatively better on their test? Explain.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.19. \n\nDarius’s score is \\(1500-1050 = 450\\) points above the mean SAT score. The standard deviation of SAT scores is 200 points. Roughly, the deviation of Darius’s score from the mean is \\(450/200 = 2.25\\) times larger the average deviation.\nThat is, Darius’s SAT score of 1500 is 2.25 standard deviations above the mean SAT score.\nAlfred’s score is \\(31-21 = 10\\) points above the mean ACT score. The standard deviation of ACT scores is 5.5 points. Roughly, the deviation of Alfred’s score from the mean is \\(10/5.5 = 1.82\\) times larger than the average deviation. That is, Alfred’s ACT score of 31 is 1.82 standard deviations above the mean ACT score.\nBoth scores are above average, but relative to other test scores, Darius’s is farther above average than Alfred’s. Both distributions are Normal, so the probability that an SAT score is greater than Darius’s is smaller than the probability that an ACT score is greater than Alfred’s. That is, Darius scored relatively better. See Figure 3.29.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.29: Comparison of the Normal distributions in Example 3.19.\n\n\n\n\n\nStandard deviation provides a “ruler” by which we can judge a particular value of a random variable relative to the distribution of values. Consider the plot for SAT scores in Figure 3.29. For now, pay attention to the two horizontal axis scales on each plot; we’ll discuss the Normal “bell shape” in more detail later. There are two scales on the variable axis: one representing the actual measurement units, and one representing “standardized units”. In the standardized scale, values are measured in terms of standard deviations away from the mean:\n\nThe mean corresponds to a value of 0.\nA one unit increment on the standardized scale corresponds to an increment equal to the standard deviation in the measurement unit scale.\n\nFor example, each one unit increment in the standardized scale corresponds to a 200 point increment in the measurement unit scale for SAT scores, and a 5.5 point increment in the measurement unit scale for ACT scores. An SAT score of 1250 is “1 standard deviation above the mean”; an ACT score of 10 is “2 standard deviations below the mean”. Given a specific distribution, the more standard deviations a particular value is away from its mean, the more extreme or “unusual” it is.\nGiven a value of a variable, its standardized value marks where the value lies on the standardized scale (e.g., 1500 on the SAT scale corresponds to 2.25 on the standardized scale).\n\\[\n\\text{Standardized value} = \\frac{\\text{Value - Mean}}{\\text{Standard deviation}}\n\\]\n\n\n\n\n\n\nWarning\n\n\n\nStandardization is useful when comparing random variables with different measurement units but whose distributions have similar shapes (like the two Normal distributions in Figure 3.29). However, standardized values are only based on two features of a distribution—mean and standard deviation—rather than the complete pattern of variability. Distributions with different shapes have different patterns of variability. We will see later than when comparing distributions with different shapes, it is better to compare percentiles rather than standardized values to determine what is “extreme” or “unusual”.\n\n\nAny random variable can be standardized, but keep in mind that just how extreme any particular standardized value is depends on the shape of the distribution. We will see that standardization is most natural for random variables that follow a Normal distribution.\n\n\n3.8.2 Normal distributions (briefly)\nStandardization is most natural for random variables that follow a Normal distribution. The Normal(30, 10) model that we assumed for arrival times in the meeting problem is an example of a Normal distribution. The pattern of variability for any Normal distribution follows a particular bell shape, like in Figure 3.29. A Normal distribution has two parameters: its mean (typically denoted \\(\\mu\\)) and its standard deviation (typically denoted \\(\\sigma\\)). For Normal distributions the probability that a value is within (or beyond) a given number of standard deviations from the mean follows a specific pattern called the “empirical rule”. For example, the empirical rule for Normal distributions specifies that\n\n68% of values are within 1 standard deviation of the mean\n95% of values are within 2 standard deviations of the mean\n99.7% of values are within 3 standard deviations of the mean\n\n\n\n\n\n\n\n\n\nFigure 3.30: Illustration of the empirical rule for Normal distributions\n\n\n\n\n\nTherefore the key to working with Normal distributions is to work in terms of standardized values. The “standard” Normal distribution is a Normal(0, 1) distribution, with a mean 0 and a standard deviation of 1. Notice how the empirical rule corresponds to the spinner in Figure 3.31.\n\n\n\n\n\n\n\n\nFigure 3.31: A standard Normal(0, 1) spinner. Only selected rounded values are displayed, but in the idealized model the spinner is infinitely precise so that any real number is a possible outcome. Notice that the values on the axis are not evenly spaced.\n\n\n\n\n\nIf a random variable follows a Normal distribution, a value of it can be simulated by spinning the standard Normal spinner in Figure 3.31 to determine how many standard deviations the value is away from the mean (above or below) and then converting to the measurement units of the variable.\nWe have only introduced a small part of the empirical rule in this section, corresponding to 1, 2, or 3 standard deviations away from the mean. We will cover Normal distributions and the empirical rule in much more detail later.\n\n\n3.8.3 Exercises\n\nExercise 3.21 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\n\nExplain how you could, in principle, conduct a simulation by hand and use the results to approximate\n\n\\(\\textrm{Var}(X)\\)\n\\(\\textrm{SD}(X)\\)\n\nWrite Symbulate code to conduct a simulation and approximate the values in part 1.\nCompute the theoretical values of \\(\\textrm{Var}(X)\\) and \\(\\textrm{SD}(X)\\) and compare to the simulation results.\n\n\n\nExercise 3.22 Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4). Let \\(X\\) be the sum of the two spins and let \\(Y\\) be the larger of the two spins.\n\nUse simulation to approximate the marginal distributions of \\(X\\) and \\(Y\\).\nWhich will have the larger standard deviation, \\(X\\) or \\(Y\\)? Make a ballpark estimate the of the standard deviation of each.\nDescribe in words how you could use simulation to approximate\n\n\\(\\textrm{Var}(X)\\) and \\(\\textrm{SD}(X)\\)\n\\(\\textrm{E}(Y)\\) and \\(\\textrm{SD}(Y)\\)\n\nWrite Symbulate code to conduct a simulation to approximate the quantities in the previous part.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-sim-corr",
    "href": "language-simulation.html#sec-sim-corr",
    "title": "3  The Language of Simulation",
    "section": "3.9 Measuring relationships: Covariance and correlation",
    "text": "3.9 Measuring relationships: Covariance and correlation\nTBA\n\n3.9.1 Exercises\n\nExercise 3.23 TBA\n\n\nExercise 3.24 TBA",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-simulation-conditioning",
    "href": "language-simulation.html#sec-simulation-conditioning",
    "title": "3  The Language of Simulation",
    "section": "3.10 Conditioning",
    "text": "3.10 Conditioning\nWe can implement conditioning in simulations by only considering repetitions that satisfy the condition. Conditioning can be thought of as taking a subset of, or “filtering”, the simulation results.\n\n3.10.1 Using simulation to approximate conditional probabilities\nConditional probabilities can be approximated using simulated relative frequencies in a similar way to unconditional probabilities, but the presence of conditioning requires more care.\n\n\n\n\n\n\n\nExample 3.20 Recall Example 2.45. Consider simulating a randomly selected U.S. adult and determining whether or not the person is age 18-29 and whether or not they use Snapchat. Let \\(A\\) be the event that the selected adult is age 18-29, \\(C\\) be the event that the selected adult uses Snapchat, and \\(\\textrm{P}\\) correspond to randomly selecting an American adult. Suppose that \\(\\textrm{P}(A) = 0.20\\), \\(\\textrm{P}(C) = 0.24\\), and \\(\\textrm{P}(A\\cap C) = 0.13\\).\n\nDonny Don’t says, “we need two spinners to simulate this situation: One spinner with areas of 0.20 and 0.80 for age 18-29 or not, and another spinner with areas of 0.24 and 0.76 to represent uses Snapchat or not. Then spin each spinner once to simulate one repetition.” Do you agree? Explain.\nHow could you perform one repetition of the simulation using just a single spinner? (Hint: it needs 4 sectors.)\nHow could you perform a simulation, using the spinner in the previous part, to estimate \\(\\textrm{P}(C | A)\\)?\nWhat determines the order of magnitude of the the margin of error for your estimate in the previous part?\nWhat is another method for performing the simulation and estimating \\(\\textrm{P}(C |A)\\) that has a smaller margin of error? What is the disadvantage of this method?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.20. \n\nDonny’s simulation assumes that age and Snapchat use are independent, but we know that younger people will be more likely to use Snapchat than older people. In general, you can not simulate pairs of events simply from the marginal probabilities of each.\nYou can construct a spinner for the possible occurrences of the pairs of events—both occur, \\(A\\) occurs and \\(C\\) does not, \\(C\\) occurs and \\(A\\) does not, neither occurs—and their joint probabilities. From the three given probabilities we can determine (see the interior cells in the two-way table in the solution to Example 2.45):\n\nage 18-29 and uses Snapchat: \\(\\textrm{P}(A\\cap C)= 0.13\\)\nage 18-29 and does not use Snapchat: \\(\\textrm{P}(A\\cap C^c)= 0.07\\)\nnot age 18-29, and uses Snapchat: \\(\\textrm{P}(A^c\\cap C)= 0.11\\)\nnot age 18-29, and does not use Snapchat: \\(\\textrm{P}(A^c\\cap C^c)= 0.69\\) See the spinner in Figure 3.32.\n\nThe following method fixes the number of total spins, say 10000.\n\nSpin the joint spinner from the previous part once to simulate a (age, Snapchat) pair.\nRepeat a fixed number of times, say 10000.\nDiscard the repetitions on which the person was not age 18-29, that is, the repetitions on which \\(A\\) did not occur. You would expect to have around 2000 repetitions left.\nAmong the remaining repetitions (on which \\(A\\) occurred), count the number of repetitions on which \\(C\\) also occurred. So for the roughly 2000 repetitions for which the person is age 18-29, count the repetitions on which the person also uses Snapchat; you would expect a count of around 1300.\nEstimate \\(\\textrm{P}(C|A)\\) by dividing the two previous counts to obtain a conditional relative frequency. \\[\n\\textrm{P}(C | A)\\approx \\frac{\\text{Number of repetitions on which both $A$ and $C$ occurred}}{\\text{Number of repetitions on which $C$ occurred}}\n\\]\n\nOnly those repetitions in which \\(A\\) occurred are used to estimate \\(\\textrm{P}(C|A)\\). So the order of magnitude of the margin of error is determined by the number of repetitions on which \\(A\\) occurs. This would be around 2000 repetitions for a margin of error of roughly \\(1/\\sqrt{2000} = 0.022\\), rather than 0.01 based on the original 10000 repetitions.\nThe previous method simulated a fixed number of repetitions first, and then discarded the ones that did not meet the condition \\(A\\). We could instead discard repetitions that do not meet the condition as we go, and keep performing repetitions until we get a fixed number, say 10000, that do satisfy the condition \\(A\\). In this way, the estimate \\(\\textrm{P}(C |A)\\) will be based on the fixed number of repetitions, say 10000, that satisfy event \\(A\\). The disadvantage is increased computational burden; we will need to simulate and discard many repetitions in order to achieve the desired number that satisfy the condition. Roughly, we would need to simulate about 50000 repetitions in total to obtain 10000 repetitions that satisfy event \\(A\\). The advantage is a more precise estimate of \\(\\textrm{P}(C|A)\\) than in the previous part.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.32: Spinner corresponding to Example 3.20.\n\n\n\n\n\nThe conditional probability of event \\(A\\) given event \\(B\\) can be approximated by simulating—according to the assumptions encoded in the probability measure \\(\\textrm{P}\\)—the random phenomenon a large number of times and computing the relative frequency of \\(A\\) among repetitions on which \\(B\\) occurs.\n\\[\n{\\small\n\\textrm{P}(A|B) \\approx \\frac{\\text{number of repetitions on which $A$ and $B$ occur}}{\\text{number of repetitions on which $B$ occurs}}, \\quad \\text{for a large number of repetitions simulated according to $\\textrm{P}$}\n}\n\\] When using simulation to approximate \\(\\textrm{P}(A|B)\\), we first use \\(B\\) to determine which repetitions to keep, then we find the relative frequency of \\(A\\).\nRemember that the margin of error when approximating a probability based on a simulated relative frequency depends on the number of independently simulated repetitions used to calculate the relative frequency. When approximating \\(\\textrm{P}(A|B)\\) as above, the margin of error is determined by the number of independently simulated repetitions on which \\(B\\) occurs.\nThere are two basic ways to use simulation34 to approximate a conditional probability \\(\\textrm{P}(A|B)\\).\n\nSimulate the random phenomenon for a set number of repetitions (say 10000), discard those repetitions on which \\(B\\) does not occur, and compute the relative frequency of \\(A\\) among the remaining repetitions (on which \\(B\\) does occur).\n\nDisadvantage: the margin of error is based on only the number of repetitions used to compute the relative frequency. So if you perform 10000 repetitions but \\(B\\) occurs only on 1000, then the margin of error for estimating \\(\\textrm{P}(A|B)\\) is roughly on the order of \\(1/\\sqrt{1000} = 0.032\\) (rather than \\(1/\\sqrt{10000} = 0.01\\)). Especially if \\(\\textrm{P}(B)\\) is small, the margin of error could be large resulting in an imprecise estimate of \\(\\textrm{P}(A|B)\\).\nAdvantage: not computationally intensive.\n\nSimulate the random phenomenon until obtaining a certain number of repetitions (say 10000) on which \\(B\\) occurs, discarding those repetitions on which \\(B\\) does not occur as you go, and compute the relative frequency of \\(A\\) among the remaining repetitions (on which \\(B\\) does occur).\n\nAdvantage: the margin of error will be based on the set number of repetitions on which \\(B\\) occurs.\nDisadvantage: requires more time/computer power. Especially if \\(\\textrm{P}(B)\\) is small, it will require a large number of repetitions of the simulation to achieve the desired number of repetitions on which \\(B\\) occurs. For example, if \\(\\textrm{P}(B)=0.1\\), then it will require roughly 100,000 repetitions in total to obtain 10,000 on which \\(B\\) occurs.\n\n\n\n\n3.10.2 Conditioning in Symbulate\nIn Symulate, filter can be used to extract repetitions that satisfy a condition. First we’ll simulate age and Snapchat use for 10000 hypothetical adults. Each ticket in the BoxModel has a (age, Snapchat) pair of labels, like the spinner in Figure 3.32.\n\nP = BoxModel([('Age 18-29', 'Snapchat user'), ('Age 18-29', 'Not Snapchat user'), ('Not Age 18-29', 'Snapchat user'), ('Not Age 18-29', 'Not Snapchat user')],\n             probs = [0.13, 0.07, 0.11, 0.69])\n\nsim_all = P.sim(10000)\n\nsim_all\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0('Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          1('Not Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          2('Not Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          3('Not Age 18-29', 'Snapchat user')\n        \n        \n        \n          4('Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          5('Not Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          6('Not Age 18-29', 'Snapchat user')\n        \n        \n        \n          7('Not Age 18-29', 'Snapchat user')\n        \n        \n        \n          8('Not Age 18-29', 'Not Snapchat user')\n        \n        ......\n        \n          9999('Not Age 18-29', 'Snapchat user')\n        \n        \n      \n    \n\n\n\nsim_all.tabulate()\n\n\n  \n    Outcome\n    Frequency\n  \n  \n    ('Age 18-29', 'Not Snapchat user')710('Age 18-29', 'Snapchat user')1308('Not Age 18-29', 'Not Snapchat user')6901('Not Age 18-29', 'Snapchat user')1081Total10000\n  \n\n\n\nNow we’ll apply filter to retain only those age 18-29. The function is_Age18 takes as an input35 a (age, Snapchat) pair and returns True if age 18-29 (and False otherwise). Applying filter(is_Age18) will only return results for which is_Age18 returns True.\n\ndef is_Age18(Age_Snapchat):\n    return Age_Snapchat[0] == 'Age 18-29'\n  \nsim_given_Age18 = sim_all.filter(is_Age18)\n\nsim_given_Age18\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0('Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          1('Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          2('Age 18-29', 'Snapchat user')\n        \n        \n        \n          3('Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          4('Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          5('Age 18-29', 'Snapchat user')\n        \n        \n        \n          6('Age 18-29', 'Snapchat user')\n        \n        \n        \n          7('Age 18-29', 'Not Snapchat user')\n        \n        \n        \n          8('Age 18-29', 'Snapchat user')\n        \n        ......\n        \n          2017('Age 18-29', 'Not Snapchat user')\n        \n        \n      \n    \n\n\n\nsim_given_Age18.tabulate()\n\n\n  \n    Outcome\n    Frequency\n  \n  \n    ('Age 18-29', 'Not Snapchat user')710('Age 18-29', 'Snapchat user')1308Total2018\n  \n\n\n\nConditional relative frequencies are computed based only on repetitions which satisfy the event being conditioned on.\n\nsim_given_Age18.tabulate(normalize = True)\n\n\n  \n    Outcome\n    Relative Frequency\n  \n  \n    ('Age 18-29', 'Not Snapchat user')0.3518334985133796('Age 18-29', 'Snapchat user')0.6481665014866204Total1.0\n  \n\n\n\nBased on these results, we would estimate \\(\\textrm{P}(C |A)\\) to be around the true value of 0.65 with a margin of error of roughly \\(1/\\sqrt{2000} = 0.022\\).\nIn Symbulate, the “given” symbol | applies the second method to simulate a fixed number of repetitions that satisfy the event being conditioned on. Be careful when using | when conditioning on an event with small probability. In particular, be careful when conditioning on the value of a continuous random variable (which we’ll discuss in more detail soon).\nBelow we use RV syntax to carry out the simulation and conditioning36. Technically, a random variable always returns a number, but RV in Symbulate does allow for non-numerical outputs. In most situations, we will usually deal with true random variables, and the code syntax below will be more natural.\nThe following code simulates (Age, Snapchat) pairs until 10000 adults age 18-29 are obtained.\n\nAge, Snapchat = RV(P)\n\nsim_given_Age18 = ( (Age & Snapchat) | (Age == 'Age 18-29') ).sim(10000)\n\nsim_given_Age18\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(Age 18-29, Snapchat user)\n        \n        \n        \n          1(Age 18-29, Not Snapchat user)\n        \n        \n        \n          2(Age 18-29, Not Snapchat user)\n        \n        \n        \n          3(Age 18-29, Snapchat user)\n        \n        \n        \n          4(Age 18-29, Not Snapchat user)\n        \n        \n        \n          5(Age 18-29, Not Snapchat user)\n        \n        \n        \n          6(Age 18-29, Snapchat user)\n        \n        \n        \n          7(Age 18-29, Not Snapchat user)\n        \n        \n        \n          8(Age 18-29, Not Snapchat user)\n        \n        ......\n        \n          9999(Age 18-29, Not Snapchat user)\n        \n        \n      \n    \n\n\n\nsim_given_Age18.tabulate()\n\n\n  \n    Value\n    Frequency\n  \n  \n    (Age 18-29, Not Snapchat user)3581(Age 18-29, Snapchat user)6419Total10000\n  \n\n\n\nSince all 10000 simulated pairs satisfy the event being conditioned on (age 18-29), they are all included in the computation of the conditional relative frequencies.\n\nsim_given_Age18.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    (Age 18-29, Not Snapchat user)0.3581(Age 18-29, Snapchat user)0.6419Total1.0\n  \n\n\n\nBased on these results, we would estimate \\(\\textrm{P}(C |A)\\) to be around the true value of 0.65 with a margin of error of roughly \\(1/\\sqrt{10000} = 0.01\\). We have obtained a more precise estimate, but the simulation takes longer to run.\n\n\n3.10.3 Using conditional probabilities to simulate\nIn Example 3.20 we directly simulated pairs of events using joint probabilities, and used the results to approximate conditional probabilities. But in many problems conditional probabilities are provided or can be determined directly.\n\n\n\n\n\n\n\nExample 3.21 Recall Example 2.46. Suppose that\n\n65% of American adults age 18-29 use Snapchat\n24% of American adults age 30-49 use Snapchat\n12% of American adults age 50-64 use Snapchat\n2% of American adults age 65+ use Snapchat\n\nAlso suppose that\n\n20% of American adults are age 18-29\n33% of American adults are age 30-49\n25% of American adults are age 50-64\n22% of American adults are age 65+\n\nConsider simulating a randomly selected U.S. adult and determining the person’s age group and whether or not they use Snapchat. How could you perform one repetition of the simulation using spinners based solely on the percentages provided above, without first constructing a two-way table or finding \\(\\textrm{P}(A_1\\cap C)\\), etc? (Hint: you’ll need a few spinners, but you might not spin them all in a single repetition.)\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.21. It’s a two-stage simulation: first spin a spinner to determine age group, then given the result spin an appropriate spinner to determine Snapchat use. There will be 4 spinners for Snapchat use, but only 1 will be spun—along with the age spinner—in any single repetition. See Figure 3.33.\n\n“Age” spinner: Areas of 0.20, 0.33, 0.25, 0.22 corresponding to, respectively, 18-29, 30-49, 50-64. 65+. Spin this to determine age group.\n“Snapchat” spinners—only one of the following will be spun in a single repetition:\n\nSnapchat given age 18-29: areas of 0.65 and 0.35 corresponding to, respectively, uses Snapchat and does not use Snapchat. If the result of the “age” spinner is 18-29, spin this spinner to determine whether or not the person uses Snapchat.\nSnapchat given age 30-49: areas of 0.24 and 0.76 corresponding to, respectively, uses Snapchat and does not use Snapchat. If the result of the “age” spinner is 30-49, spin this spinner to determine whether or not the person uses Snapchat.\nSnapchat given age 50-64: areas of 0.12 and 0.88 corresponding to, respectively, uses Snapchat and does not use Snapchat. If the result of the “age” spinner is 50-64, spin this spinner to determine whether or not the person uses Snapchat.\nSnapchat given age 65+: areas of 0.02 and 0.98 corresponding to, respectively, uses Snapchat and does not use Snapchat. If the result of the “age” spinner is 65+, spin this spinner to determine whether or not the person uses Snapchat.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.33: Spinners corresponding to Example 3.21. The spinner in the top row is spun first to simulate age group, then the corresponding spinner in the bottom row is spun to determine Snapchat use.\n\n\n\n\n\nA two-stage simulation like the one above basically implements the multiplication rule, joint = conditional \\(\\times\\) marginal. We first simulate age based on marginal probabilities, then use conditional probabilities to simulate Snapchat use, resulting in (age, Snapchat) pairs with the appropriate joint relationship.\nIn Symbulate, we can code the scenario in Example 3.21 by defining a custom probability space. An outcome is a (Age, Snapchat) pair. Each of the 5 spinners corresponds to a BoxModel. We define a function that defines how to simulate one repetition in two stages, using the draw method37. Then we use that function to define a custom ProbabilitySpace.\n\ndef Age_Snapchat_sim():\n    Age = BoxModel(['18-29', '30-49', '50-64', '65+'], probs = [0.20, 0.33, 0.25, 0.22]).draw()\n    if Age == '18-29':\n        Snapchat = BoxModel(['Use', 'NotUse'], probs = [0.65, 0.35]).draw()\n    if Age == '30-49':\n        Snapchat = BoxModel(['Use', 'NotUse'], probs = [0.24, 0.76]).draw()\n    if Age == '50-64':\n        Snapchat = BoxModel(['Use', 'NotUse'], probs = [0.12, 0.88]).draw()\n    if Age == '65+':\n        Snapchat = BoxModel(['Use', 'NotUse'], probs = [0.02, 0.98]).draw()\n    return Age, Snapchat\n    \nP = ProbabilitySpace(Age_Snapchat_sim)\nP.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0('30-49', 'NotUse')\n        \n        \n        \n          1('50-64', 'NotUse')\n        \n        \n        \n          2('65+', 'NotUse')\n        \n        \n        \n          3('65+', 'NotUse')\n        \n        \n        \n          4('65+', 'NotUse')\n        \n        \n        \n          5('65+', 'NotUse')\n        \n        \n        \n          6('18-29', 'Use')\n        \n        \n        \n          7('50-64', 'NotUse')\n        \n        \n        \n          8('65+', 'NotUse')\n        \n        ......\n        \n          9('65+', 'NotUse')\n        \n        \n      \n    \n\n\nOnce we have simulated pairs, we can proceed as in Section 3.10.1. For example, the following approximates conditional probabilities of age group given that the adult uses Snapchat, based on 10000 repetitions which satisfy the condition; compare to part 7 of Example 2.46.\n\nAge, Snapchat = RV(P)\n\nsim_given_Snapchat = ( Age | (Snapchat == 'Use') ).sim(10000)\n\nsim_given_Snapchat.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    18-290.539230-490.317350-640.126365+0.0172Total1.0\n  \n\n\n\n\n\n3.10.4 Conditioning on values of random variables\nIf \\(X\\) is a discrete random variable, we can condition on it equalling the value \\(x\\) by conditioning on the event \\(\\{X = x\\}\\).\n\n\n\n\n\n\n\nExample 3.22 We’ll continue with the dice rolling example: roll two fair four-sided dice and let \\(X\\) be the sum and \\(Y\\) the larger of the rolls. For each of the following, describe how to approximate the probability based on 10000 repetitions of a tactile simulation (in principle).\n\n\\(\\textrm{P}(X = 6 | Y = 4)\\).\n\\(\\textrm{P}(Y = 4 | X = 6)\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.22. We have already seen how to simulate \\((X, Y)\\) pairs.\n\nSimulate an \\((X, Y)\\) pair. If \\(Y=4\\) keep the pair, otherwise discard it. Continue until 10000 \\((X, Y)\\) pairs with \\(Y=4\\) are obtained. Count the number of pairs for which \\(X=6\\) and divide by 10000 to approximate \\(\\textrm{P}(X = 6 | Y = 4)\\), with a margin of error of 0.01.\nSimulate an \\((X, Y)\\) pair. If \\(X=6\\) keep the pair, otherwise discard it. Continue until 10000 \\((X, Y)\\) pairs with \\(X=6\\) are obtained. Count the number of pairs for which \\(Y=4\\) and divide by 10000 to approximate \\(\\textrm{P}(Y = 4 | X = 6)\\), with a margin of error of 0.01.\n\n\n\n\n\nTo approximate a conditional probability of an event involving a random variable \\(X\\) given the value of a random variable \\(Y\\), we first need to simulate \\((X, Y)\\) pairs. The variable being conditioned on (\\(Y\\) here) determines which pairs to keep, and the other variable determines what to find the relative frequency of.\nHere is some code for conditioning on \\(\\{Y = 4\\}\\).\n\nP = DiscreteUniform(1, 4) ** 2\n\nX = RV(P, sum)\nY = RV(P, max)\n\n( (X & Y) | (Y == 4) ).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(5, 4)\n        \n        \n        \n          1(6, 4)\n        \n        \n        \n          2(7, 4)\n        \n        \n        \n          3(7, 4)\n        \n        \n        \n          4(5, 4)\n        \n        \n        \n          5(6, 4)\n        \n        \n        \n          6(7, 4)\n        \n        \n        \n          7(7, 4)\n        \n        \n        \n          8(6, 4)\n        \n        ......\n        \n          9(7, 4)\n        \n        \n      \n    \n\n\n\n(X | (Y == 4) ).sim(10000).tabulate()\n\n\n  \n    Value\n    Frequency\n  \n  \n    52868628607286081412Total10000\n  \n\n\n\n\n(X | (Y == 4) ).sim(10000).tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    50.287560.282170.290980.1395Total1.0\n  \n\n\n\nBelow we simulate values of \\(X\\) given \\(Y=y\\) for each of the values \\(y = 2, 3, 4\\). (We omit conditioning on \\(Y=1\\) since then \\(X = 2\\) with probability 1.) Each of the three simulations below approximates a separate conditional distribution of \\(X\\) values.\n\n\nx_given_Y_eq4 = (X | (Y == 4) ).sim(10000)\n\nx_given_Y_eq3 = (X | (Y == 3) ).sim(10000)\n\nx_given_Y_eq2 = (X | (Y == 2) ).sim(10000)\n\nWe plot the three distributions on a single plot to compare how the distribution of \\(X\\) changes depending on the given value of \\(Y\\).\n\nx_given_Y_eq4.plot()\nx_given_Y_eq3.plot(jitter = True) # shifts the spikes a little\nx_given_Y_eq2.plot(jitter = True) # so they don't overlap\n\n\n\n\n\n\n\n\n\n\nExtra care is required when conditioning on the value of a continuous random variable. We’ll consider the Bivariate Normal model of the meeting problem from Section 3.4.\n\n\n\n\n\n\n\nExample 3.23 Suppose we want to approximate the conditional probability that Cady arrives first given that Regina arrives at 12:40.\n\nDonny Don’t writes the Symbulate code below to approximate this probability. What do you think will happen when Donny runs his code?\nCan you think of how to fix Donny’s code? (Hint: when we say “Regina arrives at 12:40”, what do we really mean?)\n\n\n\n\n\n\n# Donny's code - don't try to run this!\nR, Y = RV(BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7))\n\ny_given_Req40 = (Y | (R == 40) ).sim(10000)\n\ny_given_Req40.count_lt(40) / 10000\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.23. \n\nDonny’s code will run forever! Using .sim(10000) with conditioning via | will continue the simulation until obtaining 10000 repetitions that satisfy the condition. Remember, \\(R\\) is a continuous random variable, so \\(\\textrm{P}(R = 40)=\\textrm{P}(R = 40.00000000000000000\\ldots) = 0\\). The simulation will never return a single \\((R, Y)\\) pair with \\(Y\\) equal to \\(40.0000000000000\\ldots\\), let alone 10000 of them.\n“Regina arrives at 12:40” doesn’t really mean \\(R\\) “is equal to 40” but rather \\(R\\) “is close enough to 40”, where “close enough” depends on the context. Here, rounding to the nearest minute seems reasonable, in which case “Regina arrives at 12:40” really means “Regina arrives within 0.5 minutes (30 seconds) of 12:40”. So we want to condition on the event \\(\\{40 - 0.5 &lt; R &lt; 40 + 0.5\\}=\\{|R - 40|&lt;0.5\\}\\) rather than \\(\\{R = 40\\}\\). See the code below, where we condition on the event (abs(R - 40) &lt; 0.5). Aside from the conditioning event, Donny’s code is fine, but note that we have changed the number of repetitions from 10000 to 1000; see the discussion below.\n\n\n\n\n\n\nR, Y = RV(BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7))\n\ny_given_Req40 = (Y | (abs(R - 40) &lt; 0.5) ).sim(1000)\n\ny_given_Req40.count_lt(40) / 1000\n\n0.66\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe careful when conditioning on the value of a continuous random variable. Remember that the probability that a continuous random variable is equal to a particular value is 0. Mathematically, when we condition on \\(\\{X=x\\}\\) we are really conditioning on \\(\\{|X-x|&lt;\\epsilon\\}\\)—the event that the random variable \\(X\\) is within \\(\\epsilon\\) of the value \\(x\\)—and seeing what happens in the idealized limit when \\(\\epsilon\\) approaches 0. Practically, \\(\\epsilon\\) represents the degree of precision which determines “close enough” in the problem context, e.g., \\(\\epsilon=0.01\\) if “within 0.01” is close enough. When conditioning on a continuous random variable \\(X\\) in a simulation, never condition on \\(\\{X=x\\}\\); rather, condition on \\(\\{|X-x|&lt;\\epsilon\\}\\) where \\(\\epsilon\\) represents a suitable degree of precision. What counts as “suitable” depends on the context and the scale of the \\(X\\) variable. For example, if our variable is household income (U.S. dollars) and we’re conditioning on household income “equal to” 100,000 dollars, then \\(\\epsilon\\) of 1000 dollars might be reasonable.\n\n\nThe event \\(\\{|X-x|&lt;\\epsilon\\}\\) will have non-zero probability, but the probability might be small. Conditioning on low probability events introduces some computational challenges. Remember that the margin of error in using a relative frequency to approximate a probability is based on the number of independently simulated repetitions used to compute the relative frequency. When approximating a conditional probability with a conditional relative frequency, the margin of error is based only on the number of repetitions that satisfy the condition. Naively discarding repetitions that do not satisfy the condition can be horribly inefficient. For example, when conditioning on an event with probability 0.01 we would need to run about 1,000,000 repetitions to achieve 10,000 that satisfy the condition. There are more sophisticated and efficient methods (e.g., “Markov chain Monte Carlo (MCMC)” methods), but they are beyond the scope of this book. When conditioning on the value of a continuous random variable with | in Symbulate, be aware that you might need to change either the number of repetitions (but try not to go below 1000) or the degree of precision \\(\\epsilon\\) in order for the simulation to run in a reasonable amount of time.\nIn the Bivariate Normal model of the meeting problem the event \\(\\{|R - 40| &lt; 0.5\\}\\) has probability 0.04. Running (Y | (abs(R - 40) &lt; 0.5) ).sim(1000) requires about 25000 repetitions in the background to achieve the 1000 the satisfy the condition. The margin of error for approximating conditional probabilities is roughly \\(1/\\sqrt{1000} = 0.03\\).\n\nR, Y = RV(BivariateNormal(mean1 = 30, sd1 = 10, mean2 = 30, sd2 = 10, corr = 0.7))\n\n( (R & Y) | (abs(R - 40) &lt; 0.5) ).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(40.14915408128157, 40.12264058742875)\n        \n        \n        \n          1(40.25996107895743, 35.3623789144861)\n        \n        \n        \n          2(39.83611924899172, 41.34823374926064)\n        \n        \n        \n          3(40.382666753677604, 49.014575750399615)\n        \n        \n        \n          4(39.76583199273752, 36.29333826549423)\n        \n        \n        \n          5(39.930934118521016, 42.76293580994732)\n        \n        \n        \n          6(40.49426000823788, 33.499592649331326)\n        \n        \n        \n          7(40.29903852762173, 28.765114788348647)\n        \n        \n        \n          8(39.94139064678516, 41.51412121859154)\n        \n        ......\n        \n          9(40.24528662961394, 34.87730393256037)\n        \n        \n      \n    \n\n\n\n\n3.10.5 Conditional averages\nTBA\n\n\n3.10.6 Exercises\n\nExercise 3.25 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\n\nExplain how you could, in principle, conduct a simulation by hand and use the results to approximate\n\n\\(\\textrm{P}(Y = 0 | X = 1)\\)\nThe conditional distribution of \\(Y\\) given \\(X=1\\)\n\\(\\textrm{P}(X = 1 | Y = 0)\\)\nThe conditional distribution of \\(X\\) given \\(Y=0\\)\n\nWrite Symbulate code to conduct a simulation and approximate the values in part 1. Each simulation should be based on 10000 repetitions that satisfy the conditioning event.\n\n\n\nExercise 3.26 Write Symbulate code to conduct the simulation in Exercise 3.4. Use conditioning to discard any repetitions where the dart lands off the board. Use the simulation results to approximate:\n\nThe marginal distribution of \\(R\\) (via plot)\n\\(\\textrm{P}(R &lt; 1)\\)\n\\(\\textrm{P}(R &gt; 11)\\)\n\\(\\textrm{E}(R)\\)\n\\(\\textrm{SD}(R)\\).\n\n\n\nExercise 3.27 Consider a continuous version of the dice rolling problem where instead of rolling two fair four-sided dice (which return values 1, 2, 3, 4) we spin twice a Uniform(1, 4) spinner (which returns any value in the continuous range between 1 and 4). Let \\(X\\) be the sum of the two spins and let \\(Y\\) be the larger of the two spins.\n\nDescribe in words how you could use simulation to approximate\n\n\\(\\textrm{P}(Y &lt; 2.7 | X = 3.5)\\)\nThe conditional distribution of \\(Y\\) given \\(X = 3.5\\)\n\nWrite Symbulate code to conduct a simulation to approximate the quantities from the previous part.\n\nHint: be careful! What do we really mean by conditioning on \\(X = 3.5\\)?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-simulation-independence",
    "href": "language-simulation.html#sec-simulation-independence",
    "title": "3  The Language of Simulation",
    "section": "3.11 Independence",
    "text": "3.11 Independence\nFor independent events, the multiplication rule simplifies\n\\[\\begin{align*}\n\\text{If $A$ and $B$ are independent then } && \\textrm{P}(A \\cap B) & = \\textrm{P}(A)\\textrm{P}(B)\\\\\n\\text{If independent then } && \\text{Joint} & = \\text{Product of Marginals}\n\\end{align*}\\]\nSimilarly, the joint distribution of independent random variables is this product of their marginal distributions. For this reason, independence is represented by the product * syntax in Symbulate.\nFor example, in the meeting problem, if Regina’s arrival follows a Uniform(0, 60) model, Cady’s follows a Normal(30, 10) model, and they arrive independently of each other, we can simulate pairs of arrivals as follows; note the use of *.\n\nP = Uniform(0, 60) * Normal(30, 10)\nP.sim(5)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(35.91007216545916, 40.14244827651588)\n        \n        \n        \n          1(5.489201647789681, 24.325402905518178)\n        \n        \n        \n          2(1.854518147015476, 31.841877080238984)\n        \n        \n        \n          3(24.004230282198645, 52.44255044610784)\n        \n        \n        \n          4(35.253061414093345, 21.418533788913734)\n        \n        \n      \n    \n\n\nWe can think of * as “spin each spinner independently”, but what * really does is create a joint probability space as the product of two marginal probability spaces.\n\n\n\n\n\n\nWarning\n\n\n\nBe careful: * plays different roles for probability spaces and named distributions (like Uniform, Normal) than it does for random variables. Using * with probability spaces indicates that the spaces are independent. Likewise, using * with distributions of random variables, as in X, Y = RV(Distribution_X * Distribution_Y), indicates that the random variables are independent since their joint distribution is the product of their marginal distributions. In contrast, using * directly on random variables, as in X * Y, literally means multiplication. (Section 3.15 has further discussion on the difference between a random variable and its distribution.)\n\n\nNote the two uses of * in the code below. In the P = ... line, * means that the two components of the pair will be simulated independently (e.g., “spin the Uniform(0, 60) spinner then spin the Normal(30, 10) spinner”), resulting in random variables R (first component) and Y (second component) that are independent. In (R * Y), * means multiply the values of R and Y.\n\nP = Uniform(0, 60) * Normal(30, 10)\nR, Y = RV(P)\n\n(R & Y & (R * Y) ).sim(5)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(4.832484983421976, 44.077826540766395, 213.00543486013223)\n        \n        \n        \n          1(6.649204847774137, 30.80373628388576, 204.82035262836928)\n        \n        \n        \n          2(31.52708086748251, 25.278537446970468, 796.9584943023228)\n        \n        \n        \n          3(52.71302952804211, 32.757323422882514, 1726.7377568500312)\n        \n        \n        \n          4(31.10672663692339, 53.680033560921636, 1669.8101298404627)\n        \n        \n      \n    \n\n\nWe could have also coded the following, which we interpret as defining random variables R and Y whose joint distribution is the product of their marginal distributions, Uniform(0, 60) for R and Normal(30, 10) for Y, and thus R and Y are independent.\n\nR, Y = RV(Uniform(0, 60) * Normal(30, 10))\n\n(R & Y & (R * Y) ).sim(5)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(39.04875374562182, 22.80083251932396, 890.3440942422474)\n        \n        \n        \n          1(6.8205530954557165, 21.551425838756323, 146.99264421601376)\n        \n        \n        \n          2(41.8534296756618, 23.65774740819669, 990.1578674335304)\n        \n        \n        \n          3(35.28102373074602, 38.23556389788575, 1348.989837239763)\n        \n        \n        \n          4(31.63576813915898, 40.79128044929014, 1290.4634903931517)\n        \n        \n      \n    \n\n\n\n\n\n\n\n\n\nExample 3.24 Donny Don’t writes the following code to simulate \\(X\\) and \\(Y\\) from Example 2.68, but it returns an error. Can you explain why? Think about it first, but if you need a hint, run the code to see the error. How could you fix the code so it runs properly.\n\n\n\n\n\nX = RV(BoxModel([2, 3, 4, 5, 6, 7, 8], probs = [1/16, 2/16, 3/16, 4/16, 3/16, 2/16, 1/16]))\nY = RV(BoxModel([1, 2, 3, 4], probs = [1/16, 3/16, 5/16, 7/16]))\n\n(X & Y).sim(10)\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.24. Donny’s code defines the correct marginal distributions for \\(X\\) and \\(Y\\), but to simulate \\(X, Y\\) pairs we need to know their joint distribution. Recall the moral of Example 2.68 and the discussion following it: marginal distributions alone are not enough to determine the joint distribution.\nThe error message is “Events must be defined on same probability space”, which in this case really should be “random variables must be defined on same probability space”, but even that is maybe not the most informative message. The idea is that we have not provided enough information to determine how to pair \\(X\\) and \\(Y\\) values when running the simulation. If the random variables were defined on the same probability space, the probaility space outcome would be simulated first and then both \\(X\\) and \\(Y\\) would be computed for the same outcome, so there would be no problem when simulating pairs. One way to define the random variables on the same probability space is to specify their joint distribution and then simulate pairs directly from the joint distribution.\nRecall from Example 2.68 that \\(X\\) and \\(Y\\) here are independent, so their joint distribution is the product of their marginal distribution. The code below achieves Donny’s goal, using the * syntax.\n\n\n\n\n\nX, Y = RV(BoxModel([2, 3, 4, 5, 6, 7, 8], probs = [1/16, 2/16, 3/16, 4/16, 3/16, 2/16, 1/16]) * \n          BoxModel([1, 2, 3, 4], probs = [1/16, 3/16, 5/16, 7/16]))\n\n(X & Y).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(4, 3)\n        \n        \n        \n          1(4, 4)\n        \n        \n        \n          2(5, 3)\n        \n        \n        \n          3(7, 3)\n        \n        \n        \n          4(3, 3)\n        \n        \n        \n          5(7, 3)\n        \n        \n        \n          6(8, 3)\n        \n        \n        \n          7(4, 2)\n        \n        \n        \n          8(3, 3)\n        \n        ......\n        \n          9(5, 3)\n        \n        \n      \n    \n\n\n\n\n\n\n\n\n\nExample 3.25 Continuing Example 3.25, Donny says: “That error is annoying. If \\(X\\) and \\(Y\\) are independent then their marginal distributions determine their joint distribution, so my code should be fine.” How would you respond? (You might agree with Donny here. If so, imagine you have been assigned to argue against Donny.)\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.25. Donny is correct that if random variables are independent their marginal distributions determine their joint distribution. The issue is that independence is an assumption—see Section 2.7.3 —and Symbulate requires you to be explicit about all your assumptions. There are 3 main assumptions in this example:\n\n\\(X\\) is assumed to have a particular marginal distribution\n\\(Y\\) is assumed to have a particular marginal distribution\n\\(X\\) and \\(Y\\) are assumed to be independent\n\nDonny’s code has defined the first two assumptions, but not the third.\nSuppose Donny had tried to run (X & Y).sim(10) without first defining X, hence not specifying the first assumption above. That would also result in an error, because there would not be enough information to run the simulation. If you don’t specify the distribution of a random variable—either directly or by defining it as a function on a probability space—Symbulate will not assume a distribution by default.\nLikewise, Symbulate won’t assume random variables are independent unless you tell it to. You, like Donny, might want Symbulate to assume independence by default, but that’s just not the way it works. And it’s probably much safer that way because there are many real situations where independence is not a reasonable assumption, and assuming independence by default might lead to wildly inaccurate results.\n\n\n\n\nSymbulate does offer a compromise, via the AssumeIndependent command, which allows code like Donny’s in Example 3.24 while also requiring explicit specification of independence The following code would achieve Donny’s goal in Example 3.24.\n\nX = RV(BoxModel([2, 3, 4, 5, 6, 7, 8], probs = [1/16, 2/16, 3/16, 4/16, 3/16, 2/16, 1/16]))\nY = RV(BoxModel([1, 2, 3, 4], probs = [1/16, 3/16, 5/16, 7/16]))\n\nX, Y = AssumeIndependent(X, Y)\n\n(X & Y).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(6, 3)\n        \n        \n        \n          1(6, 4)\n        \n        \n        \n          2(7, 4)\n        \n        \n        \n          3(7, 2)\n        \n        \n        \n          4(8, 4)\n        \n        \n        \n          5(6, 4)\n        \n        \n        \n          6(5, 4)\n        \n        \n        \n          7(6, 4)\n        \n        \n        \n          8(6, 4)\n        \n        ......\n        \n          9(3, 3)\n        \n        \n      \n    \n\n\nWhile AssumeIndependent works, we discourage its use for two reasons. First, the code is clunky; in a sense the definition of X and Y with X = RV(...) and Y = RV(...) is incomplete until they are redefined with X, Y = AssumeIndependent(X, Y). More importantly, when dealing with multiple random variables it is their joint distribution that describes fully their probabilitistic behavior. Therefore we encourage you to get in the habit of defining joint distributions (possibly using the “marginal then conditional” construction). In many situations random variables are not independent, so marginal distributions alone are not enough. In the special case of independence, define the joint distribution directly as the product of marginal distributions using * rather than using AssumeIndependent.\n\n3.11.1 Exercises",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#working-with-symbulate",
    "href": "language-simulation.html#working-with-symbulate",
    "title": "3  The Language of Simulation",
    "section": "3.12 Working with Symbulate",
    "text": "3.12 Working with Symbulate\nIn this section we explore a little deeper some aspects of coding simulations with Symbulate.\n\n3.12.1 Two “worlds” in Symbulate\nRecall the dice rolling simulation in Section 3.3. Suppose we want to simulate realizations of the event \\(A= \\{Y &lt; 3\\}\\). We saw previously that we can define the event (Y &lt; 3) in Symbulate and simulate True/False realizations of it.\n\nP = RV(DiscreteUniform(1, 4) ** 2)\n\nY = RV(P, max)\n\nA = (Y &lt; 3)\n\nA.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0True\n        \n        \n        \n          1True\n        \n        \n        \n          2False\n        \n        \n        \n          3True\n        \n        \n        \n          4False\n        \n        \n        \n          5False\n        \n        \n        \n          6True\n        \n        \n        \n          7False\n        \n        \n        \n          8False\n        \n        ......\n        \n          9False\n        \n        \n      \n    \n\n\nSince event \\(A\\) is defined in terms of \\(Y\\), we can also first simulate values of Y, store the results as y, and then determine whether event \\(A\\) occurs for the simulated y values using38 (y &lt; 3). (The results won’t match the above because we are making a new call to sim.)\n\ny = Y.sim(10)\n\ny\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          02\n        \n        \n        \n          11\n        \n        \n        \n          24\n        \n        \n        \n          34\n        \n        \n        \n          44\n        \n        \n        \n          52\n        \n        \n        \n          62\n        \n        \n        \n          73\n        \n        \n        \n          84\n        \n        ......\n        \n          94\n        \n        \n      \n    \n\n\n\n(y &lt; 3)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0True\n        \n        \n        \n          1True\n        \n        \n        \n          2False\n        \n        \n        \n          3False\n        \n        \n        \n          4False\n        \n        \n        \n          5True\n        \n        \n        \n          6True\n        \n        \n        \n          7False\n        \n        \n        \n          8False\n        \n        ......\n        \n          9False\n        \n        \n      \n    \n\n\nThese two methods illustrate the two “worlds” of Symbulate, which we call “random variable world” and “simulation world”. Operations like transformations can be performed in either world. Think of random variable world as the “before” world and simulation world as the “after” world, by which we mean before/after the sim step.\nMost of the transformations we have seen so far happened in random variable world. For example, we have seen how to define the sum of two dice in random variable world in a few ways, e.g., via\n\nP = BoxModel([1, 2, 3, 4], size = 2)\n\nU = RV(P)\n\nX = U.apply(sum)\n\nThe sum transformation is applied to define a new random variable X, before the sim step. We could then call, e.g., (U & X).sim(10).\nWe could also compute simulated values of the sum in simulation world as follows.\n\nP = BoxModel([1, 2, 3, 4], size = 2)\n\nU = RV(P)\n\nu = U.sim(10)\n\nu\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(4, 2)\n        \n        \n        \n          1(4, 2)\n        \n        \n        \n          2(4, 2)\n        \n        \n        \n          3(1, 3)\n        \n        \n        \n          4(1, 1)\n        \n        \n        \n          5(4, 4)\n        \n        \n        \n          6(2, 3)\n        \n        \n        \n          7(2, 2)\n        \n        \n        \n          8(2, 1)\n        \n        ......\n        \n          9(4, 1)\n        \n        \n      \n    \n\n\n\nu.apply(sum)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          06\n        \n        \n        \n          16\n        \n        \n        \n          26\n        \n        \n        \n          34\n        \n        \n        \n          42\n        \n        \n        \n          58\n        \n        \n        \n          65\n        \n        \n        \n          74\n        \n        \n        \n          83\n        \n        ......\n        \n          95\n        \n        \n      \n    \n\n\nThe above code will simulate all the pairs of rolls first, store them as u (which we can think of as a table), and then apply the sum to the simulated values (which adds a column to the table). That is, the sum transformation happens after the sim step.\nWhile either world is “correct”, we generally take the random variable world approach. We do this mostly for consistency, but also to emphasize some of the probability concepts we’ll encounter. For example, the fact that a sum of random variables (defined on the same probability space) is also a random variable is a little more apparent in random variable world. However, it is sometimes more convenient to code in simulation world; for example, if complicated transformations are required.\n\n\n\n\n\n\n\nExample 3.26 Donny Don’t writes the following code to simulate \\(X\\) and \\(Y\\) in the dice problem, but it returns an error. Can you explain why? Think about it first, but if you need a hint, run the code to see the error.\n\n\n\n\n\nX = RV(BoxModel([1, 2, 3, 4], size = 2), sum)\nY = RV(BoxModel([1, 2, 3, 4], size = 2), max)\n\n(X & Y).sim(10)\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.26. The problem is that there is one box model used to determine values of X and a separate box model for Y; we can’t simulate (X, Y) pairs of values if we’re using different boxes. The code above is basically saying to roll one fair four-sided die twice and compute the sum, then roll another four-sided die twice and compute the max, but we can only compute \\(X\\) and \\(Y\\) (X & Y) for the same pair of rolls.\nThe error message is “Events must be defined on same probability space”, which in this case really should be “random variables must be defined on same probability space”, but the actual message at least reflects the spirit of the error.\n\n\n\n\n\n\n\n\n\n\n\nExample 3.27 Donny Don’t tries again to simulate just \\(X\\) in the dice problem, this time in simulation world, but Donny’s code below still returns an error. Can you explain why? Think about it first, but if you need a hint, run the code to see the error.\n\n\n\n\n\nP = BoxModel([1, 2, 3, 4], size = 2)\nU1, U2 = RV(P)\n\nu1 = U1.sim(10)\nu2 = U2.sim(10)\n\nx = u1 + u2\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.27. The error is basically the same as in Example 3.26. Running U1.sim(10) simulates one set of pairs of rolls to compute u1, but running u2 = U2.sim(10) simulates a separate set of pairs of rolls to compute u2. The error occurs when running u1+u2 because it only makes sense to add the first roll and second roll for the same pairs of rolls.\nThe error message is “Results objects must come from the same simulation”, which is maybe not the most informative message, but at least reflects the spirit of the error.\n\n\n\n\n\n\n\n\n\n\n\nExample 3.28 Continuing Example 3.27, Donny says: “That error is annoying. If \\(U_1\\) and \\(U_2\\) are independent then I should be able to simulate then independently and then add them, so my code should be fine.” How would you respond? (You might agree with Donny here. If so, imagine you have been assigned to argue against Donny.)\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.28. This is essentially the same issue we discussed in Solution 3.25. Symbulate requires you to be explicit about all your assumptions. Symbulate won’t let you operate on multiple random variables unless you have been explicit about how they’re related. In particular, Symbulate won’t assume random variables are independent unless you explicitly tell it to when you define the RVs (e.g., by specifying their joint distribution as the product of their marginal distributions using *). You, like Donny, might want the ability to simulate individual independent random variables separately and then combine the results of the simulations, but that’s just not the way Symbulate works. And it’s probably much safer that way because there are many real situations where independence is not a reasonable assumption, and combining the results from independent simulations might lead to wildly inaccurate results.\n\n\n\n\nWhen working in random variable world, it only makes sense to transform or simulate random variables defined on the same probability space. Likewise, in simulation world, it only makes sense to apply transformations to values generated in the same simulation, with all assumptions—including indepedence, if appropriate—clearly defined, via a single sim step.\nThe “simulation” step should be implemented in a single call to sim, and in that single step you should simulate realizations of all random variables of interest (e.g., with &). Afterwards you can select certain columns of the simulation results using brackets, and manage these columns in simulation world. For example, if we wanted to sum the rolls in simulation world, we could use the following code39 which has a single call to sim and runs without error.\n\nP = BoxModel([1, 2, 3, 4], size = 2)\nU1, U2 = RV(P)\n\nu1_and_u2 = (U1 & U2).sim(10)\n\nu1 = u1_and_u2[0]\nu2 = u1_and_u2[1]\n\nx = u1 + u2\nx\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          06\n        \n        \n        \n          18\n        \n        \n        \n          25\n        \n        \n        \n          35\n        \n        \n        \n          45\n        \n        \n        \n          55\n        \n        \n        \n          66\n        \n        \n        \n          78\n        \n        \n        \n          88\n        \n        ......\n        \n          95\n        \n        \n      \n    \n\n\n\n\n3.12.2 Brief summary of Symbulate commands\nWe will see a variety of scenarious throughout the book, but many simulations using Symbulate can be carried out with relatively few commands. The following table comprises the requisite Symbulate commands for a wide variety of situations.\n\n\n\nCommand\nFunction\n\n\n\n\nBoxModel\nDefine a box model\n\n\nProbabilitySpace\nDefine a custom probability space\n\n\nRV\nDefine random variables, vectors, or processes\n\n\nRandomProcess\nDefine a discrete or continuous time stochastic process\n\n\napply\nApply transformations\n\n\n[] (brackets)\nAccess a component of a random vector, or a random process at a particular time\n\n\n* (and **)\nDefine independent probability spaces or distributions\n\n\nAssumeIndependent\nAssume random variables or processes are independent\n\n\n| (vertical bar)\nCondition on events\n\n\n&\nJoin multiple random variables into a random vector\n\n\nsim\nSimulate outcomes, events, and random variables, vectors, and processes\n\n\ntabulate\nTabulate simulated values\n\n\nplot\nPlot simulated values\n\n\nfilter (and relatives)\nCreate subsets of simulated values (filter_eq, filter_lt, etc)\n\n\ncount (and relatives)\nCount simulated values which satisfy some critera (count_eq, count_lt, etc)\n\n\nStatistical summaries\nmean, median, sd, var, quantile, corr, cov, etc.\n\n\nCommon models\nNormal, BivariateNormal, and many others we will see\n\n\n\nIn addition to Symbulate commands, we can use basic Python commands to\n\ndefine functions to define random variables\ndefine for loops to investigate changing parameters\ncustomize plots produced by the Symbulate plot command (add axis labels, legends, titles, etc)\nsummarize results of multiple simulations in tables and Matplotlib plots (e.g., for different values of problem parameters)\n\nThe next section and Section 3.13 will provide some examples of how we can use Symbulate together with Python (or R) code.\n\n\n3.12.3 Working with Symbulate output in Python and R\nSymbulate has many built in commands that facilitate the summarization of simulation output in basic plots, tables, and statistics. However, it is also possible to convert Symbulate output into a data frame which can be manipulated using (non-Symbulate) Python or R code. This section provides a brief introduction.\nLet’s start with some Symbulate code and output (from the dice rolling simulation in Section 3.3).\n\nP = BoxModel([1, 2, 3, 4], size = 2)\n\nX = RV(P, sum)\nY = RV(P, max)\n\nxy = (X & Y).sim(10000)\n\nxy\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(5, 3)\n        \n        \n        \n          1(5, 3)\n        \n        \n        \n          2(5, 3)\n        \n        \n        \n          3(3, 2)\n        \n        \n        \n          4(3, 2)\n        \n        \n        \n          5(4, 3)\n        \n        \n        \n          6(3, 2)\n        \n        \n        \n          7(5, 3)\n        \n        \n        \n          8(5, 4)\n        \n        ......\n        \n          9999(7, 4)\n        \n        \n      \n    \n\n\npandas—commonly nicknamed as pd—is a popular Python package for data science. We can convert the output of a Symbulate sim to a pandas DataFrame.\n\nimport pandas as pd\n\n\nxy_df = pd.DataFrame(xy)\n\nxy_df\n\n      0  1\n0     5  3\n1     5  3\n2     5  3\n3     3  2\n4     3  2\n...  .. ..\n9995  4  3\n9996  8  4\n9997  6  3\n9998  5  4\n9999  7  4\n\n[10000 rows x 2 columns]\n\n\nBy default the column names are just their index (0, 1, 2,…), but they can be renamed.\n\nxy_df = xy_df.rename(columns={0: \"x\", 1: \"y\"})\n\nxy_df\n\n      x  y\n0     5  3\n1     5  3\n2     5  3\n3     3  2\n4     3  2\n...  .. ..\n9995  4  3\n9996  8  4\n9997  6  3\n9998  5  4\n9999  7  4\n\n[10000 rows x 2 columns]\n\n\nNow we can work with the simulation output as we would any pandas DataFrame. Here are just a few examples\n\nxy_df[\"y\"].value_counts(normalize = True).sort_index()\n\ny\n1    0.0593\n2    0.1936\n3    0.3073\n4    0.4398\nName: proportion, dtype: float64\n\n\n\nxy_df[\"x\"].value_counts().sort_index().plot.bar()\nplt.show()\n\n\n\n\n\n\n\n\n\npd.crosstab(xy_df[\"x\"], xy_df[\"y\"])\n\ny    1     2     3     4\nx                       \n2  593     0     0     0\n3    0  1317     0     0\n4    0   619  1205     0\n5    0     0  1260  1306\n6    0     0   608  1263\n7    0     0     0  1196\n8    0     0     0   633\n\n\nR is another popular software environment for statistical computing and graphics. Symbulate is a Python package, but there are a number of ways to interface between R and Python. Using an IDE such as Positron, you can toggle between R and Python (as well as other formats). The following provides examples of code cells you can include in a Quarto document that you can edit in Positron and run both Python and R code.\nUsing Quarto, we can first run a Symbulate simulation and convert the output to a pandas DataFrame (xy_df) using a Python code block.\n\n```{python}\nP = BoxModel([1, 2, 3, 4], size = 2)\n\nX = RV(P, sum)\nY = RV(P, max)\n\nxy = (X & Y).sim(10000)\n\nxy_df = pd.DataFrame(xy)\n\nxy_df = xy_df.rename(columns={0: \"x\", 1: \"y\"})\n```\n\nNow we can use the R package reticulate and access xy_df within an R code block (as py$xy_df).\n```{r}\n\nlibrary(reticulate)\n```\n\n```{r}\npy$xy_df |&gt; head()\n```\n\n  x y\n1 6 3\n2 7 4\n3 5 3\n4 5 4\n5 6 3\n6 4 2\n\n\nNow we have an R data frame that we can manipulate using commands from R packages. For example, we can use the R package ggplot2 to create visualizations of Symbulate output.\n```{r}\n\nlibrary(ggplot2)\n```\n\n```{r}\nxy_df = py$xy_df\n\nN = nrow(xy_df)\n\nggplot(xy_df,\n       aes(x = factor(x), y = factor(y))) +\n  stat_bin_2d(aes(fill = after_stat(count / N))) +\n  labs(x = \"Sum of the two rolls\",\n       y = \"Larger of the two rolls\",\n       fill = \"Proportion of pairs\",\n       title = \"10000 pairs of rolls of a fair four-sided die\")\n```",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-sim-matching-n",
    "href": "language-simulation.html#sec-sim-matching-n",
    "title": "3  The Language of Simulation",
    "section": "3.13 Case Study: Matching Problem",
    "text": "3.13 Case Study: Matching Problem\nDice rolling provides a simple scenario for us to introduce ideas, but it’s not very exciting. Now we’ll apply ideas from this chapter to investigate a more interesting problem: the matching problem. We’ll also see how we can combine Symbulate and Python code. Our analysis will illustrate sensitity analysis, where we see how probabilities, distributions, and expected values change as we vary parameters or assumptions.\nConsider the matching problem for a general \\(n\\): objects labeled \\(1, 2, 3, \\ldots, n\\) are placed at random in spots labeled \\(1, 2, 3, \\ldots, n\\) with spot 1 the correct spot for object 1, etc. Let the random variable \\(X\\) count the number of objects (out of \\(n\\)) that are put back in the correct spot; \\(X\\) is the number of “matches”. Let \\(\\textrm{P}\\) denote the probability measure corresponding to the assumption that the objects are equally likely to be placed in any spot, so that the \\(n!\\) possible placements are equally.\nWe have previously considered the case \\(n=4\\) (Example 2.2, Example 2.22, Exercise 2.15). By enumerating the \\(4! = 24\\) possible outcomes (see Table 2.2 and Table 2.9) we found the distribution of \\(X\\) when \\(n=4\\), displayed in Table 3.14 and Figure 3.34. When \\(n=4\\) the probability of at least one match is 0.625, and the expected value of \\(X\\) is 1.\n\n\n\n\nTable 3.14: Distribution of \\(X\\), the number of matches in the matching problem with \\(n=4\\) and uniformly random placement of objects in spots.\n\n\n\n\n\n\nx\nP(X=x)\n\n\n\n\n0\n0.3750\n\n\n1\n0.3333\n\n\n2\n0.2500\n\n\n4\n0.0417\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.34: Distribution of \\(X\\), the number of matches in the matching problem with \\(n=4\\) and uniformly random placement of objects in spots.\n\n\n\n\n\nWhen \\(n=4\\) we could enumerate the \\(4!=24\\) possible outcomes, but such a strategy is not feasible for a general \\(n\\). For example, if \\(n=60\\) then there are \\(60! \\approx 10^{82}\\) possible outcomes, which is about the total number of atoms in the observable universe. Therefore we need other strategies to investigate the problem.\nWe’ll use simulation to perform a sensitivity analysis to investigate how the distribution of \\(X\\), the probability of at least one match, and the expected value of \\(X\\) depend on \\(n\\).\n\n\n\n\n\n\nWarning\n\n\n\nThis is not really a warning but before proceeding, stop to think: what do you expect? How do you expect the probability of at least one match to depend on \\(n\\)? Will the probability increase, decrease, or stay about the same as \\(n\\) gets larger? What about the expected value of the number of matches? It’s always a good idea to think about a problem and make some initial guesses before just jumping into calculations or simulations.\n\n\n\n\n\n\n\n\n\nExample 3.29 For the matching problem for a given \\(n\\), describe in detail how you would use simulation to approximate:\n\nThe distribution of \\(X\\)\n\\(\\textrm{P}(X \\ge 1)\\)\n\\(\\textrm{E}(X)\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.29. We could use a box model.\n\nThe box has \\(n\\) tickets, labeled \\(1, 2, \\ldots, n\\), one for each object.\nAn outcome is simulated by selecting \\(n\\) tickets from the box without replacement and recording their order, e.g., (2, 1, 3, 4) if \\(n=4\\).\nLet \\(x\\) be the number of matches for the simulated outcome, e.g., \\(x=2\\) for outcome (2, 1, 3, 4).\nThe above two steps consist of one repetition, yielding one realized value of the random variable \\(X\\).\nRepeat these steps many times to obtain many simulated values of \\(X\\).\n\n\nSummarize the simulated values of \\(X\\) and their relative frequencies to approximate the distribution of \\(X\\).\nCount the number of repetitions on which \\(X\\ge 1\\) and divide by the total number of repetitions to approximate \\(\\textrm{P}(X\\ge 1)\\), the probability of at least one match.\nWe have seen that an expected value can be interpreted as a long run average value. To approximate \\(\\textrm{E}(X)\\), compute the average of the many simulated \\(X\\) values—sum all simulated \\(X\\) values and divide by the number of simulated \\(X\\) values.\n\n\n\n\n\nWe’ll start by coding a simulation for \\(n=4\\) so we can compare our simulation results to the analytical results to check that our simulation process is working correctly. Since Python uses zero-based indexing, we label the objects \\(0, 1, \\ldots, n-1\\).\n\nn = 4\n\nlabels = list(range(n)) # list of labels [0, ..., n-1]\nlabels\n\n[0, 1, 2, 3]\n\n\nNow we define the box model and simulate a few outcomes. Note that replace = False.\n\nP = BoxModel(labels, size = n, replace = False)\n\nP.sim(5)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(3, 0, 2, 1)\n        \n        \n        \n          1(2, 0, 3, 1)\n        \n        \n        \n          2(0, 1, 3, 2)\n        \n        \n        \n          3(3, 0, 2, 1)\n        \n        \n        \n          4(3, 0, 1, 2)\n        \n        \n      \n    \n\n\nWe simulate many outcomes to check that they are roughly equally likely.\n\nP.sim(24000).tabulate()\n\n\n  \n    Outcome\n    Frequency\n  \n  \n    (0, 1, 2, 3)984(0, 1, 3, 2)970(0, 2, 1, 3)1058(0, 2, 3, 1)936(0, 3, 1, 2)985(0, 3, 2, 1)988(1, 0, 2, 3)1030(1, 0, 3, 2)984(1, 2, 0, 3)1039(1, 2, 3, 0)997(1, 3, 0, 2)994(1, 3, 2, 0)940(2, 0, 1, 3)1010(2, 0, 3, 1)977(2, 1, 0, 3)1013(2, 1, 3, 0)1009(2, 3, 0, 1)1032(2, 3, 1, 0)1023(3, 0, 1, 2)1013......(3, 2, 1, 0)1020Total24000\n  \n\n\n\nRemember that a random variable \\(X\\) is a function whose inputs are the sample space outcomes. In this example the function “counts matches”, so would like to define \\(X\\) as X = RV(P, count_matches). Unfortunately, such a function isn’t built in like sum or max, but we can write a custom count_matches Python function. The count_matches function below starts a counter at 0 and then goes spot-by-spot through each spot in the outcome and increments the counter by 1 any time there is a match (along the lines of the discussion in Section 2.3.4). Don’t worry too much about the Python syntax yet. What’s important is that we have defined a function that we can use to define a random variable.\n\ndef count_matches(outcome):\n    count = 0\n    for i in range(0, n, 1):\n        if outcome[i] == labels[i]:\n            count += 1\n    return count\n  \noutcome = (1, 0, 2, 3) # an example outcome, with 2 matches\ncount_matches(outcome) # the function evaluated for the example outcome\n\n2\n\n\nNow we can use the function count_matches to define a Symbulate RV just like we have used sum or max.\n\nX = RV(P, count_matches)\n\nX((1, 0, 2, 3)) # evaluate X for the sample outcome\n\nWarning: Calling an RV as a function simply applies the function that defines the RV to the input, regardless of whether that input is a possible outcome in the underlying probability space.\n2\n\n\nWe can simulate many values of \\(X\\) and use the simulated values to approximate the distribution of \\(X\\), the probability of at least one match, and the expected value of \\(X\\).\n\nx = X.sim(10000)\n\nx.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    00.365510.334220.258540.0418Total1.0\n  \n\n\n\n\nx.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nx.count_geq(1) / x.count()\n\n0.6345\n\n\n\nx.sum() / x.count()\n\n1.0184\n\n\nThe simulated distribution of \\(X\\) is close to the true distribution in Table 3.14 when \\(n=4\\); the simulated relative frequencies are within the margin of error (about 0.01-0.02 for 10000 simulated values) of the true probabilities. We also see that the average of the simulated \\(X\\) values is around the theoretical expected value of 1.\nIt appears that our simulation is working properly for \\(n=4\\). To investigate a different value of \\(n\\), we simply need to revise the line n = 4. Because we want to investigate many values of \\(n\\), we wrap all the above code in a Python function matching_sim which takes n as an input40 and outputs our objects of interest: a plot of the distribution of simulated \\(X\\) values, the approximation of \\(\\textrm{P}(X \\ge 1)\\), and the approximation of \\(\\textrm{E}(X)\\).\n\n\ndef matching_sim(n):\n  \n    labels = list(range(n))\n    \n    def count_matches(omega):\n        count = 0\n        for i in range(0, n, 1):\n            if omega[i] == labels[i]:\n                count += 1\n        return count\n    \n    P = BoxModel(labels, size = n, replace = False)\n    X = RV(P, count_matches)\n    \n    x = X.sim(10000)\n    \n    plt.figure()\n    x.plot('impulse')\n    plt.show()\n    \n    return x.count_geq(1) / x.count(), x.sum() / x.count()\n\nFor example, for \\(n=4\\) we simply call\n\nmatching_sim(4)\n\n(0.628, 1.0118)\n\n\n\n\n\n\n\n\n\nNow we can easily investigate different values of \\(n\\). For example, for \\(n=10\\) we see that the approximate probability of at least one match is around 0.63 and the approximate expected value of the number of matches is around 1.\n\nmatching_sim(10)\n\n(0.6309, 0.9879)\n\n\n\n\n\n\n\n\n\nWe can use a for loop to automate the process of changing the value of \\(n\\), running the simulation, and recording the results. If ns is the list of \\(n\\) values of interest we basically just need to run\n\nfor n in ns:\n    matching_sim(n)\n\nIn Python we can also use list comprehension\n\n[matching_sim(n) for n in ns]\n\nThe table below summarizes the simulation results for \\(n=4, \\ldots, 10\\). The first line defines the values of \\(n\\), and the second line implements the for loop. We have used the Python package tabulate to add a little formatting to the table. (Don’t confuse this with the Symbulate tabulate method!) Note that we have temporarily redefined matching_sim to remove the lines that produced the plot, but we have not displayed the revised code here. (We will bring the plot back soon.)\n\nfrom tabulate import tabulate \n\n\nns = list(range(4, 11, 1))\n\nresults = [matching_sim(n) for n in ns]\n\nprint(tabulate({'n': ns,\n                'Approximate P(X &gt;= 1), Approximate E(X)': results},\n               headers = 'keys', floatfmt=\".3f\"))\n\n  n  Approximate P(X &gt;= 1), Approximate E(X)\n---  -----------------------------------------\n  4  (0.6358, 1.0177)\n  5  (0.6352, 1.0014)\n  6  (0.6328, 1.0146)\n  7  (0.6345, 1.0176)\n  8  (0.6338, 1.0008)\n  9  (0.6272, 0.9939)\n 10  (0.6273, 0.9859)\n\n\nStop and look at the table; what do you notice? How do the probability of at least one match and the expected value of the number of matches depend on \\(n\\)? They don’t! Well, maybe they do, but they don’t appear to change very much with \\(n\\) after we take into account simulation margin of error41 of about 0.01-0.02. It appears that regardless of the value of \\(n\\), the probability of at least one match is around 0.63 and the expected value of the number of matches is around 1.\nIf we’re interested in more values of \\(n\\), we just repeat the same process with a longer list of ns. The code below uses the Python package Matplotlib to create a plot of the probability of at least one match and the expected value of the number of matches versus \\(n\\). While there is some natural simulation variability, we see that the probability of at least one match (about 0.63) and the expected value of the number of matches (about 1) essentially do not depend on \\(n\\)!\n\nfrom matplotlib import pyplot as plt\n\n\nns = list(range(4, 101, 1))\n\nresults = [matching_sim(n) for n in ns]\n\nplt.figure()\nplt.plot(ns, results)\nplt.legend(['Approximate E(X)', 'Approximate P(X &gt;= 1)'])\nplt.xlabel('n')\nplt.ylabel('value')\nplt.show()\n\n\n\n\n\n\n\n\nWhat about the distribution of \\(X\\)? This Colab notebook contains code for investigating how the distribution of \\(X\\) depends on \\(n\\). The basic simulation code is identical to what we have already seen. The notebook adds a few lines to create a Jupyter widget, which produces an interactive plot (with some additional formatting) of the distribution; you can change the slider to see how the distribution of \\(X\\) changes with \\(n\\). Take a few minutes to play with the slider; what do you see?\nYou should see that unless \\(n\\) is really small (like 5 or less) the distribution of \\(X\\) is basically the same for any value of \\(n\\)! We will see soon that the number of matches follows, approximately, a “Poisson(1)” distribution, regardless of the value of \\(n\\) (unless \\(n\\) is really small). In particular, the probability of 0 matches is approximately equal to 0.37, and also approximately equal to the probability of exactly 1 match.\n\n\n\n\nTable 3.15: Approximate distribution of \\(X\\), the number of matches in the matching problem for general \\(n\\) and uniformly random placement of objects in spots.\n\n\n\n\n\n\nx\nP(X=x)\n\n\n\n\n0\n0.3679\n\n\n1\n0.3679\n\n\n2\n0.1839\n\n\n3\n0.0613\n\n\n4\n0.0153\n\n\n5\n0.0031\n\n\n6\n0.0005\n\n\n7\n0.0001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.35: Approximate distribution of \\(X\\), the number of matches in the matching problem for general \\(n\\) and uniformly random placement of objects in spots.\n\n\n\n\n\nSummarizing, our sensitivity analysis42 of the matching problem reveals that, unless \\(n\\) is really small,\n\nthe probability of at least one match does is approximately 0.632\nthe expected value—that is, long run average— of the number of matches is approximately 1\nthe distribution of the number of matches is approximately the “Poisson(1)” distribution.\n\nWe will investigate these observations further later. For now, marvel at the fact that no matter if there are 10 or 100 or 1000 people in you next Secret Santa gift exchange, it’s roughly 2 to 1 odds in favor of somebody drawing their own name!\n\n3.13.1 Exercises\n\nExercise 3.28 Katniss throws a dart at a circular dartboard with radius 12 inches. Suppose that the dartboard is on a coordinate plane, with the center of the dartboard at (0, 0) and the north, south, east, and west edges, respectively, at coordinates (0, 12), (0,-12), (12, 0), (-12, 0). When the dart hits the board its \\((X, Y)\\) coordinates are recorded.\nAssume that \\(X\\) and \\(Y\\) each follow a Normal(0, \\(\\sigma\\)), independently. Note that it is possible for the dart to land off the board. Let \\(R\\) be the distance (inches) from the location of the dart to the center of the dartboard.\nCombine Symbulate and Python code to perform a sensivity analysis of how the following depend on \\(\\sigma\\) (for say values of \\(\\sigma&lt;5\\)):\n\n\\(\\textrm{P}(R &lt; 1)\\)\n\\(\\textrm{P}(R &gt; 12)\\)\n\\(\\textrm{E}(R)\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#simulating-from-distributions",
    "href": "language-simulation.html#simulating-from-distributions",
    "title": "3  The Language of Simulation",
    "section": "3.14 Simulating from distributions",
    "text": "3.14 Simulating from distributions\nThe distribution of a random variable specifies the long run pattern of variation of values of the random variable over many repetitions of the underlying random phenomenon, or the relative degree of likelihood of possible values. The distribution of a random variable \\(X\\) can be approximated by\n\nsimulating an outcome of the underlying random phenomenon \\(\\omega\\) according to the assumptions encoded in the probability measure \\(\\textrm{P}\\)\nobserving the value of the random variable for that outcome \\(X(\\omega)\\)\nrepeating this process many times\nthen computing relative frequencies involving the simulated values of the random variable to approximate probabilities of events involving the random variable, e.g., \\(\\textrm{P}(X\\le x)\\).\n\nWe have carried out this process for several examples, including the dice rolling example in Section 3.1 and Section 3.3, where each repetition involved simulating a pair of rolls (outcome \\(\\omega\\)) and then finding the sum (\\(X(\\omega)\\)) and max (\\(Y(\\omega)\\)).\nNow we’ll discuss another method for simulating values of a random variable.\n\n\n\n\n\n\n\nExample 3.30 Recall Example 2.41, Table 2.14, and Table 2.15.\n\nConstruct a spinner to represent the marginal distribution of \\(X\\).\nHow could you use the spinner from the previous part to simulate a value of \\(X\\)?\nConstruct a spinner to represent the marginal distribution of \\(Y\\).\nHow could you use the spinner from the previous part to simulate a value of \\(Y\\)?\nDonny Don’t says: “Great! I can simulate an \\((X, Y)\\) pair just by spinning the spinner in Figure 3.36 (a) to generate \\(X\\) and the one in Figure 3.36 (b) to generate \\(Y\\).” Is Donny correct? If not, can you help him see why not?\nConstruct a single spinner for simulating \\((X, Y)\\) pairs with the proper joint distribution.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.30. \n\nThe spinner in Figure 3.36 (a) represents the marginal distribution of \\(X\\) in Table 2.14.\nJust spin it! The spinner returns the possible values of \\(X\\) according to the proper probabilities. If we’re interested in simulating the sum of two rolls of a fair four-sided dice, we don’t have to roll the dice; we can just spin the \\(X\\) spinner once.\nThe spinner in Figure 3.36 (b) represents the marginal distribution of \\(Y\\) in Table 2.15.\nJust spin it! The spinner returns the possible values of \\(Y\\) according to the proper probabilities. If we’re interested in simulating the larger of two rolls of a fair four-sided dice, we don’t have to roll the dice; we can just spin the \\(Y\\) spinner once.\nDonny is incorrect. Yes, spinning the \\(X\\) spinner in Figure 3.36 (a) will generate values of \\(X\\) according to the proper marginal distribution, and similarly with Figure 3.36 (b) and \\(Y\\). However, spinning each of the spinners will not produce \\((X, Y)\\) pairs with the correct joint distribution. For example, Donny’s method could produce \\(X=2\\) and \\(Y=4\\), which is not a possible \\((X, Y)\\) pair. Donny’s method treats the values of \\(X\\) and \\(Y\\) as if they were independent; the result of the \\(X\\) spin would not change what could happen with the \\(Y\\) spin (since the spins are physically independent). However, the \\(X\\) and \\(Y\\) values are related. For example, if \\(X=2\\) then \\(Y\\) must be 1; if \\(X=4\\) then \\(Y\\) must be 2 or 3; etc.\nSee the spinner in Figure 3.36 (c) which would properly simulate \\((X, Y)\\) pairs according to the joint distribution.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) The marginal distribution of \\(X\\); see Table 2.14\n\n\n\n\n\n\n\n\n\n\n\n(b) The marginal distribution of \\(Y\\); see Table 2.15\n\n\n\n\n\n\n\n\n\n\n\n(c) The joint distribution of \\(X\\) and \\(Y\\); see Table 2.17\n\n\n\n\n\n\n\nFigure 3.36: Spinners representing the distributions of \\(X\\) and \\(Y\\) in Example 2.41\n\n\n\nIn principle, there are always two ways of simulating a value \\(x\\) of a random variable \\(X\\).\n\nSimulate from the probability space. Simulate an outcome \\(\\omega\\) from the underlying probability space and set \\(x = X(\\omega)\\).\nSimulate from the distribution. Simulate a value \\(x\\) directly from the distribution of \\(X\\).\n\nThe “simulate from the distribution” method corresponds to constructing a spinner representing the distribution of \\(X\\) and spinning it once to generate \\(x\\).\n\n\n\n\n\n\n\nExample 3.31 Donny Don’t says: “The ‘simulate from the distribution’ method is dumb. In order to use it, I first need to know the distribution. But the whole point of simulation is to approximate a distribution. If I know the distribution, why do I need to approximate it?” How would you respond to Donny? Hint: it might help to consider the brown bag analogy in Section 2.3.2. It might also help to consider how we use simulation in the meeting problem in this chapter.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.31. Yes, this method does require that the distribution of \\(X\\) is known. However, in many situations we assume a distribution for a random variable directly, without specifying the underlying probability space. This is what we did in the meeting problem whenever we assumed a Uniform(0, 60) or Normal(30, 10) distribution for arrival times. Even Donny himself tried to implement the simulate from the distribution method in Example 3.24.\n\n\n\n\nIn many problems we often assume or identify distributions directly, without any mention of the underlying sample space or probability measure. Recall the brown bag analogy in Section 2.3.2. The probability space corresponds to the random selection of fruits to put in the bag. The random variable is weight. The distribution of weight can be obtained by randomly selecting fruits to put in the bag, weighing the bag, and then repeating this process many times to observe many weights. For example, maybe 10% of bags have weights less than 5 pounds, 75% of bags have weights less than 20 pounds, etc. We can observe the distribution of weights even if we don’t observe the actual fruits in the bag or fully specify the random phenomenon and its sample space.\n\n\n\n\n\n\n\nExample 3.32 In Section 3.3 we saw the Symbulate code for the “simulate from the probability space” method in the dice rolling example. Now we consider the “simulate from the distribution method”.\n\nWrite the Symbulate code to define \\(X\\) by specifying its marginal distribution.\nWrite the Symbulate code to define \\(Y\\) by specifying its marginal distribution.\nCan the code from the previous parts be combined to simulate \\((X, Y)\\) pairs?\nWrite the simulate code to define \\((X, Y)\\) by specifying the joint distribution.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.32. \n\nWe simulate a value of \\(X\\) from its marginal distribution by spinning the spinner in Figure 3.36 (a), which we can define via a BoxModel\nSimilarly, we simulate a value of \\(Y\\) from its marginal distribution by spinning the spinner in Figure 3.36 (b), which we can define via a BoxModel\nNo. The previous parts only define the marginal distributions, and marginal distributions alone do not define the joint distribution.\nWe simulate an \\((X, Y)\\) pair from its joint distribution by spinning the spinner in Figure 3.36 (c), which we can define via a BoxModel whose tickets represent pairs.\n\n\n\n\n\nWe can define a BoxModel corresponding to each of the spinners in Figure 3.36, and then define a random variable with that distribution via RV(BoxModel(...)). Essentially, we define the random variable by specifying its distribution (spinner), rather than specifying the underlying probability space. Note that the default size argument in BoxModel is size = 1, so we have omitted it.\n\nX = RV(BoxModel([2, 3, 4, 5, 6, 7, 8], probs = [1 / 16, 2 / 16, 3 / 16, 4 / 16, 3 / 16, 2 / 16, 1 / 16]))\n\nx = X.sim(10000)\n\n\nx.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    20.065130.127940.183950.253760.181970.125580.062Total1.0\n  \n\n\n\n\nx.plot()\n\n\n\n\n\n\n\n\n\n\nSimilarly we can define \\(Y\\) as\n\nY = RV(BoxModel([1, 2, 3, 4], probs = [1 / 16, 3 / 16, 5 / 16, 7 / 16]))\n\nTo simulate \\((X, Y)\\) pairs we need to specify the joint distribution.\n\nxy_pairs = [(2, 1), (3, 2), (4, 2), (4, 3), (5, 3), (5, 4), (6, 3), (6, 4), (7, 4), (8, 4)]\n\npxy = [1/16, 2/16, 1/16, 2/16, 2/16, 2/16, 1/16, 2/16, 2/16, 1/16]\n\nX, Y = RV(BoxModel(xy_pairs, probs = pxy, size = 1))\n\n(X & Y).sim(10000).tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    (2, 1)0.0601(3, 2)0.125(4, 2)0.0613(4, 3)0.1236(5, 3)0.1249(5, 4)0.1212(6, 3)0.0627(6, 4)0.1258(7, 4)0.1275(8, 4)0.0679Total1.0\n  \n\n\n\nBoxModel with the probs option can be used to define general discrete distributions (when there are finitely many possible values). Many commonly encountered distributions have special names, and in Symbulate we can define a random variable to have a specific named distribution through code of the form RV(Distribution(parameters)); for example X = RV(Uniform(0, 60)) or X = RV(Normal(30, 10)). Think of code like X = RV(Normal(30, 10)) as “\\(X\\) is a random variable with a Normal(30, 10) distributon”.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#sec-rv-versus-distribution",
    "href": "language-simulation.html#sec-rv-versus-distribution",
    "title": "3  The Language of Simulation",
    "section": "3.15 Do not confuse a random variable with its distribution",
    "text": "3.15 Do not confuse a random variable with its distribution\nWe close this chapter with a warning.\n\n\n\n\n\n\nWarning\n\n\n\nDo not confuse a random variable with its distribution.\n\n\nA random variable measures a numerical quantity which depends on the outcome of a random phenomenon. The distribution of a random variable specifies the long run pattern of variation of values of the random variable over many repetitions of the underlying random phenomenon43. The distribution of a random variable can be approximated by simulating an outcome of the random process, observing the value of the random variable for that outcome, repeating this process many times, and summarizing the results. But a random variable is not its distribution.\nRecall the brown bag analogy in Section 2.3.2. The probability space corresponds to the random selection of fruits to put in the bag. The random variable is weight. The distribution of weight can be obtained by randomly selecting fruits to put in the bag, weighing the bag, and then repeating this process many times to observe many weights, summarize the values, and describe the pattern of variability (e.g., 10% of bags have weights less than 5 pounds, 75% of bags have weights less than 20 pounds, etc). But the random variable is like the scale itself.\nA distribution is determined by:\n\nThe underlying probability measure \\(\\textrm{P}\\), which represents all the assumptions about the random phenomenon.\nThe random variable \\(X\\) itself, that is, the function which maps sample space outcomes to numbers.\n\nChanging either the probability measure or the random variable itself can change the distribution of the random variable. For example, consider the sample space of two rolls of a fair four-sided die. In each of the following scenarios, the random variable \\(X\\) has a different distribution.\n\nThe die is fair and \\(X\\) is the sum of the two rolls\nThe die is fair and \\(X\\) is the larger of the two rolls\nThe die is weighted to land on 1 with probability 0.1 and 4 with probability 0.4 and \\(X\\) is the sum of the two rolls.\n\nIn particular,\n\n\\(X\\) takes the value 2 with probability \\(1/16\\)\n\\(X\\) takes the value 2 with probability \\(3/16\\)\n\\(X\\) takes the value 2 with probability 0.01.\n\nIn (1) and (2), the probability measure is the same (fair die) but the function defining the random variable is different (sum versus max). In (1) and (3), the function defining the random variable is the same, and the sample space of outcomes is the same, but the probability measure is different.\nWe often specify the distribution of a random variable directly without explicit mention of the underlying probability space or function defining the random variable. For example, in the meeting problem we might assume that arrival times follow a Uniform(0, 60) or a Normal(30, 10) distribution. In situations like this, you can think of the probability space as being the distribution of the random variable and the function defining the random variable to be the identity function. In other words, we construct a spinner to represent the distribution of the random variable and spin it to simulate a value of the random variable.\n\n\n\n\n\n\n\nExample 3.33 Donny Dont is thoroughly confused about the distinction between a random variable and its distribution. Help him understand by by providing a simple concrete example of two different random variables \\(X\\) and \\(Y\\) that have the same distribution. Can you think of \\(X\\) and \\(Y\\) for which \\(\\textrm{P}(X = Y) = 0\\)? How about a discrete example and a continuous example?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.33. Roll two fair four-sided dice and let \\(U_1\\) be the result of the first roll and \\(U_2\\) the result of the second roll. Then \\(U_1\\) and \\(U_2\\) have the same distribution; each takes values 1, 2, 3, 4 with equal probability. However, these are two different random variables; one measure the first roll and one measure the second. If the first roll is 4 and the second roll is 3, then \\(U_1=4\\) and \\(U_2=3\\), which are not the same.\nAnother discrete example: Flip a fair coin 3 times and let \\(X\\) be the number of heads and \\(Y\\) be the number of tails. Then \\(X\\) and \\(Y\\) have the same distribution, because the coin is fair, roughly heads and tails would have the same long run pattern of variability. (In this case each of \\(X\\) and \\(Y\\) takes values 0, 1, 2, 3 with probability 1/8, 3/8, 3/8, 1/8.) But \\(X\\) and \\(Y\\) are not the same random variable; they are measuring different things. If the outcome is HHT then \\(X\\) is 2 but \\(Y\\) is 1. In this case \\(\\textrm{P}(X = Y)=0\\); in an odd number of flips it’s not possible to have the same number of heads and tails on any single outcome.\nA continuous example follows.\n\n\n\n\nIn some cases of the meeting time problem we assumed the distribution of Regina’s arrival time \\(R\\) is Uniform(0, 60) and the distribution of Cady’s arrival time \\(Y\\) is Uniform(0, 60), in which case \\(R\\) and \\(Y\\) have the same distribution. But these are two random variables; one measures Regina’s arrival time and one measure Cady’s. If Regina and Cady met every day for a year, then the day-to-day pattern of Regina’s arrival times would look like the day-to-day pattern of Cady’s arrival times. But on any given day, their arrival times would not be the same, since \\(R\\) and \\(Y\\) are continuous random variables so \\(\\textrm{P}(R = Y) = 0\\).\nA distribution, like a spinner, is a blueprint for simulating values of the random variable. If two random variables have the same distribution, you could use the same spinner to simulate values of either random variable. But a distribution is not the random variable itself.\nTwo random variables can have the same (long run) distribution, even if the values of the two random variables are never equal on any particular repetition (outcome). If \\(X\\) and \\(Y\\) have the same distribution, then the spinner used to simulate \\(X\\) values can also be used to simulate \\(Y\\) values; in the long run the patterns would be the same.\nAt the other extreme, two random variables \\(X\\) and \\(Y\\) are the same random variable only if for every outcome of the random phenomenon the resulting values of \\(X\\) and \\(Y\\) are the same. That is, \\(X\\) and \\(Y\\) are the same random variable only if they are the same function: \\(X(\\omega)=Y(\\omega)\\) for all \\(\\omega\\in\\Omega\\). It is possible to have two random variables for which \\(\\textrm{P}(X=Y)\\) is large, but \\(X\\) and \\(Y\\) have different distributions.\n\n\n\n\n\n\n\nExample 3.34 Explain why each of the following random variables has the same distribution.\n\n\\(X\\) is the number of Tails in three flips of a fair coin\n\\(Y\\) is the number of Tails in three flips of a fair coin\n\\(Z\\) is the number of even numbers rolled in three rolls of a fair six-sided die\n\\(W\\) is the number of females in three human births, selected randomly and independently, assuming males and females are equally likely44\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.34. Each of these situations involves a different sample space of outcomes (coins, dice, births) with a random variable which counts different things (Heads, Tails, evens, boys). But all the scenarios have some general features in common:\n\nThere are 3 “trials” (3 flips, 3 rolls, 3 babies)\nEach trial can be classified as “success”45 (Tails, even, female) or not.\nEach trial is equally likely to result in success or not (fair coin, fair die, assuming boys and girls are equally likely)\nThe trials are independent. For coins and dice the trials are physically independent. For births independence follows from random selection from a large population.\nThe random variable counts the number of successes in the 3 trials (number of H, number of T, number of even rolls, number of female babies).\n\nEach situation can be simulated by putting 2 tickets in a box labeled success or not, drawing 3 tickets with replacement, counting the number of successes drawn, and repeating many times. All of these scenarios are probabilitistically the same, so each random variable would have the same long run pattern of variability.\n\n\n\n\nMany commonly encountered distributions have special names. For example, the common distribution in Example 3.34 is called the “Binomial(3, 0.5)” distribution. If a random variable has a Binomial(3, 0.5) distribution then it takes the possible values 0, 1, 2, 3, with respective probability 1/8, 3/8, 3/8, 1/8. (We will study Binomial distributions in more detail later.)\nExample 3.34 illustrates that knowledge that a random variable has a specific distribution (e.g., Binomial(3, 0.5)) does not necessarily convey any information about the underlying outcomes or random variable (function) being measured.\nThe scenarios involving \\(W, X, Y, Z\\) in Example 3.34 illustrate that two random variables do not have to be defined on the same sample space in order to determine if they have the same distribution. This is in contrast to computing quantities like \\(\\textrm{P}(X=Y)\\): \\(\\{X=Y\\}\\) is an event which cannot be investigated unless \\(X\\) and \\(Y\\) are defined for the same outcomes. For example, you could not estimate the probability that a student has the same score on both SAT Math and Reading exams unless you measured pairs of scores for each student in a sample. However, you could collect SAT Math scores for one set of students to estimate the marginal distribution of Math scores, and collect Reading scores for a separate set of students to estimate the marginal distribution of Reading scores, and see if those two marginal distributions are the same.\n\n\n\n\n\n\n\nExample 3.35 Suppose that \\(X\\), \\(Y\\), and \\(Z\\) all have the same distribution. Donny Dont says\n\nThe pair \\((X, Y)\\) has the same joint distribution as the pair \\((X, Z)\\).\n\\(X+Y\\) has the same distribution as \\(X+Z\\).\n\\(X+Y\\) has the same distribution as \\(X+X=2X\\).\n\nDetermine if each of Donny’s statements is correct. If not, explain why not using a simple example (say a coin flipping situation).\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.35. First of all, Donny’s statements wouldn’t even make sense unless the random variables were all defined on the same probability space. For example, if \\(X\\) is SAT Math score and \\(Y\\) is SAT reading score it doesn’t makes sense to consider \\(X+Y\\) unless \\((X, Y)\\) pairs are measured for the same students. But even assuming the random variables are defined on the same probability space, we can find counterexamples to Donny’s statements.\nAs just one example, flip a fair coin 4 times and let\n\n\\(X\\) be the number of heads in flips 1 through 3\n\\(Y\\) be the number of tails in flips 1 through 3\n\\(Z\\) be the number of heads in flips 2 through 4.\n\n\nThe joint distribution of \\((X, Y)\\) is not the same as the joint distribution of \\((X, Z)\\). For example, \\((X, Y)\\) takes the pair \\((3, 3)\\) with probability 0, but \\((X, Z)\\) takes the pair \\((3, 3)\\) with nonzero probability (1/16).\nThe distribution of \\(X+Y\\) is not the same as the distribution of \\(X+Z\\); \\(X+Y\\) is 3 with probability 1, but the probability that \\(X+Z\\) is 3 is less than 1 (4/16).\nThe distribution of \\(X+Y\\) is not the same as the distribution of \\(2X\\); \\(X+Y\\) is 3 with probability 1, but \\(2X\\) takes values 0, 2, 4, 6 with nonzero probability.\n\n\n\n\n\nRemember that a joint distribution is a probability distribution on pairs of values. Just because \\(X_1\\) and \\(X_2\\) have the same marginal distribution, and \\(Y_1\\) and \\(Y_2\\) have the same marginal distribution, doesn’t necessary imply that \\((X_1, Y_1)\\) and \\((X_2, Y_2)\\) have the same joint distributions. In general, information about the marginal distributions alone is not enough to determine information about the joint distribution. Comparing Example 2.41 and Example 2.43 provides another example of two scenarios with the same marginal distributions but different joint distributions.\nThe distribution of any random variable obtained via a transformation of multiple random variables will depend on the joint distribution of the random variables involved; for example, the distribution of \\(X+Y\\) depends on the joint distribution of \\(X\\) and \\(Y\\).\n\n\n\n\n\n\n\nExample 3.36 Spin the Uniform(0, 1) spinner (see Figure 2.1) twice and let \\(U_1\\) be the result of the first spin and \\(U_2\\) the result of the second. For each of the following pairs of random variables, determine whether or not they have the same distribution as each other. No calculations necessary; just think conceptually.\n\n\\(U_1\\) and \\(U_2\\)\n\\(U_1\\) and \\(1-U_1\\)\n\\(U_1\\) and \\(1+U_1\\)\n\\(U_1\\) and \\(U_1^2\\)\n\\(U_1+U_2\\) and \\(2U_1\\)\n\\(U_1\\) and \\(1-U_2\\)\nIs the joint distribution of \\((U_1, 1-U_1)\\) the same as the joint distribution of \\((U_1, 1 - U_2)\\)?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 3.36. \n\nYes, each has a Uniform(0, 1) distribution.\nYes, each has a Uniform(0, 1) distribution. For \\(u\\in[0, 1]\\), \\(1-u\\in[0, 1]\\), so \\(U_1\\) and \\(1-U_1\\) have the same possible values, and a linear rescaling does not change the shape of the distribution. Changing from \\(U_1\\) to \\(1-U_1\\) essentially amounts to switching the [0, 1] labels on the spinner from clockwise to counterclockwise.\nNo, the two variables do not have the same possible values. The shapes would be similar though; \\(1+U_1\\) has a Uniform(1, 2) distribution.\nNo, a non-linear rescaling generally changes the shape of the distribution. For example, \\(\\textrm{P}(U_1\\le0.49) = 0.49\\), but \\(\\textrm{P}(U_1^2 \\le 0.49) = \\textrm{P}(U_1 \\le 0.7) = 0.7\\) Squaring a number in [0, 1] makes the number even smaller, so the distribution of \\(U_1^2\\) places higher density on smaller values than \\(U_1\\) does.\nNo, \\(U_1+U_2\\) has a triangular shaped distribution on (0, 2) with a peak at 1. (The shape is similar to that of the distribution of \\(X\\) in ?sec-sim-transform-joint), but the possible values are (0, 2) rather than (2, 8).) But \\(2U_1\\) has a Uniform(0, 2) distribution. Do not confuse a random variable with its distribution. Just because \\(U_1\\) and \\(U_2\\) have the same distribution, you cannot replace \\(U_2\\) with \\(U_1\\) in transformations. The random variable \\(U_1+U_2\\) is not the same random variable as \\(2U_1\\); spinning a spinner and adding the spins will not necessarily produce the same value as spinner a spinner once and multiplying the value by 2.\nYes, just like \\(U_1\\) and \\(1-U_2\\) have the same distribution.\nNo. The marginal distributions are the same, but the joint distribution of \\((U_1, 1-U_1)\\) places all density along a line, while the joint density of \\((U_1, 1-U_2)\\) is distributed over the whole two-dimensional region \\([0, 1]\\times[0,1]\\).\n\n\n\n\n\nDo not confuse a random variable with its distribution. This is probably getting repetitive by now, but we’re emphasizing this point for a reason. Many common mistakes in probability problems involve confusing a random variable with its distribution. For example, we will soon that if a continuous random variable \\(X\\) has probability density function \\(f(x)\\), then the probability density function of \\(X^2\\) is NOT \\(f(x^2)\\) nor \\((f(x))^2\\). Mistakes like these, which are very common, essentially involve confusing a random variable with its distribution. Understanding the fundamental difference between a random variable and its distribution will help you avoid many common mistakes, especially in problems involving a lot of calculus or mathematical symbols.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#chapter-exercises",
    "href": "language-simulation.html#chapter-exercises",
    "title": "3  The Language of Simulation",
    "section": "3.16 Chapter exercises",
    "text": "3.16 Chapter exercises\nTBA\n\n\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007. Statistics. 4th ed. W.W. Norton; Company.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-simulation.html#footnotes",
    "href": "language-simulation.html#footnotes",
    "title": "3  The Language of Simulation",
    "section": "",
    "text": "In most situations we’ll encounter in this book, the “set up” step requires the most work and the most computer programming, while the “simulate” and “summarize” steps are usually straightforward. In many other cases, these steps can be challenging. Complex set ups often require sophisticated methods, such MCMC (Markov Chain Monte Carlo) algorithms, to efficiently simulate realizations. Effectively summarizing high dimensional simulation output often requires the use of multivariate statistics and visualizations.↩︎\nOur use of “box models” is inspired by (Freedman, Pisani, and Purves 2007).↩︎\n“With replacement” always implies replacement at a uniformly random point in the box. Think of “with replacement” as “with replacement and reshuffling” before the next draw.↩︎\nIf we’re repeating something many times, do we perform “a simulation” or “many simulations”? Throughout, “a simulation” refers to the collection of results corresponding to repeatedly artificially recreating the random process. “A repetition” refers to a single artificial recreation resulting in a single simulated outcome. We perform a simulation which consists of many repetitions.↩︎\nTechnically, a Normal(30, 10) distribution allows for values outside the [0, 60] interval, but the probability is small, roughly 0.003.↩︎\nWe primarily view a Symbulate probability space as a description of the probability model rather than an explicit specification of the sample space \\(\\Omega\\). For example, we define a BoxModel instead of creating a set with all possible outcomes. We tend to represent a probability space with P, even though this is a slight abuse of notation (since \\(\\textrm{P}\\) typically refers to a probability measure).↩︎\nThe default argument for replace is True, so we could have just written BoxModel([1, 2, 3, 4], size = 2).↩︎\nThere is an additional argument order_matters which defaults to True, but we could set it to False for unordered pairs.↩︎\nWe generally use names in our code that mirror and reinforce standard probability notation, e.g., uppercase letters near the end of the alphabet for random variables, with corresponding lowercase letters for their realized values. Of course, these naming conventions are not necessary and you are welcome to use more descriptive names in your code. For example, we could have named the probability space DiceRolls and the random variables DiceSum and DiceMax rather than P, X, Y. Whatever you do, we encourage you to use names that distinguish the objects themselves from their simulated values, e.g. Dice_Sum for the random variable and dice_sum_sim for the simulated values.↩︎\nTechnically & joins two RVs together to form a random vector. While we often interpret Symbulate RV as “random variable”, it really functions as “random vector”.↩︎\nYou might try (P & X).sim(10). But P is a probability space object, and X is an RV object, and & can only be used to join like objects together. Much like in probability theory in general, in Symbulate the probability space plays a background role, and it is usually random variables we are interested in.↩︎\nThe components of an RV can also be accessed using brackets. U1, U2 = RV(P) is shorthand for\nU = RV(P); U1 = U[0]; U2 = U[1].↩︎\nWe could have actually defined Z = (X - 5) ** 2 here. We’ll see examples where the apply syntax is necessary later.↩︎\nWe can also define U = RV(P) and then X = U.apply(sum).↩︎\nWe can also define U = RV(P) and then X = U.apply(max).↩︎\nBraces {} are used here because this defines a Python dictionary. But don’t confuse this code with set notation.↩︎\nCareful: don’t confuse Uniform(a, b) with DiscreteUniform(a, b). Uniform(a, b) corresponds to the continuous interval \\([a, b]\\).↩︎\nWe would typically only include the values observed in the simulation in the summary. However, we include 4 and 8 here because if we had performed more repetitions we would have observed these values.↩︎\n“Normalize” is used in the sense of Section 1.3 and refers to rescaling the values so that they add up to 1 but the ratios are preserved.↩︎\nFor discrete random variables 'impulse' is the default plot type. Like .tabulate(), the .plot() method also has a normalize argument; the default is normalize=True.↩︎\nIn 10000 flips, the probability of heads on between 49% and 51% of flips is 0.956, so 98 out of 100 provides a rough estimate of this probability. We will see how to compute such a probability later.↩︎\nThis is difficult to see in Figure 3.12 due to the binning. But we can at least tell from Figure 3.12 that at most a handful of the 100 sets resulted in a proportion of heads exactly equal to 0.5.↩︎\nTechnically, we should say “a margin of error for 95% confidence of 0.01”. We’ll discuss “confidence” in a little more detail soon.↩︎\nIn 1,000,000 flips, the probability of heads on between 49.9% and 50.1% of flips is 0.955, and 91 out of 100 sets provides a rough estimate of this probability.↩︎\nIn 100 million flips, the probability of heads on between 49.99% and 50.01% of flips is 0.977, and 96 out of 100 sets provides a rough estimate of this probability.↩︎\nOne difference between RV and apply: apply preserves the type of the input object. That is, if apply is applied to a ProbabilitySpace then the output will be a ProbabilitySpace; if apply is applied to an RV then the output will be an RV. In contrast, RV always creates an RV.↩︎\nUnfortunately, for techincal reasons, RV(P, count_eq(6) / N) will not work. It is possible to divide by N within RV if we define a custom function def rel_freq_six(x): return x.count_eq(6) / N and then define RV(P, rel_freq_six).↩︎\nWe will see the rationale behind this formula later. The factor 2 comes from the fact that for a Normal distribution, about 95% of values are within 2 standard deviations of the mean. Technically, the factor 2 corresponds to 95% confidence only when a single probability is estimated. If multiple probabilities are estimated simultaneously, then alternative methods should be used, e.g., increasing the factor 2 using a Bonferroni correction. For example, a multiple of 4 rather than 2 produces very conservative error bounds for 95% confidence even when many probabilities are being estimated.↩︎\nIn all the situations in this book the repetitions will be simulated independently. However, there are many simulation methods where this is not true, most notably MCMC (Markov Chain Monte Carlo) methods. The margin of error needs to be adjusted to reflect any dependence between simulated values.↩︎\nSee the footnotes in Section 1.2.1.↩︎\nIt can be shown that the standard deviation is always at least as big as the average absolute deviation. For a Normal distribution, the average absolute deviation is about 0.8 times the standard deviation.↩︎\nIf you have some familiarity with statistics, you might have seen a formula for variance or standard deviation that includes dividing by one less than the number values (\\(n-1\\)). Dividing by \\(n\\) or \\(n-1\\) could make a difference in a small sample of data. However, we will always be interested in long run averages, and it typically won’t make any practical difference whether we divide by say 10000 or 9999. We’ll always compute averages by dividing by the number of values that we’re summing.↩︎\nThink Pythagorean theorem: it’s \\(a^2+b^2=c^2\\). On the other hand, for absolute values we only have the triangle inequality \\(|a+b| \\le |a| + |b|\\).↩︎\nAll of our simulations are based on independently simulated repetitions. More sophisticated methods, such as Markov chain Monte Carlo (MCMC) methods, allow dependent repetitions and can approximate conditional probabilities much more efficiently.↩︎\nAge_Snapchat is a pair so Age_Snapchat[0] is the first component (Age) and Age_Snapchat[1] is the second component (Snapchat user).↩︎\nIn Symbulate, events being conditioned on need to be based on RVs. But the code shows that Symbulate has a pretty broad interpretation of what can be an RV.↩︎\n.draw() is like .sim(1) but they have different properties. We will usually work with .sim() to actually run a simulation. .draw() is useful in situations like this where we have to build a custom probability space from scratch.↩︎\nPython automatically treats True as 1 and False as 0, so the code (y &lt; 3) effectively returns both True/False realizations of the event itself and 1/0 realizations of the corresponding indicator random variable.↩︎\nWe wrote this code to compare to the previous block that returned an error. Even though the revised code works, it’s clunky because we unpack the rolls and then rejoin them in random variable world and then unpack them again in simulation world. We could simplify a little by not unpacking and rejoining in random variable variable world, using U = RV(P); u1_and_u2 = U.sim(10). This still isn’t the preferred way to sum the rolls, but we’re just illustrating a few ways to work in both random variable world and simulation world.↩︎\nBecause of the way we defined count_matches we need to redefine it if we change n and labels, which is why count_matches is defined inside matching_sim.↩︎\nThe simulation margin of error for relative frequency of at least one match is about 0.01 based on 10000 simulated values. We haven’t discussed simulation margins of error when aproximating expected values yet. In this case, the margin of error for a single average based on 10000 simulated values is about 0.02.↩︎\nWe might also be interested in other sensitivity analyses, such as what if the objects are not placed uniformly at random in the spots.↩︎\nA distribution can also be interpreted as a subjective assessment of relative likelihood or plausibility, but here we’ll focus on the long run relative frequency interpretation.↩︎\nWhich isn’t quite true.↩︎\nThere is no value judgment; sSuccess” just refers to whatever we’re counting. Did the thing we’re counting happen on this trial (“success) or not (”failure”). Success isn’t necessarily good.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Language of Simulation</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html",
    "href": "language-probability-exercises.html",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "",
    "text": "4.1 Solution to Exercise 2.2\nTable 4.1: Sample space for Exercise 2.2\n\n\n\n\n\n\nbox1\nbox2\nbox3\nX\nY\n\n\n\n\n1\n1\n1\n1\n3\n\n\n2\n1\n1\n2\n2\n\n\n3\n1\n1\n2\n2\n\n\n1\n2\n1\n2\n2\n\n\n2\n2\n1\n2\n1\n\n\n3\n2\n1\n3\n1\n\n\n1\n3\n1\n2\n2\n\n\n2\n3\n1\n3\n1\n\n\n3\n3\n1\n2\n1\n\n\n1\n1\n2\n2\n2\n\n\n2\n1\n2\n2\n1\n\n\n3\n1\n2\n3\n1\n\n\n1\n2\n2\n2\n1\n\n\n2\n2\n2\n1\n0\n\n\n3\n2\n2\n2\n0\n\n\n1\n3\n2\n3\n1\n\n\n2\n3\n2\n2\n0\n\n\n3\n3\n2\n2\n0\n\n\n1\n1\n3\n2\n2\n\n\n2\n1\n3\n3\n1\n\n\n3\n1\n3\n2\n1\n\n\n1\n2\n3\n3\n1\n\n\n2\n2\n3\n2\n0\n\n\n3\n2\n3\n2\n0\n\n\n1\n3\n3\n2\n1\n\n\n2\n3\n3\n2\n0\n\n\n3\n3\n3\n1\n0",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-collector4-outcome",
    "href": "language-probability-exercises.html#solution-to-exr-collector4-outcome",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "",
    "text": "There are 3 possible prizes in each of 3 boxes, so there are \\(3^3 = 27\\) possible outcomes.\nSee Table 4.1 (ignore \\(X\\) and \\(Y\\) columns for now); there are 27 rows, each row for a different possible outcome.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-event-collector3",
    "href": "language-probability-exercises.html#solution-to-exr-event-collector3",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.2 Solution to Exercise 2.3",
    "text": "4.2 Solution to Exercise 2.3\nSee the sample space \\(\\Omega\\) of 27 possible outcomes in Table 4.1.\n\n\\(A_1^c = \\{222, 223, 232, 322, 233, 323, 332, 333\\}\\) is the event that none of the boxes contain prize 1, so \\(A_1\\) consists of the \\(27-8 = 19\\) other outcomes.\n\\(B_1 = \\{111\\}\\)\n\\(A_1 \\cap A_2 \\cap A_3 = \\{123, 132, 213, 231, 312, 321\\}\\) is the event that at least one of each prize is obtained (that is, a complete set of prizes)\n\\(A_1 \\cup A_2 \\cup A_3 = \\Omega\\), the set of all possible outcomes; you have to get at least 1 of one of the prizes.\n\\(B_1 \\cap B_2 \\cap B_3=\\emptyset\\); you can’t get only prize 1 and only prize 2\n\\(B_1 \\cup B_2 \\cup B_3 = \\{111, 222, 333\\}\\) is the event you only obtain one of the prizes (in every box)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-event-dartboard",
    "href": "language-probability-exercises.html#solution-to-exr-event-dartboard",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.3 Solution to Exercise 2.4",
    "text": "4.3 Solution to Exercise 2.4\nSee Figure 4.1\n\nFigure 4.1 (a): \\(A\\), Katniss’s dart lands within 1 inch of the center of the dartboard.\nFigure 4.1 (b): \\(B\\), Katniss’s dart lands more than 1 inch but less than 2 inches away from the center of the dartboard.\nFigure 4.1 (c): \\(E\\), Katniss’s dart lands within 1 inch of the outside edge of the dartboard.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Within 1 inch of center\n\n\n\n\n\n\n\n\n\n\n\n(b) More than 1 but less than 2 inches from center\n\n\n\n\n\n\n\n\n\n\n\n(c) Within 1 inch of edge\n\n\n\n\n\n\n\nFigure 4.1: Events in Exercise 2.4",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-rv-collector3",
    "href": "language-probability-exercises.html#solution-to-exr-rv-collector3",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.4 Solution to Exercise 2.6",
    "text": "4.4 Solution to Exercise 2.6\n\nSee Table 4.1\nThe possible values of \\(X\\) are \\(\\{1, 2, 3\\}\\)\nThe possible values of \\(Y\\) are \\(\\{0, 1, 2, 3\\}\\)\nThe possible \\((X, Y)\\) pairs are \\(\\{(1, 0), (1, 3), (2, 0), (2, 1) (2, 2), (3, 1)\\}\\), In particular, the following pairs are NOT possible: \\((1, 1), (1, 2), (2, 3), (3, 0), (3, 2), (3, 3)\\)\n\\(\\{X = 1\\} = \\{111, 222, 333\\}\\) is the event that only one distinct prize is obtained (that is, you get the same prize in every box)\n\\(\\{X=2\\}\\) is the event you get two distinct prizes, which consists of 18 putcomes. It’s easier to write \\(\\{X = 2\\}^c = \\{111, 222, 333, 123, 132, 213, 231, 312, 321\\}\\).\n\\(\\{X = 3\\} = \\{123, 132, 213, 231, 312, 321\\}\\) is the event that you get all 3 prizes; that is, the event that you get the complete set\n\\(\\{Y = 0\\}=\\{222, 223, 232, 322, 233, 323, 332, 333\\}\\) is the event that none of the boxes contain prize 1\n\\(\\{Y = 1\\}=\\{122, 123, 132, 133, 212, 213, 312, 313, 221, 231, 321, 331\\}\\) is the event that exactly one of the boxes contains prize 1\n\\(\\{Y = 2\\}=\\{112, 113, 121, 131, 211, 311\\}\\) is the event that exactly two of the boxes contain prize 1.\n\\(\\{Y = 3\\}=\\{111\\}\\) is the event that all three of the boxes contain prize 1.\n\\(\\{X = 2, Y = 1\\} = \\{122, 133, 212, 313, 221, 331\\}\\) is the event that one box contains prize one and the other two boxes contain either both prize 2 or both prize 3.\n\\(\\{X = Y\\} = \\{112, 113, 121, 131, 211, 311\\}\\) is the event that the number of boxes that contain prize 1 is equal to the number of distinct prizes obtained (in this case it only happens if both \\(X\\) and \\(Y\\) equal 2)\nLet \\(I_1\\) be the indicator random variable that prize 1 is obtained (in at least one of the three packages). Identify and intepret \\(\\{I_1 = 0\\}\\).\n\\(X = I_1+ I_2+ I_3\\)\nLabel the boxes instead of the prizes. Let \\(J_1\\) be the indicator random variable that box 1 contains prize 1, \\(J_2\\) that box 2 contains prize 1, and \\(J_3\\) that box 3 contains prize 1. Then \\(Y = J_1+ J_2+ J_3\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-rv-dartboard",
    "href": "language-probability-exercises.html#solution-to-exr-rv-dartboard",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.5 Solution to Exercise 2.7",
    "text": "4.5 Solution to Exercise 2.7\n\nFigure 4.1 (a): \\(\\{X \\le 1\\}\\), Katniss’s dart lands within 1 inch of the center of the dartboard.\nFigure 4.1 (b): \\(\\{1 &lt; X &lt; 2\\}\\), Katniss’s dart lands more than 1 inch but less than 2 inches away from the center of the dartboard.\nFigure 4.1 (c): \\(\\{X &gt; 11\\}\\), Katniss’s dart lands within 1 inch of the outside edge of the dartboard.\n\\(\\{X = 0\\}\\), the event that the dart hits exactly in the center, is just the single point in the center\n\\(\\{X = 1\\}\\), the event that the dart hits exactly 1 inch from the center, is the circle with radius 1 inch (the outside egde of the shaded region in Figure 4.1 (a))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-probspace-collector3-a",
    "href": "language-probability-exercises.html#solution-to-exr-probspace-collector3-a",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.6 Solution to Exercise 2.10",
    "text": "4.6 Solution to Exercise 2.10\nThe latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Suppose that each package is equally likely to contain any of the 3 prizes, regardless of the contents of other packages, so that there are 27 equally likely outcomes, and let \\(\\textrm{P}\\) be the corresponding probability measure.\n\nLet \\(A_1\\) be the event that prize 1 is obtained—that is, at least one of the packages contains prize 1—and define \\(A_2, A_3\\) similarly for prize 2, 3.\nLet \\(B_1\\) be the event that only prize 1 is obtained—that is, all three packages contain prize 1—and define \\(B_2, B_3\\) similarly for prize 2, 3.\n\n\nCompute \\(\\textrm{P}(A_1)\\)\nCompute \\(\\textrm{P}(B_1)\\)\nInterpret the values from parts 1 and 2 as long run relative frequencies.\nInterpret the values from parts 1 and 2 as relative likelihoods.\nCompute \\(\\textrm{P}(A_1 \\cap A_2 \\cap A_3)\\)\nCompute \\(\\textrm{P}(A_1 \\cup A_2 \\cup A_3)\\)\nCompute \\(\\textrm{P}(B_1 \\cap B_2 \\cap B_3)\\)\nCompute \\(\\textrm{P}(B_1 \\cup B_2 \\cup B_3)\\)\n\\(A_1^c = \\{222, 223, 232, 322, 233, 323, 332, 333\\}\\) is the event that none of the boxes contain prize 1, so \\(A_1\\) consists of the \\(27-8 = 19\\) other outcomes. Since the outcomes are equally likely, \\(\\text{P}(A_1) = 18/27=0.667\\).\nThere is only one outcome that satisfies \\(B_1\\) so \\(\\text{P}(B_1) = 1/27 = 0.037\\).\nOver many sets of 3 boxes, about 66.7% of sets of 3 boxes will contain at least one prize 1, and about 3.7% of sets of 3 boxes will contain only prize 1.\nIt is 18 times more likely to obtain at least one prize 1 than it is to obtain only prize 1. Also, it is 2 times more likely to obtain at least one prize 1 than to not obtain it (18/9), and it is 26 times less likely to obtain only prize 1 than it is to obtain any other collection of prizes.\n\\(A_1 \\cap A_2 \\cap A_3 = \\{123, 132, 213, 231, 312, 321\\}\\) is the event that at least one of each prize is obtained (that is, a complete set of prizes) so \\(\\textrm{P}(A_1 \\cap A_2 \\cap A_3) = 6/27 = 0.222\\)\n\\(A_1 \\cup A_2 \\cup A_3 = \\Omega\\), the set of all possible outcomes; you have to get at least 1 of one of the prizes so \\(\\textrm{P}(A_1 \\cup A_2 \\cup A_3) = 1\\)\n\\(B_1 \\cap B_2 \\cap B_3=\\emptyset\\); you can’t get only prize 1 and only prize 2, so \\(\\textrm{P}(B_1 \\cap B_2 \\cap B_3) = 0\\)\n\\(B_1 \\cup B_2 \\cup B_3 = \\{111, 222, 333\\}\\) is the event you only obtain one of the prizes (in every box), so \\(\\textrm{P}(B_1 \\cup B_2 \\cup B_3) = 3/27 = 0.111\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-probspace-dartboard-b",
    "href": "language-probability-exercises.html#solution-to-exr-probspace-dartboard-b",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.7 Solution to Exercise 2.13",
    "text": "4.7 Solution to Exercise 2.13\nSince the dart lands uniformly at random anywhere on the dartboard, probabilities are computed as the ratio between the area corresponding to the event of interest divided by the area of the total dartboard (\\(12^2\\pi\\))\nSee Figure 4.1. Find the area of the shaded pieces by subtracting areas of circles.\n\n\\(\\text{P}(X \\le 1) = \\frac{1^2\\pi}{12^2\\pi} = 1/144 = 0.00694\\)\n\\(\\text{P}(1 &lt; X &lt; 2) = \\frac{2^2\\pi - 1^2\\pi}{12^2\\pi} = 3/144 = 0.021\\)\n\\(\\text{P}(X &gt; 11) = 1 - \\frac{11^2\\pi}{12^2\\pi} = 1 - (11/12)^2 = 0.160\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-probspace-dartboard-c",
    "href": "language-probability-exercises.html#solution-to-exr-probspace-dartboard-c",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.8 Solution to Exercise 2.14",
    "text": "4.8 Solution to Exercise 2.14\nSince the dart lands uniformly at random anywhere on the dartboard, probabilities are computed as the ratio between the area corresponding to the event of interest divided by the area of the total dartboard (\\(12^2\\pi\\))\nFind the area of the events of interest by finding areas of corresponding circles and subtracting as needed.\n\n\\(\\textrm{P}(X \\le 0.1) = \\frac{0.1^2\\pi}{12^2\\pi} = (0.1/12)^2 = 0.0000694\\)\n\\(\\textrm{P}(X \\le 0.01) = \\frac{0.01^2\\pi}{12^2\\pi} = (0.01/12)^2 = 0.000000694\\)\n\\(\\textrm{P}(X = 0) = 0\\), the single point has no area\n\\(\\textrm{P}(X \\ge 11.9) = 1 - \\frac{11.9^2\\pi}{12^2\\pi} = 1 - (11.9/12)^2 = 0.0166\\)\n\\(\\textrm{P}(X \\ge 11.99) = 1 - \\frac{11.99^2\\pi}{12^2\\pi} = 1 - (11.99/12)^2 = 0.00166\\)\n\\(\\textrm{P}(X = 12) = 0\\), the circle representing the outside edge has no area\nWell, both of these events—the dart lands exactly in the center and the darts lands exactly on the edge—have 0 probability. However for practical purposes we would never be interested in probabilities like \\(\\textrm{P}(X = 0.000000000\\ldots)\\) or \\(\\textrm{P}(X = 12.000000000\\ldots)\\) with infinite precision.\nHowever we define “close to”—within 1 inch or within 0.1 inch or within 0.01 inch, etc—the dart is more likely to land close to the edge than close to the center.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-distribution-intro-collector3",
    "href": "language-probability-exercises.html#solution-to-exr-distribution-intro-collector3",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.9 Solution to Exercise 2.16",
    "text": "4.9 Solution to Exercise 2.16\n\nConstruct a two-way table representing the joint distribution of \\(X\\) and \\(Y\\).\nSketch a plot representing the joint distribution of \\(X\\) and \\(Y\\).\nIdentify the marginal distribution of \\(X\\), and sketch a plot of it.\nIdentify the marginal distribution of \\(Y\\), and sketch a plot of it.\nCompute and interpret \\(\\text{E}(X)\\).\nCompute and interpret \\(\\text{E}(Y)\\).\nOne dimension will have possible values of \\(x\\), the other possible values of \\(y\\). The interior cells should contain the probability of each \\((x, y)\\) pair.\n\n\n\n\n\\(y\\)\n\n\n\n\n\n\n\\(x\\)\n0\n1\n2\n3\nTotal\n\n\n1\n2/27\n0\n0\n1/27\n3/27\n\n\n2\n6/27\n6/27\n6/27\n0\n18/27\n\n\n3\n0\n6/27\n0\n0\n6/27\n\n\nTotal\n8/27\n12/27\n6/27\n1/27\n1\n\n\n\nMake a tile plot with color or shading representing probability; see Figure 4.2\nThe possible values of \\(X\\) are in the leftmost column (1, 2, 3) and the probabilities are in the Total column. See Figure 4.3.\nThe possible values of \\(Y\\) are in the top row (0, 1, 2, 3) and the probabilities are in the Total row. See Figure 4.4.\n\\(\\textrm{E}(X) = 1\\times (3/27) + 2 \\times (18/27) + 3 \\times (6/ 27) = 2.11\\). Over many sets of 3 boxes, we expect 2.11 distinct prizes on average.\n\\(\\textrm{E}(Y) = 0\\times (8/27) + 1\\times (12/27) + 2 \\times (6/27) + 3 \\times (1/ 27) = 1\\). Over many sets of 3 boxes, we expect 1 box containing prize 1 on average.\n\n\n\n\n\n\n\n\n\nFigure 4.2: Joint distribution of \\(X\\) and \\(Y\\) in Exercise 2.16\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.3: Marginal distribution of \\(X\\) in Exercise 2.16\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.4: Marginal distribution of \\(Y\\) in Exercise 2.16",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-distribution-conditional-collector3",
    "href": "language-probability-exercises.html#solution-to-exr-distribution-conditional-collector3",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.10 Solution to Exercise 2.22",
    "text": "4.10 Solution to Exercise 2.22\n\nEach row of the table below represents a different conditional distribution of \\(Y\\) given \\(X=x\\). For example, the row for \\(x=1\\) represents the conditional distribution of \\(Y\\) given \\(X=1\\): Given \\(X=1\\), \\(Y\\) is 0 with probability 2/3 and 3 with probability 1/3.\n\n\n\n\n\\(y\\)\n\n\n\n\n\n\n\n0\n1\n2\n3\nTotal\n\n\n\\(x\\)\n\n\n\n\n\n\n\n1\n2/3\n0\n0\n1/3\n1\n\n\n2\n1/3\n1/3\n1/3\n0\n1\n\n\n3\n0\n1\n0\n0\n1\n\n\n\nTake expected values according to each conditional distribution. In general, \\(\\text{E}(Y|X=x)\\) depends on \\(x\\), but in this case \\(\\text{E}(Y|X=x) = 1\\) for all values of \\(x\\).; regardless of how many distinct prizez people obtain in their, the average number of prize 1s obtains is 1.\n\\[\\begin{align*}\nx & \\quad \\text{E}(Y|X=x)\\\\\n1 & \\quad 0(2/3) + 3(1/3) = 1\\\\\n2 & \\quad 0(1/3) + 1(1/3) + 2(1/3) = 1\\\\\n3 & \\quad 1(1) = 1\n\\end{align*}\\]\nEach column of the table below represents a different conditional distribution of \\(X\\) given \\(Y=y\\). For example, the column for \\(y=1\\) represents the conditional distribution of \\(X\\) given \\(Y=1\\): Given \\(Y=1\\), \\(X\\) is 1 with probability 1/4 and 2 with probability 3/4.\n\n\n\n\n\\(y\\)\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\\(x\\)\n\n\n\n\n\n\n1\n1/4\n0\n0\n1\n\n\n2\n3/4\n1/2\n1\n0\n\n\n3\n0\n1/2\n0\n0\n\n\nTotal\n1\n1\n1\n1\n\n\n\nTake expected values according to each conditional distribution. For example, \\(\\text{E}(X|Y = 0) = 1.75\\); among the people who never get prize 1 in their 3 boxes, the average number of distinct prizes they obtain is 1.75.\n\\[\\begin{align*}\ny & \\quad \\text{E}(X|Y=y)\\\\\n0 & \\quad 1(1/4) + 2(3/4) = 1.75\\\\\n1 & \\quad 2(1/2) + 3(1/2) = 2.5\\\\\n2 & \\quad 2(1) = 2\\\\\n3 & \\quad 1(1) = 1\n\\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-ltp-multiple-choice",
    "href": "language-probability-exercises.html#solution-to-exr-ltp-multiple-choice",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.11 Solution to Exercise 2.17",
    "text": "4.11 Solution to Exercise 2.17\n\nSuppose there are 1000 questions on the test. (That’s a long test! But remember, 1000 is just a convenient round number.) We can classify each question by its type (know, eliminate, guess) and whether we answer it correctly or not. The probability that we answer a question correctly is 1 given that we know it, 0.5 given that we can eliminate two choices, or 0.25 given that we guess randomly.\n\n\n\n\nKnow\nEliminate\nGuess\nTotal\n\n\n\n\nCorrect\n700\n100\n25\n825\n\n\nIncorrect\n0\n100\n75\n175\n\n\nTotal\n700\n200\n100\n1000\n\n\n\nThe probability that we answer a randomly selected question correctly is 825/1000 = 0.825.\nThe overall probability of answering a question correctly is closer to 1 than 0.5 or 0.25. To construct the table and obtain the value 0.825, we basically did the following calculation\n\\[\n0.825 = (1)(0.7) + (0.5)(0.2) + (0.25)(0.1)\n\\]\nWe see that the overall probability, 0.825, is a weighted average of the case-by-case probabilities 1, 0.5, and 0.25, where 1 gets the most weight in the average because there is a higher percentage of questions that we know.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-ltp-rats",
    "href": "language-probability-exercises.html#solution-to-exr-ltp-rats",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.12 Solution to Exercise 2.18",
    "text": "4.12 Solution to Exercise 2.18\n\nMost people produce a sequence that has 30 G’s and 10 R’s, or close to those proportions, because they are trying to generate a sequence for which each outcome has a 75% chance for G and a 25% chance for R. That is, they use a strategy in which they predict G with probability 0.75, and R with probability 0.25.\nThere are two cases: the true flash is either green (with probability 0.75) or red (with probability 0.25). Given that the flash is green, your probability of correctly predicting it is 0.75 (because your probability of guessing “G” is 0.75). Given that the flash is red, your probability of correctly predicting it is 0.25 (because your probability of guessing “R” is 0.25). Use the law of total probability to find the probability that your prediction is correct: \\((0.75)(0.75) + (0.25)(0.25) = 0.625\\).\nJust pick G every time! Picking green every time has a 0.75 probability of correctly predicting any flash. When events are independent, trying to guess the pattern doesn’t help.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-bayes-elisa",
    "href": "language-probability-exercises.html#solution-to-exr-bayes-elisa",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.13 Solution to Exercise 2.19",
    "text": "4.13 Solution to Exercise 2.19\n\nWe don’t know what you guessed, but from experience many people guess 80-100%. Afterall, the test is correct for most of people who carry HIV, and also correct for most people who don’t carry HIV, so it seems like the test is correct most of the time. But this argument ignores one important piece of information that has a huge impact on the results: most people do not carry HIV.\nLet \\(H\\) denote the event that the person carries HIV (hypothesis), and let \\(E\\) denote the event that the test is positive (evidence). Therefore, \\(H^c\\) is the event that the person does not carry HIV, another hypothesis. We are given\n\n\nprior probability: \\(P(H) = 0.005\\)\nlikelihood of testing positive, if the person carries HIV: \\(P(E|H) = 0.977\\)\n\\(P(E^c|H^c) = 0.926\\)\nlikelihood of testing positive, if the person does not carry HIV: \\(P(E|H^c) = 1-P(E^c|H^c) = 1-0.926 = 0.074\\)\nWe want to find the posterior probability \\(P(H|E)\\).\n\n\nAssuming 1000000 Americans\n\n\n\n\n\n\n\n\n\n\nTests positive\nDoes not test positive\nTotal\n\n\n\n\nCarries HIV\n4885\n115\n5000\n\n\nDoes not carry HIV\n73630\n921370\n995000\n\n\nTotal\n78515\n921485\n1000000\n\n\n\nAmong the 78515 who test positive, 4885 carry HIV, so the probability that an American who tests positive actually carries HIV is 4885/78515 = 0.062.\nSee Table 4.2.\nThe result says that only 6.2% of Americans who test positive actually carry HIV. It is true that the test is correct for most Americans with HIV (4885 out of 5000) and incorrect only for a small proportion of Americans who do not carry HIV (73630 out of 995000). But since so few Americans carry HIV, the sheer number of false positives (73630) swamps the number of true positives (4885).\nPrior to observing the test result, the prior probability that an American carries HIV is \\(P(H) = 0.005\\). The posterior probability that an American carries HIV given a positive test result is \\(P(H|E)=0.062\\). \\[\n  \\frac{P(H|E)}{P(H)} = \\frac{0.062}{0.005} =  12.44\n\\] An American who tests positive is about 12.4 times more likely to carry HIV than an American whom the test result is not known.\nSo while 0.067 is still small in absolute terms, the posterior probability is much larger relative to the prior probability.\nIn this risk group\n\n\na person is 19 times more likely to not have HIV than to have it (\\(0.95/0.05 = 19\\)).\nA positive test is 13.2 times less likely when the person does not have HIV than when they have it (\\(0.074/0.977 = 1/13.2\\)).\nThe product of these ratios is \\(19(1/13.2) = 1.44\\).\n\nSince posterior is proportional to the product of prior and likelihood, a person in this risk group who tests positive is 1.44 times more likely to not have HIV than to have HIV.\n\nThe posterior probabilities of not having HIV and having HIV are in a 1.44 to 1 ratio, the so the posterior probability of not having HIV is \\(1.44/(1+1.44) = 0.59\\) and the posterior probability of having HIV is 0.41.\nYes, the posterior probability is influenced by the prior probability. Even though the prior probability of 5% is still relatively small in absolute terms, the posterior probability given a positive test is not close to 50/50.\n\n\n\n\n\nTable 4.2: Bayes table for Exercise 2.19\n\n\n\n\n\n\nhypothesis\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\nCarries HIV\n0.005\n0.977\n0.0049\n0.0622\n\n\nDoes not carry HIV\n0.995\n0.074\n0.0736\n0.9378\n\n\nsum\n1.000\nNA\n0.0785\n1.0000",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-bayes-best-player",
    "href": "language-probability-exercises.html#solution-to-exr-bayes-best-player",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.14 Solution to Exercise 2.20",
    "text": "4.14 Solution to Exercise 2.20\n\nHypotheses are which player is best (A, B, C). Evidence is that A beats B. The likelihood is the probability that A beats B given each of the best players.\n\n\nIf A is best, probability A beats B is 2/3.\nIf B is best, probability A beats B is 1/3.\nIf C is best, probability A beats B is 1/2.\n\nCompute the posterior probabilities as in the following Bayes table.\n\n\n\n\n\nbest_player\nprior\nlikelihood_A_beats_B\nproduct\nposterior\n\n\n\n\nA\n0.50\n0.6667\n0.3333\n0.6349\n\n\nB\n0.35\n0.3333\n0.1167\n0.2222\n\n\nC\n0.15\n0.5000\n0.0750\n0.1429\n\n\nTotal\n1.00\n1.5000\n0.5250\n1.0000\n\n\n\n\n\n\nA’s probability of being the best increased, which makes sense because A won the match. B’s probability of being the best decreased considerably, which makes sense because B lost the match. C’s probability of being the best decreased slightly, despite C not being involved in the match. (We have now observed some actual evidence in A’s favor while we don’t have any observations about C yet, and this information asymmetry results in a decrease in C’s posterior probability.)\nHypotheses are which player is best (A, B, C). Evidence is that B beats A. The likelihood is the probability that B beats A given each of the best players.\n\n\nIf A is best, probability B beats A is 1/3.\nIf B is best, probability B beats A is 2/3.\nIf C is best, probability B beats A is 1/2.\n\n\n\n\n\n\nbest_player\nprior\nlikelihood_B_beats_A\nproduct\nposterior\n\n\n\n\nA\n0.50\n0.3333\n0.1667\n0.3509\n\n\nB\n0.35\n0.6667\n0.2333\n0.4912\n\n\nC\n0.15\n0.5000\n0.0750\n0.1579\n\n\nTotal\n1.00\n1.5000\n0.4750\n1.0000\n\n\n\n\n\n\nA’s probability of being the best decreased, which makes sense because A lost the match. B’s probability of being the best increased, which makes sense because B won the match. C’s probability of being the best changed slightly, despite C not being involved in the match.\nThe prior is the posterior from the first part. Evidence is that A beats C. The likelihood is the probability that A beats C given each of the best players.\n\n\nIf A is best, probability A beats C is 2/3.\nIf B is best, probability A beats C is 1/2.\nIf C is best, probability A beats C is 1/3.\n\n\n\n\n\n\nbest_player\nprior\nlikelihood_A_beats_C\nproduct\nposterior\n\n\n\n\nA\n0.6349\n0.6667\n0.4233\n0.7273\n\n\nB\n0.2222\n0.5000\n0.1111\n0.1909\n\n\nC\n0.1429\n0.3333\n0.0476\n0.0818\n\n\nTotal\n1.0000\n1.5000\n0.5820\n1.0000\n\n\n\n\n\n\nBy winning both matches, A’s probability of being the best has increased considerably. By losing their only matches, B’s and C’s probabilities of being the best have decreased considerably.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-bayes-best-player-predict",
    "href": "language-probability-exercises.html#solution-to-exr-bayes-best-player-predict",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.15 Solution to Exercise 2.21",
    "text": "4.15 Solution to Exercise 2.21\n\nYou’d pick A and your subjective probability of being correct is 0.5.\nUse the law of total probability, conditioning on who is the best player (A, B, C) \\[\\begin{align*}\n\\text{P}(\\text{A beats B}) & = \\text{P}(\\text{A beats B}|A)\\text{P}(A) + \\text{P}(\\text{A beats B}|B)\\text{P}(B) + \\text{P}(\\text{A beats B}|C)\\text{P}(C)\\\\\n& = (2/3)(0.5) + (1/3)(0.35) + (1/2)(0.15) = 0.525\n\\end{align*}\\]\nGiven that A beats B, we would predict A to be the best player, and we would have probability 0.6349 of being correct.\nGiven that B beats A, we would predict B to be the best player, and we would have probability 0.4912 of being correct.\nUse the law of total probability, conditioning on the result of the first match (A beats B or B beats A). \\[\\begin{align*}\n\\text{P}(\\text{correct}) & = \\text{P}(\\text{correct} | \\text{A beats B})\\text{P}(\\text{A beats B}) + \\text{P}(\\text{correct} | \\text{B beats A})  \\text{P}(\\text{B beats A})\\\\\n& = (0.6349)(0.5250) + (0.4912)(0.4750) = 0.5666\n\\end{align*}\\] The information gained from observing the first match increases our probability of being correct from 0.5 to 0.5666.\n\n\n4.15.1 Solution to Exercise 2.24\n\n\\(X\\) can take values 1, 2, 3, \\(\\ldots\\). Even though it is unlikely that \\(X\\) is very large, there is no fixed upper bound. Even though \\(X\\) can take infinitely many values, \\(X\\) is a discrete random variables because it takes countably many possible values.\n\\(X= 1\\) only if she makes her first attempt, so \\(\\text{P}(X = 1) = 0.4\\). If Maya does this every practice, then in about 40% of practices she will make her first three pointer on her first attempt.\n\\(X= 2\\) only if she misses her first attempt and makes her second attempt, so since the attempts are independent \\(\\text{P}(X = 2) = (0.6)(0.4)=0.24\\). If Maya does this every practice, then in about 24% of practices she will make her first three pointer on her second attempt.\nIn order for \\(X\\) to be 3, Maya must miss her first two attempts and make her third. Since the attempts are independent \\(\\text{P}(X=3)=(1-0.4)^2(0.4)=0.144\\). If Maya does this every practice, then in about 14.4% of practices she will make her first three pointer on her third attempt.\nThe key is to realize that Maya requires more than 3 attempts to obtain her first success if and only if the first 5 attempts are failures. Therefore, \\[\nP(X &gt; 3) = (1-0.4)^3  = 0.216\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-branching-extinction",
    "href": "language-probability-exercises.html#solution-to-exr-branching-extinction",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.16 Solution to Exercise 2.25",
    "text": "4.16 Solution to Exercise 2.25\n\nLet \\(D\\) be the probability that the original microorganism dies after the first minute; \\(\\textrm{P}(D) = 1/4\\). Condition on the first “step” and use the law of total probability \\[\np = \\textrm{P}(E) = \\textrm{P}(E|D)\\textrm{P}(D) + \\textrm{P}(E|D^c)\\textrm{P}(D^c) = (1)(1/4) + \\textrm{P}(E|D^c)(3/4)\n\\] \\(\\textrm{P}(E|D) = 1\\) since if the first microorganism dies the population goes extinct immediately.\nThe key is to find an expression for \\(\\textrm{P}(E|D^c)\\) in terms of \\(p\\). If the first microorganism does not die (\\(D^c\\)) there are 2 microorganisms at the start of the second minute; let’s call them Marge and Homer. In order for the population to go extinct, we need Marge and all her descendants to go extinct, and the same for Homer. But Marge is just a single microorganism, so the probability that her line eventually goes extinct is \\(p\\); similarly the probability that Homer’s line goes extinct is \\(p\\). Since all microorganisms behave independently, the probability that both Marge and Homer’s lines eventually go extinct is \\((p)(p)=p^2\\). That is, \\(\\textrm{P}(E | D^c) = p^2\\).\nPlugging into the equation above yields \\[\np = (1)(1/4) + p^2(3/4)\n\\]\nSolve (quadratic formula) this equation to get1 \\(p= 1/3\\). The probability that the population eventually goes extinct is 1/3. This microorganism population is 2 times more likely to survive forever than to go extinct!\nThe process is the same as the above, with 3/4 replaced by \\(s\\) \\[\np = (1)(1-s) + p^2s\n\\] Solving gives two solutions, 1 and \\(1/s - 1\\). However, if \\(s&lt;1/2\\) then \\(1/s - 1 &gt; 1\\), which is not a valid probability. Therefore the probability of eventual extinction is 1 if \\(s \\le 1/2\\), and \\(1/s - 1&lt;1\\) if \\(s &gt; 1/2\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-best-of-five",
    "href": "language-probability-exercises.html#solution-to-exr-best-of-five",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.17 Solution to Exercise 2.27",
    "text": "4.17 Solution to Exercise 2.27\n\nIt is helpful to construct a two-way table to answer the following questions.\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\n\n\n\n\n3\n4\n5\nTotal\n\n\nA wins\n0.553 = 0.166\n3(0.553)(0.45) = 0.225\n6(0.553)(0.45)2 = 0.202\n0.593\n\n\nA does not win\n0.453 = 0.091\n3(0.453)(0.55) = 0.150\n6(0.453)(0.55)2 = 0.165\n0.407\n\n\nTotal\n0.258\n0.375\n0.368\n1\n\n\n\nThere is only one outcome for which A wins in 3 games: AAA. There are three outcomes in which A wins in 4 games: AABA, ABAA, BAAA. (Not AAAB because then the series would be over in 3 games.) Since the games are independent, an outcome like AABA has probability \\((0.55^3)(0.45)\\), so the probability that A wins in 4 games is \\(3(0.55^3)(0.45)\\). There are six outcomes in which A wins in 5 games: AABBA, ABABA, BAABA, ABBAA, BABAA, BBAAA. (Not outcomes like AAABB or AABAB because then the series would be over in 3 or 4 games.) Since the games are independent, an outcome like AABBA has probability \\((0.55^3)(0.45)^2\\), so the probability that A wins in 5 games is \\(6(0.55^3)(0.45)\\). You can fill in the rest of the table similarly.\nThe probability that team A wins the series in 3 games is \\(\\text{P}(X=3, A) = 0.55^3=0.166\\).\nEither the stronger team wins 3 in a row or loses 3 in a row. The probability is \\(0.55^3+(1-0.55)^3=0.2575\\).\nThe probability that team A wins the series is the sum of first row: \\(\\text{P}(A) = 0.593\\).\nNo. \\(\\text{P}(X=3, A) = 0.55^3=0.166 \\neq 0.152 = (0.2575)(0.593) = \\text{P}(X=3)\\text{P}(A)\\). Alternatively, \\(\\text{P}(X = 3 | A) = 0.166/0.593 = 0.2799 \\neq 0.2575 = \\text{P}(X = 3)\\). Given that \\(A\\) wins the series the series it more likely to end in 3 games than when B wins the series.\nTotal row above. \\(X\\) can take values 3, 4, or 5. Consider first the ways in which the stronger team wins in 4 games: AABA, ABAA, BAAA. (For example AABA, means the stronger team wins game 1, 2, and 4, and the weaker team wins game 3). Each of these outcomes has probability \\(0.55^3(0.45)\\) so the probability that team A wins in 4 games in \\(3(0.55)^3(0.45)\\). Similarly, the probability that team B wins in 4 games is \\(3(0.45)^3(0.55)\\). So \\[\n\\text{P}(X = 4) = 3(0.55)^3(0.45) + 3(0.45)^3(0.55) = 0.3750\n\\] You could find \\(\\text{P}(X=5)\\) in a similar way, or just use the fact that the probabilities have to add up to 1. The distribution of \\(X\\) is given by the following table. \\[\\begin{align*}\nx & \\qquad & & \\qquad \\text{P}(X = x)\\\\\n3 & \\qquad & & \\qquad 0.2575\\\\\n4 & \\qquad & & \\qquad 0.3750\\\\\n5 & \\qquad & & \\qquad 0.3675\\\\\n\\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-bayes-best-player-iterate",
    "href": "language-probability-exercises.html#solution-to-exr-bayes-best-player-iterate",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "4.18 Solution to Exercise 2.26",
    "text": "4.18 Solution to Exercise 2.26\n\nThe prior is the posterior from the first part. Evidence is that A beats C. The likelihood is the probability that A beats C given each of the best players.\n\n\nIf A is best, probability A beats C is 2/3.\nIf B is best, probability A beats C is 1/2.\nIf C is best, probability A beats C is 1/3.\n\n\n\n\n\n\nbest_player\nprior\nlikelihood_A_beats_C\nproduct\nposterior\n\n\n\n\nA\n0.6349\n0.6667\n0.4233\n0.7273\n\n\nB\n0.2222\n0.5000\n0.1111\n0.1909\n\n\nC\n0.1429\n0.3333\n0.0476\n0.0818\n\n\nTotal\n1.0000\n1.5000\n0.5820\n1.0000\n\n\n\n\n\nBy winning both matches, A’s probability of being the best has increased considerably. By losing their only matches, B’s and C’s probabilities of being the best have decreased considerably.\n\nThe prior is the posterior from the previous part. Evidence is that B beats C. The likelihood is the probability that B beats C given each of the best players.\n\n\nIf A is best, probability B beats C is 1/2.\nIf B is best, probability B beats C is 2/3.\nIf C is best, probability B beats C is 1/3.\n\n\n\n\n\n\nbest_player\nprior\nlikelihood_B_beats_C\nproduct\nposterior\n\n\n\n\nA\n0.7273\n0.5000\n0.3636\n0.7018\n\n\nB\n0.1909\n0.6667\n0.1273\n0.2456\n\n\nC\n0.0818\n0.3333\n0.0273\n0.0526\n\n\nTotal\n1.0000\n1.5000\n0.5182\n1.0000\n\n\n\n\n\nBy winning both matches, A’s probability of being the best has increased considerably. By losing one match and winning one, B’s probability of being the best decreased somewhat. By losing both matches, C’s probability of being the best has decreased considerably.\n\nThe prior is the original prior. Evidence is that A beats B and A beats C and B beats C in three conditionally independent matches. The likelihood is the probability of these match results given each of the best players.\n\n\nIf A is best, likelihood is (2/3)(2/3)(1/2).\nIf B is best, likelihood is (1/3)(1/2)(2/3).\nIf C is best, likelihood is (1/2)(1/3)(1/3)\n\n\n\n\n\n\nbest_player\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\nA\n0.50\n0.2222\n0.1111\n0.7018\n\n\nB\n0.35\n0.1111\n0.0389\n0.2456\n\n\nC\n0.15\n0.0556\n0.0083\n0.0526\n\n\nTotal\n1.00\n0.3889\n0.1583\n1.0000\n\n\n\n\n\nThe posterior is the same. It doesn’t matter if the posterior is updated after each match, or at once after all three matches.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#footnotes",
    "href": "language-probability-exercises.html#footnotes",
    "title": "4  Chapter 2 Exercise Solutions",
    "section": "",
    "text": "Technically, there are two solutions, 1 and \\(1/3\\). There are some technical justifications that can be made to show that the extinction probability is the smaller of the two solutions, but this is beyond our scope.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html",
    "href": "language-simulation-exercises.html",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "",
    "text": "5.1 Solution to Exercise 3.1\nLabel 365 cards with the numbers 1 through 365. Shuffle the cards and deal \\(n\\) with replacement. If the \\(n\\) cards dealt all have different numbers, then \\(B\\) does not occur; otherwise \\(B\\) occurs.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-tactile-geometric",
    "href": "language-simulation-exercises.html#solution-to-exr-tactile-geometric",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.2 Solution to Exercise 3.2",
    "text": "5.2 Solution to Exercise 3.2\nCreate a spinner with two sectors, one sector labeled “make” which accounts for 40% of the area, and the other 60% labeled “miss”. Spinner the spinner until it lands on “make” and then stop; let \\(X\\) be the total number of spins.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-tactile-collector",
    "href": "language-simulation-exercises.html#solution-to-exr-tactile-collector",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.3 Solution to Exercise 3.3",
    "text": "5.3 Solution to Exercise 3.3\nCreate a spinner with three equal sectors, labeled 1, 2, 3. Spin the spinner 3 times. Let \\(X\\) be the number of distinct numbers the spinner lands on; for example if the spinner lands on 3 then 1 then 3, then \\(X\\) is 2. Let \\(Y\\) be the number of spins that land on 1.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-tactile-dartboard",
    "href": "language-simulation-exercises.html#solution-to-exr-tactile-dartboard",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.4 Solution to Exercise 3.4",
    "text": "5.4 Solution to Exercise 3.4\n\nA Uniform(0, 12) spinner is basically a clock. It goes from 0 to 12 in equally spaced increments. See Figure 5.1.\nTo simulate \\(X\\), flip the coin to determine if the point is in the “east” or “west” and then spin the Uniform(0, 12) spinner to determine how far from the center in the east or west direction. Let the result of the spin be \\(U_1\\). If the coin lands on heads (east) set \\(X=U_1\\); if the coin lands on tails (west) set \\(X=-U_1\\). To simulate \\(Y\\), spin the spinner again to get \\(U_2\\), and flip the coin again. If the result of the flip is heads (north) then set \\(Y = U_2\\); if the result of the flip is tails (south) then set \\(Y=-U_2\\). Compute the distance from \\((X, Y)\\) to (0, 0) as \\(R=\\sqrt{X^2+Y^2}\\). If \\(R&gt;12\\) the dart would land off the board, so just discard the repetition and try again.\nExercise 2.13 shows that \\(R\\) is not uniformly distributed between 0 and 12. In particular, \\(R\\) is more likely to be between 11 and 12 than it is to be between 0 and 1. Therefore a Uniform(0, 12) spinner would not be appropriate.\n\n\n\n\n\n\n\n\n\nFigure 5.1: A continuous Uniform(0, 12) spinner. Only selected rounded values are displayed, but in the idealized model the spinner is infinitely precise so that any real number between 0 and 12 is a possible outcome.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-tactile-dartboard-b",
    "href": "language-simulation-exercises.html#solution-to-exr-tactile-dartboard-b",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.5 Solution to Exercise 3.5",
    "text": "5.5 Solution to Exercise 3.5\n\n\n\n\n\n\n\n\nFigure 5.2: Spinner representing the distribution of \\(R\\) in Exercise 3.5",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-computer-simulation-collector",
    "href": "language-simulation-exercises.html#solution-to-exr-computer-simulation-collector",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.6 Solution to Exercise 3.6",
    "text": "5.6 Solution to Exercise 3.6\n\nP = BoxModel([1, 2, 3], size = 3)\n\ndef count_distinct(u):\n    return len(set(u))\n\nX = RV(P, count_distinct)\n\nY = RV(P, count_eq(1))\n\n(RV(P) & X & Y).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0((2, 1, 3), 3, 1)\n        \n        \n        \n          1((1, 3, 2), 3, 1)\n        \n        \n        \n          2((3, 3, 3), 1, 0)\n        \n        \n        \n          3((1, 1, 3), 2, 2)\n        \n        \n        \n          4((2, 2, 3), 2, 0)\n        \n        \n        \n          5((2, 1, 2), 2, 1)\n        \n        \n        \n          6((1, 2, 2), 2, 1)\n        \n        \n        \n          7((2, 1, 2), 2, 1)\n        \n        \n        \n          8((2, 1, 2), 2, 1)\n        \n        ......\n        \n          9((3, 2, 3), 2, 0)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-computer-simulation-collector-b",
    "href": "language-simulation-exercises.html#solution-to-exr-computer-simulation-collector-b",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.7 Solution to Exercise 3.7",
    "text": "5.7 Solution to Exercise 3.7\n\nP = BoxModel([1, 2, 3], size = 3, probs = [0.1, 0.3, 0.6])\n\ndef count_distinct(u):\n    return len(set(u))\n\nX = RV(P, count_distinct)\n\nY = RV(P, count_eq(1))\n\n(RV(P) & X & Y).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0((1, 3, 3), 2, 1)\n        \n        \n        \n          1((3, 3, 3), 1, 0)\n        \n        \n        \n          2((1, 2, 3), 3, 1)\n        \n        \n        \n          3((3, 3, 3), 1, 0)\n        \n        \n        \n          4((3, 2, 2), 2, 0)\n        \n        \n        \n          5((3, 2, 3), 2, 0)\n        \n        \n        \n          6((3, 2, 3), 2, 0)\n        \n        \n        \n          7((3, 2, 3), 2, 0)\n        \n        \n        \n          8((1, 2, 3), 3, 1)\n        \n        ......\n        \n          9((3, 3, 3), 1, 0)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-computer-simulation-birthday",
    "href": "language-simulation-exercises.html#solution-to-exr-computer-simulation-birthday",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.8 Solution to Exercise 3.8",
    "text": "5.8 Solution to Exercise 3.8\nThe code below defines a random variable \\(X\\) that counts the number of distinct birthdays in the group of \\(n\\). Event \\(B\\) occurs if \\(X&lt;n\\).\n\nn = 30\n\nP = BoxModel(list(range(365)), size = n)\n\ndef count_distinct(u):\n  return len(set(u))\n\nX = RV(P, count_distinct)\n\nB = (X &lt; n)\n\nB.sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0True\n        \n        \n        \n          1True\n        \n        \n        \n          2False\n        \n        \n        \n          3True\n        \n        \n        \n          4True\n        \n        \n        \n          5False\n        \n        \n        \n          6True\n        \n        \n        \n          7True\n        \n        \n        \n          8True\n        \n        ......\n        \n          9True",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-computer-simulation-geometric",
    "href": "language-simulation-exercises.html#solution-to-exr-computer-simulation-geometric",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.9 Solution to Exercise 3.9",
    "text": "5.9 Solution to Exercise 3.9\n\np_success = 0.4\n\n# define a function that takes as an input a sequence of 0s and 1s (omega)\n# and returns when the first 1 occurs\ndef count_until_first_success(omega):\n    for i, w in enumerate(omega):\n        if w == 1:\n            return i + 1 # the +1 is for zero-based indexing\n\n# Either of the following probability spaces works        \n# P = Bernoulli(p_success) ** inf\nP = BoxModel([1, 0], probs = [p_success, 1 - p_success], size = inf)\n\nX = RV(P, count_until_first_success)\n\n(RV(P) & X).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0((1, 1, 0, 0, 0, 1, ...), 1)\n        \n        \n        \n          1((0, 1, 0, 0, 1, 0, ...), 2)\n        \n        \n        \n          2((0, 0, 0, 0, 0, 0, ...), 7)\n        \n        \n        \n          3((0, 0, 1, 0, 0, 0, ...), 3)\n        \n        \n        \n          4((1, 0, 1, 0, 0, 0, ...), 1)\n        \n        \n        \n          5((0, 0, 0, 0, 1, 0, ...), 5)\n        \n        \n        \n          6((0, 0, 0, 0, 0, 0, ...), 7)\n        \n        \n        \n          7((0, 0, 0, 0, 0, 1, ...), 6)\n        \n        \n        \n          8((1, 0, 1, 1, 1, 1, ...), 1)\n        \n        ......\n        \n          9((0, 0, 0, 1, 0, 0, ...), 4)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-computer-simulation-dartboard",
    "href": "language-simulation-exercises.html#solution-to-exr-computer-simulation-dartboard",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.10 Solution to Exercise 3.10",
    "text": "5.10 Solution to Exercise 3.10\nIn the code below\n\nUniform(0, 12) ** 2 corresponds to the two spins\nBoxModel([-1, 1], size = 2) corresponds to the two coin flips\nUniform(0, 12) ** 2 * BoxModel([-1, 1], size = 2) simulates a pair which we unpack and define as RVs U, F, but U is itself a pair and so is F.\nU[0] is the first spin and F[0] is the first flip.\n\n\nU, F = RV(Uniform(0, 12) ** 2 * BoxModel([-1, 1], size = 2))\n\nX = U[0] * F[0]\n\nY = U[1] * F[1]\n\nR = sqrt(X ** 2 + Y ** 2)\n\n(U & F & X & Y & R).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0((10.11141041249285, 2.041605128291537), (-1, 1), -10.11141041249285, 2.041605128291537, 10.31546276...\n        \n        \n        \n          1((7.336026893100588, 9.394495600242251), (1, 1), 7.336026893100588, 9.394495600242251, 11.9194730655...\n        \n        \n        \n          2((3.8626113110019906, 2.592791344868861), (1, 1), 3.8626113110019906, 2.592791344868861, 4.652132102...\n        \n        \n        \n          3((4.504614389806449, 9.685354833040911), (-1, 1), -4.504614389806449, 9.685354833040911, 10.68165010...\n        \n        \n        \n          4((10.80964771661665, 7.350564173715055), (-1, 1), -10.80964771661665, 7.350564173715055, 13.07208007...\n        \n        \n        \n          5((8.355822578770804, 11.35096500700348), (1, -1), 8.355822578770804, -11.35096500700348, 14.09482804...\n        \n        \n        \n          6((5.678181939941612, 3.8394496383189773), (1, -1), 5.678181939941612, -3.8394496383189773, 6.8544236...\n        \n        \n        \n          7((5.023339159824452, 7.999031340676121), (1, 1), 5.023339159824452, 7.999031340676121, 9.44555126521...\n        \n        \n        \n          8((3.436786066399019, 4.256714508424954), (-1, 1), -3.436786066399019, 4.256714508424954, 5.470933820...\n        \n        ......\n        \n          9((4.828242522556003, 9.366926324793116), (1, -1), 4.828242522556003, -9.366926324793116, 10.53808496...\n        \n        \n      \n    \n\n\nCurrently the \\((X, Y)\\) pairs are uniformly distributed in the box with sides [-12, 12]. We’ll see how to discard points off the board later.\n\nplt.figure()\n(X & Y).sim(1000).plot()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-computer-simulation-continuous-dice",
    "href": "language-simulation-exercises.html#solution-to-exr-computer-simulation-continuous-dice",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.11 Solution to Exercise 3.11",
    "text": "5.11 Solution to Exercise 3.11\n\nP = Uniform(1, 4) ** 2\n\nX = RV(P, sum)\nY = RV(P, max)\n\n(RV(P) & X & Y).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0((1.8962710443067174, 1.6222753252670201), 3.5185463695737376, 1.8962710443067174)\n        \n        \n        \n          1((2.9478311914381665, 2.1714979048186445), 5.119329096256811, 2.9478311914381665)\n        \n        \n        \n          2((2.1606029880183124, 3.5476311866974672), 5.70823417471578, 3.5476311866974672)\n        \n        \n        \n          3((2.00628637974726, 2.3893191960068334), 4.395605575754093, 2.3893191960068334)\n        \n        \n        \n          4((3.674125694636697, 2.0126231280784186), 5.686748822715115, 3.674125694636697)\n        \n        \n        \n          5((3.4642658628643748, 1.3429394622582804), 4.807205325122656, 3.4642658628643748)\n        \n        \n        \n          6((3.6735913640463664, 1.7841965641167938), 5.45778792816316, 3.6735913640463664)\n        \n        \n        \n          7((2.785932581441463, 2.8206424029749515), 5.606574984416414, 2.8206424029749515)\n        \n        \n        \n          8((1.6438301309061627, 2.087170115555848), 3.7310002464620107, 2.087170115555848)\n        \n        ......\n        \n          9((2.911430714544699, 1.1287794023909279), 4.0402101169356275, 2.911430714544699)\n        \n        \n      \n    \n\n\n\nplt.figure()\n(X & Y).sim(1000).plot()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-approximate-probability-collector",
    "href": "language-simulation-exercises.html#solution-to-exr-approximate-probability-collector",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.12 Solution to Exercise 3.12",
    "text": "5.12 Solution to Exercise 3.12\nPart 1\nSee previous solutions which discuss how to simulate \\((X, Y)\\) pairs.\nSimulate many \\((X, Y)\\) pairs, say 10000.\n\nTo approximate \\(\\textrm{P}(X = 2)\\): Divide the number of repetitions with \\(X = 2\\) by the total number of repetitions\nTo approximate \\(\\textrm{P}(Y = 1)\\): Divide the number of repetitions with \\(Y = 1\\) by the total number of repetitions\nTo approximate \\(\\textrm{P}(X = 2, Y = 1)\\): Divide the number of repetitions with \\(X = 2\\) and \\(Y=1\\) by the total number of repetitions\n\nPart 2\n\nP = BoxModel([1, 2, 3], size = 3)\n\ndef count_distinct(u):\n    return len(set(u))\n\nX = RV(P, count_distinct)\n\nY = RV(P, count_eq(1))\n\nx_and_y = (X & Y).sim(10000)\n\nx = x_and_y[0]\n\ny = x_and_y[1]\n\n\nx.count_eq(2) / x.count()\n\n0.6686\n\n\n\ny.count_eq(1) / x.count()\n\n0.4391\n\n\n\n((x == 2) * (y == 1)).sum() / x.count()\n\n0.2229\n\n\nPart 3\n\nx.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    10.115220.668630.2162Total1.0\n  \n\n\n\n\nplt.figure()\nx.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\ny.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    00.296910.439120.22530.039Total1.0\n  \n\n\n\n\nplt.figure()\ny.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nx_and_y.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    (1, 0)0.0762(1, 3)0.039(2, 0)0.2207(2, 1)0.2229(2, 2)0.225(3, 1)0.2162Total1.0\n  \n\n\n\n\nplt.figure()\nx_and_y.plot('tile')\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-approximate-probability-collector-b",
    "href": "language-simulation-exercises.html#solution-to-exr-approximate-probability-collector-b",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.13 Solution to Exercise 3.13",
    "text": "5.13 Solution to Exercise 3.13\nPart 1\nSee previous solutions which discuss how to simulate \\((X, Y)\\) pairs.\nSimulate many \\((X, Y)\\) pairs, say 10000.\n\nTo approximate \\(\\textrm{P}(X = 2)\\): Divide the number of repetitions with \\(X = 2\\) by the total number of repetitions\nTo approximate \\(\\textrm{P}(Y = 1)\\): Divide the number of repetitions with \\(Y = 1\\) by the total number of repetitions\nTo approximate \\(\\textrm{P}(X = 2, Y = 1)\\): Divide the number of repetitions with \\(X = 2\\) and \\(Y=1\\) by the total number of repetitions\n\nPart 2\n\nP = BoxModel([1, 2, 3], size = 3, probs = [0.1, 0.3, 0.6])\n\ndef count_distinct(u):\n    return len(set(u))\n\nX = RV(P, count_distinct)\n\nY = RV(P, count_eq(1))\n\nx_and_y = (X & Y).sim(10000)\n\nx = x_and_y[0]\n\ny = x_and_y[1]\n\n\nx.count_eq(2) / x.count()\n\n0.6471\n\n\n\ny.count_eq(1) / x.count()\n\n0.2484\n\n\n\n((x == 2) * (y == 1)).sum() / x.count()\n\n0.1374\n\n\nPart 3\n\nx.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    10.241920.647130.111Total1.0\n  \n\n\n\n\nplt.figure()\nx.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\ny.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    00.72310.248420.027830.0008Total1.0\n  \n\n\n\n\nplt.figure()\ny.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nx_and_y.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    (1, 0)0.2411(1, 3)0.0008(2, 0)0.4819(2, 1)0.1374(2, 2)0.0278(3, 1)0.111Total1.0\n  \n\n\n\n\nplt.figure()\nx_and_y.plot('tile')\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-approximate-probability-geometric",
    "href": "language-simulation-exercises.html#solution-to-exr-approximate-probability-geometric",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.14 Solution to Exercise 3.14",
    "text": "5.14 Solution to Exercise 3.14\nPart 1\nSee previous solutions for description of how to simulate values of \\(X\\).\nSimulate many values of \\(X\\) and summarize the simulate values and their relative frequencies to approximate the distribution of \\(X\\).\nTo approximate \\(\\textrm{P}(X  &gt; 3)\\): divide the number of repetitions with \\(X&gt;3\\) by the total number of repetitions.\nPart 2\n\np_success = 0.4\n\n# define a function that takes as an input a sequence of 0s and 1s (omega)\n# and returns when the first 1 occurs\ndef count_until_first_success(omega):\n    for i, w in enumerate(omega):\n        if w == 1:\n            return i + 1 # the +1 is for zero-based indexing\n\n# Either of the following probability spaces works        \n# P = Bernoulli(p_success) ** inf\nP = BoxModel([1, 0], probs = [p_success, 1 - p_success], size = inf)\n\nX = RV(P, count_until_first_success)\n\nx = X.sim(10000)\n\nx\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          02\n        \n        \n        \n          11\n        \n        \n        \n          22\n        \n        \n        \n          32\n        \n        \n        \n          41\n        \n        \n        \n          54\n        \n        \n        \n          64\n        \n        \n        \n          73\n        \n        \n        \n          86\n        \n        ......\n        \n          99993\n        \n        \n      \n    \n\n\n\nx.tabulate(normalize = True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    10.402320.238830.151240.081150.05460.031170.016980.009790.0064100.0033110.002120.0013130.0007140.0002150.0002160.0003180.0002190.0001200.0001......210.0001Total1.0\n  \n\n\n\n\nplt.figure()\nx.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nx.count_gt(3) / x.count()\n\n0.2077",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-approximate-probability-continuous-dice",
    "href": "language-simulation-exercises.html#solution-to-exr-approximate-probability-continuous-dice",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.15 Solution to Exercise 3.15",
    "text": "5.15 Solution to Exercise 3.15\nPart 1\nSee previous solutions for how to simulate \\((X, Y)\\) pairs.\nSimulate many \\((X, Y)\\) pairs, say 10000. To approximate:\n\n\\(\\textrm{P}(X &lt; 3.5)\\): divide number of repetitions with \\(X&lt;3.5\\) by the total number of repetitions\n\\(\\textrm{P}(Y &gt; 2.7)\\): divide number of repetitions with \\(Y&gt;2.7\\) by the total number of repetitions\n\\(\\textrm{P}(X &lt; 3.5, Y &gt; 2.7)\\): divide number of repetitions with \\(X&lt;3.5\\) and \\(Y&gt;2.7\\) by the total number of repetitions\n\nPart 2\nWe usually summarize simulated values of continuous random variables with histogram.\n\nP = Uniform(1, 4) ** 2\n\nX = RV(P, sum)\nY = RV(P, max)\n\nx_and_y = (X & Y).sim(10000)\n\nx = x_and_y[0]\n\ny = x_and_y[1]\n\n\nplt.figure()\nx.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure()\ny.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure()\nx_and_y.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure()\nx_and_y.plot('hist')\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-approximate-moe-birthday",
    "href": "language-simulation-exercises.html#solution-to-exr-approximate-moe-birthday",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.16 Solution to Exercise 3.16",
    "text": "5.16 Solution to Exercise 3.16\nSimulate 10000 repetitions and find the relative frequency of repetitions on which at least 2 people share a birthday. The margin of error is \\(1/\\sqrt{10000} = 0.01\\)\n\nn = 30\n\nP = BoxModel(list(range(365)), size = n)\n\ndef count_distinct(u):\n  return len(set(u))\n\nX = RV(P, count_distinct)\n\nB = (X &lt; n)\n\np_hat = B.sim(10000).count_eq(True) / 10000\n\np_hat\n\n0.7001\n\n\nWe estimate (with 95% confidence) that the probability that at least two people in a group of 30 share the same birthday is 0.7 with a margin of error of 0.01. In other words, we estimate (with 95% confidence) that the probability that at least two people in a group of 30 share the same birthday is between 0.69 and 0.71.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-approximate-moe-collector",
    "href": "language-simulation-exercises.html#solution-to-exr-approximate-moe-collector",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.17 Solution to Exercise 3.17",
    "text": "5.17 Solution to Exercise 3.17\nThe margin of error for any single probability would be \\(1/\\sqrt{10000} = 0.01\\), but since we are estimating many probabilities simultaneously we would use a margin of error of \\(2\\times 0.01\\). For example, if the simulated relative frequency of \\(X = 2\\) is 0.662, then we approximate \\(\\textrm{P}(X = 2)\\) to be 0.662 with a margin of error of 0.02; in other words, we estimate that \\(\\textrm{P}(X = 2)\\) is between 0.642 and 0.682.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-ev-class-size",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-ev-class-size",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.18 Solution to Exercise 3.18",
    "text": "5.18 Solution to Exercise 3.18\n\n\\(X\\) takes the value 210 with probability 1/5 and 35 with probability 4/5.\n\\(\\text{E}(X) = 210(1/5) + 35(4/5)=70\\) is the average number of students per class from the instructors’ perspective. If we randomly select an instructor, record the number of students in the instructor’s class, and repeat, the long run average number of students will be 70.\n\\(\\text{P}(X = \\text{E}(X)) = \\text{P}(X = 70) = 0\\). No instructor has a class whose size is equal to the average class size (from the instructor’s perspective).\n\\(Y\\) takes the value 210 with probability 210/350 and 35 with probability 140/350.\n\\(\\text{E}(Y) = 210(210/350) + 35(140/350)=140\\) is the average number of students per class from the students’ perspective. If we randomly select a student, record the number of students in the selected student’s class, and repeat, the long run average number of students will be 140.\n\\(\\text{P}(Y = \\text{E}(Y)) = \\text{P}(Y = 140) = 0\\). No student is in a class whose size is equal to the average class size (from the students’ perspective).\nColleges usually report average class size from the instructor/class perspective, which in this case would be 70 students. From the students’ perspective, the average class size is not even close to 70! In fact, it’s twice that size. Some students (140 of them, which is 40% of the total of 350 students) have the benefit of a small class size of 35. But most students (210 of them, which is 60% of the students) are stuck in a large class of 210 students. In other words, most students would be pretty seriously misled if they chose this college based on the advertised average class size of 35 students per class. From the students’ perspective, it seems that 140 is the more relevant average to report. However, neither average really adequately represents what is happening here: there is wide variability in class sizes between large and small.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-ev-collector",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-ev-collector",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.19 Solution to Exercise 3.19",
    "text": "5.19 Solution to Exercise 3.19\nSee previous for solutions for how to simulate \\((X, Y)\\) pairs\nPart 1\nSimulate many \\((X, Y)\\) pairs, say 10000\n\nTo approximate \\(\\textrm{E}(X)\\): average the simulated \\(X\\) values (sum the 10000 simulated \\(X\\) values and divide by 10000)\nTo approximate \\(\\textrm{E}(Y)\\): average the simulated \\(Y\\) values (sum the 10000 simulated \\(Y\\) values and divide by 10000)\nTo approximate \\(\\textrm{E}(X^2)\\): average the simulated \\(X^2\\) values (square each simulated \\(X\\) value then sum the 10000 \\(X^2\\) values and divide by 10000)\nTo approximate \\(\\textrm{E}(XY)\\): average the simulated \\(XY\\) values (for each \\((X, Y)\\) pair compute the product \\(XY\\) then sum the 10000 \\(XY\\) values and divide by 10000)\n\nPart 2\n\nP = BoxModel([1, 2, 3], size = 3)\n\ndef count_distinct(u):\n    return len(set(u))\n\nX = RV(P, count_distinct)\n\nY = RV(P, count_eq(1))\n\nx_and_y = (X & Y).sim(10000)\n\nx = x_and_y[0]\n\ny = x_and_y[1]\n\n\nx.mean()\n\n2.0951\n\n\n\ny.mean()\n\n1.0078\n\n\n\n(x ** 2).mean()\n\n4.7091\n\n\n\n(x * y).mean()\n\n2.106",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-ev-continuous-dice",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-ev-continuous-dice",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.20 Solution to Exercise 3.20",
    "text": "5.20 Solution to Exercise 3.20\nSee previous for solutions for how to simulate \\((X, Y)\\) pairs\nPart 1\nSimulate many \\((X, Y)\\) pairs, say 10000\n\nTo approximate \\(\\textrm{E}(X)\\): average the simulated \\(X\\) values (sum the 10000 simulated \\(X\\) values and divide by 10000)\nTo approximate \\(\\textrm{E}(Y)\\): average the simulated \\(Y\\) values (sum the 10000 simulated \\(Y\\) values and divide by 10000)\nTo approximate \\(\\textrm{E}(X^2)\\): average the simulated \\(X^2\\) values (square each simulated \\(X\\) value then sum the 10000 \\(X^2\\) values and divide by 10000)\nTo approximate \\(\\textrm{E}(XY)\\): average the simulated \\(XY\\) values (for each \\((X, Y)\\) pair compute the product \\(XY\\) then sum the 10000 \\(XY\\) values and divide by 10000)\n\nPart 2\n\nP = Uniform(1, 4) ** 2\n\nX = RV(P, sum)\n\nY = RV(P, max)\n\nx_and_y = (X & Y).sim(10000)\n\nx = x_and_y[0]\n\ny = x_and_y[1]\n\n\nx.mean()\n\n4.982114938139927\n\n\n\ny.mean()\n\n2.995121130334481\n\n\n\n(x ** 2).mean()\n\n26.318816096236354\n\n\n\n(x * y).mean()\n\n15.673362365692446",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-variance-collector",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-variance-collector",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.21 Solution to Exercise 3.21",
    "text": "5.21 Solution to Exercise 3.21\nSee previous parts for how to simulate \\(X\\) values.\nPart 1\nTo approximate \\(\\textrm{Var}(X)\\):\n\nSimulate many \\(X\\) values and compute the average of the simulated values\nSquare each simulated \\(X\\) value and compute the average of the squared values\nSubrtract the square of the average from part a) from the average of the squares in part b).\n\nPart 2\n\nP = BoxModel([1, 2, 3], size = 3)\n\ndef count_distinct(u):\n    return len(set(u))\n\nX = RV(P, count_distinct)\n\nx = X.sim(10000)\n\n\n(x ** 2).mean() - (x.mean()) ** 2\n\n0.3218219900000001\n\n\n\nx.var()\n\n0.32182198999999995\n\n\n\nx.sd()\n\n0.5672935659779688",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-variance-continuous-dice",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-variance-continuous-dice",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.22 Solution to Exercise 3.22",
    "text": "5.22 Solution to Exercise 3.22\nPart 1\n\nP = Uniform(1, 4) ** 2\n\nX = RV(P, sum)\n\nY = RV(P, max)\n\nx_and_y = (X & Y).sim(10000)\n\nx = x_and_y[0]\n\ny = x_and_y[1]\n\n\nx.plot()\n\n\n\n\n\n\n\n\n\ny.plot()\n\n\n\n\n\n\n\n\nPart 2\n\\(X\\) will have larger standard deviation than \\(Y\\). The values of \\(X\\) range from 2 to 8 while the values of \\(Y\\) only range from 1 to 4. Also, the values of \\(Y\\) tend to be closer to their mean (around 3.0) than the values of \\(X\\) are to their mean (around 5).\nThe values of \\(X\\) can be anywhere from 0 to 3 units away from the mean of 5, but more values are closer than farther; we might estimate the SD to be less than 1.5. (Remember, the squaring then averaging then taking the square root makes it hard to guess the actual number)\nWe would estimate the SD of \\(Y\\) to be less that of \\(X\\), and maybe a little less than 1, since a large percentage of values are between 2 and 4 (hence less than 1 unit away from the mean).\nPart 3\nTo approximate \\(\\textrm{Var}(X)\\):\n\nSimulate many \\(X\\) values and compute the average of the simulated values\nSquare each simulated \\(X\\) value and compute the average of the squared values\nSubrtract the square of the average from part a) from the average of the squares in part b).\n\nTake the square of the variance to approximate the standard deviation.\nSimilarly for \\(Y\\).\nPart 4\n\nx.var(), x.sd()\n\n(1.497811006180361, 1.2238508921352964)\n\n\n\ny.var(), y.sd()\n\n(0.4958277228123584, 0.7041503552596976)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-covariance-collector",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-covariance-collector",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.23 Solution to Exercise 3.23",
    "text": "5.23 Solution to Exercise 3.23\nTBA",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-covariance-1",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-covariance-1",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.24 Solution to Exercise 3.24",
    "text": "5.24 Solution to Exercise 3.24\nTBA",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-condition-collector",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-condition-collector",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.25 Solution to Exercise 3.25",
    "text": "5.25 Solution to Exercise 3.25\nApproximate the conditional distribution of \\(Y\\) given \\(X=1\\):\n\nSimulate \\((X, Y)\\) pair\nIf \\(X\\neq1\\) discard the repetition, otherwise keep\nRepeat until 10000 repetitions with \\(X=1\\) are obtained\nSummarize the simulated values of \\(Y\\) from these repetitions to approximate the conditional distribution of \\(Y\\) given \\(X = 1\\)\nTo approximate \\(\\textrm{P}(Y = 0 | X=1)\\) count the number of repetitions with \\(Y=0\\) and divide by 10000 (remember, all of the repetitions have \\(X = 1\\))\n\nApproximate the conditional distribution of \\(X\\) given \\(Y=0\\) similarly, with a different simulation of 10000 \\((X, Y)\\) pairs that satisfy \\(Y=0\\).\n\nP = BoxModel([1, 2, 3], size = 3)\n\ndef count_distinct(u):\n    return len(set(u))\n\nX = RV(P, count_distinct)\n\nY = RV(P, count_eq(1))\n\n\ny_given_Xeq1 = ( Y | (X == 1) ).sim(10000)\n\n\ny_given_Xeq1.tabulate()\n\n\n  \n    Value\n    Frequency\n  \n  \n    0659733403Total10000\n  \n\n\n\n\ny_given_Xeq1.tabulate(normalize=True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    00.659730.3403Total1.0\n  \n\n\n\n\nplt.figure()\ny_given_Xeq1.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nx_given_Yeq0 = ( X | (Y == 0) ).sim(10000)\n\n\nx_given_Yeq0.tabulate()\n\n\n  \n    Value\n    Frequency\n  \n  \n    1246927531Total10000\n  \n\n\n\n\nx_given_Yeq0.tabulate(normalize=True)\n\n\n  \n    Value\n    Relative Frequency\n  \n  \n    10.246920.7531Total1.0\n  \n\n\n\n\nplt.figure()\nx_given_Yeq0.plot()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-condition-dartboard",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-condition-dartboard",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.26 Solution to Exercise 3.26",
    "text": "5.26 Solution to Exercise 3.26\nIn the code below\n\nUniform(0, 12) ** 2 corresponds to the two spins\nBoxModel([-1, 1], size = 2) corresponds to the two coin flips\nUniform(0, 12) ** 2 * BoxModel([-1, 1], size = 2) simulates a pair which we unpack and define as RVs U, F, but U is itself a pair and so is F.\nU[0] is the first spin and F[0] is the first flip.\n\n\nU, F = RV(Uniform(0, 12) ** 2 * BoxModel([-1, 1], size = 2))\n\nX = U[0] * F[0]\n\nY = U[1] * F[1]\n\nR = sqrt(X ** 2 + Y ** 2)\n\n( (U & F & X & Y & R) | (R &lt; 12) ).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0((5.489057278813679, 6.146036894862179), (-1, -1), -5.489057278813679, -6.146036894862179, 8.2403591...\n        \n        \n        \n          1((1.9020643610630241, 1.8467586027355707), (-1, 1), -1.9020643610630241, 1.8467586027355707, 2.65110...\n        \n        \n        \n          2((4.873515695062407, 9.76931045341069), (1, -1), 4.873515695062407, -9.76931045341069, 10.9174439300...\n        \n        \n        \n          3((1.3910273455362168, 5.390358519624337), (1, 1), 1.3910273455362168, 5.390358519624337, 5.566949078...\n        \n        \n        \n          4((5.957314620388644, 7.897016170340516), (1, -1), 5.957314620388644, -7.897016170340516, 9.892040329...\n        \n        \n        \n          5((0.8442826667034242, 7.867527614195106), (1, 1), 0.8442826667034242, 7.867527614195106, 7.912698906...\n        \n        \n        \n          6((4.798900488891836, 3.55507020839416), (-1, -1), -4.798900488891836, -3.55507020839416, 5.972266746...\n        \n        \n        \n          7((1.3114212632316629, 11.798851499353837), (-1, -1), -1.3114212632316629, -11.798851499353837, 11.87...\n        \n        \n        \n          8((4.159419160247561, 4.831599668696406), (-1, -1), -4.159419160247561, -4.831599668696406, 6.3753527...\n        \n        ......\n        \n          9((7.972340824102731, 7.013822406957041), (-1, 1), -7.972340824102731, 7.013822406957041, 10.61847083...\n        \n        \n      \n    \n\n\n\nplt.figure()\n( (X & Y) | (R &lt; 12) ).sim(1000).plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nr = ( R | (R &lt; 12) ).sim(10000)\n\nplt.figure()\nr.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nr.count()\n\n10000\n\n\n\nr.count_lt(1) / r.count()\n\n0.007\n\n\n\nr.count_gt(11) / r.count()\n\n0.1633\n\n\n\nr.mean()\n\n8.04111908299944\n\n\n\nr.sd()\n\n2.8140732920011375",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-simulation-condition-continuous-dice",
    "href": "language-simulation-exercises.html#solution-to-exr-simulation-condition-continuous-dice",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.27 Solution to Exercise 3.27",
    "text": "5.27 Solution to Exercise 3.27\nWe condition on \\(X\\) being “close to” 3.5, say within 0.1 of 3.5\n\nP = Uniform(1, 4) ** 2\n\nX = RV(P, sum)\n\nY = RV(P, max)\n\n\n( (X & Y) | (abs(X - 3.5) &lt; 0.1) ).sim(10)\n\n\n      \n        Index\n        Result\n      \n      \n        \n        \n          0(3.436835135191134, 1.9178643496623649)\n        \n        \n        \n          1(3.5055159811649883, 2.1185250362751407)\n        \n        \n        \n          2(3.532305334831871, 2.165374289210652)\n        \n        \n        \n          3(3.5122091110004128, 2.077348801207793)\n        \n        \n        \n          4(3.5838021063949923, 2.280703473683216)\n        \n        \n        \n          5(3.5416641842818217, 1.8015760552839104)\n        \n        \n        \n          6(3.4283174569075876, 1.9389590300039234)\n        \n        \n        \n          7(3.4682620901263554, 2.347235200556181)\n        \n        \n        \n          8(3.5204033906988377, 2.225550004794287)\n        \n        ......\n        \n          9(3.42230585234324, 2.2138723488839176)\n        \n        \n      \n    \n\n\n\ny_given_Xeq3p5 = ( Y | (abs(X - 3.5) &lt; 0.1) ).sim(10000)\n\nplt.figure()\ny_given_Xeq3p5.plot()\nplt.show()\n\n\n\n\n\n\n\n\nThe true conditional distribution of \\(Y\\) given \\(X=3.5\\) is Uniform(1.75, 2.5). We see that the approximate distribution is a little rough at the boundaries (near 1.75 and 2.5), because of the “close to 3.5” approximation. But we would not be able to simulate the conditional distribution given \\(X=3.5\\) without more sophisticated methods.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-simulation-exercises.html#solution-to-exr-sensitivity-dartboard-bvn",
    "href": "language-simulation-exercises.html#solution-to-exr-sensitivity-dartboard-bvn",
    "title": "5  Chapter 3 Exercise Solutions",
    "section": "5.28 Solution to Exercise 3.28",
    "text": "5.28 Solution to Exercise 3.28\n\nsigma = 1\n\nX, Y = RV(Normal(0, sigma) ** 2)\n\nR = sqrt(X ** 2 + Y ** 2)\n\nplt.figure()\n(X & Y).sim(1000).plot()\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure()\nR.sim(10000).plot()\nplt.show()\n\n\n\n\n\n\n\n\n\ndef dartboard_sim(sigma):\n  X, Y = RV(Normal(0, sigma) ** 2)\n  \n  R = sqrt(X ** 2 + Y ** 2)\n  \n  r = R.sim(10000)\n  \n  return r.count_lt(1) / r.count(), r.count_gt(12) / r.count(), r.mean()\n\n\nsigmas = np.arange(0.1, 5.1, 0.1)\n\nresults = np.array([dartboard_sim(sigma) for sigma in sigmas])\n\nplt.figure()\nplt.plot(sigmas, results[:, 0])\nplt.xlabel('sigma')\nplt.ylabel('Approximate P(X  &lt; 1)')\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure()\nplt.plot(sigmas, results[:, 1])\nplt.xlabel('sigma')\nplt.ylabel('Approximate P(X  &gt; 12)')\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure()\nplt.plot(sigmas, results[:, 2])\nplt.xlabel('sigma')\nplt.ylabel('Approximate E(X)')\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Chapter 3 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "(APPENDIX) Appendix",
    "section": "",
    "text": "TBA",
    "crumbs": [
      "(APPENDIX) Appendix"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aldous, David. 2023. “Forty Thousand Coin Tosses Yield Ambiguous\nEvidence for Dynamical Bias.” 2023. https://www.stat.berkeley.edu/~aldous/Real-World/coin_tosses.html.\n\n\nBarclay, Scott, Rex Brown, Clinton III, Cameron Peterson, and Lawrence\nPhillips. 1977. “Handbook for Decision Analysis,”\nSeptember, 284.\n\n\nBartoš, František, Alexandra Sarafoglou, Henrik R. Godmann, Amir\nSahrani, David Klein Leunk, Pierre Y. Gui, David Voss, et al. 2024.\n“Fair Coins Tend to Land on the Same Side They Started: Evidence\nfrom 350,757 Flips.” https://arxiv.org/abs/2310.04153.\n\n\nDavid, F. N. 1955. “Studies in the History of Probability and\nStatistics i. Dicing and Gaming (a Note on the History of\nProbability).” Biometrika 42 (1/2): 1–15. http://www.jstor.org/stable/2333419.\n\n\nDiaconis, Persi, Susan Holmes, and Richard Montgomery. 2007.\n“Dynamical Bias in the Coin Toss.” SIAM Review 49\n(2): 211–35. http://www.jstor.org/stable/20453950.\n\n\nDiaconis, Persi, and Brian Skrms. 2018. Ten Great Ideas about\nChance. Princeton University Press. http://www.jstor.org/stable/j.ctvc77m33.\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007. Statistics. 4th ed. W.W. Norton; Company.\n\n\nGilovich, Thomas D., Robert P. Vallone, and Amos Tversky. 1985.\n“The Hot Hand in Basketball: On the Misperception of Random\nSequences.” Cognitive Psychology 17 (3): 295–314.\nhttps://doi.org/https://doi.org/10.1016/0010-0285(85)90010-6.\n\n\nKahneman, Daniel. 2012. Thinking, Fast and Slow. London:\nPenguin.\n\n\nMiller, Joshua B., and Adam Sanjurjo. 2018a. “Surprised by the Hot\nHand Fallacy? A Truth in the Law of Small Numbers.”\nEconometrica 86 (6): 2019–47. https://doi.org/10.3982/ECTA14943.\n\n\n———. 2018b. “A Cold Shower for the Hot Hand Fallacy: Robust\nEvidence That Belief in the Hot Hand Is Justified.” OSF\nPreprints. https://doi.org/10.31219/osf.io/pj79r.\n\n\n———. 2018c. “Is It a Fallacy to Believe in the Hot Hand in the NBA\nThree-Point Contest?” OSF Preprints. https://doi.org/10.31219/osf.io/dmksp.\n\n\nMurray, Daniel B., and Scott W. Teare. 1993. “Probability of a\nTossed Coin Landing on Edge.” Phys. Rev. E 48 (October):\n2547–52. https://doi.org/10.1103/PhysRevE.48.2547.\n\n\nRoss, Kevin, and Dennis L. Sun. 2019. “Symbulate: Simulation in\nthe Language of Probability.” Journal of Statistics\nEducation 27 (1): 12–28. https://doi.org/10.1080/10691898.2019.1600387.\n\n\nTversky, Amos, and Daniel Kahneman. 1982. “Judgments of and by\nRepresentativeness.” In Judgment Under Uncertainty:\nHeuristics and Biases, edited by Daniel Kahneman, Paul Slovic, and\nAmosEditors Tversky, 84–98. Cambridge University Press. https://doi.org/10.1017/CBO9780511809477.007.",
    "crumbs": [
      "References"
    ]
  }
]