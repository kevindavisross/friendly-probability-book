[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Friendly Introduction to Probability",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#why-study-probability-and-simulation",
    "href": "index.html#why-study-probability-and-simulation",
    "title": "A Friendly Introduction to Probability",
    "section": "Why study probability and simulation?",
    "text": "Why study probability and simulation?\nWhy study probability?\n\nProbability is the study of uncertainty, and life is uncertain\nProbability is used in a wide variety of fields, including: statistics, physics, engineering, biology, medicine, finance, actuarial science, political science, law, sports , …\nMany topics and problems in probability are frequently misunderstood and sometimes counter intuitive, so it’s worthwhile to take a careful study\n“Probabilistic thinking” is an important component of statistical literacy (e.g. how to assess risk when making decisions)\nProbability provides the foundation for many important statistical concepts and methods such as p-values and confidence intervals\n\nWhy use simulation to study probability?\n\nMany concepts encountered in probability can seem esoteric; simulation helps make them more concrete.\nSimulation provides an effective tool for analyzing probability models and for exploring effects of changing assumptions\nSimulation can be used to check analytical solutions\nSimulation is often the best or only method for investigating many problems which are too complex to solve analytically\nSimulation allows for statistical approaches to solving probability problems (e.g., treat the simulated values as data to summarize and analyze)\nSimulation-based reasoning is an important component of statistical literacy (e.g., understanding a p-value via simulation)\nMany statistical procedures employ simulation-based methods (e.g. bootstrapping)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#learn-by-doing",
    "href": "index.html#learn-by-doing",
    "title": "A Friendly Introduction to Probability",
    "section": "Learn by doing",
    "text": "Learn by doing\n\n\n\n\n\n\nThere are many examples in this book. Examples are used to both motivate new topics and to help you practice your understanding of the material. You should attempt the examples on your own before reading the solutions. To encourage you to do so, the solutions have been hidden.\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\nYou can reveal the solution by clicking on the “Solution (click to expand)” button.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#dont-do-what-donny-dont-does",
    "href": "index.html#dont-do-what-donny-dont-does",
    "title": "A Friendly Introduction to Probability",
    "section": "Don’t do what Donny Don’t does",
    "text": "Don’t do what Donny Don’t does\nSome of the examples in this book feature a character named Donny Don’t. The moral of these examples is (usually) “Don’t do what Donny Don’t does”. (This is a Simpson’s reference.) Donny represents a student who makes many of the mistakes commonly made by students studying probability. The idea of these problems is for you to learn from the common mistakes that Donny makes, by identifying why he is wrong and by helping him understand and correct his mistakes. But be careful: sometimes Donny is right!",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "A Friendly Introduction to Probability",
    "section": "Learning objectives",
    "text": "Learning objectives\nAt the completion of this book, you should be able to:\n\nInterpret conditional and unconditional probabilities and expected values\nIdentify coherent probability models, events and random variables\nApply common probability models in real contexts\nDesign simulation studies to investigate random phenomena\nAnalyze simulation results\nSolve probability problems using mathematical properties and tools\nDescribe distributions of random variables\nConstruct representations of distributions",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#symbulate",
    "href": "index.html#symbulate",
    "title": "A Friendly Introduction to Probability",
    "section": "Symbulate",
    "text": "Symbulate\nThis book uses the Python package Symbulate which provides a user friendly framework for conducting simulations involving probability models. The syntax of Symbulate reflects the “language of probability” and makes it intuitive to specify, run, analyze, and visualize the results of a simulation. In Symbulate, probability spaces, events, random variables, and random processes are symbolic objects which can be manipulated, independently of their simulated realizations. Symbulate’s consistency with the mathematics of probability reinforces understanding of probabilistic concepts. The article (Ross and Sun 2019) discusses Symbulate and its features in more detail.\nThe best way to interact with Symbulate is through Google Colab or Jupyter notebooks. A notebook is organized by cells which contain text or code that can be run interactively with output displayed after the cell.\nSymbulate can be run online in a Colab notebook by including the following line in the first cell.\n\npip install git+https://github.com/kevindavisross/symbulate\n\nSymbulate can also be used in RMarkdown or Quarto documents, if you install the package on your device. To install Symbulate on your own computer, it is recommended that you first install the Anaconda distribution, which is a Python environment with many scientific packages installed (including all of the packages that Symbulate is built on). After installing Anaconda, you can install Symbulate using the pip command above.\nYou should always include the following command once in each notebook to import Symbulate during a Python session.\n\nfrom symbulate import *\n\nThe Symbulate command plot() produces graphics. These graphics can be customized (by changing axis limits, adding titles, legends, etc) using Matplotlib, and in particular the pyplot method, which can be imported by including the lines\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nColab or Jupyter notebooks provide a natural interface for Symbulate. The code in this book matches as closely as possible the commands that would be entered into cells in a notebook. However, certain commands that appear throughout the book are needed only to properly produce the output in this book, and not if working directly in notebooks (e.g., some print statements, instances of plt.figure() or plt.show())",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "A Friendly Introduction to Probability",
    "section": "About this book",
    "text": "About this book\nThis book was created with Quarto.\n\n\n\n\nRoss, Kevin, and Dennis L. Sun. 2019. “Symbulate: Simulation in the Language of Probability.” Journal of Statistics Education 27 (1): 12–28. https://doi.org/10.1080/10691898.2019.1600387.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "literacy-probability.html",
    "href": "literacy-probability.html",
    "title": "1  What is Probability?",
    "section": "",
    "text": "1.1 Randomness\nWe hear the word “probability” often. Here are just a few quotes from recent online articles which mention probability.\nYou have some familiarity with the words “probability”, “chance”, “odds”, or “likelihood” from everyday life. But what do we really mean when talk about “probability”?\nThis chapter provides a brief but non-technical introduction to randomness and probability. Many of the topics introduced in this chapter will be covered in much more detail in later chapters.\nA wide variety of situations involve probability. Consider just a few examples.\nThe subject of probability concerns random phenomena.\nSome phenomena involve physical randomness, like flipping coins, rolling dice, drawing Powerballs at random from a bin, or random digit dialing. In many other situations randomness just vaguely reflects uncertainty. We will refer to as “random” any scenario that involves a reasonable degree of uncertainty.\nIn this book, “random” and “uncertain” are synonyms. Unfortunately, some of the everyday meanings of “random”, like “haphazard” or “unexpected”, are contrary to what we mean by “random” in this book. For example, we would consider Steph Curry attempting a free throw to be a random phenomenon because we’re not certain if he’ll make it or miss it; but we would not consider this process to be haphazard or unexpected.\nRandom does not necessarily mean equally likely. In a random phenomenon, certain outcomes or events might be more or less likely than others. For example,\nUncertainty is not something to be feared, and randomness is often desirable. In particular, many statistical applications often employ the planned use of randomness with the goal of collecting “good” data. For example,",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-randomness",
    "href": "literacy-probability.html#sec-randomness",
    "title": "1  What is Probability?",
    "section": "",
    "text": "The probability that you roll doubles in a turn of a board game.\nThe probability you win the next Powerball lottery if you purchase a single ticket, 4-8-15-16-42, plus the Powerball number, 23.\nThe probability that a randomly selected Cal Poly student is a California resident.\nThe probability that the high temperature in San Luis Obispo, CA tomorrow is above 90 degrees F.\nThe probability that Hurricane Martin makes landfall in the U.S in 2028.\nThe probability that the Philadelphia Eagles win the next Superbowl.\nThe probability that the Republican candidate wins the 2032 U.S. Presidential Election.\nThe probability that extraterrestrial life currently exists somewhere in the universe.\nThe probability that Alexander Hamilton actually wrote 51 of The Federalist Papers. (The papers were published under a common pseudonym and authorship of some of the papers is disputed.)\nThe probability that you ate an apple on April 17, 2019.\n\n\n\n\n\n\n\n\nExample 1.1 What is one feature that all of the situations have in common? How are the situations above similar, and how are they different? Is the interpretation of “probability” the same in all situations? The goal here is to just think about these situations, and not to compute any probabilities (or to even think about how you would).\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.1. This example is intended to motivate discussion, so you might have thought of some other ideas we don’t address here. That’s good! And some of the things you considered might come up later in the book. Here are a few observations.\nThe one feature that all of the situations have in common is uncertainty. Sometimes the uncertainty arises from a physical phenomenon that can result in multiple potential outcomes, like rolling dice or drawing the winning Powerball number. In other cases, there is uncertainty because there will be only one outcome but it is in the future, like tomorrow’s high temperature or the result of the next Superbowl. But there can also be uncertainty about the past: there are some Federalist papers for which the author is unknown, and you probably don’t know for sure whether or not you ate an apple on April 17, 2019.\nWhenever there is uncertainty, it is reasonable to consider the relative likelihood or plausibility of possibilities. For example, even though you don’t know for certain whether you ate an apple on April 17, 2019, you might think the probability is high if you’re usually an apple-a-day person (or you were in 2019). We don’t know for sure what team will win the next Superbowl, but we might think that the Eagles are more likely than the Cleveland Brows to be the winner.\nWhile all of the situations in this example involve uncertainty, it seems that there are different “types” of uncertainty. Even though we don’t know which side a die will land on, the notion of “fairness” implies that the sides are “equally likely”. Likewise, there are some rules to how the Powerball drawing works, and it seems like these rules should determine the probability of drawing that particular winning number.\nHowever, there aren’t any specific “rules of uncertainty” that govern whether or not you ate an apple on April 17, 2019. You either did or you didn’t, but that doesn’t mean these two possibilities are necessarily equally likely or plausible. Regarding the Superbowl, of course there are rules that govern the NFL season and playoffs, but there are no “rules of uncertainty” that tell us precisely how likely any particular team is to win any particular game, let alone how likely a team is to advance to and win the Superbowl.\nIt also seems that there are different interpretations of probability. Given that a six-sided die is fair, we might all agree that the probability that it lands on any particular side is 1/6. Similarly, given the rules of the Powerball lottery, we might all agree on the probability that a drawing results in a particular winning number. However, there isn’t necessarily consensus about what the high temperature will be in San Luis Obispo tomorrow; different weather prediction models, forecasters, or websites might provide different values for the probability that the high temperature will be above 90 degrees Fahrenheit. Similarly, Superbowl odds might vary by source. Situations like tomorrow’s weather or the Superbowl where there is no consensus about the “rules of uncertainty” require some subjectivity in determining probabilities.\nFinally, some of these situations are naturally repeatedable. We could (in principle) roll a pair of dice many times and see how often we get doubles, or repeat the Powerball drawing over and over to see how the winning numbers behave. However, many of these situations involve something that only happens once, like the next Superbowl, tomorrow, or April 17, 2019. Even when the phenomenon happens only once in reality, we can still develop models of what might happen if we were to hypothetically repeat the phenomenon many times. For example, meteorologists use historical data and meteorological models to forecast many potential paths of a hurricane.\n\n\n\n\n\n\nDefinition 1.1 A phenomenon is random if there are multiple potential possibilities, and there is uncertainty about which possibility is realized. Uncertainty is understood in broad terms, and in particular does not only concern future occurrences.\n\n\n\n\n\nAbout 84% of students at Cal Poly are California residents, so it’s more likely than not that a randomly selected Cal Poly student is a California resident.\nNot all NFL teams are equally likely to win the next Superbowl.\n\n\n\nRandom selection involves selecting a sample of individuals at random from a population (e.g., via random digit dialing), with the goal of selecting a representative sample.\n\nRandom assignment involves assigning individuals at random to groups (e.g., in a randomized experiment), with the goal of constructing groups that are similar in all aspects so that the effect of a treatment (like a new vaccine) can be isolated.\n\n\n1.1.1 Exercises\n\nExercise 1.1 For each of the following, provide examples of random phenomenon that fit the description. Try to think of examples that are interesting to you personally!\n\nJust two possible outcomes, but they are not equally likely.\nPhysically repeatable (at least in principle).\nWell defined “rules of randomness”.\nInvolves subjectivity in determining probabilities.\nInvolves uncertainty about the future.\nInvolves uncertainty about the present or past.\nAssociated with the planned use of randomness in a particular statistical study.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-interpretations",
    "href": "literacy-probability.html#sec-interpretations",
    "title": "1  What is Probability?",
    "section": "1.2 Interpretations of probability",
    "text": "1.2 Interpretations of probability\n\nThe probability of an event associated with a random phenomenon is a number in the interval \\([0, 1]\\) measuring the event’s likelihood, degree of uncertainty, or relative plausibility. A probability can take any value in the continuous scale from 0 to 1, and can be reported either as a decimal (e.g., 0.305) or as a percent (e.g., 30.5%).\n\nA few examples of probabilities:\n\nThe probability that a fair coin lands on heads 5 times in 10 flips is 0.246.\nA group of people all put their names in a hat for a Secret Santa gift exchange; the probability that at least one person in the group draws their own name is 0.632.\nThe probability that a randomly selected full term baby weighs more than 4000 grams at birth is 0.09.\nThe probability that a magnitude 5+ earthquake occurs somewhere in the world within the next 48 hours is 0.96.\nAccording to FiveThirtyEight as of Nov 8, 2016, the probability that Donald Trump would win the 2016 U.S. Presidential Election was 0.286.\n\nThroughout this book we will see many methods for computing and approximating probabilities such as these. But given the value of a probability, what does it mean? For example, what does it mean for there to be a “30% chance of rain tomorrow”? Just as there are various types of randomness, there are a few ways of interpreting probability, most notably, long run relative frequency and subjective probability.\n\n1.2.1 Long run relative frequency\nOne of the oldest documented1 problems in probability is the following: If three fair six-sided dice are rolled, what is more likely—a sum of 9 or a sum of 10? Let’s try to answer this question by simply rolling dice and seeing what happens. Roll three fair six-sided dice, find the sum, and repeat; then see how often we get a sum of 9 versus a sum of 10. Table 1.1 displays the results of a few repetitions. We encourage you to try this out on your own now; of course, your results will naturally be different from ours.\n\n\n\n\nTable 1.1: Results of 10 sets of three rolls of a fair six-sided die.\n\n\n\n\n\n\nRepetition\nFirst roll\nSecond roll\nThird roll\nSum\n\n\n\n\n1\n3\n6\n3\n12\n\n\n2\n1\n2\n4\n7\n\n\n3\n4\n2\n4\n10\n\n\n4\n2\n2\n1\n5\n\n\n5\n4\n6\n1\n11\n\n\n6\n5\n1\n2\n8\n\n\n7\n3\n1\n3\n7\n\n\n8\n5\n5\n6\n16\n\n\n9\n5\n6\n3\n14\n\n\n10\n4\n5\n2\n11\n\n\n\n\n\n\n\n\nA sum of 9 occurred in 0 repetitions and a sum of 10 occurred in 1 repetition. We see that a sum of 10 occurred more frequently than a sum of 9, but our results should not be very convincing. After all, we only performed 10 repetitions and your results are probably different than ours. We can get a much better picture by performing many, many repetitions. This would be a time consuming process by hand, but it’s quick and easy on a computer. We can have a computer simulate, say, one million repetitions—each repetition resulting in the sum of three rolls—to produce a table like Table 1.1 but with one million rows instead of 10, and then count how many repetitions result in each possible value of the sum. Figure 1.1 displays the results of such a computer simulation. We’ll see throughout the book how to conduct and analyze computer simulations like this; just focus on the process and results for now. A sum of 9 occurred in 115392 or 11.5% of the one million repetitions, and a sum of 10 occurred in 125026 or 12.5% of repetitions. The simulation results suggest that a sum of 10 is more likely to occur than a sum of 9, because a sum of 10 did occur more often than a sum of 9 when we rolled the dice many times. It seems reasonable to conclude that when rolling three fair six-sided dice the probability that the sum is 10 is greater than the probability that the sum is 9.\n\n\n\n\n\n\n\n\nFigure 1.1: Results of one million sets of three rolls of fair six-sided dice. Sets in which the sum of the dice is 9 (10) are represented by the orange (blue) spike.\n\n\n\n\n\nIn the dice rolling problem we assessed relative likelihoods of a sum of 9 or 10 by repeating the phenomenon many times. The sum of any single set of three rolls is uncertain, but over many sets of three rolls a clear pattern of which sums occur more frequently than others emerges in Figure 1.1. This is the idea behind the relative frequency interpretation of probability. We’ll investigate this idea further in the context of the most iconic random phenomenon: coin flipping.\nWe might all agree2 that the probability that a single flip of a fair coin lands on heads is 1/2, a.k.a., 0.5, a.k.a, 50%. There are only two outcomes, heads (H) and tails (T), and the notion of “fairness” implies that they should be equally likely, so we have a “50/50 chance” of heads. But how else can we interpret this 50%? As in the dice rolling problem, we can consider what would happen if we flipped the coin many times. Now, if we flipped the coin twice, we wouldn’t expect to necessarily see one head and one tail. But in many flips, we might expect to see heads on something close to 50% of flips.\nLet’s try this out. Table 1.2 displays the results of 10 flips of a fair coin. The first column is the flip number (first flip, second flip, and so on) and the second column is the result of the flip (H or T). The third column displays the running number of flips that result in H and the fourth column displays the running proportion of flips that result in H. For example, the first flip results in T so the running proportion of H after 1 flip is 0/1 = 0; the first two flips result in (T, H) so the running proportion of H after 2 flips is 1/2 = 0.5; the first three flips result in (T, H, H) so the running proportion of H after 3 flips is 2/3 = 0.667; and so on. Figure 1.2 plots the running proportion of H by the number of flips. We see that with just a small number of flips, the proportion of H fluctuates considerably and is not guaranteed to be close to 0.5. Of course, the results depend on the particular sequence of coin flips. We encourage you to flip a coin 10 times and compare your results.\n\n\n\n\nTable 1.2: Results and running proportion of H for 10 flips of a fair coin.\n\n\n\n\n\n\nFlip\nResult\nRunning count of H\nRunning proportion of H\n\n\n\n\n1\nT\n0\n0.000\n\n\n2\nH\n1\n0.500\n\n\n3\nH\n2\n0.667\n\n\n4\nH\n3\n0.750\n\n\n5\nT\n3\n0.600\n\n\n6\nT\n3\n0.500\n\n\n7\nT\n3\n0.429\n\n\n8\nT\n3\n0.375\n\n\n9\nT\n3\n0.333\n\n\n10\nH\n4\n0.400\n\n\n\n\n\n\n\n\n.\n\n\n\n\n\n\n\n\nFigure 1.2: Proportion of flips resulting in H versus number of flips for the 10 coin flips in Table 1.2\n\n\n\n\n\nAs in the dice rolling example, we shouldn’t be satisfied with the results of just 10 repetitions. Now we’ll flip the coin 90 more times for a total of 100 flips. Figure 1.3 (a) displays the results, while Figure 1.3 (b) also displays the results for 3 additional sets of 100 flips. The running proportion of H fluctuates considerably in the early stages, but settles down and tends to get closer to 0.5 as the number of flips increases. However, each of the four sets results in a different proportion of heads after 100 flips: 0.41 (gray), 0.49 (orange), 0.52 (blue), 0.53 (green). Even after 100 flips the proportion of flips that result in H isn’t guaranteed to be very close to 0.5.\n\n\n\n\n\n\n\n\n\n\n\n(a) One set of 100 flips.\n\n\n\n\n\n\n\n\n\n\n\n(b) Four sets of 100 flips.\n\n\n\n\n\n\n\nFigure 1.3: Running proportion of H versus number of flips for four sets of 100 coin flips.\n\n\n\nNow we’ll flip the coin 900 more times for a total of 1000 flips in each of the four sets. Figure 1.4 (a) displays the results, while Figure 1.4 (b) also displays the results for 3 additional sets of 1000 flips. Again, the running proportion fluctuates considerably in the early stages, but settles down and tends to get closer to 0.5 as the number of flips increases. Compared to the results after 100 flips, there is less variability between sets in the proportion of H after 1000 flips: 0.498 (gray), 0.485 (orange), 0.506 (blue), 0.462 (green). Now, even after 1000 flips the proportion of flips that result in H isn’t guaranteed to be exactly 0.5, but we see a tendency for the proportion to get closer to 0.5 as the number of flips increases.\n\n\n\n\n\n\n\n\n\n\n\n(a) One set of 1000 flips.\n\n\n\n\n\n\n\n\n\n\n\n(b) Four sets of 1000 flips.\n\n\n\n\n\n\n\nFigure 1.4: Running proportion of H versus number of flips for four sets of 1000 coin flips.\n\n\n\nIn a large number of flips of a fair coin we expect the proportion of flips which result in H to be close to 0.5, and the more flips there are the closer to 0.5 we expect the proportion to be. That is, the probability that a flip of a fair coin results in H, 0.5, can be interpreted as the long run proportion of flips that result in H, or in other words, the long run relative frequency of H.\n\nDefinition 1.2 The probability of an event associated with a random phenomenon can be interpreted as a long run proportion or long run relative frequency: the probability of the event is the proportion of repetitions on which the event would occur in a very large number of hypothetical repetitions of the random phenomenon.\n\nThe concept of long run relative frequency quantifies how often we would expect an event associated with a random phenomenon to occur if the phenomenon were repeated many, many times. The closer the probability is to 1, the more often we would expect the event to occur; the closer the probability is to 0, the less often we would expect the event to occur. Roughly, we would expect an event that has probability 0.9 to occur “90% of the time” in the long run.\nReturning to rolling three fair six-sided dice, we’ll see later that the probability of a sum of 9 is 0.116 (rounded to three decimal places) and the probability of a sum of 10 is 0.125 . Even without knowing how to compute these values we can interpret them as long run relative frequencies. The probability of 0.116 means that in 11.6% of sets of three rolls of fair six-sided dice the sum is 9. The random phenomenon involves a set of 3 rolls, so we consider many sets of 3 rolls, each set resulting in a sum which is either 9 or not. If we roll three fair six-sided dice and find the sum then repeat to get many sets of 3 rolls, we would expect the proportion of sets for which the sum is 9 to be close to 0.116. Indeed this is what we observe in the simulation summarized by Figure 1.1. Likewise, in 12.5% of sets of three rolls of fair six-sided dice the sum is 10. In this sense, a sum of 10 is more likely than a sum of 9; in the long run, a greater proportion of sets of three rolls result in a sum of 10 than a sum of 9.\n\n\n\n\n\n\n\nExample 1.2 In each of the following, write a clearly worded sentence interpreting the numerical value of the probability as a long run relative frequency in context. (Just take the numerical values—0.1, 0.078, 0.25, and 0.73—as given. We’ll see how to compute probabilities like these later.)\n\nThe probability that a roll of a fair ten-sided die lands on 1 is 0.1.\nThe probability that the largest of 5 rolls of a fair ten-sided die is at most 6 is 0.078.\nThe probability that two flips of a fair coin both land on H is 0.25.\nThe probability that in 100 flips of a fair coin the proportion of flips that land on H is between 0.45 and 0.55 is 0.73.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.2. Solution to Exercise 1.2\n\nAbout 10% of rolls of a fair ten-sided result in a roll of 1. The phenomenon is a roll of a far ten-sided die and the event of interest is whether the die lands on 1. If we roll a fair ten-sided die many, many times, we would expect the proportion of rolls that land on 1 to be close to 0.1.\nIn about 7.8% of sets of 5 rolls of a fair ten-sided die, the largest roll is at most 6. In other words, about 7.8% of sets of 5 rolls of a fair ten-sided die contain no rolls greater than 6. The phenomenon involves a set of 5 rolls of a ten-sided die, so we consider many sets of 5 rolls, each set resulting in a largest roll which is either at most 6 or not. (For example, if the 5 rolls are (4, 1, 3, 4, 2) then the largest roll is 4.) If we roll a fair ten-sided 5 times and find the largest roll then repeat to get many sets of 5 rolls, we would expect the proportion of sets for which the largest roll is at most 6 be close to 0.078.\nIn about 25% of sets of two fair coin flips, both flips in the set land on H. The phenomenon involves two flips of a coin, so we consider what would happen over many sets of two flips each.\nIn about 73% of sets of 100 fair coin flips, the proportion of H for the set is between 0.45 and 0.55. The phenomenon involves 100 coin flips, so we consider many sets of 100 coin flips, each set resulting in a proportion of H that is either between 0.45 and 0.55 or not. Imagine adding many more paths to Figure 1.3 (b), each corresponding to a set of 100 flips; we would expect 73% of paths to end in a value between 0.45 and 0.55 after 100 flips.\n\n\n\n\n\nThe relative frequency interpretation of probability is most natural in situations like coin flipping or dice rolling which we can actually physically repeat. In many contexts, the long run relative frequency interpretation, while still valid, is more conceptual and requires us to imagine many hypothetical repetitions of the random phenomenon.\n\n\n\n\n\n\n\nExample 1.3 The weather forecast calls for a 30% chance of rain in your city tomorrow. You ask Donny Don’t to interpret the 30% as a long run relative frequency. Donny says: “it will rain in 30% of the city tomorrow”. You ask him to elaborate; he says: “Well, there are many different locations in the city. In some of the locations it will rain, in some it won’t. It will rain in 30% of the locations, and not in the other 70%. That is, rain will cover 30% of the area of the city, and the other 70% won’t have rain.” Do you agree? If not, how would you interpret the 30% as a long run relative frequency?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.3. Solution to Example 1.3\nOne key to correctly interpreting probabilities is to consider the appropriate random phenomenon. Donny seems to think the random phenomenon involves selecting locations in the city. However, there is a 30% chance of rain in your city tomorrow, so the random phenomenon involves days. Yes, there is only one tomorrow, but there are—at least hypothetically—many days which have weather conditions similar to those forecast for tomorrow. On each of those days it either rains or not. What counts as rain? If we follow the U.S. National Weather Service, on any given day it rains in the city if there is accumulation over the day of at least 0.0254cm (0.01in) of rain at any point in the city. If we imagine manys days with weather conditions similar to those forecast for tomorrow, it will rain on 30% of these days, and on 70% of these days it won’t rain.\nOur interpretation also sheds light on another common misinterpretation. Namely, a 30% chance of rain does not mean “it will rain for 30% of the day tomorrow; that is, it will rain for 7.2 hours tomorrow”.\n\n\n\n\nA simulation involves an artificial recreation of the random phenomenon, usually using a computer. One implication of the relative frequency interpretation is that the probability of an event can be approximated by simulating the random phenomenon a large number of times and determining the proportion of simulated repetitions on which the event occurred. After many repetitions the relative frequency of the event will settle down to a single constant value, and that value is the approximately the probability of the event.\nOf course, the accuracy of simulation-based approximations of probabilities depends on how well the simulation represents the actual random phenomenon. Conducting a simulation can involve many assumptions which impact the results. Simulating many flips of a fair coin is one thing; simulating the evolution of meteorological conditions over time is an entirely different story.\n\n\n\n\n\n\n\nExample 1.4 In the first 7 games of his NBA career, Paolo Banchero attempted 60 free throws and successfully made 44. Donny Don’t says “the probability that Paolo Banchero successfully makes a free throw attempt is 44/60 = 0.733.” Do you agree? Explain.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.4. Donny is correctly computing a relative frequency, but he is confusing the short run with the long run. A probability is a long run relative frequency. The probability that Paolo Banchero successfully makes a free throw can be interpreted as the proportion of free throw attempts that he successfully makes over many attempts. The observed relative frequency of 0.733 is only an approximation of the long run probability. And with only 60 attempts, it’s not necessarily a good approximation of the long run (even if we ignore that players can get better or worse over time).\nThe same considerations apply to players with many more attempts. For example, Giannis Antetokounmpo has attempted over 5000 free throws in his career and successfully made about 70%. But 0.70 is still just an approximation of Antetokounmpo’s true free throw probability since the long run includes all future attempts as well (ignoring that players can get better or worse over time). The difference is that 0.70 is likely a much better estimate of Antetokounmpo’s true free throw probability than 0.733 is of Banchero’s.\n\n\n\n\nBe careful to distinguish between the short run and the long run. Observed relative frequencies based on past data (sometimes called “empirical probabilities”) are only short run approximations to theoretical probabilities which represent long run relative frequencies. The quality of the approximations depends on the extent to which what has happened is representative of all the possibilities that might happen.\nA simulation models the long run. A natural question is: “how many simulated repetitions are required to represent the long run?” We’ll investigate further later. For now we’ll just provide a very rough benchmark: we can generally expect the relative frequency based on 10000 independent repetitions to be within 0.01 of the corresponding probability.\nFinally, recall that contrary to colloquial uses of the word, random does not mean haphazard. Individual outcomes of a random phenomenon are uncertain, but the long run relative frequency interpretation implies a predictable pattern over a large number of (usually hypothetical) repetitions. For example, Figure 1.1 displays a clear distribution of the sum of the rolls of three fair six-sided dice after one million repetitions of the phenomenon. We don’t know what the sum will be when we roll the dice, but we can say that it’s equally likely to be 10 or 11, more likely to be 10 than 9, more likely to be 9 than 8, and so on. Also, we know that if we roll the dice many times, close to 12.5% of sets of three rolls will result in a sum of 10.\n\n\n1.2.2 Subjective probability\nThe long run relative frequency interpretation is most natural in repeatable situations like flipping coins, rolling dice, drawing Powerballs, or randomly selecting U.S. adults (e.g., via random digit dialing). In many other situations, it is difficult to conceptualize the long run. The next Superbowl will only be played once, the 2032 U.S. Presidential Election will only be conducted once (we hope), and there was only one April 17, 2019 on which you either did or did not eat an apple. While these situations are not naturally repeatable they still involve randomness (uncertainty) and it is still reasonable to assign probabilities. At this point in time we might think that the Philadelphia Eagles are more likely than the Cleveland Browns to win the next Superbowl and that a current U.S. Senator is more likely than Dwayne Johnson to win the U.S. 2032 Presidential Election. If you’ve always been an apple-a-day person, you might think there’s a good chance you ate one on April 17, 2019; if you’re allergic to apples, your probability might be close to 0. Even when an uncertain phenomenon is not naturally repeated, it is still reasonable to quantify the relative degree of likelihood or plausibility of related events.\nHowever, the meaning of probability does seem different in physically repeatable situations like coin flips than in single occurrences like the next Superbowl. Let’s switch sports and consider the World Series of Major League Baseball. Consider the 2022 World Series, which the Houston Astros won. As of June 17, 2022,\n\nAccording to FiveThirtyEight, the Los Angeles Dodgers had a 20% chance of winning the 2022 World Series, and the San Diego Padres had an 8% chance.\nAccording to FanGraphs, the Dodgers had a 12.4% chance of winning the 2022 World Series, and the Padres had a 9.9% chance.\nAccording to gambling site Odds Shark, the Dodgers had a 20% chance of winning the 2022 World Series, and the Padres had a 7.7% chance.\n\nEach source, as well as many others, assigned different probabilities to the Dodgers or Padres winning. Which source, if any, was “correct”?\nFor a fair coin flip, we could perform a simulation to verify that the probability that it lands on H is 0.5. Our simulation results would vary, but with enough repetitions we could all agree that the proportion of flips that land on H seems to be converging to 0.5. We could also agree on how to conduct the simulation: each repetition involves a fair coin flip. If we’re concerned about a particular coin being weighted or biased we can simulate the fair coin flip in some other way, such as writing H and T on two cards, shuffling well, and drawing a card. There is no ambiguity about the assumptions—two equally likely outcomes—and in the long run we would reach the same conclusion. That is, we can agree on the “rules” of a fair coin flip, and these rules determine a single value, 0.5, for the probability that it lands on H.\nNow consider a future World Series, say 2030. Even though the actual 2030 World Series will only happen once, we could still perform a simulation involving hypothetical repetitions. However, simulating the World Series involves first simulating the 2030 season to determine the playoff match ups, then simulating the playoffs to see which teams make the World Series, then simulating the World Series match up itself. And simulating the 2030 season involves simulating all the individual games. Even just simulating a single game involves many assumptions; differences in opinions with regards to these assumptions can lead to different probabilities. For example, on June 17, 2022, according to FiveThirtyEight the Dodgers had a 68% chance of beating the Cleveland Guardians in their game that day, but according to FanGraphs it was 66%. Even if the differences in probabilities between sources is small, many small differences over the course of the season could result in large differences in predictions for the World Series champion. (We’re not even considering uncertainty due to any changes in the rules of baseball, MLB, or the world between now and 2030.)\nUnlike physically repeatable situations such as flipping a coin, there is no single set of “rules” for conducting a simulation of a single baseball game between two teams, let alone a whole season of games or the World Series champion. Therefore, there is no single long run relative frequency that determines the probability that a certain team wins the World Series. Instead we consider subjective probability.\n\nDefinition 1.3 A subjective probability (a.k.a. personal probability) of an event associated with a random phenomenon is a number in [0, 1] representing the degree of likelihood, certainty, or plausibility a given individual assigns to the event.\n\nAs the name suggests, different individuals (or probabilistic models) might have different subjective probabilities for the same event. In contrast, in the long run relative frequency interpretation the probability of an event is agreed to be the single number that its long run relative frequency converges to.\nThink of subjective probabilities as measuring relative degrees of likelihood, uncertainty, or plausibility rather than long run relative frequencies. For example, in the FiveThirtyEight forecast, the Dodgers were about 2.5 times more likely to win the 2022 World Series than the Padres (\\(2.5 = 0.20 / 0.08\\)). Relative likelihoods can also be compared across different forecasts or scenarios. For example, FiveThirtyEight assessed that the Dodgers were about 1.6 (\\(1.6 = 0.20 / 0.124\\)) times more likely to win the World Series than FanGraphs did. Also, FiveThirtyEight believed that the likelihood that a fair coin lands on H is about 2.5 (\\(2.5 = 0.5 / 0.2\\)) times larger than the likelihood that the Dodgers would win the 2022 World Series.\n\n\n\n\n\n\n\nExample 1.5 Your favorite local weatherperson forecasts a 30% chance of rain tomorrow and a 60% chance of rain the next day in your city.\n\nExplain how these probabilities are subjective.\nYou ask Donny Don’t to interpret these values as relative degrees of likelihood. Donny says: “Well, 30% is not that big, so it’s not going to rain that hard tomorrow. Also, 60% is twice is big as 30%, so it’s going to rain twice as hard two days from now as it will tomorrow”. Do you agree? Explain.\nDonny says: “Can’t we just look at the data from all the days with weather conditions similar to the ones forecast for tomorrow, and see how often it rained on those days to find the probability of rain tomorrow? No subjectivity about that!” How would you respond?\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.5. \n\nWeather is complicated and depends on many factors. Different models for how meteorological conditions evolve over time based on different assumptions or data can provide different forecasts. One model might predict a 30% chance of rain tomorrow; another might say 25%. There is no one single agreed upon set of “rules”—model, assumptions, data—for forecasting the weather, and therefore there is not a single agreed upon value for the probability of rain tomorrow.\nProbabilities measure degree of uncertainty of whether or not it will rain rather than the severity of any rain. On any single day it either rains or doesn’t; we discussed what counts as rain in Example 1.3. It is two times more likely to rain two days from now than it is tomorrow. It doesn’t matter how hard it rains, if at all, either day. Looking at it another way: if there is a 30% chain of rain then there is a 70% chance that it does not rain tomorrow. Therefore, the weatherperson is more certain—in fact, 1.167 times more certain—that it will not rain tomorrow than they are that it will rain two days from now.\nDonny’s idea is not terrible, but there are still a few issues. First it’s much easier said than done to identify all the days with weather conditions similar to those forecast for tomorrow. There are many variables involved in the weather; which variables do we use and what counts as “similar”? There would still be subjective choices to be made in determining an appropriate reference group of days. Second, even if we identify an appropriate reference group, the relative frequency of rain still only provides an approximation of the probability of rain. The probability measures the degree of likelihood of rain tomorrow, which is a conceptually different quantity from the past frequency of rain on similar days. (We discussed related ideas in Example 1.4.) Finally, Donny has suggested one way of approximating the probability, but there are still many other reasonable approaches which might result in different probabilities.\n\n\n\n\n\nThe chance of rain in your city tomorrow and FiveThirtyEight’s MLB predictions are outputs of probabilistic forecasts. A probabilistic forecast combines observed data and statistical or mathematical models to make predictions. Rather than providing a single prediction such as “it will rain tomorrow” or “the Los Angeles Dodgers will win the 2022 World Series”, probabilistic forecasts provide a range of scenarios and their relative likelihoods. Such forecasts are subjective in nature, relying upon the data used and assumptions of the model. Changing the data or assumptions can result in different forecasts and probabilities. In particular, probabilistic forecasts are usually revised over time as more information becomes available.\nSubjective probabilities can be calibrated by weighing the relative favorability of different bets3, as in the following example.\n\n\n\n\n\n\n\nExample 1.6 What is your subjective probability that Professor Ross (the author) has a TikTok account? Consider the following two bets, and suppose you must choose only one.\n\nYou win $100 if Professor Ross has a TikTok account, and you win nothing otherwise.\nA box contains 40 green and 60 gold marbles that are otherwise identical. The marbles are thoroughly mixed and one marble is selected at random. You win $100 if the selected marble is green, and you win nothing otherwise.\n\n\nWhich of the above bets would you prefer? Or are you completely indifferent? What does this say about your subjective probability that Professor Ross has a Tik Tok account?\nIf you preferred bet B to bet A, consider bet C which has a similar setup to B but now there are 20 green and 80 gold marbles. Do you prefer bet A or bet C? What does this say about your subjective probability that Professor Ross has a Tik Tok account?\nIf you preferred bet A to bet B, consider bet D which has a similar setup to B but now there are 60 green and 40 gold marbles. Do you prefer bet A or bet D? What does this say about your subjective probability that Professor Ross has a Tik Tok account?\nContinue to consider different numbers of green and gold marbles. Can you zero in on your subjective probability?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.6. Since the bets all have the same payouts, you should prefer the one that gives you the greatest probability of winning!\n\nIf you choose bet B, the probability of winning is 0.4 (which we could verify with a simulation).\n\nIf you prefer bet B to bet A, then your subjective probability that Professor Ross has a TikTok account is less than 0.4.\nIf you prefer bet A to bet B, then your subjective probability that Professor Ross has a TikTok account is greater than 0.4.\nIf you’re indifferent between bets A and B, then your subjective probability that Professor Ross has a TikTok account is equal to 0.4.\n\n\nIf you choose bet C, the probability of winning is 0.2.\n\nIf you prefer bet C to bet A, then your subjective probability that Professor Ross has a TikTok account is less than 0.2.\nIf you prefer bet A to bet C, then your subjective probability that Professor Ross has a TikTok account is greater than 0.2.\nIf you’re indifferent between bets A and C, then your subjective probability that Professor Ross has a TikTok account is equal to 0.2.\n\n\nIf you choose bet D, the probability of winning is 0.6.\n\nIf you prefer bet D to bet A, then your subjective probability that Professor Ross has a TikTok account is less than 0.6.\nIf you prefer bet A to bet D, then your subjective probability that Professor Ross has a TikTok account is greater than 0.6.\nIf you’re indifferent between bets A and D, then your subjective probability that Professor Ross has a TikTok account is equal to 0.6.\n\n\nContinuing in this way you can narrow down your subjective probability. For example, if you prefer bet B to bet A and bet A to bet C, your subjective probability is between 0.2 and 0.4. Then you might consider bet E corresponding to 30 gold marbles and 70 green to determine if you subjective probability is greater than or less than 0.3. At some point it will be hard to choose, and you will be in the ballpark of your subjective probability. (Think of it like going to the eye doctor: “which is better: 1 or 2?” At some point you can’t really see a difference.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Bet B with a 0.4 probability of selecting green\n\n\n\n\n\n\n\n\n\n\n\n(b) Bet C with a 0.2 probability of selecting green\n\n\n\n\n\n\n\n\n\n\n\n(c) Bet C with a 0.6 probability of selecting green\n\n\n\n\n\n\n\nFigure 1.5: The three marble bins in Example 1.6.\n\n\n\nOf course, the strategy in the above example isn’t an exact science, and there is a lot of behavioral psychology behind how people make choices in situations like this4, especially when betting with real money. But the example provides a very rough idea of how you might discern a subjective probability of an event. The example also illustrates that probabilities can be “personal”; your information or assumptions will influence your assessment of the likelihood.\nWe close this section with some brief comments about subjectivity. Subjectivity is not bad; “subjective” is not a “dirty” word. Any probability model involves some subjectivity, even when probabilities can be interpreted naturally as long run relative frequencies. For example, assuming a die is fair does not codify an objective truth about the die. Instead, “fairness” reflects a reasonable and tractable mathematical model. In the real world, any “fair” six-sided die has small physical imperfections that cause the six faces to have different probabilities. However, the differences are usually small enough to be ignored for most practical purposes. Assuming that the probability that the die lands on each side is 1/6 is much more tractable than assuming the probability of a 1 is 0.1666666668, the probability of a 2 is 0.1666666665, etc. (Furthermore, measuring the probability of each side so precisely would be extremely difficult.) But assuming that the probability that the die lands on each side is 1/6 is also subjective. We might agree more easily on the probability that a six-sided die lands on 1 than on the probability that the Philadelphia Phillies win the 2030 World Series. But the fact that there can be many reasonable probability models for a situation like the 2030 World Series does not make the corresponding subjective probabilities any less valid than long run relative frequencies.\n\n\n1.2.3 Which interpretation to use?\nIn short, both! Fortunately, the mathematics of probability works the same way regardless of the interpretation. We can—and will—use the long run relative frequency and subjective interpretations interchangeably. When we introduce a new concept or problem we will employ whichever interpretation we think helps us best understand the concept or solve the problem.\nLong run relative frequency and subjective are not the only interpretations of probability. However, we will not delve further into the philosophy of probability5. You might still have questions such as:\n\nIf we flip a coin and cover it before observing what side it lands on, is the flip still random?\nIf we measure precisely all the features that determine the coin’s trajectory and what side it will land on (initial velocity, air resistance, etc.), is the flip still random?\nIs the probability of heads in the previous two cases 0.5? Or 0 or 1? Does it even make sense to talk about the probability of heads if the outcome is determined?\nWhat really is “true randomness”?\n\nYou can debate questions like these with your friends, but our position is that probability is applicable in any situation involving a reasonable degree of uncertainty. If you flip the coin but cover it, the uncertainty of the flip is not resolved so it still makes sense (to us) to say the probability that heads is facing up is 0.5. In practical situations you’re rarely, if ever, going to measure precisely all the features that determine the outcome, so you can still use probability to assess the degree of plausibility of various events. We are certainly ignoring some philosophical issues or questions6, but our brief introduction to instances of randomness and interpretations of probability provides sufficient background for discussing many interesting practical problems in a wide variety of applications.\n\n\n1.2.4 Exercises\n\nExercise 1.2 In each of the following, write a clearly worded sentence interpreting the numerical value of the probability as a long run relative frequency in context. (Just take the numerical values as given for now. We’ll see how to compute probabilities like these later.)\n\nThe probability of rolling doubles when you roll two fair six-sided dice is 1/6.\nThe probability of rolling doubles on three consecutive rolls of two fair six-sided dice is 0.00463.\nThe probability that the sum of 100 rolls of a fair six-sided die is less than 370 is 0.12.\nRoll a fair six-sided die until you roll a 6 three times and then stop. The probability that you roll the die at least 10 times is 0.822.\nThe probability that a randomly selected U.S. adult uses TikTok is 0.2.\n\n\n\nExercise 1.3 Various sources posted odds for who would win the 2024 U.S. Presidential Election. As of June 30, 2023, the website bonus.com listed the following probabilities. (They also assigned probabilities to other candidates that aren’t included here.)\n\n\n\nPotential candidate\nProbability of winning 2024 election\n\n\n\n\nJoe Biden\n44%\n\n\nDonald Trump\n29%\n\n\nRon DeSantis\n19%\n\n\nGavin Newsom\n11%\n\n\nKamala Harris\n5%\n\n\n\n\nAccording to bonus.com as of June 30, 2023, how many times more likely was Joe Biden to win than Gavin Newsom?\nHow many times more likely was Ron DeSantis to not win than to win?\nAnother source listed the probability for Kamala Harris as 10%. How many times more likely was Kamala Harris to win according to this source relative to bonus.com?\nSay it’s October 2032 and we’re trying to predict the outcome of the 2032 U.S. Presidential election. How would a table of probabilities one month before the election compare to a table one year before the election? We obviously can’t predict the future, but in general terms what would you expect? (Hint: the bonus.com predictions were made over a year in advance of the 2024 election, and we see five candidates with not-so-small probabilities. Would you expect that to be true a month before the election?)\n\n\n\nExercise 1.4 Identify your subjective probability of each of the following (to the nearest 0.05 or 0.1 is fine). Explain how you arrived at your value by considering bets like those in Example 1.6.\n\nThe probability that your favorite sports team will win a championship in the next ten years.\nThe probability that you will eventually visit all 50 current U.S. states at some time in your life.\nThe probability that there will be more than 50 U.S. states in 2050.\nThe probability that we live in a multiverse.\nChoose a situation of interest to you and identify your subjective probability!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-consistency",
    "href": "literacy-probability.html#sec-consistency",
    "title": "1  What is Probability?",
    "section": "1.3 Working with probabilities",
    "text": "1.3 Working with probabilities\nIn the previous section we encountered two interpretations of probability: long run relative frequency and subjective. Fortunately, the mathematics of probability work the same way regardless of the interpretation.\n\n1.3.1 Consistency requirements\nAny probability assessment must satisfy some basic logical consistency requirements. Roughly, probabilities cannot be negative and the sum of probabilities over all possibilities must be 1 (or 100%). We will formalize these requirements in mathematical formulas later. For now, we just proceed using intuition.\n\n\n\n\n\n\n\nExample 1.7 As of Jun 21, 2023, FiveThirtyEight listed the following probabilities for who would win the 2023 World Series.\n\n\n\nTeam\nProbability\n\n\n\n\nAtlanta Braves\n19%\n\n\nTampa Bay Rays\n16%\n\n\nLos Angeles Dodgers\n10%\n\n\nHouston Astros\n7%\n\n\nNew York Yankees\n7%\n\n\nOther\n\n\n\n\nAccording to FiveThirtyEight (as of Jun 21, 2023):\n\nAre these probabilities most naturally interpreted as long run relative frequencies or subjective probabilities? Explain.\nWhat must be the probability that the Braves do not win the 2023 World Series?\nWhat must be the probability that either the Braves or the Rays win?\nWhat must be the probability that one of the above five teams is the World Series champion?\nWhat must be the probability that a team other than the above five teams is the World Series champion? That is, what value goes in the “Other” row in the table?\nDonny Don’t says, “These are subjective probabilities, so I can’t use them to perform a simulation.” Explain to Donny how you could conduct a simulation that reflects these probabilities, say using a spinner (like from a kids game).\nWhat would you expect the results of 10000 repetitions of a simulation of the World Series champion to look like? Construct a table summarizing what you expect. Is this necessarily what would happen?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.7. \n\nThese probabilities are most naturally interpreted as subjective probabilities, because there is no single set of “rules”—model, assumptions, data—that determines long run relative frequencies.\n81%. Either the Braves win or they don’t; if there’s a 19% chance that the Braves win, there must be a 81% chance that they do not win in order to account for 100% of the possibilities. If we think of this as a simulation with 10000 repetitions (see the last part), each repetition results in either the Braves winning or not, so if they win in 1900 of repetitions then they must not win in the other 8100.\n35%. There is only one World Series champion, so if say the Braves win then no other team can win. Because “Braves win” and “Rays win” are distinct events we can add their probabilities to find the probability of the event “Braves or Rays win”. Thinking again of the simulation, the repetitions in which the Braves win are distinct from those in which the Rays win. If the Braves win in 1900 repetitions and the Rays win in 1600 repetitions, then on a total of 3500 repetitions either the Braves or Rays win.\n59%. As in the previous part, we can add the five probabilities to see that the probability that one of the five teams above wins must be 59%.\n41%. Either one of the five teams above wins, or some other team wins. If one of the five teams above wins in 5900 repetitions, then in 4100 repetitions the winner is not one of these five teams.\nThese particular values are subjective, but we can still treat them as given and use them to conduct a simulation. Imagine that we construct a spinner7 like in Figure 1.6. Spinning this spinner once simulates a World Series winner according to the given probabilities. We could conduct many repetitions by spinning the spinner many times.\nEach repetition results in a World Series champion and in the long run we would expect the Braves would be the champion in 19%, or 1900, of the 10000 repetitions. We would expect the simulation results to look like\n\n\n\nTeam\nRepetitions\n\n\n\n\nAtlanta Braves\n1900\n\n\nTampa Bay Rays\n1600\n\n\nLos Angeles Dodgers\n1000\n\n\nHouston Astros\n700\n\n\nNew York Yankees\n700\n\n\nOther\n4100\n\n\n\nOf course, there would be some natural variability from simulation to simulation, just like in the sets of 1000 coin flips in Figure 1.4. But the above counts represent about what we would expect.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.6: Spinner representation of the subjective probabilities in Example 1.7.\n\n\n\n\n\nConsistency does not tell us how to assign probabilities to events. Rather, consistency requires that however we assign probabilities they must fit together in a logically coherent way. In the previous example, there is no rule that says the probability that the Braves win must be 0.19; this value is subjective. However, once we have specified that the probability is 0.19, consistency requires that the probability that the Braves do not win must be 0.81.\n\n\n\n\n\n\n\nExample 1.8 Suppose your subjective probabilities for the 2023 World Series champion satisfy the following conditions.\n\nThe Astros and Dodgers are equally likely to win\nThe Rays are 1.5 times more likely than the Astros to win\nThe Braves are 2 times more likely than the Rays to win\nThe winner is as likely to be among these four teams— Braves, Rays, Dodgers, Astros— as not\n\nConstruct a table of your subjective probabilities like the one in Example 1.7.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.8. Here, probabilities are specified indirectly via relative likelihoods. We need to find probabilities that are in the given ratios and add up to 1 ( or 100%). It helps to designate one outcome as the “baseline”. It doesn’t matter which one, though it’s convenient to choose the one with the smallest probability; we’ll choose the Astros.\n\nSuppose the Astros account for 1 “unit”. It doesn’t really matter what a unit8 is, but let’s say it corresponds to 1000 repetitions of a simulation. That is, the Astros win in 1000 repetitions. Careful: we haven’t yet specified how many total repetitions there are, or how many units the entire simulation accounts for. We’re just starting with a baseline of what happens for the Astros.\nThe Astros and Dodgers are equally like to win, so the Dodgers also account for 1 unit.\nThe Rays are 1.5 times more likely than the Astros to win, so the Rays account for 1.5 units. If 1 unit is 1000 repetitions, then the Rays win in 1500 repetitions, 1.5 times more often than the Astros.\nThe Braves are 2 times more likely than the Rays to win, so the Braves account for \\(2\\times 1.5=3\\) units. If 1 unit is 1000 repetitions, then the Braves win in 3000 repetitions.\nThe four teams account for a total of \\(1+1+1.5+3 = 6.5\\) units. Since the winner is as likely to among these four teams as not, then “Other” also accounts for 6.5 units.\nIn total, there are 13 units which account for 100% of the probability. The Astros account for 1 unit, so their probability of winning is \\(1/13=0.077\\) or about 7.7%. Likewise, the probability that the Rays win is \\(3/13=0.231\\) or about 23.1%.\n\n\n\n\nTable 1.3: Table solution for Example 1.8\n\n\n\n\n\n\n\n\n\n\n\n\nTeam\nUnits\nHypothetical repetitions\nProbability (as fraction, decimal)\nProbability (as percent)\n\n\n\n\nAtlants Braves\n3.0\n3000\n3/13 = 0.231\n23.1%\n\n\nTampa Bay Ray\n1.5\n1500\n1.5/13 = 0.115\n11.5%\n\n\nLos Angeles Dodgers\n1.0\n1000\n1/13 = 0.077\n7.7%\n\n\nHouston Astros\n1.0\n1000\n1/13 = 0.077\n7.7%\n\n\nOther\n6.5\n6500\n6.5/13 = 0.500\n50.0%\n\n\nTotal\n13.0\n13000\n1\n100.0%\n\n\n\n\n\n\nYou should verify that all of the probabilities are in the specified ratios. For example, the Braves are 2 times more likely (\\(2 = 0.231 / 0.115\\)) than the Rays to win, and the Rays are 1.5 times more likely \\((1.5 \\approx 0.115 / 0.077)\\) than the Astros to win.\n\n\n\n\nExample 1.8 illustrates one way of formulating probabilities. We start by specifying probabilities in relative terms, and then “normalize” these probabilities so that they add up to 1 (or 100%) while maintaining the ratios. As in the example, it helps to consider one outcome as a “baseline” and to specify all likelihoods relative to the baseline.\nFigure 1.7 provides a visual representation of Example 1.8. The ratios provided in the problem setup are enough to draw the shape of the plot, represented by Figure 1.7 (a) without a scale on the vertical axis. The heights are equal for the Astros and the Dodgers, the height for the Rays is 1.5 times the height for the Astros, the height for the Braves is 2 times the height for the Rays, and if we stacked the bars for the Braves, Rays, Astros, and Dodgers on top of another another they would be as tall as the Other bar. Figure 1.7 (b) simply adds a (vertical) probability axis to ensure the heights of the bars sum to 1. Figure 1.7 (b) represents the “normalization” step, but it does not affect the shape of the plot or the relative heights of the bars.\n\n\n\n\n\n\n\n\n\n\n\n(a) Relative heights without absolute scale.\n\n\n\n\n\n\n\n\n\n\n\n(b) Heights scaled to sum to 1 to represent probabilities.\n\n\n\n\n\n\n\nFigure 1.7: Bar chart representation of the subjective probabilities in Example 1.8.\n\n\n\nThe fact that the probabilities must sum to 1 over all possibilities might seem obvious. Other consistency requirements are more subtle.\n\n\n\n\n\n\n\nExample 1.9 Consider a Cal Poly student who frequently has blurry, bloodshot eyes, generally exhibits slow reaction time, always seems to have the munchies, and disappears at 4:20 each day. Which of the following, A or B, has a higher probability?9 (Assume the two probabilities are not equal.)\n\nA: The student has a GPA above 3.0.\nB: The student has a GPA above 3.0 and smokes marijuana regularly.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.9. A has the higher probability. Many people say B, associating the description of the student with the “smokes marijuana regularly” part of event B. But every student who satisfies event B also satisfies event A, so the probability for event A can’t be any smaller than that of event B.\n\n\n\n\nThe previous example illustrates that our psychological judgment is often inconsistent with the mathematical logic of probabilities, so be careful when interpreting probabilities!\n\n\n1.3.2 Odds\nThe words “probability”, “chance”, “likelihood”, and “odds” are colloquially treated as synonyms. However, in the mathematical language of probability, odds provide a different way of reporting a probability. Rather than reporting probability on a 0 to 1 (or 0% to 100%) scale, odds report probabilities in terms of ratios.\n\n\n\n\n\n\n\nExample 1.10 Continuing Example 1.7, suppose the probability that the Dodgers win the 2023 World Series is 0.10.\n\nWhat is the probability that the Dodgers do not win the 2023 World Series?\nThe odds that the Dodgers win the World Series are “9 to 1 against”. What do you think this means?\nWhat are the odds that the Dodgers do not win the World Series?\nIf the probability that the Rays win is 0.16, what are the odds for the Rays?\nWhat are the odds that either the Dodgers or the Rays win?\nSuppose the San Francisco Giants have 19 to 1 odds against winning. What is the probability that the Giants win the World Series?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.10. \n\nThe probability that the Dodgers win is 0.1, so the probability that they do not win is 0.9.\nThe values in the previous part are in a 9 to 1 ratio: the probability of not winning (0.9) is 9 times greater than the probability of winning (0.1). So the odds against the Dodgers winning the World Series are 9 to 1; “against” because the Dodgers are less likely to win than to not win.\nThe probabilities are still in the 9 to 1 ratio, but we can say that the odds are 9 to 1 in favor of the Dodgers not winning. We could also say the odds are 1 to 9 in favor of the Dodgers winning, but odds are typically reported with the larger value first—9 to 1 instead of 1 to 9.\nThe probability that the Rays win is 0.16 and that they don’t win is 0.84, and \\(0.84/0.16 = 5.25\\). So the odds are 5.25 to 1 against the Rays winning. Odds are often reported as whole numbers, so we could say the odds are 21 to 4 against the Rays winning (since 21/4 = 5.25).\nThe probability that either the Dodgers or the Rays win is 0.16 + 0.10 = 0.26, so the probability that neither of these teams wins is 0.74. The ratio of these values is \\(0.74/0.26 = 2.85\\), so there are 2.85 to 1 odds against the winner being either the Dodgers or the Rays (or 57 to 20 in whole numbers). (Notice that 2.85 is not related in a simple way to the previous values 9 and 5.25.)\nThe odds tell us that the probability that the Giants do not win is 19 times greater than the probability that they do win. Let the event that the Giants win account for 1 “unit” so that the event that they do not win accounts for 19 units, for a total of 20 units. Then10: the probability that the Giants win is \\(1/20 = 0.05\\). Note that the probability of not winning, \\(19/20 = 0.95\\), is 19 times greater than the probability of winning.\n\n\n\n\n\n\nDefinition 1.4 The odds of an event is a ratio involving the probability that the event occurs and the probability that the event does not occur. Odds can be expressed as either “in favor” of or “against” the event occurring, depending on the order of the ratio.\n\n\\[\n\\begin{aligned}\n\\text{odds in favor of an event} & = \\frac{\\text{probability that the event occurs}}{\\text{probability that the event does not occur}} \\\\\n& \\\\\n\\text{odds against an event} & = \\frac{\\text{probability that the event does not occur}}{\\text{probability that the event occurs}}\\end{aligned}\n\\]\nIn many situations odds are typically reported as odds against. While the odds of an event is a just a single number, odds are often reported as a ratio of whole numbers, e.g., 11 to 1, 7 to 2. \nAs discussed at the end of Section Section 1.2.2 bets can be used to discern probabilities or odds.\n\n\n\n\n\n\n\nExample 1.11 Ron and Leslie agree to the following bet. They’ll ask Professor Ross if he has a TikTok account. If he does, Leslie will pay Ron $200; if not, Ron will pay Leslie $100. (Neither has any direct information about whether or not Professor Ross has a TikTok account.)\n\nGiven this setup, which of the following is being judged as more likely: that Professor Ross has a TikTok account, or that he does not? Why?\nWhat are this bet’s odds?\nRon and Leslie agree that this is a fair bet, and neither would accept worse odds. What is their subjective probability that Professor Ross has a TikTok account?\nSuppose they were to hypothetically repeat this bet many times, say 3000 times. Given the probability from the previous part, how many times would you expect Leslie to win? To lose? What would you expect Leslie’s net dollar winnings to be? In what sense is this bet “fair”? (Remember: Leslie’s winnings are Ron’s losses and vice versa.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.11. \n\nThe larger potential payout corresponds to the less likely event. So they think Professor Ross is more likely to not have a TikTok account than to have one.\nThe payouts are in a 2 to 1 ratio, so the odds that Professor Ross has a TikTok account are 2 to 1 against.\nThe odds that Professor Ross has a TikTok account are 2 to 1 against, so Professor Ross is twice as likely to not have a TikTok account than to have one. This corresponds to a subjective probability11 that Professor Ross has a TikTok account of 1/3 (and a probability that he does not have one of 2/3).\nThe probability that Leslie wins is 2/3, so you would expect her to win in 2000 of the 3000 repetitions. She wins $100 each time she wins, so you would expect her to win a total of $200,000 on games she wins. The probability that she loses is 1/3, so you would expect her to lose in 1000 of the 3000 repetions. She loses $200 each time, so you would expect her to lose a total of $200,000 on the games she loses. So you would expect Leslie’s net winnings to be 0, and likewise for Ron. The bet is fair in the sense that neither party is expected to profit or lose in the long run.\n\n\n\n\n\n\n\n\n\n\nWinner\nExpected number of repetitions\nLeslie’s winnings per repetition ($)\nLeslie’s expected total winnings ($)\n\n\n\n\nLeslie\n2000\n100\n200,000\n\n\nRon\n1000\n-200\n-200,000\n\n\nTotal\n3000\nNA\n0\n\n\n\n\n\n\n\nThe previous example illustrates that the odds of a fair bet on whether or not an event will occur, determined by the ratio of the payouts, imply a probability for the event.\n\\[\\begin{align*}\n\\text{probability that event occurs} & = \\frac{\\text{odds in favor of the event}}{1+\\text{odds in favor of the event}}\\\\\n& \\\\\n& = \\frac{1}{1+\\text{odds against the event}}\n\\end{align*}\\]\nWe have defined odds as a ratio of probabilities; these are sometimes called “fractional odds”. But odds can be reported in other ways. In particular, “moneyline odds” (a.k.a., “American odds”) are expressed in terms of the net profit on a 100 dollar bet12. For example, in Example 1.7 the moneyline odds for the Dodgers are +900. This means that someone who bets 100 dollars on the Dodgers to win the World Series would receive 100+900 dollars if the Dodgers actually win, for a net profit of +900 dollars after subtracting the initial stake of 100 dollars. A $100 bet at +900 moneyline odds results in a profit of $900 if the bet is won or a loss of the initial $100 stake otherwise; the amounts 900 and 100 are in a 9 to 1 ratio (against winning), implying a probability of \\(1/(1+9) = 0.10\\) of winning the bet.\n\n\n1.3.3 Why do we need consistency?\nRegardless of the interpretation probabilities must follow basic logical consistency requirements. If these requirements are mistakenly not satisfied, bad things can happen.\n\n\n\n\n\n\n\nExample 1.12 Donny Don’t thinks the Dodgers have a pretty good chance to win the World Series. He thinks their only real competition is the Yankees. The following are Donny’s subjective probabilities for which team will win the World Series.\n\n\n\nTeam\nProbability\n\n\n\n\nLos Angeles Dodgers\n0.50\n\n\nNew York Yankees\n0.25\n\n\nOther\n0.10\n\n\n\n\nWhat is wrong with Donny’s probabilities?\nWhat are Donny’s odds that the Dodgers win? (Consider only Donny’s probability that the Dodgers win13.)\nWould Donny agree to a bet where he pays you $100 if the Dodgers win but you pay him $100 if the Dodgers do not win?\nWhat are Donny’s odds that the Yankees win? Would Donny agree to a bet where he pays you $150 if the Yankees win but you pay him $50 if the Yankees do not win?\nWhat are Donny’s odds that a team other than the Dodgers or Yankees wins? Would Donny agree to a bet where he pays you $180 if an other team wins but you pay him $20 if the winner is either the Yankees or Dodgers?\nSuppose you and Donny agree to make all of the bets in the three previous parts. Consider your net profit for each of the potential outcomes (Dodgers win, Yankees win, other wins). What do you notice? Who would you rather be in this situation: you or Donny?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.12. \n\nDonny’s probabilities do not add up to 1. If we had listed the odds for every outcome (see below) instead of the probabilities, his mistake would have been less obvious.\nDonny’s odds that the Dodgers win are \\(\\frac{0.5}{0.5}=1\\), or even odds.\nDonny believes that the Dodgers are equally likely to win as to not win so, yes, he would agree to this bet with even payouts.\nDonny’s odds that the Yankees do not win are \\(\\frac{0.75}{0.25}=3\\), or 3 to 1 odds against the Yankees winning. Donny believes that the Yankees are 3 times more likely to not win than to win. Since the payouts are in a 3 to 1 ratio with the larger payout corresponding to the Yankees winning (the less likely event), then Donny would agree to this bet.\nDonny’s odds that an other team does not win are \\(\\frac{0.9}{0.1}=9\\), or 9 to 1 odds against an other team winning. Donny believes that an other team is 9 times more likely to not win than to win. Since the payouts are in a 9 to 1 ratio with the larger payout corresponding to an other team winning (the less likely event), then Donny would agree to this bet.\nGiven Donny’s odds for each outcome, he would agree to each of these bets.\n\nIf the Dodgers win, you win the first bet but lose the other two, so your net profit is 100 - 50 - 20 = 30.\nIf the Yankees win, you win the second bet but lose the other two, so your net profit is 150 - 100 - 20 = 30\nIf an other team wins, you win the third bet but lose the other two, so your net profit is 180 - 100 - 50 = 30.\n\nRegardless of the outcome, you are guaranteed to earn a net profit of $30, and Donny is guaranteed to lose a net of $30. That’s free money for you with no risk, and pretty bad business on Donny’s part.\n\n\n\n\n\nThe situation in Example 1.12 is known as a “Dutch book”. A Dutch book14 is a set of probabilities and bets which guarantees a profit, regardless of the outcome of the gamble. Probabilities that fail to satisfy logical consistency requirements allow for the possibility of Dutch books. The fact that no one should ever want to get caught in a Dutch book, like Donny was in the previous problem, is one justification of why even probabilities should satisfy logical consistency requirements.\n\n\n1.3.4 Exercises\n\nExercise 1.5 Various sources posted odds for who would win the 2024 U.S. Presidential Election. As of June 30, 2023, the website bonus.com listed the following probabilities.\n\n\n\nPotential candidate\nProbability of winning 2024 election\n\n\n\n\nJoe Biden\n44%\n\n\nDonald Trump\n29%\n\n\nRon DeSantis\n19%\n\n\nGavin Newsom\n11%\n\n\nKamala Harris\n5%\n\n\n\n\nAccording to bonus.com, what is the probability that either Donald Trump or Ron DeSantis wins the 2024 election?\nAccording to bonus.com, what is the probability that a candidate other than these five wins the 2024 election?\nAccording to bonus.com, is the probability that Joe Biden wins the Democratic nomination greater than, less than, or equal to 44%? Why?\nAccording to bonus.com, what are the odds against Kamala Harris wining the 2024 election?\nSuppose that a source gives Dwayne Johnson 500 to 1 odds of winning. What is the probability that Dwayne Johnson wins?\n\n\n\nExercise 1.6 Suppose that at some point your subjective probabilities for who would win the 2024 U.S. Presidential Election satisfied the following.\n\nJoe Biden is 5 times more likely to win than Kamala Harris, and no other Democratic candidate has a chance of winning\nThe Democratic candidate and the Republican candidate are equally likely to be the winner\nDonald Trump is twice as likely to win as any other Republican candidate.\n\nCreate a table of your subjective probabilities.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#probabilities-proportions-and-percentages",
    "href": "literacy-probability.html#probabilities-proportions-and-percentages",
    "title": "1  What is Probability?",
    "section": "1.4 Probabilities, proportions, and percentages",
    "text": "1.4 Probabilities, proportions, and percentages\nIt is helpful to think of probabilities as proportions—fractions or decimals—or percentages. When dealing with percentages (or proportions or probabilities) be sure to ask “percent of what?” Thinking in fraction terms, be careful to identify the correct reference group which corresponds to the denominator.\n\n\n\n\n\n\n\nExample 1.13 The following two phrases contain exactly the same words, just in different orders. Which is larger, the numerical value of 1 or 2?\n\nThe percentage of men that are greater than six feet tall who play in the National Basketball Association (NBA).\nThe percentage of men that play in the National Basketball Association (NBA) who are greater than six feet tall.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.13. The value of the percentage in (2) is much larger.\n\nThere are over a billion men in the world who are greater than six feet tall, only a few hundred of whom play in the NBA. The percentage of men greater than six feet tall who play in the NBA is pretty close to 0.\nThere only a few hundred men who play in the NBA, almost all of whom are greater than six feet tall. The percentage of men who play in the NBA that are greater than six feet tall is pretty close to 100%.\n\nThink in terms of fractions. The corresponding fractions would have the same numerator—number of men who are both greater than six feet tall and play in the NBA—but vastly different denominators.\n\\[\\begin{align*}\n(1): & \\quad \\frac{\\text{number of men who are greater than six feet tall and play in the NBA}}{\\text{number of men who are greater than six feet tall}}\\\\\n(2): & \\quad \\frac{\\text{number of men who are greater than six feet tall and play in the NBA}}{\\text{number of men who play in the NBA}}\n\\end{align*}\\]\n\n\n\n\nWhen working with multiple percentages (or proportions or probabilities), it is helpful to construct hypothetical tables of counts.\n\n\n\n\n\n\n\nExample 1.14 Are Americans in favor of free tuition at public colleges and universities? Suppose that15\n\n83% of Democrats are in favor of free tuition\n60% of Independents are in favor of free tuition\n39% of Republicans are in favor of free tuition\n\nAlso suppose that16\n\n32% of Americans are Democrats\n42% of Americans are Independents\n26% of Americans are Republicans\n\nWe’ll use this information to investigate the following questions, as well as a few others.\n\nWhat percentage of Americans are in favor of free college tuition?\nWhat percentage of Americans who are in favor of free college tuition are Democrats?\n\n\nDonny Don’t answers the second question: “That’s easy. We’re told that 83% of Americans in favor of free college tuition are Democrats.” Is Donny necessarily correct? Explain without doing any calculations.\nFor the next few parts, consider a hypothetical group of 10000 Americans and assume the percentages provided apply to this group. How many people in the group are Democrats?\nHow many Americans in the group are Democrats who are in favor of free college tuition?\nFill in the counts in each cell of the following “two-way” table.\n\n\n\n\n\n\n\n\n\n\n\nDemocrat\nIndependent\nRepublican\nTotal\n\n\n\n\nIn favor of free tuition\n\n\n\n\n\n\nNot in favor of free tuition\n\n\n\n\n\n\nTotal\n\n\n\n10000\n\n\n\nWhat percentage of Americans in this group who are in favor of free college tuition are Democrats? Answer as unreduced fraction, a decimal (proportion), and a percent.\nSuppose we had started with a hypothetical group of 100,000 Americans. How would the table of counts change? Would the answer to the previous part change?\nNow answer the original question: What percentage of Americans who are in favor of free college tuition are Democrats? Hint: do we need to know how many Americans there are?\nWhat percentage of Americans who are Democrats are in favor of free college tuition? Answer as unreduced fraction, a decimal (proportion), and a percent.\nWhat percentage of Americans are Democrats in favor of free college tuition? Answer as unreduced fraction, a decimal (proportion), and a percent.\nCompare the unreduced fractions for the previous three parts. What is the same? What is different?\nWhat percentage of Americans are in favor of free college tuition? Answer as unreduced fraction, a decimal (proportion), and a percent.\nSuppose that we were only told that 61.9% of Americans overall support free tuition, and that we not given the values 83%, 60%, 39%. Would we be able to complete the two-way table?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.14. \n\nDonny is confusing two different percentages, which refer to two different groups.\n\nWe are given that 83% of Democrats are in favor of free college tuition. This percentage applies to Democrats; among Democrats what percentage are in favor of free college tuition?\nWhat we want is the percent of Americans in favor of free tuition who are Democrats. This percentage applies to Americans in favor of free tuition; among Americans in favor of free tuition what percentage are Democrats?\n\nWe are given that 32% of Americans are Democrats. Of the 10000 Americans, 32%, that is 3200, are Democrats. (\\(10000 \\times 0.32 = 3200\\))\nWe are given that 83% of Democrats are in favor of free college tuition. Out of the 3200 Democrats, 83%, that is 2656 are in favor of free tuition. (\\(3200 \\times 0.83 = 2656\\))\nWe fill in the total count for each party first, then we determine the number who are in favor of free tuition within each party. For example, of the 10000 Americans, 42%, that is 4200, are Independent, and 60% of the 4200 Independents are in favor of free tuition. (\\(4200 \\times 0.6 = 2520\\))\n\n\n\n\n\n\n\n\n\n\n\nDemocrat\nIndependent\nRepublican\nTotal\n\n\n\n\nIn favor of free tuition\n2656\n2520\n1014\n6190\n\n\nNot in favor of free tuition\n544\n1680\n1586\n3810\n\n\nTotal\n3200\n4200\n2600\n10000\n\n\n\nLook at the “in favor” row of the table. Out of 6190 Americans in this group who are in favor of free college tuition, 2656 are Democrats. Since \\(\\frac{2656}{6190}\\approx 0.429\\), about 42.9% of Americans in this group who are in favor of free college tuition are Democrats.\nIf we had started with a hypothetical group of 100,000 Americans for which the given percentages applied, then the count in every cell in the table would be 10 times greater. However, ratios and percentages would still be the same. The answer to the previous part would not change; it would still be \\(\\frac{26560}{61900} =\\frac{2656}{6190}\\approx 0.429\\).\nNow we are interested in Americans in general rather than the 10000 Americans in our hypothetical group. But as the previous part illustrates, the relative percentages will be the same regardless of the size of the group, assuming that the percentages provided in the setup apply to the group. We don’t need to know how many Americans there are; we can just start with a nice round number like 10000 and construct a hypothetical table of counts representing the proper percentages. Since we’re assuming the percentages provided in the setup apply to Americans, we can say that 42.9% of Americans who are in favor of free college tuition are Democrats.\nWe were told that the percentage of Americans who are Democrats that are in favor of free college tuition is 83%. But we can also look at the Democrat column in the table: \\(\\frac{2656}{3200} = 0.83\\). Pay careful attention to the difference in wording between this part and the previous one.\nOut of 10000 Americans, 2656 are Democrats in favor of free college tuition, so \\(\\frac{2656}{10000}= 26.56\\%\\) of Americans are Democrats in favor of free college tuition.\nThere are subtle but important differences in wording between the percentages of interest in the previous three parts. Note that the numerator is the same in each part: 2656, the number of Americans in the group who are both Democrats and in favor of free tuition. But the denominators are different, each corresponding to a different reference group\n\nthe percentage of Americans who are in favor free tuition… (denominator of 6190)\nthe percentage of Americans who are Democrats… (denominator of 3200)\nthe percentage of Americans… (denominator of 10000)\n\nOut of 10000 Americans, 6190 are in favor of free college tuition, so 61.9% of Americans are in favor of free college tuition.\nEven if 61.9% of Americans overall support free tuition, it would not be safe to assume that 61.9% of Democrats support, 61.9% of Independent support, and 61.9% of Republicans support. We would expect support to vary by party, but without such information we would not be able to complete the two-way table.\n\n\n\n\n\nTwo-way tables (a.k.a., contingency tables) of counts are a useful tool for probability problems dealing with two “dimensions” (like political party and free tuition support). For the purposes of constructing the table and computing related probabilities, any value can be used for the hypothetical17 total count18.\nFigure 1.8 provides a visual representation of Example 1.14. The mosaic plot in Figure 1.8 (a) has three bars, each representing a political party. The widths of the bars are scaled based on the proportions of Americans within each party. The breaks within each bar are scaled based on the proportions who do and do not support free tuition within the party. The mosaic plot in Figure 1.8 (b) has the roles of the dimensions reversed, and displays how party affiliation varies based on support for free tuition or not.\n\n\n\n\n\n\n\n\n\n\n\n(a) Support for free tuition within party.\n\n\n\n\n\n\n\n\n\n\n\n(b) Political party affiliation based on support for free tuition or not.\n\n\n\n\n\n\n\nFigure 1.8: Mosaic plots for Example 1.14.\n\n\n\nIn Example 1.14, we needed information about support for free tuition within in each party to fill in the table. That is, it was not enough to know that 61.9% of Americans overall support free tuition. In general, knowing probabilities of individual events alone is not enough to determine probabilities of combinations of them.\n\n\n\n\n\n\n\nExample 1.15 Suppose19 that 47% of American adults20 have a pet dog and 25% have a pet cat.\n\nStart constructing a two-way table. What are the two “dimensions”?\nDonny Don’t says, “72% (which is 47% + 25%) of American adults have a pet dog or a pet cat.” Is that necessarily true? Under what circumstance (however unrealistic) would this be true? Construct a two-way table for this scenario.\nGiven only the information provided, what is the smallest possible percentage of American who adults have a pet dog or a pet cat (or both)? Under what circumstance (however unrealistic) would this be true? Construct a two-way table for this scenario.\nDonny Don’t says that 11.75% (which is 47% \\(\\times\\) 25%) of Americans have both a pet dog and a pet cat. Explain to Donny why that’s not necessarily true. Without further information, what can you say about the percentage of American adults who have both a pet dog and a pet cat?\nFor the remaining parts, suppose that 14% of American adults have both a pet dog and a pet cat. Construct a corresponding two-way table.\nWhat is the percentage of American adults who have a pet dog or a pet cat (or both)?\nDonny Don’t says, “I thought ‘or’ means ‘add’. In Example 1.7 I added 19% and 16% to get the probability that the Braves or the Rays win. Why can’t I add 47% and 25% to get the percentage who have a pet dog or a pet cat?” Explain the difference between the two examples, and help Donny correct his error.\nDonny Don’t says, “Wait, you told me that the percentage who have a pet dog or pet cat includes those who have both, so why are you telling me to subtract 14% after I add 47% and 25%?” Does Donny have a point? Explain.\nWhat percentage of American adults who have a pet cat also have a pet dog? Is it 47%?\nWhat percentage of American adults who do not have a pet cat have a pet dog? Is this the same value as in the previous part?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.15. \n\nThere is a cat dimension—has cat or not—and a dog dimension—has dog or not. The table has four interior cells.\n\n\n\n\nHas dog\nNo dog\nTotal\n\n\n\n\nHas cat\n\n\n\n\n\nNo cat\n\n\n\n\n\nTotal\n\n\n\n\n\n\nDonny’s conclusion isn’t necessarily true because some people have both a pet dog and a pet cat. It’s theoretically possible that 72% have a pet dog or a pet cat, but this would only be true if absolutely no Americans have both a pet dog and a pet cat (which is obviously not realistic). The two-way table corresponding to Donny’s claim is\n\n\n\n\nHas dog\nNo dog\nTotal\n\n\n\n\nHas cat\n0\n25\n25\n\n\nNo cat\n47\n28\n75\n\n\nTotal\n47\n53\n100\n\n\n\nThe situation in the previous part corresponds to the largest possible value, 72%, which occurs when the percentage who have both a dog and cat is as small as possible (0%). Now we consider the reverse situation. The percentage who have both a dog and cat can’t be greater than the percentage who have a cat, 25%. It is theoretically possible for the percentage who have both a dog and cat to be 25%, but only if every person who has a cat also has a dog, which isn’t realistic. The two-way table would be\n\n\n\n\nHas dog\nNo dog\nTotal\n\n\n\n\nHas cat\n25\n0\n25\n\n\nNo cat\n22\n53\n75\n\n\nTotal\n47\n53\n100\n\n\n\nThus the smallest possible percentage of American adults who have a pet dog or a pet cat is 47%.\nIn the first two parts of this problem we have provided two theoretically possible (though unrealistic) scenarios of how Donny’s claim would be false: if no Americans who have a pet cat have a pet dog, and if all Americans who have a pet cat also have a pet dog. Obviously, somewhere between 0% and 100% of Americans who have a pet cat also have a pet dog, but what is this percentage? Donny’s claim would only be true if exactly 47% of American adults who have a pet cat also have a pet dog. (Equivalently, his claim would be true if exactly 25% of American adults who have a pet dog also have a pet cat.) But all we are given is that 47% of American adults in general have a pet dog. The likelihood of having a pet dog could plausibly change based on whether or not the adult has a cat. We need more information about the relationship between pet dog and pet cat ownership before we can determine what percentage of American adults have both. Without further information, all we can say is that between 0% and 25% of Americans have both a pet dog and a pet cat.\nIf 14% of American adults have both a pet dog and a pet cat the two-way table is\n\n\n\n\nHave dog\nNo dog\nTotal\n\n\n\n\nHave cat\n14\n11\n25\n\n\nNo cat\n33\n42\n75\n\n\nTotal\n47\n53\n100\n\n\n\n58% of American adults have a pet dog or a pet cat (58 = 14 + 11 + 33). In other words, 42% of of American adults have neither a pet dog nor a pet cat.\nThe difference between the two examples is that it’s not possible for both the Braves and Rays to win the World Series in the same year, but it is possible for an American adult to have both a pet dog and a pet cat. By adding 47% and 25%, Donny has double-counted the 14% who have both a dog and a cat. Donny can correct for the double-counting by subtracting 14% from his 72%: 47 + 25 - 14 = 58.\nDonny is correct that “or” includes both, so we do want to count those who have both a pet dog and a pet cat. The problem with adding 47% and 25% is that it double-counts both. Think of 47% as 14% + 33% and 25% as 14% + 11%; when we add 47% and 25% we add the 14% twice. We only want to count those who have both a pet dog and a pet cat once, which is why we subtract 14%.\nOut of the 25 (hypothetical) adults who have a pet cat, 14 also have a pet dog, and \\(\\frac{14}{25} = 0.56\\). So 56% of American adults who have a pet cat also have a pet dog. American adults who have a pet cat are more likely than American adults in general to have a pet dog.\nOut of the 75 (hypothetical) American adults who do not have a pet cat, 33 have a pet dog, and \\(\\frac{33}{75} = 0.44\\). So 44% of American adults who do not have a pet cat have a pet dog. American adults with pet cats are more likely than American adults without pet cats to have a pet dog.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion who have a pet dog for those with and without pet cats.\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion who have a pet cat for those with and without pet dogs.\n\n\n\n\n\n\n\nFigure 1.9: Mosaic plots for Example 1.15.\n\n\n\nWe can treat probabilities like proportions or percentages, so what’s the difference? Remember that probabilities measure likelihoods of events corresponding to random (uncertain) phenomena. The probability of an event can be interpreted as a long run proportion. For example, if we randomly select an American adult what is the probability that they have a pet dog? We can imagine repeatedly selecting American adults; if 47% of American adults have a pet dog, then the proportion of randomly selected adults that have a pet dog will converge to 0.47 in the long run. A probability represents a theoretical long run value. A proportion or percentage typically represents an observed short run value. In Example 1.15, we assumed 47%, 25%, and 14% applied to all American adults, but the values actually come from a random sample of just hundreds of American adult respondents.\nIn Example 1.13, switching the places of the words “greater than six feet tall” and “play in the NBA” resulted in two very different percentages. Without going into a grammar lesson, pay careful attention to how probabilities (or proportions or percentages) are worded. Think carefully about what the ordering of the words represents, and look out for words like “if” or “given” which signify information that influences probabilities.\n\n\n\n\n\n\n\nExample 1.16 A NY Times article titled “When They Warn of Rare Disorders, These Prenatal Tests are Usually Wrong” investigated the efficacy of noninvasive prenatal screenings (NIPS, usually blood tests) for microdeletions (small missing pieces of chromosomes) that cause a wide range of conditions. The results of the screenings are used to provide genetic counseling for pregnant women. The article claims the screenings are in widespread use: “One large test maker, Natera, said that in 2020 it performed more than 400,000 screenings for one microdeletion—the equivalent of testing roughly 10 percent of pregnant women in America.”\nWe’ll investigate the screening for 22q11.2 deletion syndrome, a.k.a., DiGeorge syndrome, a disorder caused when a small part of chromosome 22 is missing. Medical problems associated with DiGeorge syndrome include heart defects, poor immune system function, a cleft palate, complications related to low levels of calcium in the blood, and delayed development with behavioral and emotional problems.\nSuppose that if we randomly select a pregnant woman who is screened21\n\nThe probability that the baby actually has DiGeorge syndrome is 0.00025.\nIf the baby has DiGeorge syndrome, the probability that the test returns a positive result22 is 0.9.\nIf the baby does not have DiGeorge syndrome, the probability that the test returns a (false) positive is 0.0026.\n\nWe’ll investigate a few things, but our main question of interest is: If the screening for a randomly selected pregant woman returns a positive result23, what is the probability that the baby actually has DiGeorge syndrome?\n\nBefore proceeding, make a guess for the probability in question; do you think it is closest to 0.1, 0.3, 0.5, 0.7, or 0.9?\nDonny Don’t says, “A baby either has DiGeorge syndrome or not so 0.90 and 0.0026 should add up to 1, and 0.0026 should really be 0.1.” Explain to Donny why 0.9 and 0.0026 don’t need to add to 1, and what 0.1 represents in this context.\nConsidering a hypothetical population of screenings, interpret the probabilities as percents in context.\nConstruct a hypothetical two-way table of counts.\nCompute and interpret the probability that the test returns a positive result. (For this and the remaining parts, express your answer first as an unreduced fraction based on the table, then as a decimal, and interpret the value in words as a percent.)\nCompute and interpret the probability the test result is correct.\nThe value in the previous part seems pretty high. However, explain why we should not assess the effectiveness of the screening based on the probability that the test is correct alone. Hint: consider a separate test that never returns a positive result; what would be the probability that this test is correct?\nRecall the original question: If the screening for a randomly selected pregnant woman returns a positive result, what is the probability that the baby actually has DiGeorge syndrome? Compute and interpret this probability.\nIn light of your original guess, is the previous answer surprising? Explain why the probability is so low. Hint: consider the hypothetical counts in the table.\nIf the screening for a randomly selected pregnant woman returns a positive result, how many times more likely is it for the baby to not have DiGeorge syndrome than to have it?\nCompare the probability of having DiGeorge syndrome before and after the positive test. How much more likely is it for a baby who tests positive to have DiGeorge syndrome than one for whom the test result is unknown?\nIf the screening for a randomly selected pregnant woman does not return a positive result, what is the probability that the baby does not have DiGeorge syndrome?\nNIPS are in widespread use, but what if the tests were only used for pregnant women with known risk factors? Suppose that among pregnant women who have a known risk factor for DiGeorge syndrome24 the probability that the baby has DiGeorge syndrome is 10 times greater, 0.0025 instead of 0.00025. If the screening for a randomly selected pregnant woman with this risk factor returns a positive result, what is the probability that the baby actually has DiGeorge syndrome? How does this compare to the value in part 8?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.19. \n\nWe don’t know what you guessed, but many people guess 0.7 or 0.9. Afterall, it seems like the test is positive for most babies that have DiGeorge syndrome, and positive for only a small percentage of babies that don’t have it. But this argument ignores one important piece of information: most babies do not have DiGeorge syndrome. We’ll see the influence this has below.\nThe probabilities do not need to add to 1 because they apply to different groups: 0.9 to babies with DiGeorge syndrome, and 0.0026 to babies without DiGeorge syndrome. What Donny really needs to consider is this: Among babies with DiGeorge syndrome, the test result is either positive or not. If 0.9 is the probability that a baby with DiGeorge syndrome tests positive, then 0.1 is the probability that a baby with DiGeorge syndrome does not test positive; both probabilities apply to babies with DiGeorge syndrome. Likewise, if 0.0026 is the probability that a baby without DiGeorge syndrome tests positive, then 0.9974 is the probability that a baby without DiGeorge syndrome does not test positive25.\nConsidering a hypothetical population of babies (of pregnant women who are screened):\n\n0.025% of babies have DiGeorge syndrome\n90% of babies with DiGeorge syndrome test positive\n0.26% of babies without DiGeorge syndrome test positive\n\nBe very careful with 0s. For example, mistaking 0.025 percent for 0.025 can have a huge impact.\nThere are two dimensions: whether or not the baby has DiGeorge syndrome, and whether or not the test is positive. Assuming 1000000 babies (of pregnant women who are screened), 0.025% or 250 have DiGeorge syndrome and 999750 do not. Of the 250 who have DiGeorge syndrome, 90% or 225 test positive (\\(225 = 250 \\times 0.9\\)). Of the 999750 who do not have DiGeorge syndrome, 0.26% or 2599 test positive (\\(2599 = 999750 \\times 0.0026\\)).\n\n\n\n\nHas DiGeorge\nDoes not have DiGeorge\nTotal\n\n\n\n\nPositive\n225\n2599\n2824\n\n\nNot positive\n25\n997151\n997176\n\n\nTotal\n250\n999750\n1000000\n\n\n\nImagine we have one million cards and we write “positive” on 2824 of them. Shuffle the cards, select one and note if it is positive or not, then replace the card and repeat. If we repeat this process many times, the proportion of selections that return a positive result will converge to \\(\\frac{2824}{1000000} = 0.0028\\). In practice, we randomly select a pregnant woman who is screened and see if the test result is positive. In the long run, 0.28% of pregnant women who are screened test positive for DiGeorge syndrome.\nThe test is correct for 225 babies who have DiGeorge syndrome and test positive and for 997151 babies who do not have DiGeorge syndrome and do not test positive. \\(\\frac{225 + 997151}{1000000} = 0.9974\\). The test result is correct for 99.74% of pregnant women who are screened for DiGeorge syndrome.\nA screening that never returned a positive result would be correct for all the babies without DiGeorge syndrome and incorrect for all the babies with it, so the probability that this screening is correct is just the probability that a baby does not have DiGeorge syndrome, 0.99975, which is even greater than the value in the previous part. Any screening is going to divide the participants into two groups—those who test positive and those who do not—and we want to consider how effective the test is within each of these groups, not just its overall accuracy.\nLook at the “positive” row of the table. Among the 2824 babies who test positive, 225 have DiGeorge syndrome, so the probability that a baby who tests positive has DiGeorge syndrome is \\(\\frac{225}{2824} = 0.0797\\). 7.97% of babies who test positive have DiGeorge syndrome.\nThe value from the previous part seems low to many people. Only 7.97% of babies who test positive actually have DiGeorge syndrome? The counts in the table help us see why this value is so low. It is true that the test is correct for most babies with DiGeorge syndrome (225 out of 250) and incorrect only for a small proportion of babies without DiGeorge Syndrome (2599 out of 999750). But since relatively few babies have DiGeorge syndrome, the sheer number of false positives (2599) swamps the number of true positives (225). A high percentage of the positive tests are due to babies who do not have DiGeorge syndrome; that is, most of the positives are false positives. See Figure 1.10 for an illustration.\nThe probability that a baby who tests positive does not have DiGeorge syndrome is \\(\\frac{2599}{2824} = 0.9203\\). A baby who tests positive is 11.55 times more likely to not have DiGeorge syndrome than to have it. (\\(\\frac{0.9203}{0.0797} = 11.55\\))\nBefore observing the test result, the probability that a baby has DiGeorge syndrome is 0.00025. The probability that a baby who tests positive has DiGeorge syndrome is \\(0.0797\\). A baby who tests positive is about 319 times more likely to have DiGeorge syndrome than a baby for whom the test result is not known (\\(\\frac{0.0797}{0.00025} = 319\\)). So while 0.0797 is still small in absolute terms, the probability of having DiGeorge syndrome given a positive test is much larger relative to the probability of having DiGeorge syndrome before the test result is known.\nLook at the “not positive” row of the table. Among the 997176 babies who do not test positive, 997151 do not have DiGeorge syndrome, so the probability that a baby who does not test positive does not have DiGeorge syndrome is \\(\\frac{997151}{997176} = 0.999975\\). In contrast to the positives, almost all of the negative results are true negatives.\nRedo the table with 0.00025 replaced by 0.0025.\n\n\n\n\nHas DiGeorge\nDoes not have DiGeorge\nTotal\n\n\n\n\nPositive\n2250\n2594\n4844\n\n\nNot positive\n250\n994906\n995156\n\n\nTotal\n2500\n997500\n1000000\n\n\n\nAmong pregnant women with this risk factor, the probability that a baby actually has DiGeorge syndrome given a positive test is \\(\\frac{2250}{4844} = 0.464\\). The probability of having a baby with DiGeorge syndrome given a positive test is 5.83 times greater among those with this risk factor than for pregnant women in general. (\\(0.464 / 0.0797 = 5.83\\).)\n\n\n\n\n\nRemember to ask “percentage of what”? For example, the percentage of babies who have DiGeorge syndrome that test positive is a very different quantity than the percentage of babies who test positive that have DiGeorge syndrome.\nLikewise, always ask “probability of what”? For example, the probability that a baby who has DiGeorge syndrome tests positive is a very different quantity than the probability that a baby who tests positive has DiGeorge syndrome; in the first probability we are given that the baby has DiGeorge syndrome, in the second that the baby tests positive. Probabilities are often conditional on information; look out for words like “if” or “given” which signify this information. Revising or changing the order of information will usually change probabilities.\n“Posterior” conditional probabilities (e.g., probability of DiGeorge syndrome given a positive test) can be highly influenced by the original unconditional “prior” probabilities (e.g. probability of DiGeorge syndrome), sometimes called the base rates. Example 1.16 and Figure 1.10 illustrate that when the base rate for a condition is very low and the test for the condition is less than perfect there can be a relatively high probability that a positive test is a false positive. The last part of Example 1.16 illustrates how changing the prior unconditional probability (base rate) influences the posterior conditional probability.\n\n\n\n\n\n\n\n\nFigure 1.10: Illustration of Example 1.16. Each dot represents the baby of a randomly selected pregnant woman who is screened; there are 4000 dots. Only one of these 4000 babies has DiGeorge syndrome (4000 * 0.00025 = 1), represented by the dark blue dot in the top left corner. The other 3999 dots represent babies without DiGeorge syndrome. Suppose the baby with DiGeorge syndrome tests positive. Among the 3999 babies without DiGeorge syndrome, 11 test positive (roughly 0.26% of 3999); these false positives are represented by the light blue dots in the first row. There are 12 positive results, only 1 of which is a true positive. That is, the probability that a positive test result is a true positive is 1/12 = 0.083. (The values aren’t quite the same as in Example 1.16 due to some rounding, but the picture conveys the idea.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Conditioning on DiGeorge Syndrome status.\n\n\n\n\n\n\n\n\n\n\n\n(b) Conditioning on test result.\n\n\n\n\n\n\n\nFigure 1.11: Mosaic plots for Example 1.16.\n\n\n\nPeople have a tendency to ignore base rates; you probably did if your original guess in Example 1.16 was 0.7 or 0.9. Don’t neglect the base rates when evaluating probabilities! We will discuss the role that base rates play and how to revise probabilities in light of new information in much more detail later.\nWe close this section with a brief tangent relating to the discussion in Section 1.2.3. In Example 1.16 there is uncertainty due to the random selection, uncertainty about whether the test will be positive or not, and uncertainty that someone who tests positive actually has the condition. You might consider these three different kinds of randomness, with three different interpretations of corresponding probabilities. For example, you might interpret the probability that a randomly selected person has the condition (0.00025) as a long run relative frequency; however, once the person is selected and tests positive they either have the condition or not—we just don’t know for sure—so you might interpret the probability that they have the condition given a positive test (0.0797) differently. The point is: how we interpret the probabilities does not affect how we solve the problem. The probabilities involved in Example 1.16 “fit together” in the same way regardless of the interpretation; given the context and values 0.00025, 0.9, and 0.0026 we must arrive at 0.0797. Furthermore, to make sense of the value 0.0797 we used both long run relative frequency and relative degrees of likelihood interpretations. We will treat many examples like Example 1.16; we will generally not distinguish between different types of randomness, and we will use interpretations of probability interchangeably.\n\n1.4.1 Exercises\n\nExercise 1.7 In each of the following, which is greater: (a) or (b)? Or are they equal? Or is there not enough information to decide?\n\nSurfing\n\nThe probability that a randomly selected Californian likes to surf.\nThe probability that a randomly selected American is a Californian who likes to surf\n\nCal Poly alums\n\nThe probability that a California resident is a Cal Poly alum.\nThe probability that a Cal Poly alum is a California resident\n\n\n\n\nExercise 1.8 Continuing Example 1.15.\n\nIs the overall percentage of American adults who have a pet cat closer to the value in part 9 or part 10? Why do you think that is?\nWhat percentage of American adults who have a pet dog also have a pet cat?\nWhat percentage of American adults who do not have a pet dog have a pet cat?\n\n\n\nExercise 1.9 Continuing Example 1.15. Now suppose that 11.75% of American adults have both a pet cat and a pet dog (as Donny claimed was necessarily true). Redo Example 1.15 and Exercise 1.8 under this assumption. What is true in this scenario that wasn’t true in Example 1.15?\n\n\nExercise 1.10 Suppose that you have applied to two graduate schools, A and B. Your subjective probability of being accepted is 0.6 for school A and 0.7 for school B.\n\nWhat is the largest possible probability of being accepted by both schools? Under what scenario (however unrealistic) would this be true? Explain.\nWhat is the smallest possible probability of being accepted by both schools? Under what scenario (however unrealistic) would this be true? Explain.\nExplain why the probability of being accepted by both schools is not necessarily 0.42.\nFor the remaining parts, suppose your subjective probability of being accepted at both schools is 0.55. If you are accepted at school A, what is your probability of also being accepted at school B?\nIf you are accepted at school A, what is your probability of not being accepted at school B?\nIf you are not accepted at school A, what is your probability of being accepted at school B?\nIf you are accepted at school B, what is your probability of also being accepted at school A?\nIf you are not accepted at school B, what is your probability of being accepted at school A?\nHow much more likely are you to be accepted at school A if you are accepted at school B than if you are not accepted at school B?\nHow much more likely are you to be accepted at school A if you are accepted at school B compared to before receiving the decision from school B?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-literacy-conditioning",
    "href": "literacy-probability.html#sec-literacy-conditioning",
    "title": "1  What is Probability?",
    "section": "1.5 Conditioning on information",
    "text": "1.5 Conditioning on information\nA probability is a measure of the likelihood or degree of uncertainty or plausibility of an event. A “conditional” probability revises this measure to reflect any additional information about the outcome of the underlying random phenomenon. In Example 1.16 the probability that a baby has DiGeorge syndrome is 0.00025, but if the screening returns a positive result then the probability increases to 0.0797. Always look out for words like “if” or “given” which signify information that influences probabilities.\n\n\n\n\n\n\n\nExample 1.17 In each of the following parts, which of the two probabilities, (a) or (b), is greater, or are they equal? You should answer conceptually without attempting any calculations.\n\nImagine that you randomly select, from birth records, a person who was born in 1950.\n\nThe probability that a person born in 1950 lives to age 100.\nThe probability that a person born in 1950 lives to age 100 given that they are alive in 2045.\n\nImagine the 2032 U.S. Presidential Election (we’re doing so as of this writing in 2023). Assume (a) and (b) below are not 0.\n\nThe probability that Dwayne “The Rock” Johnson wins the 2032 U.S. Presidential Election.\nThe probability that Dwayne “The Rock” Johnson wins the 2032 U.S. Presidential Election given that he does not win the nomination of the Democratic or the Republican Party.\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.17. \n\nThe probability in (b) is greater. Someone who has already lived to age 95 has a better chance of living at least 5 more years than a person has of living from birth to age 100. Think in fraction terms. The denominator in (a) is all people born in 1950; the denominator in (b) is all people born in 1950 who are alive in 2045. It’s the same numerator in each case—people born in 1950 who live until age 100—but (b) has a much smaller denominator, so the fraction corresponding to (b) is larger.\nThis is more subjective, but our assessment is that the probability in (a) is greater. As of this writing (2023), the 2032 election is still many years away so there is a great deal of uncertainty about who will even run let alone win (to say nothing about uncertainty regarding changes in the U.S. and the world that might happen before 2032 and affect the election). Dwayne Johnson’s name has been tossed around in the media as a potential presidential candidate, so let’s say he has some non-zero probability of winning, represented by (a) (which could be very small). As of this writing, we would assess the probability of someone other than the Democratic or Republican nominee winning a U.S. presidential election to be very small, and some pretty major changes would need to occur in order for us to change that assessment. So the information that Dwayne Johnson is the nominee of neither party would lead us to decrease his probability of winning the election.\n\n\n\n\n\nIn a sense, all probabilities are conditional upon some information, even if that information is vague (“well, it has to be one of these possibilities”). Be careful to clearly identify what information is reflected in probabilities, and don’t make assumptions. In part 1 of Example 1.17 if we’re randomly selecting a person from 1950 birth records, then we shouldn’t assume that the person is alive today when evaluating the probability in (a); the selected person could have died between 1950 and now. That is, “the probability that a person born in 1950 lives to age 100” is not the same as “the probability that a person born in 1950 who is alive today lives to age 100”. In part 2 of Example 1.17, we shouldn’t assume that Dwayne Johnson actually runs for president in 2032; the value of our probability should reflect that uncertainty. That is, “the probability that Dwayne Johnson wins the 2032 U.S. Presidential Election” is not the same as “the probability that Dwayne Johnson wins the 2032 U.S. Presidential Election given that he declares himself a candidate”.\n\n\n\n\n\n\n\nExample 1.18 Consider a group of 5 people: Harry, Fleur, Viktor, Cedric, Angelina. Suppose each of their names is written on a slip of paper and the 5 slips of paper are placed into a hat. The papers are mixed up and 2 are pulled out, one after the other without replacement. (That is, the first paper is not added back to the hat before selecting the second.)\n\nWhat is the probability that Harry is the first name selected?\nWhat is the probability that Harry is the second name selected?\nIf you were asked question (2) before question (1), would your answer change? Should it?\nIf Fleur is the first name selected, what is the probability that Harry is the second name selected?\nIf Harry is not the first name selected, what is the probability that Harry is the second name selected?\nIf Harry is the first name selected, what is the probability that Harry is the second name selected?\nConstruct a hypothetical table corresponding to the results of the draws. Hint: one dimension represents the result of the first draw which is Harry or not, and the other dimension represents the second draw.\nIf Fleur is the second name selected, what is the probability that Harry was the first name selected?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.18. \n\nThe probability that Harry is the first name selected is 1/5, which is an answer we think most people would agree with. There are 5 names which are equally likely to be the first one selected, 1 of which is Harry.\nThe probability that Harry is the second name selected is also 1/5. Many people might answer this as 1/4, since after selecting the first person there are now 4 names left. But we show and discuss below that the unconditional probability is 1/5.\nYour answer to question (2) certainly shouldn’t change depending on whether we ask question (1) first. But perhaps after seeing question (1) you are implicitly assuming that Harry has not been selected first? But there is nothing in question (2) that gives you any additional information about what happened on the first card.\nIf Fleur is the first name selected, the probability that Harry is the second name selected is 1/4. We think most people find this intuitive. If Fleur is first, there are 4 cards remaining, equally likely to be the next card, of which 1 is Harry.\n1/4, similar to the previous part. If Harry is not selected first, there are 4 cards remaining, equally likely to be the next card, of which 1 is Harry.\nIf Harry is the first name selected, the probability that Harry is the second name selected is 0 since the cards are drawn without replacement.\nHere is a two-way table of 1000 hypothetical repetitions. Harry is selected first in \\(1000\\times 1/5 = 200\\) repetitions, in which case he can’t be selected second. Among the 800 repetitions where Harry is not selected first, he is selected second in \\(800\\times 1/4 = 200\\) repetitions. Harry is selected second in 200 of the 1000 total repetitions, so the probability that Harry is selected second is \\(200/1000 = 1/5\\).\n\n\n\n\nHarry first\nHarry not first\nTotal\n\n\n\n\nHarry second\n0\n200\n200\n\n\nHarry not second\n200\n600\n800\n\n\nTotal\n200\n800\n1000\n\n\n\nIf Fleur is the second name selected, the probability that Harry was the first name selected is 1/4. It doesn’t really matter what is “first” and what is “second”, but rather the information conveyed. In part 4, what’s important is that you know that one of the cards selected was Fleur, so the probability that the other card selected is Harry is 1/4. But this part conveys the same information.\n\n\n\n\n\nBe careful to distinguish between conditional and unconditional probabilities. A conditional probability reflects additional information about the outcome of the random phenomenon. In the absence of such information, we must continue to account for all the possibilities. When computing probabilities, be sure to only reflect information that is known. Especially when considering a phenomenon that happens in stages, don’t assume that when considering what happens second that you know what happened first.\nIn Example 1.18, the question “if Harry is not the first name selected, what is the probability that Harry is the second name selected?” involves a conditional probability, since we are given additional information about the outcome; it is no longer possible that Harry was the first name selected. The question “What is the probability that Harry is the second name selected?” involves an unconditional probability. The words “the probability that Harry is the second name selected” alone do not imply that Harry was not selected first; we still need to account for the possibility that Harry was selected first.\nImagine shuffling the five cards and putting two on a table face down. Now point to one of the cards and ask “what is the probability that THIS card is Harry?” Well, all you know is that this card is one of the five cards, each of the 5 cards is equally likely to be the one you’re pointing to, and only one of the cards is Harry. Should it matter whether the face down card you’re pointing to was the first or second card you laid on the table? No, the probability that THIS card is Harry should be 1/5, regardless of whether you put it down first or second.\nNow turn over one other card that you’re not pointing to, and see what name is on it. The probability that the card you’re pointing to is Harry has now changed, because you have some information about the outcome of the shuffle. If the card you turned over says Harry, you know the probability that the card you’re pointing to is Harry is 0. If the card you turned over is not Harry, then you know that the probability that the card you’re pointing to is Harry is 1/4. It is not “first” or “second” that matters; it is whether or not you have obtained additional information by revealing one of the cards.\nAnother way of asking the question is: Shuffle the five cards; what is the probability that Harry is the second card from the top? Without knowing any information about the result of the shuffle, all you know is that Harry should be equally likely to be in any one of the 5 positions, so the probability that he is the second card from the top should be 1/5. It is only after revealing information about the result of the shuffle, say the top card, that the probability that Harry is in the second position changes.\nWe often start with a probability for an event and then revise it whenever additional information becomes available. The original, unconditional probability is called a “prior probability” or “base rate”; the revised, conditional probability is called a “posterior probability”. We will discuss the role that base rates play and how to revise probabilities in light of additional information in much more detail later. But remember: Don’t neglect the base rates when evaluating probabilities!\n\n\n\n\n\n\n\nExample 1.19 Within both the colleges of Agriculture and Architecture at Cal Poly, about 49% of admitted students are female, about 84% of admitted students went to high school in CA, and the median GPA of admitted students is about 4.1.\nAn orientation group of 100 newly admitted Cal Poly students includes 75 students in Agriculture and 25 students in Architecture. A student is randomly selected from this group. The selected student is Maddie, who is female, went to high school in CA, and had a high school GPA of 4.1.\n\nIf you are trying to decide which college Maddie is in, is the information that she is female, went to high school in CA, and had a high school GPA of 4.1 helpful? Why?\nDonny Don’t says, “The information about Maddie applies equally well to Agriculture or Architecture and doesn’t help us decide which college she’s in, so it’s just 50/50. Given the information about Maddie, the conditional probability that she is in Agriculture is 0.5.” Do you agree? If not, what is the conditional probability that Maddie is in the college of Agriculture given the information about her? Hint: what was the last sentence before this example!\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.19. \n\nThe information tells us that Maddie would be pretty typical for either group, so it doesn’t help us decide.\nDonny has neglected the base rate. The group has 75 students in Agriculture and 25 students in Architecture. If we randomly select a student from this group, the unconditional probability that the selected student is in Agriculture is 0.75 (the base rate). Yes, the information about Maddie applies equally well to either college, but that means we have no reason to revise our probability from the base rate. The conditional probability that Maddie is in Agriculture given the information about her is still 0.75.\n\n\n\n\n\nWe use the terminology “unconditional” and “conditional” probability, but any probability is conditional on some information. A better way to think about it might just be “before” and “after”. When new information becomes available we revise our probability. The unconditional (prior) probability is the probability before the revision, reflecting any information that was previously available. The conditional (posterior) probability is the probability after the revision, updated to reflect the newly available information. Probabilities are often updated sequentially as more information becomes available, with the conditional (posterior) probability after one piece of information is received becoming the unconditional (prior) probability before the next.\nDo not think of “unconditional” as “based on no information”. Any probability should reflect as much relevant information as possible, even if it plays the role of an unconditional probability.\n\n\n\n\n\n\n\nExample 1.20 Marge takes a home pregnancy test which turns out positive. She decides to perform an analysis like in Example 1.16 to find the conditional probability that she is actually pregnant given the positive test. She knows she’ll need a base rate—that is, an unconditional probability that she is pregnant before the positive test—so she Googles “what percent of women are pregnant?” Information from the CDC suggests that 10.2% of American women aged 15–44 are pregnant at any point in time. Is 0.102 an appropriate value for Marge to use as her base rate? Or is it too high or too low? How will this influence her conditional probability that she is actually pregnant given the positive test? Explain. Hint: did Marge Google the right question?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.20. The value 0.102 is too low for Marge to use as a base rate, and so her conditional probability that she is actually pregnant given the positive test will also be too low. The idea is that a woman who takes a pregnancy test is more likely to be pregnant than a woman in general, simply because many women who take pregnancy tests do so because they suspect they might be pregnant26.\nIf we randomly select an American woman aged 15-44 to take a pregnancy test, then 0.102 would be an appropriate base rate. But we are not told that Marge is a randomly selected woman, so we should not assume that she is. What we do know is that “Marge took a pregnancy test”. Why? From our perspective, it seems more plausible that she took the test because she suspected she might be pregnant as opposed to just “randomly” deciding to take it. And if there is a reason for her to suspect she might be pregnant, then it’s more likely that she actually is and our base rate should reflect that, resulting in a value greater than 0.102. It should be even clearer from Marge’s perspective; she knows why she took the test (e.g., missed period, morning sickness, etc.) and her personal base rate should reflect her information.\nNow we’re not saying it would be easy to determine what an appropriate base rate is, but it should definitely be greater than 0.102. Whatever the prior probability of pregnancy, it will influence the posterior probability of pregnancy given a positive test. Knowing that the test is positive will lead us to revise our probability of pregnancy upward, but if we start with a prior probability that is too low, then our posterior probability will also be too low. (See the last part of Example 1.16 for a related example.)\n\n\n\n\n\n1.5.1 Exercises\n\nExercise 1.11 In each of the following, which is greater: (a) or (b)? Or are they equal? Or is there not enough information to decide? Answer without doing any computations.\n\nShuffle a standard deck of playing cards (52 cards, 4 of which are aces) and deal 5 cards without replacement.\n\nThe probability that the first card dealt is an ace.\nThe probability that the firth card dealt is an ace.\n\nShuffle a standard deck of playing cards (52 cards, 4 of which are aces) and deal 5 cards without replacement.\n\nThe probability that the first card dealt is an ace.\nThe probability that the fifth card dealt is an ace if the first card dealt is an ace.\n\nRandomly select a college student.\n\nThe probability that the selected student went surfing yesterday.\nThe probability that the selected student went surfing yesterday if they student attends Cal Poly.\n\nBoth ballerinas and football players are graceful and nimble. A group of people contains both some ballerinas and some football players. A person is randomly selected from this group; the person is graceful and nimble.\n\nThe probability that the selected person is a ballerina.\nThe probability that the selected person is a football player.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-probofwhat",
    "href": "literacy-probability.html#sec-probofwhat",
    "title": "1  What is Probability?",
    "section": "1.6 Probability of what?",
    "text": "1.6 Probability of what?\nA probability takes a value in the sliding scale from 0 to 1 (or 0% to 100%). Throughout the book we will study how to compute probabilities in many situations. But don’t just focus on computation. Always remember to interpret probabilities properly. This section covers a few ideas to keep in mind when interpreting probabilities.\n\n\n\n\n\n\n\nExample 1.21 In each of the following parts, which of the two probabilities, a or b, is greater, or are they equal? You should answer conceptually without attempting any calculations.\n\nFlip a coin which is known to be fair 10 times.\n\nThe probability that the results are, in order, HHHHHHHHHH.\nThe probability that the results are, in order, HHTHTTTHHT.\n\nFlip a coin which is known to be fair 10 times.\n\nThe probability that all 10 flips land on H.\nThe probability that exactly 5 flips land on H.\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.21. \n\nMany people would say the probability in (b) is larger, but the probabilities in (a) and (b) are equal27. The sequence in (b) seems to look “more random”. However, the probability of seeing that particular sequence—H then H then T then H then T…—is the same as seeing the sequence H then H then H then H then H… If the coin is fair and the flips are independent, all possible sequences of flips are equally likely. Think of it this way: choose any flip, say the third. Then that flip is equally likely to be H (as in the third flip for (a)) or T (as in the third flip for (b)). No matter which flip it is, or the results of the other flips, any flip is equally likely to be H or T.\nOf course, our response assumes that the coin is fair. If the coin is known to be fair then the sequences in (a) and (b) are equally likely. However, if we actually observed the sequence in (a) we might suspect that the coin is actually not fair. There is an important difference between assumption and observation.\nThe probability in (b) is larger. Contrast this to the previous part. There is only one sequence which results in 10 heads, HHHHHHHHHH. However, there are many sequences28 which result in exactly 5 heads—HHHHHTTTTT, HTHTHTHTHT, TTHHTHTHHT, etc—of which HHTHTTTHHT is just one possibility.\n\n\n\n\n\nPay close attention to the differences in the two parts in Example 1.21. The first part involves probabilities of the particular outcome sequence. The second part involves more general “events” that the particular outcome sequence might satisfy. The following provides another example of this “particular” versus “general” dichotomy.\n\n\n\n\n\n\n\nExample 1.22 In each of the following parts, which of the two probabilities, a or b, is greater, or are they equal? You should answer conceptually without attempting any calculations.\n\nIn the Powerball lottery there are roughly29 300 million possible winning number combinations, all equally likely.\n\nThe probability you win the next Powerball lottery if you purchase a single ticket, 4-8-15-16-42, plus the Powerball number, 23.\nThe probability you win the next Powerball lottery if you purchase a single ticket, 1-2-3-4-5, plus the Powerball number, 6.\n\nContinuing with the Powerball\n\nThe probability that the numbers in the winning number are in a row.\nThe probability that the numbers in the winning number are not in a row.\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.22. \n\nMany people would say the probability in (a) is larger, since the sequence in (a) looks “more random”, but the probabilities in (a) and (b) are equal. Since the outcomes are equally likely, the probability that any single sequence is the winning number is (roughly) 1/300,000,000. If you don’t believe this, ask yourself: Why would the Powerball conduct its drawing in such a way that some numbers are more likely to be winners than others? And if some numbers were more likely than others, why wouldn’t people know about this?\nThe probability in (b) is larger. Contrast this to the previous part. There are only a handful of winning numbers for which the numbers are in a row: 1 through 6, 2 through 7, 3 through 8, etc. However, almost all of the 300 million possibilities do not have numbers in a row.\n\n\n\n\n\nWhen interpreting probabilities, be careful not to confuse “the particular” with “the general”.\n“The particular:” A very specific event, surprising or not, often has low probability.\n\nFor a fair coin, observing the particular sequence HHTHTTTHHT in 10 flips is just as likely as observing HHHHHHHHHH.\nThe probability that the winning powerball number is 4-8-15-16-42-(23) is exactly the same as the probability that the winning powerball number is 1-2-3-4-5-(6).\n\nThe probability that you get a text from your best friend at 7:43pm two weeks from today inviting you to dinner at your favorite pizza place after you’ve just ordered pizza from there is probably pretty small. None of these items — getting a text, having a friend invite you to dinner, ordering pizza from your favorite pizza place — is unusual, but the chances of them all combining in this way at this particular time are fairly small.\n\n“The general:” While a very specific event often has low probability, if there are many like events their combined probability can be high.\n\nThere are many possible sequences of 10 coin flips which result in 5 heads.\nFor almost all of the possible Poweball combinations the numbers are not in order.\nThe probability that some time in the next month or so a friend texts a dinner invitation is probably fairly high.\n\n\n\n\n\n\n\n\nExample 1.23 Which of the following two probabilities is greater, or are they equal? You should answer conceptually without attempting any calculations.\n\nThe probability that you win the next Powerball lottery if you purchase a single ticket.\nThe probability that someone wins the next Powerball lottery. (FYI: especially when the jackpot is large, there are hundreds of millions of tickets sold.)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.23. The probability in (2) is much greater. (This is an understatement.)\n\nThe probability that a specific powerball ticket is the winning number is about 1 in 300 million. So if you buy a single ticket, it is extremely unlikely that you will win.\nHowever, if hundreds of millions of powerball tickets are sold, the probability that someone somewhere wins is pretty high.\n\nWe elaborate on these ideas below.\n\n\n\n\nThe probability that you win the next Powerball lottery if you purchase a single ticket is about 1 in 300 million. Let’s put this number in perspective. There are about 260 million adults (over age 18) in the U.S.30 Suppose that the name of every adult in the U.S. is written on a 3x5 index card. These 260 million cards stacked would stretch about 62 miles high; that’s commonly referenced as the distance from the earth to where space begins. The stack would also weigh about 400 tons, about as much 4 blue whales. Suppose we shuffle the cards—much easier said than done—and select one. The probability that your name is on the selected card is about 1 in 260 million. The chances that your next Powerball ticket is the winning number are a little less likely than this31.\nHowever, if hundreds of millions of Powerball tickets are sold, the probability that someone somewhere wins is pretty high. For example, if 500 million tickets are sold then there is a roughly 80% chance that at least one ticket has the winning number (under certain assumptions).\nEven if an event has extremely small probability, given enough repetitions of the random phenomenon, the probability that the event occurs on at least one of the repetitions is often high32.\nConsider the headline of this news article from 2010: “Man mauled by bear after lightning strike”. We certainly feel sorry for this poor man, but just how unlikely is such an occurrence? Let’s look a little closer.\nThe headline seems to imply that the man got struck by lightning and then, while he was trying to reach safety, a bear attacked. But the mauling occurred four years after the lightning strike. Getting mauled by a bear and struck by lightning within one’s lifetime is certainly much more likely than both happening on the same day.\n“Getting struck by lightning” is often colloquially used to describe a rare event, but how unlikely is it? One study estimates that about 250,000 people in the world are struck by lightning each year, and the National Weather Service estimates that the probability that you get struck by lightning within your lifetime is 1/15,000. Still not very likely, but maybe not as rare as you might think.\nGetting mauled by a bear is much less likely than being struck by lightning. There are only about 40 bear attacks of humans each year. However, if the headline had been “Man bitten by shark after lightning strike” or “Man attacked by mountain lion after lightning strike” or “Man trampled by moose after lightning strike” it probably would have been equally newsworthy. Thus we should account for all similar animal attacks, not just bear attacks, when assessing the likelihood.\nThe probability that you get struck by lightning and mauled by a bear today is certainly very small. But the probability that someone somewhere within their lifetime gets both struck by lightning and attacked by an animal is orders of magnitude higher. In general, even though the probability that something very specific happens to you today is often extremely small, the probability that something similar happens to someone some time is often quite high.\nWhen something surprising happens, don’t just consider the probability of that particular outcome. Rather, consider all the other possible outcomes that would have been equally surprising if they had occurred, and consider the probability that at least one of them would happen (which often turns out to be not so small). From this perspective, most coincidences turn out to be much more probable than they seem at first.\nWhen assessing a probability, always ask “probability of what”? Does the probability represent “the particular” or “the general”? Is it the probability that the event happens in a single occurrence of the random phenomenon, or the probability that the event happens at least once in many occurrences? Keep these questions in mind when assessing numerical probabilities. Remember that something that has a “one in a million chance” of happening to you today will happen to about 7000 people in the world every day.\n\n1.6.1 How likely is “likely”?\nConsider each of the following statements (presented in no particular order). If you were to assign a numerical value to the probability of rain tomorrow in each case, what would it be?\n\nIt is likely that it will rain tomorrow.\nIt is probable that it will rain tomorrow.\nThere is little chance that it will rain tomorrow.\nIt is highly unlikely that it will rain tomorrow.\nWe doubt that it will rain tomorrow.\nThere is a very good chance that it will rain tomorrow.\nIt is almost certain that it will rain tomorrow.\nIt is improbable that it will rain tomorrow.\nIt will probably not rain tomorrow.\nIt is highly likely that it will rain tomorrow.\nIt is almost certain that it will not rain tomorrow.\nIt will probably rain tomorrow.\nWe believe that it will rain tomorrow.\nThere is a better than even chance that it will rain tomorrow.\n\nIn a study conducted in the 1960s (Barclay et al. (1977)), twenty-three military officers were asked to provide numerical probabilities for a similar set of statements (“It is almost certain that the Soviets will invade Czechoslovakia”, “It is highly likely that the Soviets will invade Czechoslovakia”, etc.) For most of the statements there was considerable variability in the responses. For example,\n\nProbabilities assigned to “almost certain” ranged from 0.75 to 0.99.\nProbabilities assigned to “highly likely” ranged from 0.50 to 0.99.\nProbabilities assigned to “likely” ranged from 0.30 to 0.90.\nProbabilities assigned to “probable” ranged from 0.25 to 0.90.\n\nRecent similar studies have produced comparable results that exhibit wide variability in the numerical values people associate with words describing probabilities. Studies like these provide evidence of differences in how people perceive probability.\nOne way to avoid ambiguity is to provide numerical values of probability rather than just vague words like “likely” or “probable”. However, people can still perceive numbers differently. An event that has a probability of 0.4 is four times more likely than an event with a probability of 0.1, but how likely is either event? Depending on their background, people might interpret a probability of 0.4 differently. Someone familiar with baseball knows that 0.4 would be an extremely high value for the probability that a particular batter successfully gets a hit in at bat, while someone familiar with basketball knows that 0.4 would be extremely low value for the probability that a particular player successfully scores on a free throw attempt. An audience that routinely encounters probabilities close to 0 will perceive a probability of 0.4 differently than one that commonly deals with probabilities around 0.5. When reporting probabilities, it is helpful to provide some benchmarks from a context more familiar to the audience to provide a sense of scale33.\nFor example, for people from California you might provide benchmarks based on county populations. If you randomly select a single California resident (about 39 million people) there is, roughly, a\n\n25% chance they are from Los Angeles County (about 9.7 million people)\n8% chance they are from Orange County (about 3.2 million people)\n0.7% chance they are from San Luis Obispo County (about 300 thousand people)\n0.1% chance they are from Calaveras County (about 46 thousand people)\n\nProviding a few values in this manner can help the audience gauge the magnitude of a probability like 0.2 or 0.0134.\nBe sure to keep in mind “the particular versus the general”. When reporting the value of a probability, provide enough contextual detail so that the audience can distinguish “the particular from the general”. If the probability of interest represents “the particular”, then provide benchmarks in terms of “the particular”; likewise for “the general”. In the California county example, we could use the values provided for a single randomly selected resident to benchmark “particular” probabilities (what is the probability this happens to me?). For “general” probabilities we could revise in terms like “if we randomly select 100 CA residents, there is a 50% chance that at least one resident is from San Luis Obispo County”.\nSo how likely is “likely”? We hope you see that there is no clear answer to this question. When communicating probabilities, our best advice is to:\n\nReport numerical values instead of ambiguous words.\nProvide enough contextual detail to identify “probability of what?”. In particular, be careful to distinguish “the particular from the general”.\nProvide the value of a few helpful benchmark probabilities in a familiar context to provide a sense of scale.\nRemember that despite your best efforts, people might still perceive probabilities differently.\n\n\n\n1.6.2 Exercises\n\nExercise 1.12 Create your own analogy for how unlikely that a single ticket wins the Powerball lottery. How would you describe a 1 in 300 million chance?\n\n\nExercise 1.13 In each of the following, which is greater: (a) or (b)? Or are they equal? Or is there not enough information to decide?\n\nElection interference\n\nThe probability that Russian agents successfully interfere with the 2024 U.S. Presidential election through posts on Facebook with the goal of helping the Republican candidate get elected.\nThe probability that non-U.S. actors attempt to interfere with the 2024 U.S Presidential election.\n\nRoll a six-sided die which is known to be fair 10 times.\n\nThe probability that the results are, in order, 1223334444.\nThe probability that the results are, in order, 4614253226.\n\nRoll a six-sided die which is known to be fair 10 times.\n\nThe probability that the results are, in order, 1234561234.\nThe probability that you roll each of the six faces at least once.\n\n\n\n\nExercise 1.14 Search online to find some benchmark probabilities (e.g., 0.25, 0.1, 0.01, 0.001, 0.0001, etc.) in a context that is interesting and familiar to you.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-literacy-ev",
    "href": "literacy-probability.html#sec-literacy-ev",
    "title": "1  What is Probability?",
    "section": "1.7 “Expected” value",
    "text": "1.7 “Expected” value\nWe are often interested in numerical values associated with a random phenomenon. If we flip a coin 100 times we might be interested in the number of flips which land on heads or the longest streak of heads. Forecasting tomorrow’s weather, we might be interested in the high temperature or amount of precipitation. Predicting the next Superbowl, we might be interested in the total number of points scored or the margin of victory.\nWhen dealing with uncertain numerical quantities, we often ask: what value do we expect? In this section we’ll introduce how we might answer this question. We’ll also give a first warning to be careful about what we mean by “expected” values.\n\n\n\n\n\n\n\nExample 1.24 This is a very simplified example illustrating the basic idea of how insurance works. Every year an insurance company sells many thousands of car insurance policies to drivers within a particular risk class. Each policyholder pays a “premium” of $1000 at the start of the year, and the insurance company agrees to pay for the cost of all damages that occur during the year. Suppose that each policy incurs damage of either $0, $5000, $20000, or $50000 with the following probabilities.\n\n\n\nAmount of damage ($)\nProfit ($)\nProbability\n\n\n\n\n0\n1000\n0.910\n\n\n5000\n-4000\n0.070\n\n\n20000\n-19000\n0.019\n\n\n50000\n-49000\n0.001\n\n\n\nThe insurance company’s profit on a policy at the end of the year is the difference between the premium of $1000 and any damage paid out. For example, a policy that incurs no damage results in a profit of $1000; a policy that incurs $5000 in damage results in a profit of -$4000 (that is, a loss of $4000) for the insurance company.\n\nInterpret the probabilities 0.91, 0.07, 0.019, and 0.001 as long run relative frequencies in this context.\nCompute the probability that a policy results in a positive profit for the insurance company.\nImagine 100,000 hypothetical policies. How many of these policies would you expect to result in a profit of $1000? -$4000? -$19000? -$49000?\nWhat do you expect the total profit for these 100,000 policies to be?\nWhat do you expect the average profit per policy for these 100,000 policies to be?\nCompute the probability that a policy has a profit equal to the value from part 5.\nCompute the probability that a policy has a profit greater than the value from part 5.\nIs the value from part 5 the most likely value of profit for a single policy?\nIs the value from part 5 the profit you would expect for a single policy?\nExplain in what sense the value from part 5 is “expected”.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.24. \n\nIf the insurance company sells many such policies, 91% of policies will incur $0 in damage and result in a profit of $1000, 7% of policies will incur $5000 in damage and result in a profit of -$4000, etc.\nIn this scenario a policy results in a positive profit for the insurance company only if it incurs no damage, so the probability is 0.91.\nOver many policies, we would expect 91% of policies to result in a profit of $1000, so we would expect \\(100000\\times 0.91 = 91000\\) of these policies to result in a profit of $1000. Continue in a similar manner to complete the “expected number of policies” column in the table below.\nWe expect 91000 polices to each result in a profit of $1000, for a total expected profit from these policies of \\(91000 \\times 1000 = 91000000\\). Continue in a similar manner to complete the “expected total profit” column in the table below. The expected total profit for all 100000 policies is $22,000,000.\n\n\n\n\n\n\n\n\n\n\nAmount of damage ($)\nNet profit ($)\nProbability\nExpected number of policies\nExpected total profit ($)\n\n\n\n\n0\n1000\n0.910\n91000\n91,000,000\n\n\n5000\n-4000\n0.070\n7000\n-28,000,000\n\n\n20000\n-19000\n0.019\n1900\n-36,100,000\n\n\n50000\n-49000\n0.001\n100\n-4,900,000\n\n\nTotal\nNA\n1\n100000\n22,000,000\n\n\n\nThe expected total profit for these 100000 policies is $22,000,000, so the expected average profit per policy is $220. (\\(\\frac{22000000}{100000} = 220\\))\nThe probability that a policy has a profit equal to $220 is 0. In this scenario, the only possible values of profit are 1000, -4000, -19000, and -49000.\nThe probability that a policy has a profit greater than $220 is 0.91. Over many policies, 91% of policies have a profit greater than the expected average profit per policy.\nNo! Not only is $220 not the most likely value, it’s not even a possible value of the profit of a policy.\nNo! It’s not even possible for a single policy to have a profit of $220.\nOver many policies, we expect the average profit per policy to be $220. That is, $220 is the long run average profit per policy.\n\n\n\n\n\nA single policy either results in a positive profit for the insurance company or not. For a group of policies we can compute the relative frequency of a positive profit: count the number of policies with a positive profit and divide by the total number of policies. The probability that a policy results in a positive profit can be interpreted as a long run relative frequency over many policies.\nBut there is more to the profit on a policy than whether it is positive or not; we are also interested in the amount of profit. For a group of policies we can compute the average profit: add up the values of the profits and divide by the total number of policies. The long run average value over many policies is called the “expected value” of profit.\nBe careful: the term “expected value” is somewhat of a misnomer. The expected value is not necessarily the value we expect on a single repetition of the random phenomenon. In Example 1.24 the expected value of profit is $220, but it is not possible for a single policy to have a profit of $220. Rather, $220 is the average profit per policy we expect to see in the long run over many policies. A probability can be interpreted as a long run relative frequency; an expected value can be interpreted as a long run average value.\n\n\n\n\n\n\n\nExample 1.25 Continuing Example 1.24. We considered what we would expect for 100000 hypothetical policies, but what about an unspecified large number of policies?\n\nImagine that we have recorded the profit for each of a large number of policies (not necessarily 100000). Explain in words the process by which you would compute the average profit per policy. (In other, more general, words: how do you compute an average of a list of numbers?)\nGiven that the profit of any policy is either 1000, -4000, -19000, or -49000, how could we simplify the calculation of the sum in the previous part? Write a general expression for the average profit per policy in this scenario.\nWhat do you think the expression in the previous part converges to in the long run?\nExplain how the value in the previous part is a “probability-weighted average value”.\nCompute the expected value of damage (not profit) as a probability-weighted average value.\nInterpret the value from the previous part as a long run average value in this context.\nHow is the expected value of profit related to the expected value of damage? Does this make sense? Why?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.25. \n\nCompute an average in the usual way: add up all the values and divide by the number of values. If there were 100000 policies, we would add up the 100000 values of profit and divide by 100000; this is basically what we did in part 5 of Example 1.24).\nThe profit of any policy is either 1000, -4000, -19000, or -49000, so when we add up the profits of many policies we’re adding the same values over and over. If 91000 values are equal to 1000, then we add \\(1000 + 1000 + \\cdots\\), 91000 times; in other words, the contribution to the sum for the policies with a profit of $1000 is \\(1000\\times 91000\\). For a general number of policies, the contribution to the sum of the policies with a profit of 1000 is \\(1000\\times\\) number of policies with a profit of 1000. The average profit per policy can be expressed as \\[\n{\\scriptscriptstyle\n\\frac{1000\\times \\text{number with profit of 1000} + (-4000)\\times \\text{number with profit of -4000}  + (-19000) \\times \\text{number with profit of -19000}  + (-49000) \\times \\text{number with profit of -49000} }{\\text{total number of policies}}\n}\n\\]\nDivide through by the total number of policies \\[\n{\\scriptstyle\n1000\\times \\frac{\\text{number with profit of 1000}}{\\text{total number of policies}} + (-4000)\\times \\frac{\\text{number with profit of -4000}}{\\text{total number of policies}}  + (-19000) \\times \\frac{\\text{number with profit of -19000}}{\\text{total number of policies}}  + (-49000) \\times \\frac{\\text{number with profit of -49000}}{\\text{total number of policies}}\n}\n\\] The fractions in the expression above are the relative frequencies of each value of profit. In the long run (over many policies), the relative frequencies will converge to the respective probabilities; for example, \\(\\frac{\\text{number with profit of 1000}}{\\text{total number of policies}}\\) will converge to 0.91. Therefore, the long run average profit per policy is \\[\n1000\\times 0.910 + (-4000)\\times 0.070 + (-19000) \\times 0.019 + (-49000) \\times 0.001 = 220\n\\]\nThe profit for each policy is either 1000, -4000, -19000, or -49000. However, when computing the average profit per policy we can’t simply average these four values since many policies will have a profit of 1000 and very few will have a profit of -49000. In a sense, 1000 will have more “weight” in the average profit per policy than -49000 does. Therefore, we multiply each possible value of profit by its corresponding probability and then add to get a “probability-weighted average value” which reflects how likely each possible value is.\nMultiply each value of damage by its corresponding probability and then sum. \\[\n0\\times 0.910 + 5000\\times 0.070 + 20000 \\times 0.019 + 50000 \\times 0.001 = 780\n\\]\nOver many policies we expect the long run average damage per policy to be $780.\nThe expected value of profit is $1000 minus the expected value of damage: \\(220 = 1000 - 780\\). The profit on any policy is the difference between the premium of $1000 and the amount of damage, so it makes sense that the average profit per policy is $1000 minus the average damage per policy.\n\n\n\n\n\nThe previous example illustrates that the long run average value is also the probability-weighted average value. That is, we multiplied each possible value by its corresponding probability and then summed. Interpreting an expected value as a probability-weighted average value might be more natural in situations involving subjective probabilities.\n\n\n\n\n\n\n\nExample 1.26 As of this writing there are currently fifty U.S. states, with Hawaii being the last new state admitted (in 1959). How many new states will be admitted in the next twenty years? Sam assesses that 0 new states is most plausible, and 10 times more plausible than 1 new state, which is 10 times more plausible than 2 new states, which is 10 times more plausible than 3 new states, and more than 3 states has negligible plausibility. What is Sam’s expected value of the number of new states? How do you interpret this value?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 1.26. First compute Sam’s subjective probabilities. Let 3 new states represent 1 “unit”, then 2 new states represents 10 units, 1 new state 100 units, and 0 new states 1000 units, for a total of 1111 units. Rescale the values so they sum to 1 to obtain Sam’s subjective probabilities.\n\n\n\n\n\n\n\n\nNumber of new states\nUnits\nProbability (as fraction, rounded decimal)\n\n\n\n\n0\n1000\n1000/1111 = 0.9001\n\n\n1\n100\n100/1111 = 0.0900\n\n\n2\n10\n10/1111 = 0.0090\n\n\n3\n1\n1/1111 = 0.0009\n\n\nTotal\n1111\n1\n\n\n\nNow compute Sam’s expected value as a probability-weighted average value \\[\n0\\left(\\frac{1000}{1111}\\right)  + 1\\left(\\frac{100}{1111}\\right) + 2\\left(\\frac{10}{1111}\\right) + 3 \\left(\\frac{1}{1111}\\right) = \\frac{123}{1111} = 0.1107\n\\]\nThis does not mean that Sam expects 0.11 new states; it’s not possible to have 0.11 new states. Rather, 0.11 represents an average of the possible values of the number of new states, weighted to reflect the relative plausibilities of the possible values.\n\n\n\n\nWe will see other interpretations of expected values later. In particular, we will see in what sense an expected value can be interpreted as a “best guess” of an uncertain random quantity.\nReturning to Example 1.24, the insurance company’s profit is the policyholder’s loss. Most policyholders pay the $1000 premium and incur no damage. Furthermore, the expected value of the loss for a policyholder is $220. Why are people willing to buy insurance despite this? Individuals live in the short run; any individual is either going to incur damage or not. Insurance is protection against the risk of a large loss. Even though the probability of occurrence is small, incurring a large amount of damage like $50000 would have serious financial consequences for most individuals. Many people are willing to trade a sure but relatively small monetary loss like $1000 to protect against an unlikely but serious loss like $50000.\nOn the other hand, insurance companies operate in the long run. Over many policies, an insurance company is virtually guaranteed an average profit of $220 per policy. The insurance company will lose, and lose big, on some policies. But these losses are more than offset in the long run by the relatively small profits on the large number of policies that incur no damage.\n\n1.7.1 Exercises\n\nExercise 1.15 A roulette wheel has 18 black spaces, 18 red spaces, and 2 green spaces, all the same size and each with a different number on it. Suppose you bet $1 on black. If the wheel lands on black, you win your initial bet back plus an additional $1; otherwise you lose the money you bet. That is, your net winnings are either +1 or -1 dollar.\n\nCompute the probability-weighted average value of your net winnings.\nIs the value in the previous part the net winnings you would expect on a single bet?\nExplain in what sense the value from the first part is “expected”.\n\n\n\nExercise 1.16 A roulette wheel has 18 black spaces, 18 red spaces, and 2 green spaces, all the same size and each with a different number on it. Suppose you bet $1 on 7. If the wheel lands on 7, you win your initial bet back plus an additional $35; otherwise you lose the money you bet. That is, your net winnings are either +35 or -1 dollar.\n\nCompute the probability-weighted average value of your net winnings.\nIs the value in the previous part the net winnings you would expect on a single bet?\nExplain in what sense the value from the first part is “expected”.\n\n\n\nExercise 1.17 Compare Exercise 1.15 and Exercise 1.16. Are the two $1 bets — bet on black versus bet on 7 — identical? In what way are these betters the same? In what ways are they different?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-sim",
    "href": "literacy-probability.html#sec-sim",
    "title": "1  What is Probability?",
    "section": "1.8 A brief introduction to simulation",
    "text": "1.8 A brief introduction to simulation\nHere’s a seemingly simple problem. Flip a fair coin four times and record the results in order. For the recorded sequence, compute the proportion of the flips which immediately follow a H that result in H. What value do you expect for this proportion? (If there are no flips which immediately follow a H, i.e. the outcome is either TTTT or TTTH, discard the sequence and try again with four more flips.)\nFor example, the sequence HHTT means the first and second flips are heads and the third and fourth flips are tails. For this sequence there are two flips which immediately followed heads, the second and the third, of which one (the second) was heads. So the proportion in question for this sequence is 1/2.\nSo what value do you expect for this proportion? We think it’s safe to say that most people would answer 1/2. After all, it shouldn’t matter if a flip follows heads or not, right? We would expect half of the flips to land on heads regardless of whether the flip follows H, right? We’ll see there are some subtleties lurking behind these questions.\nTo get an idea of what we would expect for this proportion, we could conduct a simulation: flip a coin 4 times and see what happens. Table 1.4 displays the results of a few repetitions; each repetition consists of an ordered sequence of 4 coin flips for which the proportion in question is measured. (Flips which immediately follow H are in bold.)\n\n\n\nTable 1.4: Simulated outcomes for 10 sets of four flips of a fair coin, each set with at least one flip following a flip of H.\n\n\n\n\n\n\n\n\n\n\n\n\nRepetition\nOutcome\nFlips that follow H\nH that follow H\nProportion of H followed by H\n\n\n\n\n1\nHHTT\n2\n1\n0.5\n\n\n2\nHTTH\n1\n0\n0\n\n\ndiscarded\nTTTH\n0\nNA\ntry again\n\n\n3\nHTHT\n2\n0\n0\n\n\n4\nTHHH\n2\n2\n1\n\n\n5\nHHTT\n2\n1\n0.5\n\n\n6\nHHHT\n3\n2\n0.667\n\n\n7\nHTTH\n1\n0\n0\n\n\n8\nTHHT\n2\n1\n0.5\n\n\n9\nTHTT\n1\n0\n0\n\n\n10\nHHHH\n3\n3\n1\n\n\n\n\n\n\nTable 1.5 and Figure 1.12 summarize the results of these 10 repetitions of the simulation.\n\n\n\n\nTable 1.5: Table of observed values of the proportion of H followed by H and their frequencies for the ten sets of coin flips in Table 1.4.\n\n\n\n\n\n\nProportion of H following H\nFrequency\nRelative frequency\n\n\n\n\n0.0000\n4\n0.4\n\n\n0.5000\n3\n0.3\n\n\n0.6667\n1\n0.1\n\n\n1.0000\n2\n0.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.12: Dot plot: Each dot represents the proportion of H followied by H for a set of four coin flips in Table 1.4\n\n\n\n\n\nWe can keep repeating the above process to investigate what happens in the long run. Rather than actually flipping coins, we use a computer to run a simulation. Figure 1.13 summarizes the results of 1,000,000 successful repetitions of the simulation, after discarding the sequences with no flips following H. (We will see how to program, run, and summarize simulations like this in later chapters.) While you can’t see the individual “dots” like in Figure 1.12 each dot would represent a sequence of 4 coin flips (with at least one flip following a H) and the value being plotted is the proportion of H followed by H for that sequence. The results would look like those in Table 1.4, albeit a table with 1,000,000 rows (after discarding rows with no flips immediately following H.)\n\n\n\n\n\n\n\n\n\n\n\n(a) Table of observed values and frequencies.\n\n\n\n\n\n\n\n\n\n\n\n(b) Spike plot: heights of the spikes represent the relative simulated relative frequencies of each possible value of proportion of H followied by H for a set of four coin flips\n\n\n\n\n\n\n\nFigure 1.13: Proportion of flips immediately following H that result in H for 1,000,000 sets of 4 coin flips, each set having at least one flip immediately following H. For example, the proportion of H followed by H is 0 in 429,123 of the sets.\n\n\n\nWe asked the question: what would you expect for the proportion of the flips which immediately follow a H that result in H? That depends on how we define what’s “expected”. If we are interested in the value that is most likely to occur when we flip a coin four times, then the answer is 0: we see that in the long run a little over 40% of the sets resulted in a proportion of 0, while only about 30% of sets resulted in a value of 1/2. We see that Figure 1.13 (b) is not centered at 1/2; a higher percentage of repetitions resulted in a proportion below 1/2 than above 1/2. We think that most people would find this surprising.\nAnother way to interpret “expected” is as “average”; in particular, expected value can be interpreted as the long run average value. After 1,000,000 repetitions, each involving a set of four fair coin flips, we have 1,000,000 simulated values of the proportion of H following H. We could then average these values: add up all the values and divide by 1,000,000.\n\\[\n{\\scriptscriptstyle\n\\frac{0\\times 429123 + (1/2)\\times 285906 + (2/3) \\times 71414 + 1 \\times 213557}{1000000} = 0.404\n}\n\\]\nIt turns out that the long run average value is 0.405, which is not 1/2. Again, we think most people find this surprising.\nA reminder: the term “expected value” is somewhat of a misnomer. We are not saying that if we flip a coin four times we would expect the proportion of H following H for that set of flips to be 0.405. In fact, in any single set of four fair coin flips the only possible values for the proportion of H followed by H are 0, 1/2, 2/3, and 1. So in a set of four coin flips it’s not possible to see a proportion of 0.405. Rather, 0.405 is the average value of the proportion of H followed by H that we would expect to see in the long run over many sets of four fair coin flips.\nThe simulation provides evidence that, counter to our intuition, we would expect the proportion of H followed by H to be less than 0.5. So what is happening here? We will return to this example several times to investigate these results more closely. We’ll leave it as a mystery for now, but observe that:\n\nThe study of probability can involve some subtleties and our intuition isn’t always right.\nSimulation is an effective way of investigating probability problems, and can reveal interesting and surprising patterns.\nThere is a difference between (1) the probability that a flip following H lands on H and (2) the proportion of flips following H which result in H in a fixed sequence of fair coin flips35.\nIn a fixed number of fair coin flips, the proportion of flips following H which result in H is “expected” to be less than the true probability of H, even though the trials are independent.\n\n\n1.8.1 Exercises\n\nExercise 1.18 In a group of \\(n\\) people, what is the probability that at least two people in the group people have the same birthday?\n\nConsider \\(n=30\\): what do you think the probability that at least two people in a group of 30 people share a birthday is: 0-20%, 20-40%, 40-60%, 60-80%, 80-100%?\nHow large do you think \\(n\\) needs to be in order for the probability that at least two people share a birthday to be larger than 0.5?\nWe’ll save the answer to these questions for later, but they turn out to be unintuitive to many people, and simulation can shed some light. Explain how, in principle, you might perform a simulation using cards or slips of paper to estimate the probability that at least two people have the same birthday when \\(n=30\\). You can make some simplifying assumptions: Ignore multiple births and February 29 and assume that the other 365 days are all equally likely36.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#sec-why-toys",
    "href": "literacy-probability.html#sec-why-toys",
    "title": "1  What is Probability?",
    "section": "1.9 Why study coins, dice, cards, and spinners?",
    "text": "1.9 Why study coins, dice, cards, and spinners?\nMany probability problems involve “toy” situations like flipping coins, rolling dice, shuffling cards, or spinning spinners. These situations might seem unexciting, or at least not very practically meaningful. However, coins and spinners and the like provide familiar, concrete situations which facilitate understanding of probability concepts. Furthermore, simple situations often provide insight into real and complex problems. The following is just one illustration.\nMany basketball players and fans alike believe in the “hot hand” phenomenon: the idea that making several shots in a row increases a player’s chances of making the next shot. However, the consensus conclusion of thirty years of studies on the hot hand, beginning with the seminal study Gilovich, Vallone, and Tversky (1985), had been that there is no statistical evidence that the hot hand in basketball is real. As a result, many statisticians regularly caution against the “hot hand fallacy”: the belief that the hot hand exists when, in reality, the degree of streaky behavior typically observed in sequential data is consistent with what would be expected simply by chance in independent trials.\nThe idea behind studies like Gilovich, Vallone, and Tversky (1985) is essentially the following. Consider a player who attempts 100 shots and makes 50%. If there is no hot hand, then we might expect the player to make 50% of shots both on attempts that follow hit streaks— usually considered three (or more) made attempts in a row—and on other attempts. Therefore, a success rate of 50% on both sets of attempts provides no evidence of the hot hand.\nHowever, recent research of Miller and Sanjurjo (2018a), Miller and Sanjurjo (2018c), Miller and Sanjurjo (2018b) concludes that previous studies on the hot hand in basketball, starting with Gilovich, Vallone, and Tversky (1985), have been subject to a bias. After correcting for the bias, the authors find evidence in favor of the hot hand effect in basketball shooting, suggesting the hot hand fallacy is not a fallacy after all. One interesting aspect of these studies is that Miller and Sanjurjo’s methods are simulation-based.\nMiller and Sanjurjo (2018a) introduced the coin flipping problem in Section Section 1.8) to illustrate the idea behind their research and the bias in previous studies. Consider again a player who attempts 100 shots and makes 50%. Even if there is no hot hand, Miller and Sanjurjo show that we would actually expect the player to have a shooting percentage of strictly less than 50% on the attempts which followed streaks, and strictly greater than 50% on the other attempts. The reason is similar to what we observed in the the coin flipping problem in Section 1.8: in a fixed number of trials, the proportion of H on trials following H is expected to be less than the true probability of H, even though the trials are independent. Therefore, for the example player a success rate of 50% on both sets of attempts actually provides directional evidence in favor of the hot hand. Properly acccounting for this bias leads to substantially different statistical analyses (i.e., p-values) and conclusions.\n\n1.9.1 Exercises\n\nExercise 1.19 Find the value of some probability in a real world situation of interest to you. Then describe how this situation could be modeled with coins, dice, cards, or spinners. How would you use your “toys” to simulate the situation and approximate the probability of interest?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#chapter-exercises",
    "href": "literacy-probability.html#chapter-exercises",
    "title": "1  What is Probability?",
    "section": "1.10 Chapter exercises",
    "text": "1.10 Chapter exercises\n\nExercise 1.20 True or false.\n\nProbability can be used to assess the likelihood or plausibility of an event associated with a phenomenon that only happens once.\nProbability can be used to assess the likelihood of an event associated with a phenomenon that happended in the past.\nThe subjective and long run relative frequency interpretations of probability can be used interchangeably.\nSuppose the probability that a randomly selected CP student has an internship this summer is 0.2, and the probability that a randomly selected CP student is taking at least one course this summer is 0.4. True false: the probability that a randomly selected CP student either has an internship or is taking at least one class (or both) must be 0.6.\nSuppose the probability that a randomly selected CP student has an internship this summer is 0.2, and the probability that a randomly selected CP student is taking at least one course this summer is 0.4. True false: the probability that a randomly selected CP student both has an internship and is taking at least one class must be 0.08.\n\n\n\nExercise 1.21 Short answer.\n\nYour subjective probability that the price of regular unleaded gasoline at your favorite gas station in SLO stays above $5 per gallon throughout the next month is 0.95. How many times more likely than not is it for the price to stay above $5 per gallon through the next month?\nIt is 3 times more likely than not that the high temperature tomorrow will be greater than 80 degrees F. What is the probability that the high temperature tomorrow will be greater than 80 degrees F?\nLaszlo, Nadja, and Nandor are having a tournament. Guillermo thinks that Nandor is 3.5 times more likely to win than Nadja, and Nadja is 2 times more likely to win than Lazlso. Find Guillermo’s probability that Nandor wins.\n\n\n\nExercise 1.22 In each of the following, which of a or b is strictly greater? Or are they equal? Or is there not enough information to decide? Explain your reasoning.\n\nSurfing Californians\n\nThe probability that a randomly selected Californian likes to surf\nThe probability that a randomly selected American is a Californian who likes to surf\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\nCal Poly graduates\n\nThe probability that a randomly selected Cal Poly graduate is a California resident\nThe probability that a randomly selected California resident is a Cal Poly graduate\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\nFlips a coin which is known to be fair six times and record the results in sequence\n\nThe probability that the first five flips are, in order, HHHHH\nThe probability that the first six flips are, in order, HTTHTH\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\nI catch my child hiding in the bathroom washing chocolate off her face. I ask what her what she’s doing, and she says she just had to go the bathroom.\n\nThe probability that my child just went to the bathroom.\nThe probability that my child just went to the bathroom and has secretly been eating chocolate cake.\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\nAmong American workers, 40% have a college degree and 10% belong to a labor union.\n\n4%\nThe percentage of American workers who have a college degree and belong to a labor union.\na and b are necessarily equal\nThere is not enough information provided to decide whether a or b is strictly greater\n\n\n\n\nExercise 1.23 Suppose\n\n85% of people have a dominant right hand.\n75% of people with a dominant right hand have a dominant right eye.\n55% of people who do not have a dominant right hand have a dominant right eye.\n\n\nWhat percent of people with a dominant eye have a dominant right hand?\nWhat percent of people with a dominant right eye do not have a dominant right hand?\nWhat percent of people without a dominant right eye have a dominant right hand?\nWhat percent of people with a dominant right hand have a dominant right eye?\nWhat percent of people have a dominant right eye and a dominant right hand?\n\n\n\n\n\n\nAldous, David. 2023. “Forty Thousand Coin Tosses Yield Ambiguous Evidence for Dynamical Bias.” 2023. https://www.stat.berkeley.edu/~aldous/Real-World/coin_tosses.html.\n\n\nBarclay, Scott, Rex Brown, Clinton III, Cameron Peterson, and Lawrence Phillips. 1977. “Handbook for Decision Analysis,” September, 284.\n\n\nBartoš, František, Alexandra Sarafoglou, Henrik R. Godmann, Amir Sahrani, David Klein Leunk, Pierre Y. Gui, David Voss, et al. 2024. “Fair Coins Tend to Land on the Same Side They Started: Evidence from 350,757 Flips.” https://arxiv.org/abs/2310.04153.\n\n\nDavid, F. N. 1955. “Studies in the History of Probability and Statistics i. Dicing and Gaming (a Note on the History of Probability).” Biometrika 42 (1/2): 1–15. http://www.jstor.org/stable/2333419.\n\n\nDiaconis, Persi, Susan Holmes, and Richard Montgomery. 2007. “Dynamical Bias in the Coin Toss.” SIAM Review 49 (2): 211–35. http://www.jstor.org/stable/20453950.\n\n\nDiaconis, Persi, and Brian Skrms. 2018. Ten Great Ideas about Chance. Princeton University Press. http://www.jstor.org/stable/j.ctvc77m33.\n\n\nGilovich, Thomas D., Robert P. Vallone, and Amos Tversky. 1985. “The Hot Hand in Basketball: On the Misperception of Random Sequences.” Cognitive Psychology 17 (3): 295–314. https://doi.org/https://doi.org/10.1016/0010-0285(85)90010-6.\n\n\nKahneman, Daniel. 2012. Thinking, Fast and Slow. London: Penguin.\n\n\nMiller, Joshua B., and Adam Sanjurjo. 2018a. “Surprised by the Hot Hand Fallacy? A Truth in the Law of Small Numbers.” Econometrica 86 (6): 2019–47. https://doi.org/10.3982/ECTA14943.\n\n\n———. 2018b. “A Cold Shower for the Hot Hand Fallacy: Robust Evidence That Belief in the Hot Hand Is Justified.” OSF Preprints. https://doi.org/10.31219/osf.io/pj79r.\n\n\n———. 2018c. “Is It a Fallacy to Believe in the Hot Hand in the NBA Three-Point Contest?” OSF Preprints. https://doi.org/10.31219/osf.io/dmksp.\n\n\nMurray, Daniel B., and Scott W. Teare. 1993. “Probability of a Tossed Coin Landing on Edge.” Phys. Rev. E 48 (October): 2547–52. https://doi.org/10.1103/PhysRevE.48.2547.\n\n\nTversky, Amos, and Daniel Kahneman. 1982. “Judgments of and by Representativeness.” In Judgment Under Uncertainty: Heuristics and Biases, edited by Daniel Kahneman, Paul Slovic, and AmosEditors Tversky, 84–98. Cambridge University Press. https://doi.org/10.1017/CBO9780511809477.007.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "literacy-probability.html#footnotes",
    "href": "literacy-probability.html#footnotes",
    "title": "1  What is Probability?",
    "section": "",
    "text": "The Grand Duke of Tuscany posed this problem to Galileo, who published his solution in 1620. However, unbeknownst to Galileo, the same problem had been solved almost 100 years earlier by Gerolamo Cardano, one of the first mathematicians to study probability (David 1955).↩︎\nOr maybe not. We are considering heads and tails as the only outcomes, but what about a coin landing on its edge? It can happen, but the probability is very small; Murray and Teare (1993) estimates the probability that a U.S. nickel lands on its edge to be about 0.000167. Furthermore, there is evidence (Diaconis, Holmes, and Montgomery (2007), Aldous (2023), Bartoš et al. (2024)) that a coin is slightly more likely to land the same way it started. That is, if the coin starts facing heads up, the probability that it lands facing heads up is slightly greater than 0.5, but the difference is small. Quoting Section 7 of Diaconis, Holmes, and Montgomery (2007): “The classical assumptions of independence with probability 1/2 are pretty solid.” We hope you agree that assuming two equally likely outcomes is reasonable for practical purposes.↩︎\nWe do not advocate gambling. We merely use gambling contexts to motivate probability concepts.↩︎\nThere is a vast literature on how people make decisions when faced with uncertainty. Kahneman (2012) provides an excellent introduction.↩︎\nDiaconis and Skrms (2018) provides a nice introduction.↩︎\nFor example, we are not distinguishing between “aleatoric variability” and “epistemic uncertainty”.↩︎\nThis is the first of many spinners in this book. Our purpose in using spinners is not to advocate pie charts for summarizing data. Rather, we think spinners provide a concrete representation of probability distributions that helps facilitate understanding of difficult concepts.↩︎\nWe can also solve this problem using algebra. Let \\(x\\) be the probability, as a decimal, that the Astros are the winner. (Again, it doesn’t matter which team is the baseline.) Then \\(x\\) is also the probability that the Dodgers are the winner, \\(1.5x\\) for the Rays, and \\(3x\\) for the Braves. The probability that one of the four teams wins is \\(x + x + 1.5x + 3x = 6.5x\\), so the probability of Other is also \\(6.5x\\). The probabilities in decimal form must sum to 1, so \\(1 = x + x + 1.5x + 3x + 6.5x = 13x\\). Solve for \\(x=1/13\\) and then plug in \\(x=1/13\\) to find the other probabilities; e.g., \\(3x = 3(1/13) = 0.231\\) for the Braves.↩︎\nThis example is inspired by the famous “Linda problem” of Tversky and Kahneman (1982) which they used to illustrate the “conjunction fallacy”.↩︎\nYou could also solve this with algebra. Let \\(x\\) be the probability that the Giants win, so \\(19x\\) is the probability that they don’t win. The probabilities must sum to 1, so set \\(x + 19x = 1\\) and solve for \\(x\\).↩︎\nTechnically, Ron and Leslie could still have different subjective probabilities. Leslie would not agree to worse odds, but she would accept better if Ron offered them. For example, given a potential loss of $200, Leslie would also agree to a potential payout from Ron of $125 rather than $100. That is, Leslie would accept odds of 1.6 to 1 against (\\(200/125 = 1.6\\)), corresponding to a subjective probability of \\(1/(1 + 1.6) = 0.385\\). So Leslie’s subjective probability that Professor Ross has a TikTok account is at least 1/3. Similarly, Ron’s subjective probability that Professor Ross has a TikTok account is at most 1/3.↩︎\nTechnically this is only true if the moneyline odds are positive, which is the case when the probability of winning the bet is less than 0.5. Negative moneyline odds, which occur when the probability of winning the bet is greater than 0.5, represent how much money must be wagered in order to receive a net profit of $100. For example, moneyline odds of -900 indicate that you must bet $900 to receive $1000, for a net profit of 1000-900 = 100. A bet at -900 moneyline odds results in a profit of $100 if the bet is won or a loss of the initial $900 stake otherwise; the amounts 900 and 100 are in a 9 to 1 ratio (in favor of winning), implying a probability of \\(9/(1+9) = 0.90\\) of winning the bet.↩︎\nWe’re assuming Donny’s probability that the Dodgers don’t win is 50%. But if Donny’s probabilities don’t add to 100% why would we expect him to obey other consistency requirements? A fair question, but the point is that bad things can happen even if just one of the consistency requirements is violated. If we assume instead 35% as Donny’s probability that the Dodgers don’t win, we can construct a scenario similar to the one in this solution which guarantees us a sure profit with no risk.↩︎\n“Book” in the sense of a bookie taking bets, as opposed to a Dutch-language novel like De ontdekking van de hemel.↩︎\nThese values are based on a study by the Pew Research Foundation conducted in January 2020.↩︎\nThese values are based on surveys by Gallup, but the values change somewhat over time.↩︎\nCareful: we are only claiming that the total does not matter when constructing hypothetical tables. When collecting real data, the sample size matters a great deal. For example, a random sample of 1000 Americans provides a more precise estimate of the population proportion of all Americans who support free tuition than a sample of 100 Americans does. The Pew Research study was based on a random sample of over 12000 Americans.↩︎\nYou can only run into problems if you round. Suppose we had started with a group size of 100. Then the top left cell in the table would have been 26.56. If we had rounded this to 27, our answers would change. So when dealing with a hypothetical table of counts, don’t round. If you are uncomfortable with decimal counts, just add a few zeros to your total count and try again↩︎\nThis example is adapted from an article by Allan Rossman.↩︎\nThe values in this example are based on a Washington Post article which uses data from the 2018 General Social Survey. An earlier Washington Post article discusses discrepancies in estimates of pet ownership.↩︎\nThese values come from the NY Times article and a related study.↩︎\nThis is called the sensivity of the test.↩︎\nWe are treating “not positive” as “negative” but in practice there could also be inconclusive tests.↩︎\nDiGeorge syndrome isn’t the greatest example since most cases result from a purely random deletion on chromosome 22. However, DiGeorge syndrome can be inherited from a parent who has it.↩︎\nThis is called the specificity of the test↩︎\nPregnancy tests are included as part of health screenings for other reasons, but most women who take home pregnancy tests do so for pregnancy related reasons.↩︎\nAnd both equal to \\(\\left(\\frac{1}{2}\\right)^{10} =\\frac{1}{1024}\\)↩︎\n252 out of 1024 possibilities in fact↩︎\nThe exact count is 292,201,338. We will see how to compute this number later.↩︎\nSource: U.S. Census Bureau.↩︎\nThe statistician Ron Wasserstein has provided several fanciful perspectives on the likelihood of winning the Powerball lottery.↩︎\nFor an interesting investigation of this idea check out the Infinite Monkey Theorem Experiment at the site The Pudding.↩︎\nThis idea was inspired by Randall Munroe.↩︎\nFor probabilities closer to 1, we could report the chances of not being from these counties.↩︎\nThe probability that a flip following H lands on H is 0.5. This example shows that the proportion of flips following H which result in H in a fixed sequence of coin flips is a “biased estimator” of the probability that a flip following H lands on H.↩︎\nWhich isn’t quite true.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "language-probability.html",
    "href": "language-probability.html",
    "title": "2  The Language of Probability",
    "section": "",
    "text": "2.1 Outcomes\nA phenomenon is random if there are multiple potential possibilities, and there is uncertainty about which possibility is realized. This chapter introduces the fundamental terminology and objects of random phenomena, including\nProbability models put all of the above together. A probability model of a random phenomenon consists of a sample space of possible outcomes, associated events and random variables, and a probability measure which specifies probabilities of events and determines distributions of random variables according to the assumptions of the model and available information.\nThroughout this chapter we will illustrate ideas using the following examples.\nTotal or best? Roll a four-sided1 die twice and consider the sum and the larger of the two rolls (or the common roll if a die). Not very exciting? Maybe, but it is a familiar, simple, and concrete example. Also, a “toy” example can provide insight into more interesting problems, such as the following. In many sports, a competitor’s final ranking is based on the results of multiple attempts. Competitors in Olympic bobsled, for example, make four separate timed runs on the same course and their ranking is based on their total time. Competitors in Olympic shot put make six throws, but their ranking is based on their best throw. In sports with multiple attempts, how do the rankings compare if they are based on the total (or average) over all attempts (as in bobsled) or on the best attempt (as is shot put)?\nMatching problem. A group of people all put their names in a hat for a Secret Santa gift exchange. The names are shuffled and everyone draws a name from the hat. We might be interested in questions like: What is the probability that someone selects their own name? How many people are expected to draw their own name? How do the answers to these questions depend on the name of people in the group? This a is version of a well known probability problem called the “matching problem”. The general setup involves \\(n\\) distinct “objects” labeled \\(1, \\ldots, n\\) which are placed in \\(n\\) distinct “boxes” labeled \\(1, \\ldots, n\\), with exactly one object placed in each box; for how many objects does the label on the object match the label on the box it is placed in?\nMeeting problem. Several people plan to meet for lunch, but their arrival times are uncertain. We might be interested in whether they arrive within 15 minutes of one another, who arrives first and at what time, or how long the first person to arrive needs to wait for the others.\nCollector problem. Each box of a brand of cereal contains a single prize from a collection. We might be interested in how many boxes we need to buy to complete the collection, or how many boxes we need to buy to complete five collections (say one collection for each of five kids), or which prize we get in the most boxes.\nArrivals over time. Customers enter a deli and take a number to mark their place in line. When the deli opens the counter starts 0; the first customer to arrive takes number 1, the second 2, etc. We record the counter over time, continuously, as it changes as customers arrive. We might be interested in the number of customers that arrive in some window of time, the time between customer arrivals, or the amount of time it takes for some number of customers to arrive. (And this is just the arrivals; we might also be interested in questions which involve the departures, such as: how much time a customer spends in the deli or how many customers are in the deli at a certain time.)\nFull disclosure: many of the examples in this chapter involve rather dry tasks like discussing mathematical notation or listing elements of sets. Also, some of the things we do in these examples are rarely done in practice. So why bother? Many common mistakes in solving probability problems arise from misunderstanding these foundational objects. We hope that concrete—though sometimes uninteresting—examples foster understanding of fundamental concepts.\nThis chapter introduces what the fundamental objects of probability are, but not yet how to solve probability problems. Don’t worry; we’ll solve many interesting problems in the remaining chapters. Think of this chapter as introducing the “language” or “grammar” of probability. When first learning to write, we learn the basic elements of sentences: subjects, predicates, clauses, modifiers, etc. Understanding these fundamental building blocks is essential to learning how to write well, even if we don’t explicitly identify the subject, the verb, etc., in every sentence we write. Likewise, understanding the language of probability is crucial to learning how to solve probability problems, even if the language is sometimes unspoken.\nProbability models can be applied to any situation in which there are multiple potential outcomes and there is uncertainty about which outcome is realized. Due to the wide variety of types of random phenomena, an outcome can be virtually anything:\nAnd on and on. In particular, an outcome does not have to be a number.\nThe first step in defining a probability model for a random phenomenon is to identify the possible outcomes.\nMathematically, the sample space is a set containing all possible outcomes, while any individual outcome is an element in the sample space. The sample space is typically denoted2 \\(\\Omega\\), the uppercase Greek letter “Omega”. An outcome is typically denoted \\(\\omega\\), the lowercase Greek letter “omega”; \\(\\omega\\) denotes a generic outcome much like the symbol \\(u\\) in \\(\\sqrt{u}\\) denotes a generic input to the square root function. We write \\(\\omega \\in \\Omega\\) (read \\(\\in\\) as “in” or “an element of”) to represent that \\(\\omega\\) is a possible outcome of sample space \\(\\Omega\\).\nThe simplest random phenomena have just two distinct outcomes, in which case the sample space is just a set with two elements, e.g., \\(\\Omega=\\{\\text{no}, \\text{yes}\\}\\), \\(\\Omega=\\{\\text{off}, \\text{on}\\}\\), \\(\\Omega=\\{0, 1\\}\\), \\(\\Omega=\\{-1, 1\\}\\). For example, the sample space for a single coin flip could be \\(\\Omega = \\{H, T\\}\\). If the coin lands on heads, we observe the outcome \\(\\omega = H\\); if tails we observe \\(\\omega=T\\).\nIn simple examples we can describe the sample space by listing all possible outcomes. However, constructing a list of all possible outcomes is rarely done in practice. We do so here only to provide some concrete examples of sample spaces. While a random phenomenon always has a corresponding sample space, in most situations the sample space of outcomes is at best only vaguely specified and can not be feasibly enumerated.\nTable 2.1: Table representing the sample space of two rolls of a four-sided die. Each row represents an outcome.\n\n\n\n\n\n\nFirst roll\nSecond roll\n\n\n\n\n1\n1\n\n\n1\n2\n\n\n1\n3\n\n\n1\n4\n\n\n2\n1\n\n\n2\n2\n\n\n2\n3\n\n\n2\n4\n\n\n3\n1\n\n\n3\n2\n\n\n3\n3\n\n\n3\n4\n\n\n4\n1\n\n\n4\n2\n\n\n4\n3\n\n\n4\n4\nA random phenomenon is modeled by a single sample space. In Example 2.1 there was a single sample space whose outcomes represented the result of the pair of rolls; in particular, there was not a separate sample space for each of the individual rolls3. Whenever possible, a sample space outcome should be defined to provide the maximum amount of information about the outcome of random phenomenon.\nHere’s another concrete example where we can list all the outcomes in the sample space. However, keep in mind that enumerating the sample space is rarely done in practice.\nTable 2.2: Table representing the sample space in the matching problem with \\(n=4\\). Each row represents an outcome.\n\n\n\n\n\n\nSpot 1\nSpot 2\nSpot 3\nSpot 4\n\n\n\n\n1\n2\n3\n4\n\n\n1\n2\n4\n3\n\n\n1\n3\n2\n4\n\n\n1\n3\n4\n2\n\n\n1\n4\n2\n3\n\n\n1\n4\n3\n2\n\n\n2\n1\n3\n4\n\n\n2\n1\n4\n3\n\n\n2\n3\n1\n4\n\n\n2\n3\n4\n1\n\n\n2\n4\n1\n3\n\n\n2\n4\n3\n1\n\n\n3\n1\n2\n4\n\n\n3\n1\n4\n2\n\n\n3\n2\n1\n4\n\n\n3\n2\n4\n1\n\n\n3\n4\n1\n2\n\n\n3\n4\n2\n1\n\n\n4\n1\n2\n3\n\n\n4\n1\n3\n2\n\n\n4\n2\n1\n3\n\n\n4\n2\n3\n1\n\n\n4\n3\n1\n2\n\n\n4\n3\n2\n1\nIn the two previous examples, the sample space was discrete, in the sense that the outcomes could be enumerated in a list (though it could be a very long list). But in many cases, it is not possible to enumerate outcomes in a list, even in principle.\nFor example, consider the circular spinner (like from a kids game) in Figure 2.1. Imagine a needle anchored at the center of the circle which is spun and eventually lands pointing at a number on the outside of the circle. The values in the picture are rounded to two decimal places, but consider an idealized model where the spinner is infinitely precise and the needle infinitely fine so that any real number between 0 and 1 is a possible outcome. The sample space corresponding to a single spin of this spinner is the interval4 [0, 1]. There are uncountably many numbers in [0, 1] so it would not be possible to enumerate them in a list. The interval [0, 1] is an example of a continuous sample space.\nFigure 2.1: A continuous uniform spinner on [0, 1]. The values in the picture are rounded to two decimal places, but in the idealized model the spinner is infinitely precise so that any real number between 0 and 1 is a possible outcome.\nFigure 2.2: The square represents the sample space in Example 2.3). Each point within the square is a (Regina, Cady) pair of arrival times in \\([0, 60]\\).\nIn the previous example, outcomes were measured on a continuous scale; any real number between 0 and 60 was a possible arrival time. In practice we might round the arrival time to the nearest minute or second, but in principle and with infinite precision any real number in the continuous interval \\([0, 60]\\) is possible.\nFurthermore, even in situations where outcomes are inherently discrete, it is often more convenient to model them as continuous. For example, if an outcome represents the annual salary in dollars of a randomly selected U.S. household, it would be more convenient to model the sample space as the continuous interval6 \\([0, \\infty)\\) rather than discrete intervals like \\(\\{0, 1, 2, \\ldots\\}\\) or \\(\\{0, 0.01, 0.02, \\ldots\\}\\). Continuous models are often more tractable mathematically than discrete models.\nIn the previous examples, the sample space could be defined rather explicitly, either by direct enumeration or using set notation (like a Cartesian product). However, explicitly defining a sample space in a compact way is often not possible, as in the following example.\nAny random phenomenon has a corresponding sample space but in some situations explicitly defining a outcome is not feasible. For example, suppose the random phenomenon is tomorrow’s weather. In order to describe an outcome, we need to specify (among other things): temperature, atmospheric pressure, wind, humidity, precipitation, and cloudiness, and how it all evolves over over the course of tomorrow, possibly in multiple locations. Representing all of this information in a compact way to define even just one outcome is virtually impossible; explicitly defining a sample space of all possible outcomes is hopeless. Regardless, the sample space is still there in the background whether we specify it or not.\nEven though the sample space often is at best vaguely defined (“tomorrow’s weather”) and plays a background role, it is important to first consider what is possible before determining how probable events are. The sample space essentially defines the denominator in probability calculations. In particular, considering the sample space can help distinguish between “the particular and the general” (as discussed in Section 1.6).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-language-outcomes",
    "href": "language-probability.html#sec-language-outcomes",
    "title": "2  The Language of Probability",
    "section": "",
    "text": "the result of a coin flip\nthe results of a sequence of coin flips\na shuffle of a deck of cards\nthe weather conditions tomorrow in your city\nthe path of a particular Atlantic hurricane\nthe daily closing price of a certain stock over the next 30 days\na noisy electrical signal\nthe result of a diagnostic medical test\na sample of car insurance polices\nthe customers arriving at a store\nthe result of an election\nthe next World Series champion\na play in a basketball game\n\n\n\n\nDefinition 2.1 The sample space is the collection of all possible outcomes of a random phenomenon.\n\n\n\n\n\n\n\n\n\n\n\nExample 2.1 Roll a four-sided die twice, and record the result of each roll in sequence. For example, a 3 on the first roll and a 1 on the second is not the same outcome as a 1 on the first roll and a 3 on the second.\n\nIdentify the sample space.\nWe might be interested in the sum of the two rolls. Explain why it is still advantageous to define the sample space as in the previous part, rather than as just \\(2, \\ldots, 8\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.1. \n\nWe simply enumerate all the possible outcomes: first roll is a 1 and second roll is a 1, first roll is a 1 and second roll is a 2, etc. The sample space consists of 16 possible ordered pairs of rolls, which we can display in a list or table. See Table 2.1; any row is a possible outcome, and the table contains all possible outcomes.\nWe can write the sample space as a set of ordered pairs, \\[\\begin{align*}\n\\Omega & = \\{(1, 1), (1, 2), (1, 3), (1, 4),\\\\\n& \\qquad (2, 1), (2, 2), (2, 3), (2, 4),\\\\\n& \\qquad (3, 1), (3, 2), (3, 3), (3, 4),\\\\\n& \\qquad (4, 1), (4, 2), (4, 3), (4, 4)\\}.\n\\end{align*}\\] Any element of this set is a possible outcome \\(\\omega\\). For example, the outcome \\(\\omega = (4, 2)\\) occurs when the first roll is a 4 and the second roll is a 2.\nYes, we might be interested in the sum of the two dice. But we might also be interested in other things, like the larger of the two rolls, or if at least one 3 was rolled, or the result of the first roll. Knowing just the sum of the rolls does not provide as much information about the outcome of the random phenomenon as the sequence of individual rolls does.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.2 Consider the matching problem with \\(n=4\\). Label the objects 1, 2, 3, 4, and the spots 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. Identify an appropriate sample space.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.2. We can consider each outcome to be a particular placement of objects in the spots. For example, one outcome is when object 3 is placed in spot 1, object 2 in spot 2, object 1 in spot 3, and object 4 in spot 4; another is when object 3 is placed in spot 1, object 2 in spot 2, object 4 in spot 3, and object 1 in spot 4. The sample space consists of all the possible arrangments of the object labels into the 4 spots. There are 24 outcomes; see Table 2.2). Recording outcomes in this way provides more information than if we had chosen the sample space to correspond to, for example, the number of objects that were placed in the correct spot.\nUsing set notation the sample space is \\[\\begin{align*}\n\\Omega & = \\{1234, 1243, 1324, 1342, 1423, 1432 \\\\\n  & \\qquad 2134, 2143, 2314, 2341, 2413, 2431 \\\\\n  & \\qquad 3124, 3142, 3214, 3241, 3412, 3421 \\\\\n  & \\qquad 4123, 4132, 4213, 4231, 4312, 4321\\}\n\\end{align*}\\] For example, the outcome 3214 (or \\((3, 2, 1, 4)\\)) represents that object 3 is placed in spot 1, object 2 in spot 2, object 1 in spot 3, and object 4 in spot 4.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.3 Consider a version of the meeting problem where two people. Regina and Cady, will each definitely arrive between noon and 1, but their exact arrival times are uncertain. Rather than dealing with clock time, it is helpful to represent noon as time 0 and measure time as minutes after noon, including fractions of a minute, so that arrival times take values in the continuous interval [0, 60].\nDescribe an appropriate sample space. Hint: it might be easiest to draw a picture.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.3. We can represent an outcome as a (Regina, Cady) pair of arrival times, each in [0, 60]. For example, the outcome (30, 45.2) represents Regina arriving at 12:30:00 and Cady at 12:45:12, while (45.2, 0) represents Regina arriving at time (12:45:12) and Cady at noon. The sample space is the set of all possible pairs. Figure 2.2 displays the sample space5 as the set of points within the colored square with [0, 60] sides.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.4 Consider the collector problem with 3 prizes in the collection, labeled 1, 2, and 3. We open boxes one at a time. Identify an appropriate sample space. Is it possible to identify a sample space in which all outcomes have the same “length”?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.4. An outcome could represent the sequence of prizes we obtain in order. For example, (2, 3, 3, 2, 2, 2, 3, 1) represents prize 2 in the first box, prize 3 in the second and third boxes, prize 2 in the fourth, and so on, completing a collection with prize 1 in the eighth box. Outcomes recorded in this way can have different lengths if we only record the boxes we open until we complete a collection; for example (2, 3, 1) versus (2, 3, 3, 1) versus (2, 3, 3, 2, 1). However, it is often convenient for sample space outcomes to have the same length.\nWe can define outcomes with the same “length” if we assume the process continues indefinitely, that is, if we continue to open boxes even after we complete a set. Now an outcome is an infinite sequence, with each component of the sequence taking a value of 1, 2, or 3; for example, (2, 3, 3, 2, 2, 2, 3, 1, 2, 1, 1, 3, \\(\\ldots\\)). Thus the sample space7 is the set of all infinite sequences whose components take values in \\(\\{1, 2, 3\\}\\). Outcomes of this sample space all have the same “length”—infinite. Moreover, this sample space allows for a broader range of questions to be investigated. For example, we might be interested in the number of packages needed to obtain 5 complete collections (which might be relevant if you have 5 kids and they all want their own collection).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.5 Customers enter a deli and take a number to mark their place in line. When the deli opens the counter starts 0; the first customer to arrive takes number 1, the second 2, etc. We record the counter over time, continuously, as it changes as customers arrive. Time is measured in minutes after the deli opens (time 0). How might you define an appropriate sample space?\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.5. A sample space outcome could be represented as a path of the value of the counter over time; a few such paths are illustrated in Figure 2.3. The horizontal axis represents time and the vertical axis represents the number of customers that have arrived. Notice the stairstep feature: a customer arrives and takes a number then the counter stays on that number for some time (the flat spots) until another customer arrives and the counter increases by one (the jumps). In other words, an outcome is a nondecreasing function mapping the time interval \\([0, \\infty)\\) to nonnegative integers \\(\\{0, 1, 2, \\ldots\\}\\), that only jumps by one unit at a time. The sample space consists of all possible functions of this form.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) A single sample path of the number of customer arrivals over time.\n\n\n\n\n\n\n\n\n\n\n\n(b) Several possible paths.\n\n\n\n\n\n\n\n\n\n\n\n(c) Many possible paths.\n\n\n\n\n\n\n\nFigure 2.3: Sample space outcomes for Example 2.5. Horizontal axes represent time and vertical axes represent the number of customers that have arrived.\n\n\n\n\n\n\n2.1.1 Counting outcomes\nWhen there are finitely many possibilities, we can ask: how many possible outcomes are there? In Example 2.1 and Example 2.2 we counted outcomes by enumerating them in a list. Of course, listing all the outcomes is unfeasible unless the sample space is very small. Now we’ll see a simple principle that can be applied to count outcomes.\n\n\n\n\n\n\n\nExample 2.6 A soft serve ice cream shop has three flavors: vanilla, chocolate, or swirl. Customers can choose to have a cone or a bowl.\n\nHow can you determine the number of different ways the ice cream can be served? (Two possible ways are vanilla in a cone and chocolate in a bowl).\nCustomers can also add rainbow or chocolate sprinkles8 or not. Now how many different ways can the ice cream be served?\nCustomers who request bowls can choose to add whipped cream. Is the number of different ways the ice cream can be served equal to the answer to the previous part multiplied by two?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.6. \n\nEach flavor can be served in 2 ways, cone or bowl. Since there are 3 flavors, the number of ways to serve is \\(2+2+2 = 3\\times2 = 6\\).\nEach of the 6 pairs from the previous part can be served in 3 ways, with rainbow sprinkles, with chocolate sprinkles, or without sprinkles. So the number of ways to serve is now \\(3\\times 2 \\times 3 = 18\\).\nNo. Only the bowls can get whipped cream so we can’t just multiply 18 by 2. Of the 18 possibilities from the previous part, 9 are in bowls. So these 9 can be served with or without whipped cream, but the other 9 in cones can only be served without whipped cream. The number of possibilities is now \\(9\\times 2 + 9 = 27\\).\n\n\n\n\n\nAll of the counting rules we will see are based on multiplying like in Example 2.6.\n\nLemma 2.1 (Multiplication principle for counting) Suppose that stage 1 of a process can be completed in any one of \\(n_1\\) ways. Further, suppose that for each way of completing the stage 1, stage 2 can be completed in any one of \\(n_2\\) ways. Then the two-stage process can be completed in any one of \\(n_1\\times n_2\\) ways. This rule extends naturally to a \\(\\ell\\)-stage process, which can then be completed in any one of \\(n_1\\times n_2\\times n_3\\times\\cdots\\times n_\\ell\\) ways.\n\nIn the multiplication principle it is not important whether there is a “first” or “second” stage. What is important is that there are distinct stages, each with its own number of “choices”. In Example 2.6, there was a bowl/cone stage, an ice cream flavor stage, and a sprinkle stage; it didn’t matter if the flavor was chosen first or second or third.\nWe can use the multiplication principle to verify the total number of possible outcomes for a few of our previous examples. In Example 2.1 an outcome is a pair (first roll, second roll). There are 4 possibilities for the first roll and 4 for the second, so \\(4\\times4 = 16\\) possible pairs. In Example 2.2 an outcome is an arrangement of the 4 outcomes in the 4 spots. There are 4 possibilities for the object placed in spot 1. After placing that object, there are 3 possibilities for spot 2, then 2 possibilities for spot 3, with one object left for spot 4. So there are \\(4\\times3\\times2\\times1 = 24\\) possible arrangements.\n\n\n\n\n\n\n\nExample 2.7 Use the multiplication principle to count the total number of possible outcomes in each of the following situations.\n\nRoll a six-sided die three times and record the result of each roll in sequence\nRoll a four-sided die and a six-sided die and record the result of each roll.\nFlip a coin four times and record the result of each flip in sequence\nThe number of arrangements of the objects in the matching problem with \\(n=10\\).\nThe number of possible draws in Example 1.18.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.7. \n\nAn outcome is a sequence of the results of each of the 3 flips. There are six possibilities for each roll, so \\(6\\times6\\times6= 6^3=216\\) possible outcomes.\nThere are 4 possibilities for one roll and 6 possibilities for the other, so there are \\(4\\times 6 = 24\\) possible outcomes.\nAn outcome is a sequence of the H/T results of each of the 4 flips. There are two possibilities for each flip, so \\(2\\times2\\times2\\times2 = 2^4=16\\) possible outcomes.\nThere are 10 objects that could potentially go in spot 1, then 9 objects that could potentially go in spot 2, 8 to spot 3, and so on, with 1 left for spot 10. This results in \\(10\\times9\\times8\\times\\cdots\\times1=10! = 3,628,800\\) possible outcomes. (That’s over 3.6 million possibilities; we certainly wouldn’t want to make a table!)\nThere are 5 possibilities for the first draw, then 4 possibilities for the second. If we record the outcome as the (first draw, second draw) result, there are \\(5\\times4 = 20\\) possible outcomes.\n\n\n\n\n\nThe multiplication principle provides the foundation for some other counting rules we will see later.\n\n\n2.1.2 Exercises\n\nExercise 2.1 Consider the outcome of a sequence of 4 flips of a coin.\n\nWithout enumerating the sample space, determine the number of outcomes.\nEnumerate the sample space and confirm the number of outcomes.\nWe might be interested in the number of flips that land on heads. Explain why it is still advantageous to define the sample space as in the previous part, rather than as \\(\\Omega=\\{0, 1, 2, 3, 4\\}\\).\n\n\n\nExercise 2.2 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.\n\nWithout enumerating the sample space, determine the number of outcomes.\nEnumerate the sample space and confirm the number of outcomes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-language-events",
    "href": "language-probability.html#sec-language-events",
    "title": "2  The Language of Probability",
    "section": "2.2 Events",
    "text": "2.2 Events\nAn event is something that might happen or might be true. For example, if we’re interested in the weather conditions in our city tomorrow, events include\n\nit rains\nit does not rain\nthe high temperature is 75°F (rounded to the nearest °F)\nthe high temperature is above 75°F\nit rains and the high temperature is above 75°F\nit does not rain or the high temperature is not above 75°F\n\nThere are many possible outcomes for tomorrow’s weather, but each of the above will be true only for certain outcomes.\n\nDefinition 2.2 An event is a subset of the sample space. An event represents a collection of outcomes that some criteria.\n\nThe sample space is the collection of all possible outcomes; an event represents only those outcomes which satisfy some criteria. Events are typically denoted with capital letters near the start of the alphabet, with or without subscripts (e.g. \\(A\\), \\(B\\), \\(C\\), \\(A_1\\), \\(A_2\\)).\nMathematically, events are sets, so events can be composed from others using basic set operations like unions (\\(A\\cup B\\)), intersections (\\(A \\cap B\\)), and complements (\\(A^c\\)).\n\nComplements. Read \\(A^c\\) as “not \\(A\\)”, the outcomes that do not satisfy \\(A\\)\nIntersections. Read \\(A\\cap B\\) as “\\(A\\) and \\(B\\)”, the outcomes that satisfy both \\(A\\) and \\(B\\)\nUnions. Read \\(A \\cup B\\) as “\\(A\\) or \\(B\\)”, the outcomes that satisfy \\(A\\) or \\(B\\). Unions (\\(\\cup\\), “or”) are always inclusive: \\(A\\cup B\\) occurs if \\(A\\) occurs but \\(B\\) does not, \\(B\\) occurs but \\(A\\) does not, or both \\(A\\) and \\(B\\) occur. Note that the complement of a union is the intersection of the complements, and vice versa: \\((A \\cup B)^c = A^c \\cap B^c\\) and \\((A \\cap B)^c = A^c \\cup B^c\\),\n\nIn the weather example above we can write\n\n\\(A\\): it rains\n\\(B=A^c\\): it does not rain\n\\(C\\): the high temperature is 75°F (rounded to the nearest °F)\n\\(D\\): the high temperature is above 75°F\n\\(E = A \\cap D\\): it rains and the high temperature is above 75°F\n\\(F = A^c \\cup D^c = (A\\cap D)^c = B\\cap D^c = E^c\\): it does not rain or the high temperature is not above 75°F\n\n\n\n\n\n\n\n\nExample 2.8 Every year the NBA Draft Lottery is conducted to determine which non-playoff teams will receive the top draft picks. Table 2.3 displays the teams that participated in the 2023 NBA Draft Lottery (held on May 16, 2023) along with some team statistics from the 2022-2023 season and the number of previous NBA championships won by the franchise (as of 2023).\nImagine it’s early May 2023 and the lottery hasn’t happened yet. The lottery determines—at random—the top three picks, but we’ll just consider the team who wins the first pick in the 2023 draft. The sample space is the 14 teams in Table 2.3. Identify each of the following events relating to the team that wins the top pick.\n\n\\(A\\), the team is in the Western Conference.\n\\(B\\), the team has never won a championship.\n\\(C\\), the team won fewer than 25 games (Wins) in the 2022-2023 season\n\\(D\\), the team scored over 115 points per game (PPG) in the 2022-2023 season\nIdentify and interpret \\(A\\cap B\\)\nIdentify and interpret \\(A \\cap B \\cap D\\)\nIdentify and interpret \\(A \\cup B\\)\nIdentify and interpret \\(B^c\\)\n\n\n\n\n\n\n\n\n\nTable 2.3: Teams in the 2023 NBA Draft Lottery\n\n\n\n\n\n\nTeam\nConference\nChampionships\nWins\nPPG\nFG3\nFG3A\nFG2\nFG2A\nFT\nFTA\n\n\n\n\nDetroit Pistons\nEastern\n3\n17\n110.3\n11.4\n32.4\n28.2\n54.6\n19.8\n25.7\n\n\nHouston Rockets\nWestern\n2\n22\n110.7\n10.4\n31.9\n30.2\n56.9\n19.1\n25.3\n\n\nSan Antonio Spurs\nWestern\n5\n22\n113.0\n11.1\n32.2\n32.0\n60.4\n15.8\n21.2\n\n\nCharlotte Hornets\nEastern\n0\n27\n111.0\n10.7\n32.5\n30.5\n57.9\n17.6\n23.6\n\n\nPortland Trail Blazers\nWestern\n1\n33\n113.4\n12.9\n35.3\n27.6\n50.1\n19.6\n24.6\n\n\nOrlando Magic\nEastern\n0\n34\n111.4\n10.8\n31.1\n29.8\n55.2\n19.6\n25.0\n\n\nIndiana Pacers\nEastern\n0\n35\n116.3\n13.6\n37.0\n28.4\n52.6\n18.7\n23.7\n\n\nWashington Wizards\nEastern\n1\n35\n113.2\n11.3\n31.7\n30.9\n55.2\n17.6\n22.4\n\n\nUtah Jazz\nWestern\n0\n37\n117.1\n13.3\n37.8\n29.2\n52.0\n18.7\n23.8\n\n\nDallas Mavericks\nWestern\n1\n38\n114.2\n15.2\n41.0\n24.8\n43.3\n19.0\n25.1\n\n\nChicago Bulls\nEastern\n6\n40\n113.1\n10.4\n28.9\n32.1\n57.9\n17.6\n21.8\n\n\nOklahoma City Thunder\nWestern\n1\n40\n117.5\n12.1\n34.1\n31.0\n58.5\n19.2\n23.7\n\n\nToronto Raptors\nEastern\n1\n41\n112.9\n10.7\n32.0\n31.1\n59.3\n18.4\n23.4\n\n\nNew Orleans Pelicans\nWestern\n0\n42\n114.4\n11.0\n30.1\n31.1\n57.5\n19.3\n24.4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.8. We’ll write each of the events as a set of teams, but you can also think of each event as a subset of the rows of Table 2.3.\n\n\\(A = \\{\\text{Houston, San Antonio, Portland, Utah, Dallas, Oklahoma City, New Orleans}\\}\\)\n\\(B = \\{\\text{Charlotte, Orlando, Indiana, Utah, New Orleans}\\}\\)\n\\(C=\\{\\text{Detroit, Houston, San Antonio}\\}\\)\n\\(D = \\{\\text{Indiana, Utah, Oklahoma City}\\}\\)\n\\(A\\cap B = \\{\\text{Utah, New Orleans}\\}\\) is the event that the team is in the Western Conference and has won no previous championships.\n\\(A \\cap B \\cap D=\\{\\text{Utah}\\}\\) is the event that the team is in the Western Conference, has won no previous championships, and scored over 115 points per game in the 2022-2023 season.\n\\(A \\cup B=\\{\\text{Charlottle, Houston, San Antonio, Portland, Orlando, Indians, Utah, Dallas, Oklahoma City, New Orleans}\\}\\) is the event that the team is in the Western Conference or has won no previous championships. Notice that teams that satisfy both \\(A\\) and \\(B\\), Utah and New Orleans, are included but only once.\n\\(B^c=\\{\\text{Detroit, Houston, San Antonio, Portland, Washington, Dallas, Chicago, Oklahoma City, Toronto}\\}\\) is the event that the team has won at least one previous championship.\n\n\n\n\n\nIn Example 2.8 notice that we ony said the winner was determined “at random”; we didn’t mention how. “At random” only implies that the winning team will be selected in a manner that involves uncertainly. “At random” does not necessarily imply that the 14 teams are equally likely. In fact, the 2023 NBA Draft Lottery was weighted to give teams with fewer wins the previous season a greater probability of winning the top pick. We’ll return to this idea later. For now, we’re just defining some events that are possible; later we will consider how probable they are.\nIf the outcomes of a sample space are represented by rows in a table, then events are subsets of rows which satisfy some criteria.\n\n\n\n\n\n\n\nExample 2.9 Roll a four-sided die twice, and record the result of each roll in sequence. Using the sample space from Example 2.1, identify the following events.\n\n\\(A\\), the event that the sum of the two dice is 4.\n\\(B\\), the event that the sum of the two dice is at most 3.\n\\(C\\), the event that the larger of the two rolls (or the common roll if a tie) is 3.\n\\(A\\cap C\\) (identify and interpret).\n\\(D\\), the event that the first roll is a 3.\n\\(E\\), the event that the second roll is a 3.\n\\(D \\cap E\\) (identify and interpret).\n\\(D \\cup E\\) (identify and interpret).\nIf the outcome is \\((1, 3)\\), which of the events above occurred?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.9. Remember that the sample space consists of 16 possible ordered pairs of rolls, (first roll, second roll); see Table 2.1. All events must be defined as subsets of this sample space.\n\n\\(A\\) consists of the outcomes (1, 3), (2, 2), and (3, 1). In set notation, event \\(A\\) is the set \\(\\{(1, 3), (2, 2), (3, 1)\\}\\). This event is highlighted in Table 2.4.\n\\(B\\) consists of the outcomes (1, 1), (1, 2), and (2, 1). In set notation, \\(B = \\{(1, 1), (1, 2), (2, 1)\\}\\).\n\\(C\\) consists of the outcomes (1, 3), (2, 3), (3, 1), (3, 2), and (3, 3). In set notation, \\(B = \\{(1, 3), (2, 3), (3, 1), (3, 2), (3, 3)\\}\\).\n\\(A\\cap C\\), which consists of the outcomes (1, 3) and (3, 1), is the event that both the sum of the two dice is 4 and the larger of the two rolls is 3. In set notation, \\(A \\cap C = \\{(1, 3), (3, 1)\\}\\).\nEach outcome in the sample space consists of a pair of rolls, so we must account for both rolls in defining events, even if the event of interest involves just the first roll. (Remember, there is always a single sample space upon which all events are defined.) So \\(D\\) consists of the outcomes (3, 1), (3, 2), (3, 3), and (3, 4). In set notation, \\(D = \\{(3, 1), (3, 2), (3, 3), (3, 4)\\}\\).\n\\(E\\) consists of the outcomes (1, 3), (2, 3), (3, 3), and (4, 3). In set notation, \\(E = \\{(1, 3), (2, 3), (3, 3), (4, 3)\\}\\). Note that this is not the same event as \\(D\\).\n\\(D \\cap E\\), which consists only of the outcome (3, 3), is the event that both rolls result in a 3. While an event is always a set, it can be a set consisting of a single outcome (or the empty set). In set notation, \\(D\\cap E = \\{(3, 3)\\}\\).\n\\(D \\cup E\\), which consists of the outcomes (3, 1), (3, 2), (3, 3), (3, 4), (1, 3), (2, 3), and (4, 3) is the event that at least one of the two rolls results in a 3. In set notation, \\(D \\cup E = \\{(3, 1), (3, 2), (3, 3), (3, 4), (1, 3), (2, 3), (4, 3)\\}\\). Notice that the union is inclusive: \\((3, 3)\\), the outcome that satisfies both \\(D\\) and \\(E\\), is an element of \\(D\\cup E\\). But also notice that the outcome \\((3, 3)\\) only appears once in \\(D\\cup E\\).\nIf the outcome is \\((1, 3)\\) then events \\(A\\), \\(C\\), \\(A\\cap C\\), \\(E\\), \\(D\\cup E\\) all occur. Events \\(B,\\) \\(D\\) and \\(D\\cap E\\) do not occur. The outcome \\((1, 3)\\) is an element of each of the sets \\(A\\), \\(C\\), \\(A\\cap C\\), \\(E\\), \\(D\\cup E\\), but not of \\(B,\\) \\(D\\) and \\(D\\cap E\\).\n\n\n\n\n\n\n\n\n\nTable 2.4: Table representing the sample space of two rolls of a four-sided die. The outcomes in orange comprise the event \\(A\\), the sum is equal to 4.\n\n\n\n\n\n\nFirst roll\nSecond roll\nSum is 4?\n\n\n\n\n1\n1\nno\n\n\n1\n2\nno\n\n\n1\n3\nyes\n\n\n1\n4\nno\n\n\n2\n1\nno\n\n\n2\n2\nyes\n\n\n2\n3\nno\n\n\n2\n4\nno\n\n\n3\n1\nyes\n\n\n3\n2\nno\n\n\n3\n3\nno\n\n\n3\n4\nno\n\n\n4\n1\nno\n\n\n4\n2\nno\n\n\n4\n3\nno\n\n\n4\n4\nno\n\n\n\n\n\n\n\n\nWe reiterate (again!) that there is a single sample space, upon which all events are defined. In the above example, events that involved only the first or second roll such as \\(D\\) and \\(E\\) were still defined in terms of pairs of rolls. An outcome in a sample space should be defined to record as much information as possible so that the occurrence or non-occurrence of all events of interest can be determined.\nSome events consist of a single outcome, or no outcomes at all (the “empty set” denoted \\(\\{\\}\\) or \\(\\emptyset\\)).\n\nDefinition 2.3 Events \\(A_1, A_2. A_3, \\ldots\\) are disjoint (a.k.a. mutually exclusive) if none of the events have any outcomes in common; that is, if \\(A_i \\cap A_j = \\emptyset\\) for all \\(i\\neq j\\).\n\nRoughly, disjoint events do not “overlap”. In Example 2.9, events \\(B\\) and \\(C\\) are disjoint since \\(B \\cap C = \\emptyset\\); there are no outcomes for which both the sum of the dice is at most 3 and the larger roll is a 3.\n\n\n\n\n\n\n\nExample 2.10 In the matching problem with \\(n=4\\) objects labeled 1, 2, 3, 4, are placed in spots labeled 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. Using the sample space from Example 2.2, identify the following events.\n\n\\(A\\), the event that all objects are put in the correct spot.\n\\(F\\), the event that no objects are put in the correct spot.\n\\(D\\), the event that exactly 3 objects are put in the correct spot.\n\\(A_3\\), the event that object 3 is put (correctly) in spot 3.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.10. Recall that each outcome is a particular placement of objects in the spots. For example, the outcome (3, 2, 1, 4)—which we’ll shorten to 3214—signifies that object 3 is put in spot 1, object 2 in spot 2, object 1 in spot 3, and object 4 in spot 4.\n\nThere is only one outcome, 1234, for which all objects are put in the correct spot, so \\(A=\\{1234\\}\\). Remember that an event is always a set, but it can be a set consisting of a single outcome.\nFor each outcome in the sample space check to see if the criteria holds to identify \\(F=\\{2143, 2341, 2413, 3142, 3412, 3421, 4123, 4312, 4321\\}\\) as the event that no objects are put in the correct spot.\nThere are no outcomes in which exactly 3 objects are put in the correct spot so \\(D=\\emptyset\\). (For \\(n=4\\), if three objects are in their correct spots, then the remaining object must be in its correct spot too.)\n\\(A_3=\\{1234, 1432, 2134, 2431, 4132, 4231\\}\\) is the event that object 3 is put (correctly) in spot 3. This event is highlighted in Table 2.5. Even though event \\(A_3\\) only concerns object 3, since the sample space consists of the placements of each of the objects then all events must be expressed in terms of these outcomes.\n\n\n\n\n\n\n\n\n\nTable 2.5: Table representing the sample space in the matching problem with \\(n=4\\). The outcomes in orange comprise the event \\(A_3\\), object 3 in spot 3.\n\n\n\n\n\n\nSpot 1\nSpot 2\nSpot 3\nSpot 4\nObject 3 in spot 3?\n\n\n\n\n1\n2\n3\n4\nyes\n\n\n1\n2\n4\n3\nno\n\n\n1\n3\n2\n4\nno\n\n\n1\n3\n4\n2\nno\n\n\n1\n4\n2\n3\nno\n\n\n1\n4\n3\n2\nyes\n\n\n2\n1\n3\n4\nyes\n\n\n2\n1\n4\n3\nno\n\n\n2\n3\n1\n4\nno\n\n\n2\n3\n4\n1\nno\n\n\n2\n4\n1\n3\nno\n\n\n2\n4\n3\n1\nyes\n\n\n3\n1\n2\n4\nno\n\n\n3\n1\n4\n2\nno\n\n\n3\n2\n1\n4\nno\n\n\n3\n2\n4\n1\nno\n\n\n3\n4\n1\n2\nno\n\n\n3\n4\n2\n1\nno\n\n\n4\n1\n2\n3\nno\n\n\n4\n1\n3\n2\nyes\n\n\n4\n2\n1\n3\nno\n\n\n4\n2\n3\n1\nyes\n\n\n4\n3\n1\n2\nno\n\n\n4\n3\n2\n1\nno\n\n\n\n\n\n\n\n\nWe can use the multiplication principle to count the number of outcomes that satisfy event \\(A_3\\) in Table 2.5. If object 3 is in spot 3, there are 3 objects that can go in spot 1, then 2 that can go in spot 2, leaving 1 for spot 4; for a total of \\(3\\times2\\times1\\times1=6\\) of the 24 outcomes which satisfy event \\(A_3\\).\nWhen more than just a few events are of interest, subscripts are commonly used to identify different events. In the previous example, we might also be interested in \\(A_1\\), the event that object 1 is placed in spot 1; \\(A_2\\), the event that object 2 is placed in spot 2; and so on.\nRemember that intervals of real numbers such as \\((a,b), [a,b], (a,b]\\) are also sets, and so can also be events. For example, if an outcome is the result of a single spin of the spinner in Figure 2.1, events include\n\n\\([0, 0.5]\\), the result is between 0 and 0.5 (the needle lands in the right half of the spinner)\n\\([0.75, 1]\\), the result is between 0.75 and 1 (the needle lands in the northwest quarter of the spinner)\n\\([0.595, 0.605)\\), the result rounded to two decimal places is 0.60\n\\(\\{0.6\\}\\), the result is 0.6 exactly (the needle points exactly at 0.60000000\\(\\ldots\\))\n\nIt is often helpful to conceptualize and visualize events (sets) with pictures, especially when dealing with continuous sample spaces.\n\n\n\n\n\n\n\nExample 2.11 Using the sample space from Example 2.3, identify the following events using pictures.\n\n\\(A\\), the event that Regina arrives after Cady.\n\\(B\\), the event that either Regina or Cady arrives before 12:30.\n\\(C\\), the event that Cady arrives first and Regina arrives at most 15 minutes after Cady.\n\\(D\\), the event that Regina arrives before 12:24.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.11. Figure 2.2 represents the sample space, a square with \\([0, 60]\\) sides. Each point within the square is a (Regina, Cady) pair of arrival times. We can shade the regions of the sample space corresponding to pairs of points that satisfy these events. See Figure 2.4.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.4: Depiction of the events in Example 2.11.\n\n\n\n\n\nIn Example 2.11 the sample space consists of (Regina, Cady) pairs of arrival times so any event must be expressed as a collection of pairs. Even though the criteria for event \\(D\\) involves only Regina’s arrival time, the event is not simply [0, 24]; we need to consider all (Regina, Cady) pairs for which the Regina component is in the interval [0, 24].\n\n\n\n\n\n\n\nExample 2.12 Consider the sample space in Example 2.5. Sketch a picture representing \\(A\\), the event that no arrivals occur in the first 5 minutes.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.12. The sample space consists of all possible non-decreasing integer-valued paths that start at 0 at time 0; a few outcomes are depicted in Figure 2.5. Only paths that result in 0 arrivals at time 5 satisfy event \\(A\\). Figure 2.5 highlights in orange a few possible outcomes that satisfy event \\(A\\). Event \\(A\\) consists of all paths that stay constant at 0 from time 0 until at least time 5.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.5: Sample space outcomes for Example 2.12. Paths in orange satisfy \\(A\\), the event that no arrivals occur in the first 5 minutes; paths in blue do not satisfy event \\(A\\).\n\n\n\n\n\nIn many situations it is not possible to explicitly define a sample space in a compact way, and so outcomes and events are often only vaguely defined. Nevertheless, there is always a sample space in the background representing possible outcomes, and collections of these outcomes represent events of interest.\n\n\n\n\n\n\n\nExample 2.13 Donny Don’t is asked a series of questions involving a pair of rolls of six-sided dice, such as “identify the event that the sum of the dice is at least 10”. Donny’s responses are below; explain to him what is wrong with his responses and help him understand the correct answers.\n\nThe possible rolls are 1 through 6, so the sample space is \\(\\{1, 2, 3, 4, 5, 6\\}\\).\nThe sum of the two dice can be 2 through 12, so the event that the sum of the two dice is at least 10 is \\(\\{10, 11, 12\\}\\).\nThe event that the first roll is a 3 is \\(\\{3\\}\\).\nThe event that the first roll is a 3 and the second roll is a 1 is \\(\\{3, 1\\}\\)\nDonny’s sample space from the first question might correspond to what dice rolling scenario?\nDonny says “OK, I get that \\(\\{1, 2, 3, 4, 5, 6\\}\\) is the sample space for a single roll of a six-sided die. But \\(\\{3, 1\\}\\) doesn’t make any as an event because the die can’t land on both 1 and 3.” Explain to Donny what the event \\(\\{3, 1\\}\\) represents in this scenario.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.13. \n\nThe questions involve a pair of rolls, so best to record an outcome as an ordered pair, e.g., (5, 2) for 5 on the first roll and 2 on the second. Therefore, the sample space would be the following set of 36 possible outcomes. \\[\\begin{align*}\n\\Omega  = & \\{\n(1, 1), (1, 2), \\ldots, (1, 6),\\\\\n& \\;\\; (2, 1), (2, 2), \\ldots, (2, 6),\\\\\n& \\;\\; \\vdots\\qquad \\qquad \\quad \\cdots \\qquad \\vdots\\\\\n& \\;\\; (6, 1), (6, 2), \\ldots, (6, 6)\n\\}\n\\end{align*}\\]\nDonny’s answers to the first two parts are inconsistent, since there is always a single sample space. So if he says the answer to the first part is \\(\\{1, \\ldots, 6\\}\\), then any event must be a subset of that sample space and his answer to the second part must be wrong. Using the sample space of 36 ordered pairs from the previous answer, the correct event that the sum of the two dice is at least 10 is \\(\\{(4, 6), (5, 5), (5, 6), (6, 4), (6, 5), (6, 6)\\}\\). If Donny’s sample space in the first part had been \\(\\{2, \\ldots, 12\\}\\), corresponding to the sum of the two dice, then his answer of \\(\\{10, 11, 12\\}\\) would have been correct. However, using such a sample space, he would not have been able to answer the remaining questions (which don’t involve the sum of the rolls). There is always one sample space on which all events are defined.\nDonny didn’t take into account that an outcome is a pair of rolls. The correct event is \\(\\{(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)\\}\\), the set of all pairs of rolls for which the first roll is 3.\nMaybe Donny is just using sloppy notation here, but it sure looks like he is confusing an outcome with an event. The answer should be \\(\\{(3, 1)\\}\\), the set containing the single outcome \\((3, 1)\\). Notice that this is not the same set as \\(\\{(1, 3)\\}\\). (But the set \\(\\{3, 1\\}\\) is the same as the set \\(\\{1, 3\\}\\).)\nThe sample space of \\(\\{1, 2, 3, 4, 5, 6\\}\\) could correspond to a single roll of a fair six-sided die. The possible outcomes for a single roll would be \\(\\{1, 2, 3, 4, 5, 6\\}\\).\nFor a single roll, \\(\\{3, 1\\}\\) is the event the the die lands on 3 or 1, that is, “1 or 3”; the set \\(\\{3, 1\\}\\) is the same as the set \\(\\{1, 3\\}\\). The event “1 or 3” occurs if the die lands on 1, so 1 satisifies the event and is in the corresponding set; The event “1 or 3” occurs if the die lands on 3, so 3 satisifies the event and is in the corresponding set. Therefore the event “1 or 3” corresponds to the set \\(\\{1, 3\\}\\). The event occurs if any of the outcomes that satisfy the event occurs (not if they all do). (Donny is right that the die can’t land on both 1 and 3, but the event “1 and 3” would be \\(\\{1\\}\\cap \\{3\\}=\\emptyset\\); there are no outcomes that satisfy the event “1 and 3”.)\n\n\n\n\n\n\n2.2.1 The collection of events of interest\nAn outcome is a possible realization of a random phenomenon. The sample space is the set of all possible outcomes. An event is a subset of the space space consisting of outcomes that satisfy some criteria. There are many events of interest for any random phenomenon. The collection of all events of interest is often denoted \\(\\mathcal{F}\\).\nAn event \\(A\\) is a set. The collection \\(\\mathcal{F}\\) of events of interest is a collection of sets. For the purposes of this text, \\(\\mathcal{F}\\) can be considered to be the set of all subsets9 of \\(\\Omega\\).\nAs an example, consider a single roll of a four-sided die.\n\n\n\n\n\n\nCaution\n\n\n\nThis section concerns a single roll of a fair four-sided die. Don’t confuse this scenario with many other examples that involve two rolls.\n\n\n\n\n\n\n\n\n\nExample 2.14 Consider a single roll of a four-sided die. The sample space consists of the four possible outcomes \\(\\Omega = \\{1, 2, 3, 4\\}\\).\n\nIdentify \\(A\\), the event that the die lands on 1.\nIdentify \\(B\\), the event that the die lands on an odd number.\nIdentify \\(C\\), the event that the die lands on 1 or 2.\nIdentify \\(D\\), the event that the die does not land on 4.\nWhich of the events \\(A, B, C, D\\) occur if the die lands on 3?\nIdentify all possible events for this sample space, and determine whether or not each event occurs if the die lands on 3.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.14. For a single roll of a four-sided die, the sample space consists of the four possible outcomes \\(\\Omega = \\{1, 2, 3, 4\\}\\). (Again, don’t confuse this scenario with other examples!) Any subset of this sample space is an event.\n\n\\(A = \\{1\\}\\) is the event that the die lands on 1.\n\\(B = \\{1, 3\\}\\) is the event that the die lands on an odd number. (This event occurs if the die lands on 1 so 1 is in \\(B\\); it also occurs if the die lands on 3 so 3 is in \\(B\\).)\n\\(C = \\{1, 2\\}\\) is the event that the die lands on 1 or 2.\n\\(D = \\{1, 2, 3\\}\\) is the event that the die does not land on 4.\nIf the die lands on 3 then events \\(B\\) and \\(D\\) occur and events \\(A\\) and \\(C\\) do not occur. Notice that 3 is an element of the sets \\(B\\) and \\(D\\) but not \\(A\\) and \\(C\\).\nAny subset of \\(\\{1, 2, 3, 4\\}\\) is an event, including \\(\\emptyset\\) and \\(\\{1, 2, 3, 4\\}\\) itself. Table 2.6 lists all possible events, and whether they occur if the single roll results in a 3 (that is, for the outcome \\(\\omega=3\\)).\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nWe usually think of a table as a list of all possible outcomes, with one row for each outcome. Table 2.6 is a different kind of table. Each row of Table 2.6 is an event, and the table lists the collection of all events (\\(\\mathcal{F}\\))\n\n\n\n\n\nTable 2.6: All possible events associated with a single roll of a four-sided die.\n\n\n\n\n\nEvent\nDescription\nOccurs upon observing outcome \\(\\omega=3\\)?\n\n\n\n\n\\(\\emptyset\\)\nRoll nothing (not possible)\nNo\n\n\n\\(\\{1\\}\\)\nRoll a 1\nNo\n\n\n\\(\\{2\\}\\)\nRoll a 2\nNo\n\n\n\\(\\{3\\}\\)\nRoll a 3\nYes\n\n\n\\(\\{4\\}\\)\nRoll a 4\nNo\n\n\n\\(\\{1, 2\\}\\)\nRoll a 1 or a 2\nNo\n\n\n\\(\\{1, 3\\}\\)\nRoll a 1 or a 3\nYes\n\n\n\\(\\{1, 4\\}\\)\nRoll a 1 or a 4\nNo\n\n\n\\(\\{2, 3\\}\\)\nRoll a 2 or a 3\nYes\n\n\n\\(\\{2, 4\\}\\)\nRoll a 2 or a 4\nNo\n\n\n\\(\\{3, 4\\}\\)\nRoll a 3 or a 4\nYes\n\n\n\\(\\{1, 2, 3\\}\\)\nRoll a 1, 2, or 3 (a.k.a. do not roll a 4)\nYes\n\n\n\\(\\{1, 2, 4\\}\\)\nRoll a 1, 2, or 4 (a.k.a. do not roll a 3)\nNo\n\n\n\\(\\{1, 3, 4\\}\\)\nRoll a 1, 3, or 4 (a.k.a. do not roll a 2)\nYes\n\n\n\\(\\{2, 3, 4\\}\\)\nRoll a 2, 3, or 4 (a.k.a. do not roll a 1)\nYes\n\n\n\\(\\{1, 2, 3, 4\\}\\)\nRoll something\nYes\n\n\n\n\n\n\nA random phenomenon corresponds to a single sample space, but there are many events of interest. Listing the collection of all possible events as in the previous table is rarely done in practice, but we do so here to provide a concrete example of \\(\\mathcal{F}\\).\n\n\n2.2.2 Exercises\n\nExercise 2.3 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package.\n\nLet \\(A_1\\) be the event that prize 1 is obtained—that is, at least one of the packages contains prize 1—and define \\(A_2, A_3\\) similarly for prize 2, 3.\nLet \\(B_1\\) be the event that only prize 1 is obtained—that is, all three packages contain prize 1—and define \\(B_2, B_3\\) similarly for prize 2, 3.\n\nIdentify the following events as sets and interpret them in words\n\n\\(A_1\\) (hint: define \\(A_1^c\\) first)\n\\(B_1\\)\n\\(A_1 \\cap A_2 \\cap A_3\\)\n\\(A_1 \\cup A_2 \\cup A_3\\)\n\\(B_1 \\cap B_2 \\cap B_3\\)\n\\(B_1 \\cup B_2 \\cup B_3\\)\n\n\n\nExercise 2.4 Katniss throws a dart at a circular dartboard with radius 1 foot. (Assume that Katniss’s dart never misses the dartboard.)\nDraw a picture to represent each of these events.\n\n\\(A\\), Katniss’s dart lands within 1 inch of the center of the dartboard.\n\\(B\\), Katniss’s dart lands more than 1 inch but less than 2 inches away from the center of the dartboard.\n\\(E\\), Katniss’s dart lands within 1 inch of the outside edge of the dartboard.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-rv",
    "href": "language-probability.html#sec-rv",
    "title": "2  The Language of Probability",
    "section": "2.3 Random variables",
    "text": "2.3 Random variables\nStatisticians use the terms observational unit and variable. Observational units are the people, places, things, etc., for which data is observed. Variables are the measurements made on the observational units. For example, the observational units in a study could be college students, while variables could be age, high college GPA, major GPA, number of credits completed, number of Statistics courses taken, etc.\nIn probability, an outcome of a random phenomenon plays a role analogous to an observational unit in statistics. The sample space of outcomes is often only vaguely defined. In many situations we are less interested in detailing the outcomes themselves and more interested in whether or not certain events occur, or with measurements that we can make for the outcomes. For example, if the random phenomenon corresponds to randomly selecting a single student at a college an outcome would be the selected student, but we are more interested in quantities like the student’s GPA or number of credits completed. If we randomly select a sample of students, we are less interested in who the students are, and more interested in questions which involve variables such as what is the relationship between college GPA and major GPA? In probability, random variables play a role analogous to variables in statistics.\n\nDefinition 2.4 A random variable assigns a number measuring some quantity of interest to each outcome of a random phenomenon. That is, a random variable is a function that takes an outcome in the sample space as input and returns a number as output.\n\nIf we’re interested in the weather conditions in our city tomorrow, random variables include\n\nhigh temperature (°F)\namount of precipitation (cm)\nhumidity (%)\nmaximum wind speed (mph)\n\nEach of these quantities will take a value that depends on tomorrow’s weather conditions. Since there are a range of possibilities for tomorrow’s weather conditions, there is a range of values that each of these random variables can take.\nRandom variables are typically denoted by capital letters near the end of the alphabet, with or without subscripts: e.g. \\(X\\), \\(Y\\), \\(Z\\), or \\(X_1\\), \\(X_2\\), \\(X_3\\), etc.\n\n\n\n\n\n\n\nExample 2.15 Donny Don’t is working on a problem that starts “let \\(X\\) be a random variable representing tomorrow’s high temperature in your city”. Donny says: “There is only one tomorrow and there will only be one high temperature tomorrow in my city. Tomorrow’s high temperature will just be a single number, there’s nothing variable about it.” Explain to Donny what it means to say “tomorrow’s high temperature is a random variable”.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.15. Yes, tomorrow’s high temperature will be a single number, but we do not know what that number will be. Tomorrow’s weather conditions are uncertain, that is, random. Even if the forecast calls for a high of 75 degrees F, the high temperature could be 75 degrees, or 78 or 72 or 74, etc. A random variable represents all the different possible values that tomorrow’s high temperature might be depending on the uncertain weather conditions.\n\n\n\n\nA random variable is “variable” in the sense that it can take different values—that is, it can vary—and the value it takes is uncertain—that is, “random”.\n\n\n\n\n\n\n\nExample 2.16 Continuning Example 2.8. Let \\(X\\) be the number of previous championships won by the team that wins the top pick in the lottery. Explain what it means for \\(X\\) to be a random variable and identify its possible values.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.16. Before the lottery is conducted, the team that will win the top pick is uncertain and so their number of previous championships is also uncertain, and the value will vary depending on which team wins. The possible values are \\(\\{0, 1, 2, 3, 5, 6\\}\\).\n\n\n\n\nIn statistics, data is often stored in a spreadsheet or data table with rows corresponding to observational units and columns to variables. Likewise, in probability it helps to visualize a table with rows corresponding to outcomes and columns to random variables. Each outcome is associated with a value of the random variable. Since the outcome is uncertain, the value the random variable takes is also uncertain.\n\n\n\n\n\n\n\nExample 2.17 Roll a four-sided die twice, and record the result of each roll in sequence. Recall the sample space from Example 2.1. Let \\(X\\) be the sum of the two dice, and let \\(Y\\) be the larger of the two rolls (or the common value if both rolls are the same).\n\nConstruct a table identifying the values of \\(X\\) and \\(Y\\) for each outcome in the sample space. Hint: add columns to Table 2.1.\nEvaluate \\(X((1, 3))\\), \\(X((4, 3))\\), and \\(X((2, 2))\\).\nEvaluate \\(Y((1, 3))\\), \\(Y((4, 3))\\), and \\(Y((2, 2))\\).\nIdentify the possible values of \\(X\\).\nIdentify the possible values of \\(Y\\).\nIdentify the possible values of the pair \\((X, Y)\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.17. \n\nSee Table 2.7. The first column corresponds to sample space outcomes, and there is a column for each random variable.\n\\(X\\) is the sum of the two rolls, so \\(X((1, 3))=1+3=4\\), \\(X((4, 3))=4+3=7\\), and \\(X((2, 2))=2+2=4\\).\n\\(Y\\) is the larger of the two rolls (or the common value if a tie) so \\(Y((1, 3))=\\max(1, 3) = 3\\), \\(Y((4, 3))=\\max(4, 3) =4\\), and \\(Y((2, 2))=\\max(2, 2) = 2\\).\nThe possible values of \\(X\\) are \\(2, 3, 4, 5, 6, 7, 8\\).\nThe possible values of \\(Y\\) are \\(1, 2, 3, 4\\).\nThe possible values of the pair \\((X, Y)\\) are: (2, 1), (3, 2), (4, 2), (4, 3), (5, 3), (5, 4), (6, 3), (6, 4), (7, 4), (8,4). Notice that while, for example, 8 is a possible value of \\(X\\) and 1 is a possible value of \\(Y\\), (8, 1) is not a possible value of the pair \\((X, Y)\\); it’s not possible for the larger of the two dice to be 1 but their sum to be 8.\n\n\n\n\n\n\n\n\n\nTable 2.7: Table representing the sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die\n\n\n\n\n\n\nOutcome (First roll, second roll)\nX (sum)\nY (max)\n\n\n\n\n(1, 1)\n2\n1\n\n\n(1, 2)\n3\n2\n\n\n(1, 3)\n4\n3\n\n\n(1, 4)\n5\n4\n\n\n(2, 1)\n3\n2\n\n\n(2, 2)\n4\n2\n\n\n(2, 3)\n5\n3\n\n\n(2, 4)\n6\n4\n\n\n(3, 1)\n4\n3\n\n\n(3, 2)\n5\n3\n\n\n(3, 3)\n6\n3\n\n\n(3, 4)\n7\n4\n\n\n(4, 1)\n5\n4\n\n\n(4, 2)\n6\n4\n\n\n(4, 3)\n7\n4\n\n\n(4, 4)\n8\n4\n\n\n\n\n\n\n\n\nMathematically, a random variable \\(X\\) is a function that takes an outcome \\(\\omega\\) in the sample space \\(\\Omega\\) as input and returns a number \\(X(\\omega)\\) as output; we write \\(X:\\Omega\\mapsto \\mathbb{R}\\). The random variable itself is typically denoted with a capital letter (\\(X\\)); possible values of that random variable are denoted with lower case letters (\\(x\\)). Think of the capital letter \\(X\\) as a label standing in for a formula like “the sum of two rolls of a four-sided die” and \\(x\\) as a dummy variable standing in for a particular value like 3.\nIn Example 2.17, the pair \\((X, Y)\\) is a random vector10. The output of each of \\(X\\) and \\(Y\\) is a number; the output of \\((X, Y)\\) is an ordered pair of numbers. A random vector is simply a vector of random variables.\nOne of the main reasons for modeling a sample space as the set of possible outcomes rather than the set of all possible values of some random variable is that we often want to define many random variables on the same sample space, and study relationships between them. As a statistics analogy, you would not be able to study the relationship between college GPA and major GPA unless you measured both variables for the same set of students.\n\n2.3.1 Types of random variables\nThere are two main types of random variables.\n\nDiscrete random variables take at most countably many possible values (e.g., \\(0, 1, 2, \\ldots\\)). They are often counting variables (e.g., the number of coin flips that land on heads).\nContinuous random variables can take any real value in some interval (e.g., \\([0, 1]\\), \\([0,\\infty)\\), \\((-\\infty, \\infty)\\).). That is, continuous random variables can take uncountably many different values. Continuous random variables are often measurement variables (e.g., height, weight, income).\n\nIn some problems, there are many random variables of interest, as in the following example.\n\n\n\n\n\n\n\nExample 2.18 Recall Example 2.5. Customers enter a deli and take a number to mark their place in line. When the deli opens the counter starts 0; the first customer to arrive takes number 1, the second 2, etc. We record the counter over time, continuously, as it changes as customers arrive. Time is measured in minutes after the deli opens (time 0).\nThere are many random variables that could be of interest, including\n\n\\(N_t\\), the number of customers that have arrived by time \\(t\\), where \\(t\\ge0\\) is minutes after time 0\n\\(T_j\\), the time (in minutes after time 0) at which the \\(j\\)th customer arrives, for \\(j=1, 2, \\ldots\\)\n\\(W_j\\), the “waiting” time (in minutes) between the arrival of the \\(j\\)th and the \\((j-1)\\)th customer.\n\nFor each of the following random variables, classify it as discrete or continuous. Then identify its value for the outcome represented by the path in Figure 2.6 (as best as you can from the plot).\n\n\\(N_4\\)\n\\(N_{6.5}\\)\n\\(T_4\\)\n\\(T_5\\)\n\\(W_1\\)\n\\(W_5\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.6: A sample outcome for Example 2.5.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.18. Let \\(\\omega\\) denote the outcome represented by Figure 2.6.\n\nThe random variable \\(N_4\\) counts the number of customers who have arrived by time 4. \\(N_4\\) is a discrete random variable taking values in the countable set \\(\\{0, 1, 2, \\ldots \\}\\). To compute the value of \\(N_4\\) for the outcome \\(\\omega\\) in Figure 2.6, find time \\(t=4\\) on the horizontal axis and find the corresponding value on the vertical axis: \\(N_4(\\omega)=8\\) customers; for this outcome, the number of customers that have arrived by time 4 is 8.\nThe random variable \\(N_{6.5}\\) which counts the number of customers who have arrived by time 6.5 is a discrete random variable taking values in the countable set \\(\\{0, 1, 2, \\ldots \\}\\). \\(N_{6.5}(\\omega)=13\\) customers; the number of customers that have arrived by time 6.5 is 13. The number of customers is a whole number, but time is measured continuously (e.g., 6.5 minutes after opening). There is a different discrete random variable \\(N_t\\) corresponding to each value of time \\(t\\ge 0\\), but the possible values of each of these variables are \\(\\{0, 1, 2, \\ldots\\}\\).\nThe random variable \\(T_4\\), which measures the time at which the fourth customer arrives, is a continuous random variable (since we’re assuming time is measured continuously). The smallest possible value of \\(T_4\\) is 0, but there is no definite largest possible value of \\(T_4\\), so \\(T_4\\) can take theoretically take any value in the continuous time interval \\([0, \\infty)\\). The fourth customer arrives when the path jumps from 3 customers so far to 4. For the outcome \\(\\omega\\) in Figure 2.6 the path jumps from 3 to 4 a little after time 2 so \\(T_4(\\omega)\\approx 2.1\\) minutes after noon.\nThe random variable \\(T_5\\) which measures the arrival time of the fifth customer is a continuous random variable taking values in \\([0, \\infty)\\). The fifth customer arrives when the path jumps from 4 customers so far to 5. For this outcome the path jumps from 4 to 5 almost right after it jumps from 3 to 4, and almost right after time 2, so \\(T_5(\\omega)\\approx 2.2\\) minutes after noon. There is a different continuous random variable \\(T_j\\) for each customer \\(j=1, 2, \\ldots\\), but the possible values of each of these random variables is \\([0,\\infty)\\).\n\\(W_1\\) is the waiting time from open until the first customer arrives, a continuous random variable taking values in \\([0, \\infty)\\). For the outcome \\(\\omega\\) in Figure 2.6 the path jumps from 0 to 1 a little after time 0 so \\(W_1(\\omega)\\approx 0.1\\) minutes.\n\\(W_5\\) is the time elapsed between the arrival of the fourth customer (at roughly time 2.1 for outcome \\(\\omega\\)) and fifth customer (at roughly time 2.2 for outcome \\(\\omega\\)), which is about 0.1 minutes.\n\n\n\n\n\n\n\n2.3.2 A random variable is a function\nRecall that for a mathematical function11 \\(g\\), given an input \\(u\\), the function returns a real number \\(g(u)\\). For example, if \\(g\\) is the square root function, \\(g(u) = \\sqrt{u}\\), then \\(g(9) = 3\\) and \\(g(10) = 3.162278...\\). If the input comes from some set \\(S\\) (i.e. \\(u\\in S\\)), we write \\(g:S\\mapsto \\mathbb{R}\\).\nA random variable \\(X\\) is a function which maps each outcome \\(\\omega\\) in the sample space \\(\\Omega\\) to a real number \\(X(\\omega)\\); \\(X:\\Omega\\mapsto\\mathbb{R}\\). For a single outcome \\(\\omega\\), the value \\(x = X(\\omega)\\) is a single number; notice that \\(x\\) represents the output of the function \\(X\\) rather than the input. However, it is important to remember that the random variable \\(X\\) itself is a function, and not a single number.\nYou are probably familiar with functions expressed as simple closed form formulas of their inputs: \\(g(u)=5u\\), \\(g(u)=u^2\\), \\(g(u)=\\log u\\), etc. While any random variable is some function, the function is rarely specified as an explicit mathematical formula of its input \\(\\omega\\). Often, outcomes are not even numbers (e.g., sequences of coin flips), or only vaguely specified if at all (e.g., tomorrow’s weather conditions). In Example 2.17 we defined \\(X\\) through the words “sum of two rolls of a fair four-sided dice” instead of as a formula12.\nIt is more appropriate to think of a random variable as a function in the sense of a scale at a grocery store which maps a fruit to its weight, \\(X: \\text{fruit}\\mapsto\\text{weight}\\). Put an apple on the scale and the scale returns a number, \\(X(\\text{apple})\\), the weight of the apple. Likewise, \\(X(\\text{orange})\\), \\(X(\\text{banana})\\). The random variable \\(X\\) is the scale itself. This simplistic analogy assumes a sample space outcome is a single fruit. Of course, it’s even more complicated in reality since an outcome can be considered a set of fruits, so that we have for example \\(X(\\{\\text{2 apples}, \\text{3 oranges}\\})\\), and all fruits do not weigh the same, so that \\(X(\\text{this apple})\\) is not the same as \\(X(\\text{that apple})\\). But the idea is that a function is like a scale, with an input (fruits) and an output (weight). The input does not have to be a number, but the output does.\nSuppose I’m going to randomly select some fruits, put them in a brown grocery bag, and place it on the scale. It wouldn’t be feasible to enumerate all the combinations of fruits I could put in the bag, but even so you know that any possible combination has some weight which could be measured by the scale. There is still a function (scale) that maps an input (fruits in the bag) to a numerical output (weight), even if that function is not explicitly specified with a mathematical formula. Now suppose I’ve selected some fruits and put the bag on the scale. Even if you can’t see what fruits are inside the bag, you can still read the weight off the scale. But even if you only observe the weight, you know there was still a background random process of putting fruits in a bag which resulted in a particular outcome having the observed weight.\nThe “weighing fruits in a bag” scenario in the previous paragraph illustrates how probability usually works:\n\nWe typically don’t explicitly specify outcomes or the sample space, but we know that different outcomes can result in different values of random variables. That is, we know there is some function which maps outcomes of the random phenomenon to values of the random variable, even if we don’t have an explicit formula for the inputs to the function (sample space outcomes) or the function itself.\nWe might not observe outcomes in full detail (e.g., tomorrow’s weather conditions), but we often can still observe values of random variables (e.g., tomorrow’s high temperature).\n\n\n\n\n\n\n\n\nExample 2.19 Recall the sample space from Example 2.3. Let \\(R\\) be the random variable representing Regina’s arrival time, and \\(Y\\) for Cady.\n\nIdentify the function that defines \\(R\\), and the possible values of \\(R\\). (Hint: remember the sample space.)\nIdentify the function that defines \\(Y\\), and the possible values of \\(Y\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.19. \n\nRecall that an outcome is an ordered pair representing the arrival times of (Regina, Cady); we can write an outcome as \\(\\omega\\equiv(\\omega_1, \\omega_2)\\). Remember there is a single sample space corresponding to the pairs of arrival times, rather than a separate sample space for each. Therefore, random variables need to be defined on this single sample space; inputs to random variables defined on this sample space are pairs of arrival times. Regina’s arrival time is defined by the function \\(R(\\omega) \\equiv R((\\omega_1, \\omega_2))=\\omega_1\\). That is, \\(R\\) maps the ordered pair \\((\\omega_1, \\omega_2)\\) to its first coordinate \\(\\omega_1\\). For example, \\(R((45, 30.2)) = 45\\).\nOn this sample space, Cady’s arrival time is defined by the function \\(Y(\\omega) \\equiv Y((\\omega_1, \\omega_2))=\\omega_2\\). That is, \\(Y\\) maps the ordered pair to its second coordinate. The input to \\(Y\\) is a pair of numbers (Regina, Cady) and the output is Cady’s arrival time only. For example, \\(Y((45, 30.2)) = 30.2\\).\n\n\n\n\n\n\n\n2.3.3 Tranformations of random variables\nWe are often interested in random variables that are derived from others. For example, if the random variable \\(X\\) represents the radius (cm) of a randomly selected circle, then \\(Y = \\pi X^2\\) is a random variable representing the circle’s area (\\(\\text{cm}^2\\)). If the random variables \\(W\\) and \\(T\\) represent the weight (kg) and height (m), respectively, of a randomly selected person, then \\(S = W / T^2\\) is a random variable representing the person’s body mass index (\\(\\text{kg}/\\text{m}^2\\)).\nA function of a random variable is also a random variable. That is, if \\(X\\) is a random variable and \\(g\\) is a function, then \\(Y=g(X)\\) is also a random variable13. For example, if \\(u\\) is a radius of a circle, the function \\(g(u) = \\pi u^2\\) outputs its area; if \\(X\\) is a random variable representing the radius of a randomly selected circle then \\(Y = g(X)=\\pi X^2\\) is a random variable representing the circle’s area.\nSums and products, etc., of random variables defined on the same sample space are random variables. That is, if random variables \\(X\\) and \\(Y\\) are defined on the same sample space then \\(X+Y\\), \\(X-Y\\), \\(XY\\), and \\(X/Y\\) are also random variables. Similarly, it is possible to make comparisons such as \\(X\\ge Y\\) and apply other transformations for random variables defined on the same sample space.\n\n\n\n\n\n\n\nExample 2.20 Continuning Example 2.8. In basketball games, teams attempt field goals and they score points for made field goals. Made field goals are worth either 2 or 3 points. Teams also attempt free throws which are worth 1 point if made. Each team plays 82 games in a season.\nFor the team that wins the top pick in the lottery in the 2022-2023 season, let\n\n\\(W\\) be the number of wins\n\\(Y_1\\) be free throw attempts per game (FT)\n\\(Y_2\\) be 2 point field goal attempts per game (FG2)\n\\(Y_3\\) be 3 point field goal attempts per game (FG3)\n\\(X_1\\) be free throws made per game (FTA)\n\\(X_2\\) be 2 point field goals made per game (FG2A)\n\\(X_3\\) be 3 point field goals made per game (FG3A)\n\nInterpret the following random variables in this context. How could they be represented in a table like Table 2.3?\n\n\\(82 - W\\)\n\\(W / 82\\)\n\\(X_1 / Y_1\\)\n\\(\\frac{X_2 + X_3}{Y_2+Y_3}\\)\n\\(\\frac{Y_3}{Y_2+Y_3}\\)\n\\(3X_3 + 2X_2 + X_1\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.20. Table 2.8 provides a representation of these random variables. For the team that wins the 2023 NBA draft in the 2022-2023 season:\n\n\\(82 - W\\) is the team’s number of losses\n\\(W / 82\\) is the proportion of games in the season that the team won (a.k.a., winning percentage, as a decimal)\n\\(X_1 / Y_1\\) is the proportion of free throw attempts that the team successfully made (a.k.a., free throw percentage, as a decimal)\n\\(\\frac{X_2 + X_3}{Y_2+Y_3}\\) is the proportion of total field goal attempts that the team successfully made (a.k.a., field goal percentage, as a decimal)\n\\(\\frac{Y_3}{Y_2+Y_3}\\) is the proportion of the team’s total field goal attempts that were 3 point attempts\n\\(3X_3 + 2X_2 + X_1\\) is the total points per game scored by the team (any differences between Table 2.8 and PPG in Table 2.3 are due to rounding.)\n\n\n\n\n\n\n\n\n\nTable 2.8: The random variables from Example 2.20 for teams in the 2023 NBA Draft Lottery.\n\n\n\n\n\n\nTeam\n$W$\n$X_3$\n$Y_3$\n$X_2$\n$Y_2$\n$X_1$\n$Y_1$\n$82-W$\n$W/82$\n$X_1/Y_1$\n$\\frac{X_2+X_3}{Y_2+Y_3}$\n$\\frac{Y_3}{Y_2+Y_3}$\n$3X_3 + 2X_2 + X_1$\n\n\n\n\nDetroit Pistons\n17\n11.4\n32.4\n28.2\n54.6\n19.8\n25.7\n65\n0.207\n0.770\n0.455\n0.372\n110.4\n\n\nHouston Rockets\n22\n10.4\n31.9\n30.2\n56.9\n19.1\n25.3\n60\n0.268\n0.755\n0.457\n0.359\n110.7\n\n\nSan Antonio Spurs\n22\n11.1\n32.2\n32.0\n60.4\n15.8\n21.2\n60\n0.268\n0.745\n0.465\n0.348\n113.1\n\n\nCharlotte Hornets\n27\n10.7\n32.5\n30.5\n57.9\n17.6\n23.6\n55\n0.329\n0.746\n0.456\n0.360\n110.7\n\n\nPortland Trail Blazers\n33\n12.9\n35.3\n27.6\n50.1\n19.6\n24.6\n49\n0.402\n0.797\n0.474\n0.413\n113.5\n\n\nOrlando Magic\n34\n10.8\n31.1\n29.8\n55.2\n19.6\n25.0\n48\n0.415\n0.784\n0.470\n0.360\n111.6\n\n\nIndiana Pacers\n35\n13.6\n37.0\n28.4\n52.6\n18.7\n23.7\n47\n0.427\n0.789\n0.469\n0.413\n116.3\n\n\nWashington Wizards\n35\n11.3\n31.7\n30.9\n55.2\n17.6\n22.4\n47\n0.427\n0.786\n0.486\n0.365\n113.3\n\n\nUtah Jazz\n37\n13.3\n37.8\n29.2\n52.0\n18.7\n23.8\n45\n0.451\n0.786\n0.473\n0.421\n117.0\n\n\nDallas Mavericks\n38\n15.2\n41.0\n24.8\n43.3\n19.0\n25.1\n44\n0.463\n0.757\n0.474\n0.486\n114.2\n\n\nChicago Bulls\n40\n10.4\n28.9\n32.1\n57.9\n17.6\n21.8\n42\n0.488\n0.807\n0.490\n0.333\n113.0\n\n\nOklahoma City Thunder\n40\n12.1\n34.1\n31.0\n58.5\n19.2\n23.7\n42\n0.488\n0.810\n0.465\n0.368\n117.5\n\n\nToronto Raptors\n41\n10.7\n32.0\n31.1\n59.3\n18.4\n23.4\n41\n0.500\n0.786\n0.458\n0.350\n112.7\n\n\nNew Orleans Pelicans\n42\n11.0\n30.1\n31.1\n57.5\n19.3\n24.4\n40\n0.512\n0.791\n0.481\n0.344\n114.5\n\n\n\n\n\n\n\n\nRemember that we can visualize outcomes as rows in a spreadsheet with random variables as columns. Random variables defined on the same sample space can be put in a single spreadsheet. Each row corresponds to an outcome, and reading across any row there is a value in the column corresponding to each random variable. Random variables derived from transformations of other random variables append columns to the spreadsheet. New random variables can be defined by going row-by-row, outcome-by-outcome, and applying a transformation within each row to the values of other random variables.\nUsing capital letters like \\(X\\) or \\(Y\\) to denote random variables is standard practice. To help develop comfort with this mathematical notation, we will often label columns in tables with their random variable symbols (as we did in Table 2.8). Later, when writing code we will often denote random variables with symbols like X or Y. However, keep in mind that mathematical symbols like \\(X\\) or \\(Y\\) represent variables in a context. While you should develop comfort with the notation, you can—and probably should—use more informative labels like “wins” or wins rather than \\(W\\).\n\n\n\n\n\n\n\nExample 2.21 Continuing Example 2.19.\n\nWhat does the random variable \\(U_1 = R / 60\\) represent in context? What are the possible values of \\(U_1\\)?\nWhat does the random variable \\(T = \\min(R, Y)\\) represent in context? What are the possible values of \\(T\\)?\nWhat does the random variable \\(W = |R - Y|\\) represent in context? What are the possible values of \\(W\\)?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.21. \n\n\\(U_1= R / 60\\) represents Regina’s arrival time measured as a fraction of the hour after noon. For example, if Regina arrives 15 minutes after noon then \\(R=15\\) and \\(U_1= 15/60 = 0.25\\). \\(U_1\\) takes values in [0, 1].\n\\(T=\\min(R, Y)\\) represents the time (minutes after noon) of the first arrival. For example, if Regina arrives 15 minutes after noon and Cady 22.3 minutes after noon then \\(R=15\\), \\(C=22.3\\) and \\(T=\\min(15, 22.3) = 15\\). \\(T\\) takes values in \\([0, 60]\\). If either Regina and Cady arrives at time 0 (noon) then \\(T\\) is 0, the smallest possible value of \\(T\\); if both arrive at 1:00 then \\(T\\) is 60, the largest possible value of \\(T\\).\n\\(W=|R-Y|\\) represents the amount of time the first person to arrive waits for the second person to arrive. For example, if Regina arrives 15 minutes after noon and Cady 22.3 minutes after noon then \\(R=15\\), \\(C=22\\) and \\(W = |15-22.3| = 7.3\\). \\(W\\) takes values in \\([0, 60]\\). If both Regina and Cady arrive at the same time then \\(W\\) is 0; if one arrives at noon and the other at 1:00 then \\(W\\) is 60, the largest possible value of \\(W\\).\n\n\n\n\n\n\n\n2.3.4 Indicator random variables\nRandom variables that only take two possible values, 0 and 1, have a special name.\n\nDefinition 2.5 An indicator (a.k.a., Bernoulli, a.k.a. Boolean) random variable can take only the values 0 or 1. If \\(A\\) is an event then the corresponding indicator random variable \\(\\textrm{I}_A\\) is defined as \\[\n\\textrm{I}_A(\\omega) =\n\\begin{cases}\n1, & \\omega \\in A,\\\\\n0, & \\omega \\notin A\n\\end{cases}\n\\] That is, \\(\\textrm{I}_A\\) equals 1 if event \\(A\\) occurs, and \\(\\textrm{I}_A\\) equals 0 if event \\(A\\) does not occur.\n\nIndicators provide the bridge between events (sets) and random variables (functions). Any event either occurs or not; a realization of any event is either true (\\(\\omega \\in A\\)) or false (\\(\\omega \\notin A\\)). An indicator random variable just translates “true” or “false” into numbers, 1 for “true” and 0 for “false”.\n\n\n\n\n\n\n\nExample 2.22 Recall the sample space from Example 2.2 for the matching problem with \\(n=4\\). Let the random variable \\(X\\) count the number of objects that are placed in the correct spot. Let \\(I_1\\) be equal to 1 if object 1 is placed (correctly) in spot 1, and define \\(I_2, I_3, I_4\\) similarly.\n\nConstruct a table identifying the value of \\(X, I_1, \\ldots, I_4\\) for each outcome in the sample space.\nIdentify the possible values of \\(X\\).\nWhat is the relationship between \\(I_3\\) and event \\(A_3\\) from Example 2.10?\nHow can you express \\(X\\) in terms of \\(I_1, \\ldots, I_4\\)?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.22. \n\nSee Table 2.9. Each random variable corresponds to a different column in the table.\n\\(X\\) can take values 0, 1, 2, and 4, but 3 is not a possible value of \\(X\\).\n\\(I_3\\) is equal to 1 only for outcomes that satisfy \\(A_3\\), the event that object 3 is placed in spot 3; \\(I_3\\) is equal 0 for outcomes that do not satisfy event \\(A_3\\). In this way, the value of the random variable \\(I_3\\) indicates whether or not the event \\(A_3\\) occurs; that is, \\(I_3\\) is the indicator random variable of event \\(A_3\\), \\(I_3 = \\textrm{I}_{A_3}\\).\nFor every outcome (row), the value of \\(X\\) is equal to the sum of the values of \\(I_1\\), \\(I_2\\), \\(I_3\\), \\(I_4\\). That is, \\(X = I_1+I_2+I_3+I_4\\). For example, for outcome 2134, \\(X\\) is equal to 2, \\(I_1\\) and \\(I_2\\) are equal to 0, and \\(I_3\\) and \\(I_4\\) are equal to 1, and \\(2 = 0 + 0 + 1 + 1\\). The relationship \\(X = I_1+I_2+I_3+I_4\\) is true for every outcome (row). The spot-by-spot indicators provide a way to incrementally count the total number of matches.\n\n\n\n\n\n\n\n\n\nTable 2.9: Total number of matches and indicator random variables for each item in the matching problem with \\(n=4\\).\n\n\n\n\n\n\nOutcome\n$X$\n$I_1$\n$I_2$\n$I_3$\n$I_4$\n\n\n\n\n1234\n4\n1\n1\n1\n1\n\n\n1243\n2\n1\n1\n0\n0\n\n\n1324\n2\n1\n0\n0\n1\n\n\n1342\n1\n1\n0\n0\n0\n\n\n1423\n1\n1\n0\n0\n0\n\n\n1432\n2\n1\n0\n1\n0\n\n\n2134\n2\n0\n0\n1\n1\n\n\n2143\n0\n0\n0\n0\n0\n\n\n2314\n1\n0\n0\n0\n1\n\n\n2341\n0\n0\n0\n0\n0\n\n\n2413\n0\n0\n0\n0\n0\n\n\n2431\n1\n0\n0\n1\n0\n\n\n3124\n1\n0\n0\n0\n1\n\n\n3142\n0\n0\n0\n0\n0\n\n\n3214\n2\n0\n1\n0\n1\n\n\n3241\n1\n0\n1\n0\n0\n\n\n3412\n0\n0\n0\n0\n0\n\n\n3421\n0\n0\n0\n0\n0\n\n\n4123\n0\n0\n0\n0\n0\n\n\n4132\n1\n0\n0\n1\n0\n\n\n4213\n1\n0\n1\n0\n0\n\n\n4231\n2\n0\n1\n1\n0\n\n\n4312\n0\n0\n0\n0\n0\n\n\n4321\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\nEven though they seem simple, indicator random variables are very useful. In the matching problem, it is not feasible to enumerate the outcomes and count when there is a large number \\(n\\) of items and spots. Using indicators allows you to count incrementally—is just this item in the correct spot?— rather than all at once. Representing a count as a sum of indicator random variables is a very common and useful strategy, especially in problems that involve “find the expected number of…”\nHere is a little story that illustrates the idea of incremental counting with indicators. Imagine a dad and his young child are reading a picture book. They come to a page that has twenty pictures of fruits, of which seven are bananas. The following conversation ensues.\n\nDad: Can you count all the bananas? Let’s see! How many bananas have we counted so far?\nKid: We haven’t started counting yet!\nDad: Right, so how many bananas have we counted so far?\nKid: Zero.\nDad: That’s right! We’ve counted zero bananas so far. (Dad points to a banana.) Is that a banana?\nKid: Yes!\nDad: So how many more bananas did we just count?\nKid: One more.\nDad: So how many bananas have we counted so far?\nKid: One.\nDad: Great job! We’ve counted one banana so far. (Dad points to a different banana.) Is that a banana?\nKid: Yes!\nDad: So how many more bananas did we just count?\nKid: We counted one more banana.\nDad: So how many bananas have we counted so far?\nKid: Two.\nDad: Great job! We’ve counted two bananas so far. (Dad points to a different banana.) Is that a banana?\nKid: Yes!\nDad: So how many more bananas did we just count?\nKid: We counted one more banana.\nDad: So how many bananas have we counted so far?\nKid: Three.\nDad: Great job! We’ve counted three bananas so far. (Dad points to an orange14.) Is that a banana?\nKid: No, that’s an orange!\nDad: So how many more bananas did we just count?\nKid: Zero. It was not a banana!\nDad: So how many bananas have we counted so far?\nKid: Still three.\nDad: Great job! We’ve counted three bananas so far. (Continues in this manner until Dad points to the twentieth and last fruit on the page, a banana.) Almost done. We’ve counted six bananas so far. Is that a banana?\nKid: Yes!\nDad: So how many more bananas did we just count?\nKid: We counted one more banana.\nDad: So how many bananas have we counted so far?\nKid: Seven.\nDad: We looked at each fruit on the page. How many were bananas?\nKid: Seven.\nDad: Great job! Now you know how indicator random variables can be used to count.\n\nIn the story, the kid counted the bananas by examining each object, determining whether or not it was a banana, and then incrementing the banana counter by 1 for each object that was a banana (and by 0 for the objects that were not bananas). The kid essentially created an indicator (of “banana”) variable for each object on the page (\\(I_{B_1}=1\\), \\(I_{B_2}=1\\), \\(I_{B_3}=1\\), \\(I_{B_4}=0\\ldots\\), \\(I_{B_{20}}=1\\)) and then summed these indicators to obtain the total count of bananas. This strategy gives a way of breaking down a complicated counting problem into smaller pieces and counting incrementally.\n\n\n\n\n\n\n\nExample 2.23 Continuing Example 2.22, interpret each of the following random variables.\n\n\\(1 - \\textrm{I}_3\\)\n\\(\\textrm{I}_1 \\textrm{I}_2\\), that is, the product of \\(\\textrm{I}_1\\) and \\(\\textrm{I}_2\\)\n\\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.23. \n\n\\(1 - \\textrm{I}_3\\) is 1 if \\(\\textrm{I}_3 = 0\\), which occurs when object 3 is not in spot 3, and \\(1 - \\textrm{I}_3\\) is 0 otherwise. So \\(1 - \\textrm{I}_3\\) is the indicator that object 3 is not placed in spot 3; \\(1-\\textrm{I}_3 = \\textrm{I}_{A_3^c}\\).\n\\(\\textrm{I}_1 \\textrm{I}_2\\) is 1 if both \\(\\textrm{I}_1\\) and \\(\\textrm{I}_2\\) are 1, which occurs when objects 1 and 2 are in the correct spots; otherwise, \\(\\textrm{I}_1 \\textrm{I}_2\\) is 0. Therefore \\(\\textrm{I}_1 \\textrm{I}_2\\) is the indicator that object 1 is placed in spot 1 and object 2 is placed in spot 2; \\(\\textrm{I}_1\\textrm{I}_2 = \\textrm{I}_{A_1 \\cap A_2}\\).\n\\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2\\) is 1 if: object 1 is in spot 1 but object 2 is not in spot 2 (1 + 0 - 0), object 1 is not in spot 1 but object 2 is in spot 2 (0 + 1 - 0), or if both object 1 is in spot 1 and object 2 is in spot 2 (1 + 1 - 1). \\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2\\) is 0 only if object 1 is not in spot 1 and object 2 is not in spot 2. Therefore \\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2\\) is the indicator that object 1 is placed in spot 1 or object 2 is placed in spot 2; \\(\\textrm{I}_1 + \\textrm{I}_2 - \\textrm{I}_1 \\textrm{I}_2 = \\textrm{I}_{A_1 \\cup A_2}\\).\n\n\n\n\n\nExample 2.23 illustrates that for two events \\(A\\) and \\(B\\) \\[\\begin{align*}\n\\textrm{I}_{A^c} & = 1 - \\textrm{I}_A & & \\\\\n\\textrm{I}_{A \\cap B} & = \\textrm{I}_A \\textrm{I}_B & & =\\min(\\textrm{I}_A, \\textrm{I}_B)\\\\\n\\textrm{I}_{A \\cup B} & = \\textrm{I}_A + \\textrm{I}_B - \\textrm{I}_{A \\cap B} & & = \\max(I_A, I_B)\n\\end{align*}\\]\nIn particular, the indicator of an intersection is the product of the indicators of each event. The \\(\\min, \\max\\), and product formulas work for more than two events, but the addition formula is more complicated15.\n\n\n2.3.5 Events involving random variables\nMany events of interest involve random variables. The event “tomorrow’s high temperature is above 75°F” involves the random variable “tomorrow’s high temperature”. Each possible outcome of tomorrow’s weather conditions will correspond to a value of high temperature, but only some of these outcomes will result in values of high temperature above 75 °F.\n\n\n\n\n\n\n\nExample 2.24 Continuning Example 2.8. For the team that wins the top pick in the lottery, let\n\n\\(X\\) be the number of previous championships won by the team that wins the top pick in the lottery\n\\(Y\\) be the number of wins in the 2022-2023 season\n\\(Z\\) be the points per game in the 2022-2023 season\n\\(I\\) be the indicator random variable that the team is in the Western Conference\n\nIdentify and interpret the following events.\n\n\\(\\{I=1\\}\\)\n\\(\\{X = 0\\}\\)\n\\(\\{Y &lt; 25\\}\\)\n\\(\\{Z &gt; 115\\}\\)\n\\(\\{I = 1, X = 0\\}\\)\n\\(\\{I = 1, X = 0, Y &lt; 25\\}\\)\n\\(\\{I = 1\\}\\cup \\{X = 0\\}\\)\n\\(\\{X \\ge 1\\}\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.24. These events are the same as those in Example 2.24 just with different notation.\n\n\\(\\{I = 1\\} = \\{\\text{Houston, San Antonio, Portland, Utah, Dallas, Oklahoma City, New Orleans}\\}\\) is the event that the team is in the Western Conference.\n\\(\\{X = 0\\} = \\{\\text{Charlotte, Orlando, Indiana, Utah, New Orleans}\\}\\) is the event that the team has never won a championship.\n\\(\\{Y &lt; 25\\} = \\{\\text{Detroit, Houston, San Antonio}\\}\\) is the event that the team won fewer than 25 games in the 2022-2023 season\n\\(\\{Z &gt; 115\\} = \\{\\text{Indiana, Utah, Oklahoma City}\\}\\) is the event that the team scored over 115 points per game in the 2022-2023 season\n\\(\\{I = 1, X = 0\\} = \\{\\text{Utah, New Orleans}\\}\\) is the event that the team is in the Western Conference and has won no previous championships.\n\\(\\{I = 1, X = 0, Y &lt; 25\\}=\\{\\text{Utah}\\}\\) is the event that the team is in the Western Conference, has won no previous championships, and scored over 115 points per game in the 2022-2023 season.\n\\(\\{I = 1\\}\\cup \\{X = 0\\}=\\{\\text{Charlottle, Houston, San Antonio, Portland, Orlando, Indians, Utah, Dallas, Oklahoma City, New Orleans}\\}\\) is the event that the team is in the Western Conference or has won no previous championships.\n\\(\\{X \\ge 1\\}=\\{\\text{Detroit, Houston, San Antonio, Portland, Washington, Dallas, Chicago, Oklahoma City, Toronto}\\}\\) is the event that the team has won at least one previous championship.\n\n\n\n\n\nThe expressions \\(X=x\\) or \\(\\{X=x\\}\\) are shorthand for the event that the random variable \\(X\\) takes the value \\(x\\). Remember that any event is a collection of outcomes that satisfy some criteria, a subset of the sample space. So objects like \\(\\{X=x\\}\\) are sets representing the outcomes for which the value of the random variable \\(X\\) is equal to the number \\(x\\). Remember to think of the capital letter \\(X\\) as a label standing in for a formula like “the sum of two rolls of a four-sided die” and \\(x\\) as a dummy variable standing in for a particular value like 3.\n\n\n\n\n\n\n\nExample 2.25 Roll a four-sided die twice, and record the result of each roll in sequence. Recall the sample space from Example 2.1. Let \\(X\\) be the sum of the two dice, and let \\(Y\\) be the larger of the two rolls (or the common value if both rolls are the same). Identify and interpret each of the following.\n\n\\(\\{X = 4\\}\\).\n\\(\\{X = 3\\}\\).\n\\(\\{X \\le 3\\}\\).\n\\(\\{Y = 4\\}\\).\n\\(\\{Y = 3\\}\\).\n\\(\\{Y \\le 3\\}\\).\n\\(\\{X = 4, Y = 3\\}\\) (that is, \\(\\{X = 4\\}\\cap \\{Y = 3\\}\\)).\n\\(\\{X = 4, Y \\le 3\\}\\).\n\\(\\{X = 3, Y = 3\\}\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.25. Notice we encountered many of these events in Example 2.9, but now we are denoting the events in terms of random variables.\n\n\\(\\{X = 4\\}\\), which consists of the outcomes (1, 3), (2, 2), (3, 1), is the event that the sum of the two dice is 4. Recalling Example 2.9, \\(A = \\{X = 4\\}\\).\n\\(\\{X = 3\\}\\), which consists of outcomes (1, 2) and (2, 1), is the event that the sum of the two dice is 3.\n\\(\\{X \\le 3\\}\\), which consists of outcomes (1, 1), (1, 2), and (2, 1), is the event that the sum of the two dice is at most 3. Recalling Example 2.9, \\(B = \\{X \\le 3\\}\\).\n\\(\\{Y = 4\\}=\\{(1, 4), (2, 4), (3, 4), (4, 4), (4, 1), (4, 2), (4,3)\\}\\) is the event that the larger of the two rolls is 4.\n\\(\\{Y = 3\\}=\\{(1, 3), (2, 3), (3, 3), (3, 1), (3, 2)\\}\\) is the event that the larger of the two rolls is 3. Recalling Example 2.9, \\(C = \\{Y = 3\\}\\).\n\\(\\{Y \\le 3\\}=\\{(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)\\}\\) is the event that the larger of the two rolls is at most 3. Notice that since in this example \\(Y\\) can only take values 1, 2, 3, 4, we have \\(\\{Y\\le 3\\} = \\{Y=4\\}^c\\).\n\\(\\{X = 4, Y = 3\\} \\equiv \\{X = 4\\}\\cap \\{Y = 3\\}=\\{(1, 3), (3, 1)\\}\\) is the event that both the sum of the two dice is 4 and the larger of the two rolls is 3. Even though this involves two random variables, it is a single event (that is, a single subset of the sample space). There are only two outcomes for which both the sum of the two dice is 4 and the larger of the two dice is 3.\n\\(\\{X = 4, Y \\le 3\\} \\equiv \\{X = 4\\}\\cap \\{Y \\le 3\\}=\\{(1, 3), (2, 2), (3, 1)\\}\\) is the event that both the sum of the two dice is 4 and the larger of the two rolls is at most 3. Notice that since in this example \\(\\{X=4\\} \\subset \\{Y\\le 3\\}\\), we have \\(\\{X = 4, Y \\le 3\\} = \\{X=4\\}\\). If the sum is 4 we know the larger roll must be at most 3.\n\\(\\{X = 3, Y = 3\\} \\equiv \\{X = 3\\}\\cap \\{Y = 3\\}=\\emptyset\\), since there are no outcomes for which both the sum is 3 and the larger of the two dice is 3. (If the the larger of the two dice is 3, then the sum must be at least 4.)\n\n\n\n\n\n\n\n\n\nTable 2.10: Table representing the sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die. The event \\(X = 4\\) is highlighted in orange.\n\n\n\n\n\n\nOutcome (First roll, second roll)\nX (sum)\nY (max)\n\n\n\n\n(1, 1)\n2\n1\n\n\n(1, 2)\n3\n2\n\n\n(1, 3)\n4\n3\n\n\n(1, 4)\n5\n4\n\n\n(2, 1)\n3\n2\n\n\n(2, 2)\n4\n2\n\n\n(2, 3)\n5\n3\n\n\n(2, 4)\n6\n4\n\n\n(3, 1)\n4\n3\n\n\n(3, 2)\n5\n3\n\n\n(3, 3)\n6\n3\n\n\n(3, 4)\n7\n4\n\n\n(4, 1)\n5\n4\n\n\n(4, 2)\n6\n4\n\n\n(4, 3)\n7\n4\n\n\n(4, 4)\n8\n4\n\n\n\n\n\n\n\n\nWhen dealing with probabilities, it is common to write \\(X=3\\) instead of16 \\(\\{X=3\\}\\), and \\(X = 4, Y = 3\\) instead of \\(\\{X = 4\\}\\cap \\{Y = 3\\}\\); read the comma in \\(X = 4, Y = 3\\) as “and”. But keep in mind that an expression like “\\(X=3\\)” really represents an event \\(\\{X=3\\}\\), a subset of outcomes of the sample space.\n\n\n\n\n\n\n\nExample 2.26 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. Recall the sample space from Example 2.3. Let \\(R\\) be the random variable representing Regina’s arrival time (minutes after noon), and \\(Y\\) for Cady. Interpret each of the following in words and draw a picture representing it.\n\n\\(\\{R &gt; Y\\}\\).\n\\(\\{\\min(R, Y) &lt; 30\\}\\).\n\\(\\{Y&lt;R&lt;Y+15\\}\\).\n\\(\\{R &lt; 24\\}\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.26. The parts of this problem are almost identical to those in Example 2.11. The main difference is in notation; we are now denoting events in terms of random variables.\n\nSee Figure 2.7 for pictures. \\(\\{R&gt;Y\\}\\)is the event that Regina arrives after Cady (event \\(A\\) from Example 2.11).\n\\(\\{\\min(R, Y)&lt;30\\}\\), is the event that the earlier of the two arrival times is before 12:30 (event \\(B\\) from Example 2.11). This event can also be written as \\(\\{R &lt; 30\\}\\cup \\{Y &lt; 30\\}\\), the event that either Regina or Cady arrives before 12:30.\n\\(\\{Y&lt;R&lt;Y+15\\}\\) is the event that Cady arrives first and Regina arrives at most 15 minutes after Cady (event \\(C\\) from Example 2.11).\n\\(\\{R &lt; 24\\} = \\{(\\omega_1, \\omega_2): \\omega_1&lt;24\\}\\) is the event that Regina arrives before 12:24 (event \\(D\\) from Example 2.11).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.7: Illustration of the events in Example 2.26. The square represents the possible values of \\((R, Y)\\), the random vector representing the arrival times of Regina and Cady.\n\n\n\n\n\n\n\n2.3.6 Outcomes, events, and random variables\nOutcomes, events, and random variables are some of the main objects of probability. While they are related, these are distinct objects. Thinking in terms of a spreadsheet, an outcome is a row, an event is a subset of rows, and a random variable is a column. Mathematically, an outcome is a point, an event is a set, and a random variable is a function which outputs a number. As such, different operations are valid depending on what you’re dealing with. Don’t confuse operations like \\(\\cap\\) that operate on sets (events, “and”) with operations like \\(+\\) that operate on numbers and functions (random variables, “plus” meaning addition).\n\n\n\n\n\n\n\nExample 2.27 At various points in his homework, Donny Don’t writes the following. Explain to Donny why each of the following symbols is nonsense, both mathematically and intuitively using a simple example (like tomorrow’s weather). Below, \\(A\\) and \\(B\\) represent events, \\(X\\) and \\(Y\\) represent random variables.\n\n\\(A = 0.5\\)\n\\(A + B\\)\n\\(X = A\\)\n\\(X + A\\)\n\\(X \\cap Y\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.27. We’ll respond to Donny using tomorrow’s weather as an example, with \\(A\\) representing the event that it rains tomorrow, \\(X\\) tomorrow’s high temperature (degrees F), \\(B=\\{X&gt;80\\}\\) the event that tomorrow’s high temperature is above 80 degrees, and \\(Y\\) tomorrow’s rainfall (inches).\n\n\\(A\\) is a set and 0.5 is a number; it doesn’t make mathematical sense to equate them. It doesn’t make sense to say “it rains tomorrow equals 0.5”.\n\\(A\\) and \\(B\\) are sets; it doesn’t make mathematical sense to add them. It doesn’t make sense to say “the sum of (it rains tomorrow) and (tomorrow’s high temperature is above 80 degrees F)”. If we want “(it rains tomorrow) OR (tomorrow’s high temperature is above 80 degrees F)”, then we need \\(A\\cup B\\). Union is an operation on sets; addition is an operation on numbers.\n\\(X\\) is a random variable (a function) and \\(A\\) is an event (a set), and it doesn’t make sense to equate these two different mathematical objects. It doesn’t make sense to say “tomorrow’s high temperature equals the event that it rains tomorrow”.\n\\(X\\) is a random variable (a function) and \\(A\\) is an event (a set), and it doesn’t make sense to add these two different mathematical objects. It doesn’t make sense to say “the sum of (tomorrow’s high temperature) and (the event that it rains tomorrow)”.\n\\(X\\) and \\(Y\\) are random variables (functions) and intersection is an operation on sets. \\(X \\cap Y\\) is attempting to say “tomorrow’s high temperature in degrees F and the amount of rainfall in inches tomorrow”. If we’re talking about a random vector containing these two variables, we would write \\((X, Y)\\) not \\(X \\cap Y\\). If we’re interested in an event involving \\(X\\) and \\(Y\\), we’re missing qualifying information to define a valid event. We could write \\(X &gt;80, Y &lt; 2\\) or \\(\\{X &gt; 80\\} \\cap \\{Y &lt; 2\\}\\) to represent “the event that (tomorrow’s high temperature is greater than 80 degrees F) AND (the amount of rainfall tomorrow is less than 2 inches)”.\n\n\n\n\n\n\n\n2.3.7 Exercises\n\nExercise 2.5 Consider the outcome of a sequence of 4 flips of a coin. One random variable is \\(X\\), the number of heads flipped.\n\nExplain why \\(X\\) is a random variable.\nEvaluate each of the following: \\(X(HHHH), X(HTHT), X(TTHH)\\).\nIdentify the possible values of \\(X\\). Why not let the sample space just consist of this set of possible values?\nWhat does \\(4-X\\) represent?\nWhat does \\(X/4\\) represent?\n\n\n\nExercise 2.6 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Let \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\nThe sample space consists of 27 outcomes, listed in the table below.\n\n\n\n\n111\n112\n113\n121\n122\n123\n131\n132\n133\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n211\n212\n213\n221\n222\n223\n231\n232\n233\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n311\n312\n313\n321\n322\n323\n331\n332\n333\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse the table above and evaluate \\(X\\) and \\(Y\\) for each of the outcomes.\nIdentify the possible values of \\(X\\).\nIdentify the possible values of \\(Y\\).\nIdentify the possible \\((X, Y)\\) pairs.\nIdentify and interpret \\(\\{X = 1\\}\\).\nIdentify and interpret \\(\\{X = 2\\}\\).\nIdentify and interpret \\(\\{X = 3\\}\\).\nIdentify and interpret \\(\\{Y = 0\\}\\).\nIdentify and interpret \\(\\{Y = 1\\}\\).\nIdentify and interpret \\(\\{Y = 2\\}\\).\nIdentify and interpret \\(\\{Y = 3\\}\\).\nIdentify and interpret \\(\\{X = 2, Y = 1\\}\\).\nIdentify and interpret \\(\\{X = Y\\}\\).\nLet \\(I_1\\) be the indicator random variable that prize 1 is obtained (in at least one of the three packages). Identify and intepret \\(\\{I_1 = 0\\}\\).\nLet \\(I_2\\) be the indicator random variable that prize 2 is obtained (in at least one of the three packages), and similarly \\(I_3\\) for prize 3. What is the relationship between \\(X\\) and \\(I_1, I_2, I_3\\)?\nHow can you write \\(Y\\) in terms of indicator random variables?\n\n\n\nExercise 2.7 Katniss throws a dart at a circular dartboard with radius 1 foot. (Assume that Katniss’s dart never misses the dartboard.) Let \\(X\\) be the distance (inches) from the location of the dart to the center of the dartboard.\n\nIdentify (with a picture) and interpret \\(\\{X \\le 1\\}\\)\nIdentify (with a picture) and interpret \\(\\{1 &lt; X &lt; 2\\}\\)\nIdentify (with a picture) and interpret \\(\\{X &gt; 11\\}\\)\nIdentify (with a picture) and interpret \\(\\{X = 0\\}\\)\nIdentify (with a picture) and interpret \\(\\{X = 1\\}\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-probspace",
    "href": "language-probability.html#sec-probspace",
    "title": "2  The Language of Probability",
    "section": "2.4 Probability spaces",
    "text": "2.4 Probability spaces\nIn this chapter we have defined outcomes, events, and random variables, the main mathematical objects associated with a random phenomenon. But we haven’t actually computed any probabilities yet! So far we have only been concerned with what is possible. You might have noticed that the examples often did not include any assumptions like the “die is fair”, “each object is equally likely to be put in any spot”, or “Regina is more likely to arrive late and Cady is more likely to arrive early”. Now we will start to incorporate assumptions of the random phenomenon to determine how probable various events are.\n\n2.4.1 Probability measures\nAs we saw in Section 1.3, there are some basic logical consistency requirements that probabilities must satisfy, which are formalized in three “axioms”.\n\nDefinition 2.6 A probability measure, typically denoted \\(\\textrm{P}\\), assigns probabilities to events to quantify their relative likelihoods, plausibilities, or degrees of uncertainty according to the assumptions of the model of the random phenomenon. The probability of event17 \\(A\\) is denoted \\(\\textrm{P}(A)\\).\nAny valid probability measure must satisfy the following axioms.\n\n\nFor any event \\(A\\), \\(0 \\le \\textrm{P}(A) \\le 1\\).\nIf \\(\\Omega\\) represents the sample space then \\(\\textrm{P}(\\Omega) = 1\\).\nCountable additivity. If \\(A_1, A_2, A_3, \\ldots\\) are disjoint events (recall Definition 2.3), then \\[\n\\textrm{P}(A_1 \\cup A_2 \\cup A_2 \\cup \\cdots) = \\textrm{P}(A_1) + \\textrm{P}(A_2) +\\textrm{P}(A_3) + \\cdots\n\\]\n\nAn event \\(A\\) is something that can happen or can be true; \\(\\textrm{P}(A)\\) quantifies how likely it is that \\(A\\) will happen or how plausible it is that \\(A\\) is true. Probabilities are always defined for events (sets) but remember than many events are defined in terms of random variables. For example, if \\(X\\) is tomorrow’s high temperature (degrees F) we might be interested in \\(\\textrm{P}(\\{X&gt;80\\})\\), the probability of the event that tomorrow’s high temperature is above 80 degrees F. If \\(Y\\) is the amount of rainfall tomorrow (inches) we might be interested in \\(\\textrm{P}(\\{X &gt; 80\\}\\cap \\{Y &lt; 2\\})\\), the probability of the event that tomorrow’s high temperature is above 80 degrees F and the amount of rainfall is less than 2 inches. To simplify notation, it is common to write \\(\\textrm{P}(X&gt;80)\\) instead of \\(\\textrm{P}(\\{X&gt;80\\})\\), or \\(\\textrm{P}(X &gt; 80, Y &lt; 2)\\) instead of \\(\\textrm{P}(\\{X &gt; 80\\}\\cap \\{Y &lt; 2\\})\\). Read the comma in \\(\\textrm{P}(X &gt; 80, Y &lt; 2)\\) as “and”. But keep in mind that an expression like “\\(X&gt;80\\)” really represents an event \\(\\{X&gt;80\\}\\).\nThe three axioms require that probabilities of different events must fit together in a logically coherent way.\nThe requirement \\(0\\le \\textrm{P}(A)\\le 1\\) makes sense in light of the relative frequency interpretation: an event \\(A\\) can not occur on more than 100% of repetitions or less than 0% of repetitions of the random phenomenon.\nThe requirement that \\(\\textrm{P}(\\Omega)=1\\) just ensures that the sample space accounts for all of the possible outcomes. Basically, \\(\\textrm{P}(\\Omega)=1\\) says that on any repetition of the random phenomenon, “something has to happen”. Roughly, \\(\\textrm{P}(\\Omega)=1\\) implies that all outcomes taken together need to account for 100% of the probability. If \\(\\textrm{P}(\\Omega)\\) were less than 1, then the sample space hasn’t accounted for all of the possible outcomes.\nEvent \\(A_1 \\cup A_2 \\cup \\cdots\\) is the event that \\(A_1\\) occurs OR \\(A_2\\) occurs OR… In other words, \\(A_1 \\cup A_2 \\cup \\cdots\\) is the event that at least one of the \\(A_i\\)’s occur. Countable additivity says that as long as events share no outcomes in common, then the probability that at least one of the events occurs is equal to the sum of the probabilities of the individual events. In Example 1.7, the events \\(B\\)=“the Braves win the 2023 World Series” and \\(A\\)=“the Rays win the 2023 World Series” are disjoint, \\(A\\cap B = \\emptyset\\); in a single World Series, both teams cannot win. If \\(\\textrm{P}(B) = 0.19\\) and \\(\\textrm{P}(A) = 0.16\\), then the probability of \\(A\\cup B\\), the event that either the Rays or the Braves win, must be \\(\\textrm{P}(A\\cup B)=0.29\\).\nCountable additivity can be understood through a diagram with areas representing probabilities, as in the figure below which represents two events (yellow / and blue \\). On the left, there is no “overlap” between areas so the total area is the sum of the two pieces; this depicts countable additivity for two disjoint events. On the right, there is overlap between the two areas, so simply adding the two areas “double counts” the intersection (green \\(\\times\\)) and does not result in the correct total area. Countable additivity applies to any countable number18 of events, as long as there is no “overlap”.\n\n\n\n\n\n\n\n\nFigure 2.8: Illustration of countable additivity for two events. The events in the picture on the left are disjoint, but not on the right.\n\n\n\n\n\nThe three axioms of a probability measure are simply minimal logical consistency requirements that must be satisfied by any probability model to ensure that probabilities fit together in a coherent way. There are also many physical aspects of the random phenomenon or assumptions (e.g. “fairness”, independence, conditional relationships) that must be considered when determining a reasonable probability measure for a particular situation. Sometimes \\(\\textrm{P}(A)\\) is defined explicitly for an event \\(A\\) via a formula. But it is much more common for a probability measure to be defined only implicitly through modeling assumptions; probabilities of events then follow from the axioms and related properties.\n\n\n2.4.2 Some probability measures for a four-sided die\n\n\n\n\n\n\nCaution\n\n\n\nThis section concerns a single roll of a fair four-sided die. Don’t confuse this scenario with many other examples that involve two rolls. This section also discusses all possible events (beyond just all possible outcomes). We encourage you to review Section 2.2.1 before reading this section.\n\n\nConsider a single roll of a four-sided die. The sample space consists of four possible outcomes, \\(\\Omega = \\{1, 2, 3, 4\\}\\). Events concern what might happen on a single roll. For example, if \\(A\\) is the event that we roll an odd number then \\(A = \\{1, 3\\}\\); “roll an odd number” occurs if we roll a 1 so 1 is an \\(A\\), or “roll an odd number” occurs if we roll a 3 so 3 is in \\(A\\). Table 2.6 lists the collection of all events.\n\n\n\n\n\n\nCaution\n\n\n\nWe usually think of a table as a list of all possible outcomes, with one row for each outcome. Table 2.6 and the tables in this section (Table 2.11, Table 2.12, Table 2.13) are different kinds of tables. Each row of these tables is an event, and the tables list the collection of all events.\n\n\n\n\n\n\n\n\n\nExample 2.28 Let’s first assume that the die is fair. Let \\(\\textrm{P}\\) denote the probability measure corresponding to a single roll of a fair four-sided die.\n\nWhat is the probability that a single roll lands on 1? 2? 3? 4?\nCompute the probability of each of the events in Table 2.6.\nSpecify a general formula for \\(\\textrm{P}(A)\\) for any event of interest \\(A\\) in this example.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.28. \n\nAssuming the die is fair implies that all four outcomes are equally likely, each with probability19 1/4.\nGiven the probability of each outcome20, we can find the probability of an event via countable additivity—sum the probabilities of the distinct outcomes that comprise the event. For example, if \\(A=\\{1, 3\\}\\) is the event that the die lands on an odd number, then \\[\n\\textrm{P}(A) = \\textrm{P}(\\{1, 3\\}) = \\textrm{P}(\\{1\\}\\cup \\{3\\}) = \\textrm{P}(\\{1\\}) + \\textrm{P}(\\{3\\}) = 1/4+ 1/4 = 2/4.\n\\] Table 2.11 lists all the possible events, and their probabilities according to the probability measure \\(\\textrm{P}\\).\nSince there are four equally likely outcomes, the probability of any event is \\[\n\\textrm{P}(A) = \\frac{\\text{number of outcomes that satisfy $A$}}{4}, \\qquad{\\text{$\\textrm{P}$ assumes a fair four-sided die}}\n\\]\n\n\n\n\n\n\n\n\nTable 2.11: All possible events associated with a single roll of a four-sided die, and their probabilities assuming the die is fair.\n\n\n\n\n\n\n\n\n\n\nEvent\nDescription\nProbability of event assuming a fair die\n\n\n\n\n\\(\\emptyset\\)\nRoll nothing (not possible)\n0\n\n\n\\(\\{1\\}\\)\nRoll a 1\n1/4\n\n\n\\(\\{2\\}\\)\nRoll a 2\n1/4\n\n\n\\(\\{3\\}\\)\nRoll a 3\n1/4\n\n\n\\(\\{4\\}\\)\nRoll a 4\n1/4\n\n\n\\(\\{1, 2\\}\\)\nRoll a 1 or a 2\n2/4\n\n\n\\(\\{1, 3\\}\\)\nRoll a 1 or a 3\n2/4\n\n\n\\(\\{1, 4\\}\\)\nRoll a 1 or a 4\n2/4\n\n\n\\(\\{2, 3\\}\\)\nRoll a 2 or a 3\n2/4\n\n\n\\(\\{2, 4\\}\\)\nRoll a 2 or a 4\n2/4\n\n\n\\(\\{3, 4\\}\\)\nRoll a 3 or a 4\n2/4\n\n\n\\(\\{1, 2, 3\\}\\)\nRoll a 1, 2, or 3 (a.k.a. do not roll a 4)\n3/4\n\n\n\\(\\{1, 2, 4\\}\\)\nRoll a 1, 2, or 4 (a.k.a. do not roll a 3)\n3/4\n\n\n\\(\\{1, 3, 4\\}\\)\nRoll a 1, 3, or 4 (a.k.a. do not roll a 2)\n3/4\n\n\n\\(\\{2, 3, 4\\}\\)\nRoll a 2, 3, or 4 (a.k.a. do not roll a 1)\n3/4\n\n\n\\(\\{1, 2, 3, 4\\}\\)\nRoll something\n1\n\n\n\n\n\n\nWhen outcomes are equally likely, we find the probability of an event by counting the number of outcomes that satisfy the event.\nThe probability measure \\(\\textrm{P}\\) in Example 2.28 satisfies all the axioms and so it is a valid probability measure. However, assuming that the outcomes are equally likely is a much stricter condition than the basic logical consistency requirements of the axioms. There are many other possible probability measures, like in the following.\n\n\n\n\n\n\n\nExample 2.29 Now consider a single roll of a four-sided die, but suppose the die is weighted so that the outcomes are no longer equally likely. Suppose that the probability of event \\(\\{2, 3\\}\\) is 0.5, of event \\(\\{3, 4\\}\\) is 0.7, and of event \\(\\{1, 2, 3\\}\\) is 0.6. Let \\(\\textrm{Q}\\) denote the probability measure corresponding to a single roll of this weighted four-sided die.\n\nIn what particular way is the die weighted? That is, what is the probability of each the four possible outcomes?\nComplete a table, like Table 2.11, listing the probability of each event for this particular weighted die.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.29. \n\nSince the probability of event \\(\\{1, 2, 3\\}\\)—that is, not rolling a 4—is 0.6, the probability of rolling a 4 must be21 0.4. Since the probability of rolling a 3 or 4 is 0.7 and the probability of rolling a 4 is 0.4, the probability of rolling a 3 must be 0.3. Similarly, the probability of rolling a 2 must be 0.2, and the probability of rolling a 1 must be 0.1.\nGiven the probability of each outcome we can find the probability of an event by summing the probabilities of the distinct outcomes that comprise the event. For example, the probability that a single roll of this die lands on an odd number is \\[\n\\textrm{Q}(\\{1, 3\\}) = \\textrm{Q}(\\{1\\}\\cup \\{3\\}) = \\textrm{Q}(\\{1\\}) + \\textrm{Q}(\\{3\\}) = 0.1+ 0.3 = 0.4.\n\\] We can similarly find the probabilities of all possible events for this particular weighted die, displayed in Table 2.12.\n\n\n\n\n\n\n\n\nTable 2.12: All possible events associated with a single roll of a four-sided die, and their probabilities assuming the die is weighted: roll a 1 with probability 0.1, 2 with probability 0.2, 3 with probability 0.3, 4 with probability 0.4.\n\n\n\n\n\n\n\n\n\n\nEvent\nDescription\nProbability of event assuming a particular weighted die\n\n\n\n\n\\(\\emptyset\\)\nRoll nothing (not possible)\n0\n\n\n\\(\\{1\\}\\)\nRoll a 1\n0.1\n\n\n\\(\\{2\\}\\)\nRoll a 2\n0.2\n\n\n\\(\\{3\\}\\)\nRoll a 3\n0.3\n\n\n\\(\\{4\\}\\)\nRoll a 4\n0.4\n\n\n\\(\\{1, 2\\}\\)\nRoll a 1 or a 2\n0.3\n\n\n\\(\\{1, 3\\}\\)\nRoll a 1 or a 3\n0.4\n\n\n\\(\\{1, 4\\}\\)\nRoll a 1 or a 4\n0.5\n\n\n\\(\\{2, 3\\}\\)\nRoll a 2 or a 3\n0.5\n\n\n\\(\\{2, 4\\}\\)\nRoll a 2 or a 4\n0.6\n\n\n\\(\\{3, 4\\}\\)\nRoll a 3 or a 4\n0.7\n\n\n\\(\\{1, 2, 3\\}\\)\nRoll a 1, 2, or 3 (a.k.a. do not roll a 4)\n0.6\n\n\n\\(\\{1, 2, 4\\}\\)\nRoll a 1, 2, or 4 (a.k.a. do not roll a 3)\n0.7\n\n\n\\(\\{1, 3, 4\\}\\)\nRoll a 1, 3, or 4 (a.k.a. do not roll a 2)\n0.8\n\n\n\\(\\{2, 3, 4\\}\\)\nRoll a 2, 3, or 4 (a.k.a. do not roll a 1)\n0.9\n\n\n\\(\\{1, 2, 3, 4\\}\\)\nRoll something\n1\n\n\n\n\n\n\nThe symbol \\(\\textrm{P}\\) is more than just shorthand for the word “probability”. \\(\\textrm{P}\\) denotes the underlying probability measure, which represents all the assumptions about the random phenomenon. Changing assumptions results in a change of the probability measure and a different probability model. We often consider several probability measures for the same sample space and collection of events; these several measures represent different sets of assumptions or available information and different probability models.\nThe probability measure \\(\\textrm{P}\\) in Example 2.28 corresponds to the assumption of a fair die (equally likely outcomes). With this measure \\(\\textrm{P}(A) = 2/4=0.5\\) for \\(A = \\{1, 3\\}\\). But under the probability measure \\(\\textrm{Q}\\) corresponding to the weighted die in Example 2.29, \\(\\textrm{Q}(A) = 0.4\\). The outcomes and events are the same in both scenarios, because both scenarios involve a four sided-die. What is different is the probability measure that assigns probabilities to the events. One scenario assumes the die is fair while the other assumes the die has a particular weighting, resulting in two different probability measures.\nBoth probability measures \\(\\textrm{P}\\) and \\(\\textrm{Q}\\) can be written as explicit set functions: for an event \\(A\\)\n\\[\\begin{align*}\n\\textrm{P}(A) & = \\frac{\\text{number of outcomes that satisfy $A$}}{4}, & & {\\text{a fair four-sided die}}\n\\\\\n\\textrm{Q}(A) & = \\frac{\\text{sum of elements in $A$}}{10}, & & {\\text{a specific weighted four-sided die}}\n\\end{align*}\\]\nWe provide the above descriptions to illustrate that a probability measure operates on sets. However, in many situations there does not exist a simple closed form expression for the set function defining the probability measure which maps events to probabilities.\n\n\n\n\n\n\n\nExample 2.30 Consider again a single roll of a weighted four-sided die. Suppose that\n\nRolling a 1 is twice as likely as rolling a 4\nRolling a 2 is three times as likely as rolling a 4\nRolling a 3 is 1.5 times as likely as rolling a 4\n\nLet \\(\\tilde{\\textrm{Q}}\\) be the probability measure corresponding to this die.\n\nIn what particular way is the die weighted? That is, what is the probability of each the four possible outcomes?\nCompute \\(\\tilde{\\textrm{Q}}(A)\\) for each event in Table 2.11.\nWeighting a die in a particular way might be hard to conceptualize and even harder to achieve in practice. Construct a circular spinner to represent this weighted die.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.30. \n\nLet \\(q = \\tilde{\\textrm{Q}}(\\{4\\})\\) denote the probability of rolling a 4. Then \\(\\tilde{\\textrm{Q}}(\\{1\\}) = 2q\\), \\(\\tilde{\\textrm{Q}}(\\{2\\}) = 3q\\), and \\(\\tilde{\\textrm{Q}}(\\{3\\}) = 1.5q\\). Since these probabilities must sum to 1, we have \\(2q + 3q + 1.5q + q = 1\\) so \\(q = 2/15\\). Therefore, the probability of rolling a 1 is 4/15, a 2 is 6/15, a 3 is 3/15, and a 4 is 2/15. (We could have also solved this without algebra similiar to how we solved Example 1.8.)\nGiven the probability of each outcome we can find the probability of an event by summing the probabilities of the distinct outcomes that comprise the event. For example, the probability of rolling an odd number is \\[\n\\tilde{\\textrm{Q}}(\\{1, 3\\}) = \\tilde{\\textrm{Q}}(\\{1\\}\\cup \\{3\\}) = \\tilde{\\textrm{Q}}(\\{1\\}) + \\tilde{\\textrm{Q}}(\\{3\\}) = 4/15+ 3/15 = 7/15 \\approx 0.467.\n\\]\nWe can similarly find the probabilities of all possible events for this particular weighted die, displayed in Table 2.13. Note this probability measure does not have a simple closed formula for \\(\\tilde{\\textrm{Q}}(A)\\).\nConstruct a spinner with four sectors of area 4/15, 6/15, 3/15, and 2/15 representing, respectively, the values 1, 2, 3, and 4. See Figure 2.9 (c).\n\n\n\n\n\n\n\n\nTable 2.13: All possible events associated with a single roll of a four-sided die, and their probabilities assuming the die is weighted: roll a 1 with probability 4/15, 2 with probability 6/15, 3 with probability 3/15, 4 with probability 2/15.\n\n\n\n\n\n\n\n\n\n\nEvent\nDescription\nProbability of event assuming a particular weighted die\n\n\n\n\n\\(\\emptyset\\)\nRoll nothing (not possible)\n0\n\n\n\\(\\{1\\}\\)\nRoll a 1\n4/15\n\n\n\\(\\{2\\}\\)\nRoll a 2\n6/15\n\n\n\\(\\{3\\}\\)\nRoll a 3\n3/15\n\n\n\\(\\{4\\}\\)\nRoll a 4\n2/15\n\n\n\\(\\{1, 2\\}\\)\nRoll a 1 or a 2\n10/15\n\n\n\\(\\{1, 3\\}\\)\nRoll a 1 or a 3\n7/15\n\n\n\\(\\{1, 4\\}\\)\nRoll a 1 or a 4\n6/15\n\n\n\\(\\{2, 3\\}\\)\nRoll a 2 or a 3\n9/15\n\n\n\\(\\{2, 4\\}\\)\nRoll a 2 or a 4\n8/15\n\n\n\\(\\{3, 4\\}\\)\nRoll a 3 or a 4\n5/15\n\n\n\\(\\{1, 2, 3\\}\\)\nRoll a 1, 2, or 3 (a.k.a. do not roll a 4)\n13/15\n\n\n\\(\\{1, 2, 4\\}\\)\nRoll a 1, 2, or 4 (a.k.a. do not roll a 3)\n12/15\n\n\n\\(\\{1, 3, 4\\}\\)\nRoll a 1, 3, or 4 (a.k.a. do not roll a 2)\n9/15\n\n\n\\(\\{2, 3, 4\\}\\)\nRoll a 2, 3, or 4 (a.k.a. do not roll a 1)\n11/15\n\n\n\\(\\{1, 2, 3, 4\\}\\)\nRoll something\n1\n\n\n\n\n\n\nThe die rolling example is not the most exciting or practical scenario. But the example does illustrate the idea of several probability measures, each corresponding to a different set of assumptions about the random phenomenon. If it’s difficult to imagine how to physically weight a die in these particular ways, consider the spinners (like from a kids game) in Figure 2.9).\n\n\n\n\n\n\n\n\n\n\n\n(a) A fair die\n\n\n\n\n\n\n\n\n\n\n\n(b) The weighted die of Example 2.29\n\n\n\n\n\n\n\n\n\n\n\n(c) The weighted die of Example 2.30\n\n\n\n\n\n\n\nFigure 2.9: Three possible spinners corresponding to the roll of a four-sided die.\n\n\n\n\n\n\n\n\n\n\nExample 2.31 Using the set up of this section, the event \\(A = \\{1, 3\\}\\), and the spinners from Figure 2.9,\n\nInterpret each of \\(\\textrm{P}(A) = 0.5\\), \\(\\textrm{Q}(A) = 0.4\\), and \\(\\tilde{\\textrm{Q}}(A) = 7/15\\) as a long run relative frequency.\nInterpret each of \\(\\textrm{P}(A) = 0.5\\), \\(\\textrm{Q}(A) = 0.4\\), and \\(\\tilde{\\textrm{Q}}(A) = 7/15\\) in terms of a relative degree of likelihood.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.31. \n\nUse the spinners from Figure 2.9.\n\n\\(\\textrm{P}(A) = 0.5\\): Spin the spinner on the left many times; it will land on an odd number on about 50% of spins.\n\\(\\textrm{Q}(A) = 0.4\\): Spin the spinner in the middle many times; it will land on an odd number on about 40% of spins.\n\\(\\tilde{\\textrm{Q}}(A) = 7/15\\): Spin the spinner on the right many times; it will land on an odd number on about 46.67% of spins.\n\nUse the spinners from Figure 2.9.\n\n\\(\\textrm{P}(A) = 0.5\\): The spinner on the left is equally likely to land on an odd number or an even number\n\\(\\textrm{Q}(A) = 0.4\\): The spinner in the middle is 1.5 times more likely to land on an even number than on an odd number.\n\\(\\tilde{\\textrm{Q}}(A) = 7/15\\): The spinner on the right is \\(8/7\\approx 1.14\\) times more likely to land on an even number than on an odd number.\n\n\n\n\n\n\nIt is usually reasonable to assume that dice are fair, but most real world situations are not as simple as rolling dice. Just because a situation has 16 possible outcomes doesn’t mean the outcomes have to be equally likely. For example, there might be 12 contestants on your favorite reality competition show, but that doesn’t mean that all of the 12 contestants are equally likely to win the season.\n\n\n2.4.3 Some probability measures in the meeting problem\nRecall the meeting problem. The general problem involves multiple people, but we’ll first consider the arrival time of just a single person, who we’ll call Han22.\n\n\n\n\n\n\nCaution\n\n\n\nSome of the examples in this section involve just a single person arriving, while other examples involve two people.\n\n\nSuppose that Han’s arrival time will definitely be between noon and 1:00, so that the sample space—with time measured in minutes after noon, including fractions of a minute—is \\(\\Omega = [0, 60]\\).\n\n\n\n\n\n\n\nExample 2.32 Suppose that Han arrives “uniformly at random” at a time in \\([0, 60]\\). Use your intuition to provide your best guess for each of the following probabilities.\n\nThe probability that Han arrives before 12:30.\nThe probability that Han arrives before 12:15.\nThe probability that Han arrives after 12:45.\nThe probability that Han arrives between 12:15 and 12:45.\nThe probability that Han arrives before 12:05.\nThe probability that Han arrives between 12:15 and 12:20.\nLet \\(\\textrm{P}\\) denote the corresponding probability measure. Suggest a general formula for \\(\\textrm{P}([a, b])\\), the probability that Han arrives between \\(a\\) and \\(b\\) minutes after noon for \\(0\\le a&lt;b\\le 60\\) (e.g., \\(a=15, b=20\\) for “between 12:15 and 12:20” or \\(a = 0, b=5\\) for “before 12:05”).\nFind the probability that Han’s arrival time, truncated to the nearest minute, is 0 minutes after noon; that is, find the probability that Han arrives between 12:00 and 12:01.\nContinue to find the probability that Han’s arrival time truncated23 to the nearest minute is \\(1, 2, 3, \\ldots, 59\\), and sketch a plot with arrival time (truncated minutes after noon) on the horizontal axis and probability on the vertical axis. Is the plot what you would expect for arriving “uniformly at random”?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.32. “Uniformly at random” means that in some sense Han is “equally likely” to arrive at any time between noon and 1:00.\n\n0.5. It seems that Han should be as likely to arrive before 12:30 as after.\n0.25. The time interval before 12:15 is 0.25 of the total noon to 1:00 time interval, so if he is “equally likely” to arrive at any time, the probability that he arrives in a 15 minute interval is \\(15/60 = 0.25\\).\n0.25. Similar to the previous part.\n0.5. This 30 minute interval makes up half of the total noon to 1:00 time interval.\n\\(1/12 = 0.083\\). The time interval before 12:05 is \\(5/60=1/12\\) of the total noon to 1:00 time interval, so if he is “equally likely” to arrive at any time, the probability that he arrives in a 5 minute interval is \\(5/60 = 1/12=0.083\\).\n1/12, similar to the previous part.\nIt seems reasonable that if Han arrives uniformly at random within the 60 minute time interval, the probability that he arrives within any time interval \\([a, b]\\) (in \\([0, 60]\\)) is \\(\\textrm{P}([a, b]) = (b-a)/60\\), the length of the time interval of interest divided by the length of the total time interval.\nThe probability that Han arrives in the one minute interval between 12:00 and 12:01 is \\(1/60\\approx 0.0167\\).\nThe probability that Han arrives in any one minute interval is \\(1/60\\approx 0.0167\\). See Figure 2.10.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.10: Probability of Han arriving at each minute between noon (0) and 1:00 (60), truncated to the nearest minute, for the uniform probability measure in Example 2.32).\n\n\n\n\n\nExample 2.28 illustrated that for a finite sample space with equally likely outcomes, computing the probability of an event reduces to counting the number of outcomes that satisfy the event and dividing by the total number of possible outcomes. The continuous analog of equally likely outcomes is a uniform probability measure. When the sample space is uncountable, size is measured continuously (length, area, volume) rather that discretely (counting).\n\\[\n\\textrm{P}(A) = \\frac{\\text{size of } A}{\\text{size of } \\Omega} \\qquad \\text{if $\\textrm{P}$ is a uniform probability measure}\n\\]\nThe uniform probability measure in Example 2.32 is just one probability measure for Han’s arrival, reflecting an assumption that Han is “equally likely” to arrive at any time between noon and 1:00. Now we’ll model Han’s arrival time with a non-uniform probability measure which reflects that he is more likely to arrive near certain times than others.\n\n\n\n\n\n\n\nExample 2.33 Assume that the probability that Han arrives between \\(a\\) and \\(b\\) minutes after noon is \\((b/60)^2 - (a/60)^2\\) (for \\(0\\le a&lt;b\\le 60\\)) . Let \\(\\textrm{Q}\\) denote the corresponding probability measure; notice that \\(\\textrm{Q}([0, 60]) = (60/60)^2 - (0/60)^2 = 1\\). (We will see where such a probability measure might come from later. For now, we’ll just use it to compute probabilities and observe that it is a non-uniform measure.) Compute the following probabilities and compare your answers to the corresponding parts from Example 2.32.\n\nThe probability that Han arrives before 12:30.\nThe probability that Han arrives before 12:15.\nThe probability that Han arrives after 12:45.\nThe probability that Han arrives between 12:15 and 12:45.\nFind the probability Han’s arrival time, truncated to the nearest minute, is 0 minutes after noon; that is, find the probability that Han arrives between 12:00 and 12:01.\nContinue to find the probability that Han’s arrival time truncated to the nearest minute is \\(1, 2, 3, \\ldots, 59\\), and sketch a plot with arrival time (truncated minutes after noon) on the horizontal axis and probability on the vertical axis. What assumptions about Han’s arrival time does this probability measure reflect?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.33. \n\nThe probability Han arrives before 12:30 is \\(\\textrm{Q}([0, 30]) = (30/60)^2 - (0/60)^2 =0.5^2 =0.25\\). Han is 3 times more likely to arrive after 12:30 than before 12:30. (Han is now less likely to arrive before 12:30 than in the uniform case.)\nThe probability Han arrives before 12:15 is \\(\\textrm{Q}([0, 15)) = (15/60)^2 - (0/60)^2 =0.25^2 = 0.0625\\); \\(\\textrm{Q}([0, 15)) = 0.0625\\). Han is 15 times more likely to arrive after 12:15 than before 12:15. (Han is now less likely to arrive within 15 minutes of noon than in the uniform case.)\nThe probability Han arrives before 12:45 is \\(\\textrm{Q}([0, 45)) = (45/60)^2 - (0/60)^2 =0.75^2 = 0.5625\\). Therefore, the probability that Hans arrives after 12:45 is \\(\\textrm{Q}([45, 60]) = 1 - 0.5625 = 0.4375\\). Han is 7 times more likely to arrive within 15 minutes of 1:00 than within 15 minutes of noon. (Han is now more likely to arrive with 15 minutes of 1:00 than in the uniform case.)\nThe probability that Han arrives between 12:15 and 12:45 is \\(\\textrm{Q}((15, 45)) = (45/60)^2-(15/60)^2 = 0.5\\). (This probability happens to be the same as in the uniform case.)\n\\(\\textrm{Q}([0, 1]) = (1/60)^2 - (0/60)^2 = 1/3600 = 0.000278\\) is the probability that Han arrives within 1 minute of noon. (This probability is less than what it was in the uniform case.)\nContinue as in the previous part. For example, \\(\\textrm{Q}([1, 2]) = (2/60)^2 - (1/60)^2 = 3/3600 = 0.000833\\) is the probability that Han arrives between 12:01 and 12:02; \\(\\textrm{Q}([2, 3]) = (3/60)^2 - (2/60)^2 = 5/3600 = 0.000833\\) is the probability that Han arrives between 12:01 and 12:02; \\(\\textrm{Q}([59, 60]) = (60/60)^2 - (59/60)^2 = 119/3600 = 0.033\\) is the probability that Han arrives within 1 minute of 1:00. In general, \\(\\textrm{Q}([a, a+1]) = ((a+1)/60)^2 - (a/60)^2 = (2a+1)/3600\\) for \\(a = 0, 1, \\ldots, 59\\). See Figure 2.10. This probability measure assumes that Han is more likely to arrive closer to 1:00 than to noon.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.11: Probability of Han arriving at each minute between noon (0) and 1:00 (60), truncated to the nearest minute, for a uniform probability measure (blue) and the probability measure in Example 2.33 (orange).\n\n\n\n\n\nThe probability measure in Example 2.33 is a non-uniform measure. Han is much more likely to arrive between 12:45 and 1:00 than between 12:00 and 12:15, even though both these intervals have the same length.\n\n\n\n\n\n\nWarning\n\n\n\nBe careful when reading Figure 2.11! For example, the probability that the arrival time truncated to the nearest minute is 0 is 1/60 for the uniform measure in Example 2.32 and 1/3600 for the non-uniform measure in Example 2.33; these probabilities represent the probability that Han arrives within one minute of noon rather than the probability that Han arrives exactly at noon. Likewise, the probability that the arrival time truncated to the nearest minute is 59 is 0.0167 = 60/3600 for the uniform measure in Example 2.32 and 0.033 = 119/3600 for the non-uniform measure in Example 2.33; these probabilities represent the probability that Han arrives within one minute of 1:00 rather than the probability that Han arrives exactly at 1:00. All of the dots in Figure 2.11 correspond to one-minute intervals, not exact time points.\n\n\n\n\n\n\n\n\n\nExample 2.34 Continuing with the uniform probability measure of Example 2.32.\n\nFind the probability that Han arrives between 12:00 and 12:01, within 1 minute after noon.\nFind the probability that Han arrives between 12:00:00 and 12:00:01, within 1 second after noon.\nFind the probability that Han arrives between 12:00:00.000 and 12:01:00.001, within 1 millisecond after noon.\nFind the probability that Han arrives at the exact time 12:00:00.00000… (with infinite precision).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.34. For the uniform probability measure, the probability of arriving in any interval is the length of the time interval divided by the length of the total interval. With time measured in minutes, a one minute interval has length 1, a one second interval has length \\(1/60\\), and a one millisecond interval has length \\(1/60000\\).\n\n\\(1/60 = 0.0167\\) is Han’s probability of arriving in this 1 minute interval.\n\\((1/60)/60 = 0.000278\\) is Han’s probability of arriving in this 1 second interval.\n\\((1/60000)/60 = 0.000000278\\) is Han’s probability of arriving in this 1 millisecond interval\nThe exact time 12:00:00.0000 represents a single point the sample space, an interval of length 0. The probability that Han arrives at the exact time 12:00:00000 (with infinite precision) is 0; \\(\\textrm{P}(\\{0\\}) = 0\\).\n\n\n\n\n\nThe last part in Example 2.34 might seem counterintuitive at first. There was nothing special about 12:00; pick any precise time in the continuous interval from noon to 1:00, and the probability that Han arrives at that exact time, with infinite precision, is 0. This idea can be understood as a limit. The probability that Han arrives within one minute of the specified time is small, within one second of the specified time is even smaller, within one millisecond of the specified time is even smaller still; with infinite precision these time increments can get smaller and smaller indefinitely. Of course, infinite precision is not practical, but assuming the possible arrival times are represented by a continuous interval provides a reasonable mathematical model. Even though any particular time has probability 0 of being the precise arrival time, intervals of time still have positive probability of containing the arrival time. When we ask a question like “what is the probability that Han arrives at noon”, “at noon” really means “within 1 minute of noon” or “within 1 second of noon” or within whatever degree of precision is good enough for our practical purposes, and such intervals have non-zero probability.\n\n\n\n\n\n\n\nExample 2.35 Continuing with the non-uniform probability measure of Example 2.33.\n\nFind the probability that Han arrives between 12:00 and 12:01, within 1 minute after noon.\nFind the probability that Han arrives between 12:00:00 and 12:00:01, within 1 second after noon.\nFind the probability that Han arrives between 12:00:00.000 and 12:01:00.001, within 1 millisecond after noon.\nFind the probability that Han arrives at the exact time 12:00:00.00000… (with infinite precision).\nFind the probability that Han arrives between 12:59 and 1:00, within 1 minute before 1:00.\nFind the probability that Han arrives between 12:59:59 and 1:00:00, within 1 second before 1:00.\nFind the probability that Han arrives between 12:59:59.999 and 1:00:00.000, within 1 millisecond before 1:00.\nFind the probability that Han arrives at the exact time 1:00:00.00000… (with infinite precision).\nWhich is more likely: that Han arrives “at noon” or “at 1:00”? Explain.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.35. With time measured in minutes, one minute is 1, one second is \\(1/60\\), and one millisecond is \\(1/60000\\).\n\n\\((1/60)^2 - 0 = 0.000278\\) is Han’s probability of arriving within 1 minute of noon.\n\\(((1/60)/60)^2 - 0 = 0.000000077\\) is Han’s probability of arriving within 1 second of noon.\n\\(((1/60000)/60)^2 - 0= 0.000000000000077\\) is Han’s probability of arriving within 1 millisecond of noon.\nThe exact time 12:00:00.0000 represents a single point the sample space, an interval of length 0. The probability that Han arrives at the exact time 12:00:00000 (with infinite precision) is 0; \\(\\textrm{Q}(\\{0\\}) = 0\\).\n\\(1-((60 - 1)/60)^2 = 0.033\\) is Han’s probability of arriving within 1 minute of 1:00.\n\\(1-((60 - 1/60)/60)^2  = 0.00055\\) is Han’s probability of arriving within 1 second of 1:00.\n\\(1-((60 - 1/60000)/60)^2  = 0.00000055\\) is Han’s probability of arriving within 1 millisecond of 1:00.\nThe exact time 1:00:00.0000 represents a single point the sample space, an interval of length 0. The probability that Han arrives at the exact time 1:00:00000 (with infinite precision) is 0; \\(\\textrm{Q}(\\{60\\}) = 0\\).\nThe probabilities of arriving precisely at noon or 1:00 are both 0. However, the probability of arriving “close to” 1:00 is greater than the probability of arriving “close to” noon, regardless of how “close to” is defined (within 1 minute, within 1 second, etc). In practice, “at” is probably best interpreted as “close to”, and in this sense Han is more likely to arrive “at 1:00” than “at noon”.\n\n\n\n\n\nContinuous sample spaces introduce some complications that we didn’t encounter when dealing with discrete sample spaces. For a continuous sample space, the probability of any particular outcome24 is 0. However, Example 2.35 illustrates that in some sense certain outcomes can be more likely than others; Han is more likely to arrive close to 1:00 than close to noon. For continuous sample spaces it makes more sense to consider “close to” probabilities rather than “equals to” probabilities. We will investigate related ideas in much more detail as we go.\nNow we’ll return to the two-person (Regina, Cady) meeting problem from Example 2.3, with sample space depicted in Figure 2.2. We will use pictures to represent a few probability measures corresponding to different assumptions about the arrival times. In the pictures below, lighter colors represent regions of outcomes that are more likely; darker colors, less likely.\nFigure 2.12 corresponds to a uniform probability measure under which all outcomes are “equally likely”. This probability measure would be appropriate if we assume that Regina and Cady each arrive at a time uniformly at random between noon and 1, independently of each other.\n\n\n\n\n\n\n\n\nFigure 2.12: A uniform probability measure in the (Regina, Cady) meeting problem.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.36 Assume the uniform probability measure \\(\\textrm{P}\\) represented by Figure 2.12. Hint: when finding probabilities below, recall Example 2.11 and Figure 2.13.\n\nFind the probability that Regina arrives after Cady.\nFind the probability that either Regina or Cady arrives before 12:30.\nFind the probability that Cady arrives first and Regina arrives at most 15 minutes after Cady.\nFind the probability that Regina arrives before 12:24.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.36. For a uniform probability measure, the probability of an event is the size of the event divided by the size of the sample space. Since the sample space is \\([0, 60]\\times[0, 60]\\), a continuous two-dimensional region, size is measured by area. The sample space has area 3600.\nSee Figure 2.13 for pictures of the events of interest.\n\nThe triangular region corresponding to the event that Regina arrives after Cady has area 3600/2 = 1800. So the probability that Regina arrives after Cady is \\(1800/3600=0.5\\).\nThe L-shaped region corresponding to the event that Regina or Cady arrives before 12:30 has area \\((0.75)(3600)\\), so the probability is 0.75.\nThe trapezoidal region corresponding to the event that that Regina arrives at most 15 minutes after Cady (and Cady arrives first) has area \\((7/32)(3600) = (0.21875)(3600)\\). (It’s easiest to find the area of the two unshaded triangles and subtract from the total area of 3600: \\(3600 - 0.5(3600) - (3600)(1-0.25)^2/2=7/32(3600)\\).) So the probability that Regina arrives at most 15 minutes after Cady (and Cady arrives first) is 0.21875.\nThe rectangular region corresponding to the event that that Regina arrives before 12:24 has area (0.4)(3600), so the probability is 0.4.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.13: Illustration of the events in Exercise Example 2.36. The square represents the sample space. With a uniform probability measure, the areas of the shaded regions relative to the whole represent their probabilities.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2.37 Continuing Example 2.36\n\nFind the probability that Cady arrives first and Regina arrives at most 1 minute after Cady.\nFind the probability that Cady arrives first and Regina arrives at most 1 second after Cady.\nFind the probability that Cady arrives first and Regina arrives at most 1 millisecond after Cady.\nFind the probability that Regina and Cady arrive at exactly the same time, with infinite precision.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.37. \n\nSimilar to part 3 of Example 2.36, the probability that Regina arrives at most 1 minute after Cady (and Cady arrives first) is \\(1 - 0.5 - (1-1/60)^2/2=0.0165\\).\nThe probability that Regina arrives at most 1 second after Cady (and Cady arrives first) is \\(1 - 0.5 - (1-1/3600)^2/2=0.000278\\).\nThe probability that Regina arrives at most 1 millisecond after Cady (and Cady arrives first) is \\(1 - 0.5 - (1-1/3600000)^2/2=0.000000278\\).\nThe event that Regina and Cady arrive at exactly the same time, with infinite precision, corresponds to the “Regina = Cady” line segment. The area of this line segment is 0, so the probability that Regina and Cady arrive at exactly the same time, with infinite precision, is 0.\n\n\n\n\n\nExample 2.37 and Example 2.34 illustrate similar ideas. Regardless of the precise time in the continuous interval \\([0, 60]\\) at which Regina arrives, the probability that Cady arrives at that exact time, with infinite precision, is 0. In practice, if we’re interested in “the probability that Regina at Cady arrive at the same time”, we really mean “close enough to the same time”, where “close enough” could be within one minute or one second or whatever degree of precision is good enough for practical purposes.\nMost random phenomenon do not involve equally likely outcomes or uniform probability measures. Even when the underlying outcomes are equally likely, the values of related random variables are usually not. Therefore, most interesting probability problems involve “non-uniform” probability measures.\nFigure 2.14 corresponds to one non-uniform probability measure for the two-person meeting problem; certain outcomes are more likely than others. (Lighter colors represent regions of outcomes that are more likely; darker colors, less likely.) Such a probability measure would be appropriate if we assume that Regina and Cady each are more likely to arrive around 12:30 than noon or 1:00, independently of each other. Switching from the uniform probability measure represented by Figure 2.12 to the non-uniform one represented by Figure 2.14 would change the probability of the events in Example 2.36 and Example 2.37. (We’ll see how to compute probabilities for non-uniform measures later.)\n\n\n\n\n\n\n\n\nFigure 2.14: A non-uniform probability measure in the two person meeting problem. Lighter colors represent regions of outcomes that are more likely; darker colors, less likely.\n\n\n\n\n\nFigure 2.15 corresponds to another “non-uniform” probability measure. Such a probability measure would be appropriate if we assume that Regina and Cady each are more likely to arrive around 12:30 than noon or 1:00, but they coordinate their arrivals so they are more likely to arrive around the same time.\n\n\n\n\n\n\n\n\nFigure 2.15: Another non-uniform probability measure in the two person meeting problem. Lighter colors represent regions of outcomes that are more likely; darker colors, less likely. Notice how the probability is concentrated along the \\(R=Y\\) line\n\n\n\n\n\nThere are many other probability measures for the meeting problem, representing different sets of assumptions. Each probability measure assigns a probability to events like “Cady arrives first”, “both arrive before 12:20”, and “the first person to arrive has to wait less than 15 minutes for the second to arrive”, and these probabilities can differ between models.\n\n\n2.4.4 Some properties of probability measures\nMany other properties follow from the axioms, some of which we state below. Don’t let notation or names like the “complement rule” confuse you. We have already successfully used all of the properties below intuitively when working with two-way tables. All that is new in this section is mathematical formalism. Yes, getting comfortable with proper notation is part of learning the language of probability. But don’t let formality get in the way of your intuition. Continue to use the ideas from Chapter 1, including tools like two-way tables.\nThe main “meat” of the axioms is countable additivity. Thus, the key to many proofs of probability properties is to express relevant events in terms of unions of disjoint events. (Proof are included in the footnotes.)\n\nLemma 2.2 (Complement rule) For any event25 \\(A\\), \\(\\textrm{P}(A^c) = 1 - \\textrm{P}(A)\\).\n\nThe complement rule follows from the fact that an event either happens or it doesn’t. We’ll see that it is sometimes more convenient to compute directly the probability that an event does not happen and then use the complement rule. Subtracting a computed probability from 1 seems like a small computational step, but it’s an important one. If you’re taking a test, a 0.9 probability of getting a question correct is much different than a 0.1 probability. Unfortunately, the complement rule step is often overlooked when doing probability calculations. It’s a good idea to ask yourself if the probability you are computing should be greater than or less than 0.5. If your computed value seems to be on the wrong side of 0.5, check your calculations to see if you have forgotten (or misapplied) the complement rule.\n\nLemma 2.3 (Subset rule) If \\(A \\subseteq B\\) then26 \\(\\textrm{P}(A) \\le \\textrm{P}(B)\\).\n\nThe subset rule says that if every outcome that satisfies event \\(A\\) also satisfies event \\(B\\) then the probability of event \\(B\\) must be at least as large as the probability of event \\(A\\). We saw an application of the subset rule in Example 1.9.\n\nLemma 2.4 (Addition rule for two events) If \\(A\\) and \\(B\\) are any two events then27\n\n\\[\\begin{align*}\n    \\textrm{P}(A\\cup B) = \\textrm{P}(A) + \\textrm{P}(B) - \\textrm{P}(A \\cap B)\n\\end{align*}\\]\n\n\n\n\n\n\n\nExample 2.38 Donny Don’t says: “Wait a minute. You said unions are inclusive; \\(\\textrm{P}(A\\cup B)\\) means the probability of \\(A\\) or \\(B\\) OR BOTH. So \\(\\textrm{P}(A\\cup B)\\) should just be \\(\\textrm{P}(A)+\\textrm{P}(B)\\).” Explain to Donny his mistake, using the picture on the right in Figure 2.8 as an example.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.38. \\(A\\cup B\\) is inclusive so we do want to count the possibility of both, \\(A\\cap B\\). The problem with simply adding \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) is that their sum double counts \\(A \\cap B\\). We do want to count the outcomes that satisfy both \\(A\\) and \\(B\\), but we only want to count them once. Subtracting \\(\\textrm{P}(A \\cap B)\\) in the general addition rule for two events corrects for the double counting.\nFor example, consider the picture on the right in Figure 2.8. Suppose each rectangular cell represents a distinct outcome; there are 16 outcomes in total. Assume the outcomes are equally likely, each with probability \\(1/16\\). Let \\(A\\) represent the yellow / event which has probability \\(4/16\\) and let \\(B\\) represent the blue \\ event which has probability 4/16. (Remember, green represents outcomes that satisfy both blue and yellow.) Then \\(\\textrm{P}(A\\cup B) = 6/16\\), since there are 6 outcomes which satisfy either event \\(A\\) or \\(B\\) (or both). However, simply adding \\(\\textrm{P}(A)+\\textrm{P}(B)\\) yields \\(8/16\\) because the two outcomes that satisfy the green event \\(A\\cap B\\) are counted both in \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\). So to correct for this double counting, we subtract out \\(\\textrm{P}(A\\cap B)\\): \\[\n\\textrm{P}(A)+\\textrm{P}(B)-\\textrm{P}(A\\cap B) = 4/16 + 4/16 -2/16 = 6/16 = \\textrm{P}(A\\cup B)\n\\]\n\n\n\n\nThe addition rule for more than two events is complicated28 (unless the events are disjoint). For example, the addition rule for three events is \\[\\begin{align*}\n    \\textrm{P}(A\\cup B\\cup C) & = \\textrm{P}(A) + \\textrm{P}(B) + \\textrm{P}(C)\\\\\n    & \\qquad - \\textrm{P}(A\\cap B) - \\textrm{P}(A \\cap C) - \\textrm{P}(B \\cap C)\\\\\n    & \\qquad + \\textrm{P}(A \\cap B \\cap C).\n\\end{align*}\\]\nMany problems involve finding the “probability of at least one…” On the surface such problems involve unions (“at least one of events \\(A_1, A_2, \\ldots\\) occur if event \\(A_1\\) occurs OR event \\(A_2\\) occurs OR…”) Since the general addition rule for multiple events is complicated, unless the events are disjoint it is usually more convenient to use the complement rule and compute “the probability of at least one…” as one minus “the probability of none…” The “probability of none…” involves intersections (“none of the events \\(A_1, A_2, \\ldots\\) occur if event \\(A_1\\) does not occur AND event \\(A_2\\) does not occur AND…”). We will see more about probabilities of intersections later.\n\nLemma 2.5 (Law of total probability) If \\(C_1, C_2, C_3\\ldots\\) are disjoint events with \\(C_1\\cup C_2 \\cup C_3\\cup \\cdots =\\Omega\\), then29\n\n\\[\\begin{align*}\n    \\textrm{P}(A) & = \\textrm{P}(A \\cap C_1) + \\textrm{P}(A \\cap C_2) + \\textrm{P}(A \\cap C_3) + \\cdots\n\\end{align*}\\]\nSince \\(C\\) and \\(C^c\\) are disjoint with \\(C \\cup C^c = \\Omega\\), a special case is\n\\[\\begin{align*}\n    \\textrm{P}(A) & = \\textrm{P}(A \\cap C) + \\textrm{P}(A \\cap C^c)\n\\end{align*}\\]\nIn the law of total probability the events \\(C_1, C_2, C_3, \\ldots\\), which represent “cases”, form a partition of the sample space; each outcome in the sample space satisfies exactly one of the cases \\(C_i\\). The law of total probability says that we can compute the “overall” probability \\(\\textrm{P}(A)\\) by breaking \\(A\\) down into pieces and then summing the case-by-case probabilities \\(\\textrm{P}(A\\cap C_i)\\). We use the law of total probability intuitively when we sum across rows and columns in two-way tables. (Later we will see a different and more useful expression of the law of total probability, involving conditional probabilities.)\nThe following example is one we have basically covered before, Example 1.15, but now we use mathematical notation and properties. However, the ideas are the same as we discussed in Example 1.15.\nThe following example involves randomly selecting a U.S. household. Note that while “randomly select” is commonly used terminology, it is not the best wording. Remember that “random” simply means uncertain, so technically “randomly select” just means selecting in a way that the outcome is uncertain. Suppose I want to “randomly select” one of two households, A or B. I could put 10 tickets in a hat, with 9 labeled A and 1 labeled B, and then draw a ticket; this is random selection because the outcome of the draw is uncertain. However, what is often meant by “randomly select” is selecting in a way that each outcome is equally likely. To give households A and B the same chance of being selected, I would put a single ticket for each in the hat. Randomly selecting in a way that each outcome is equally likely could be described more precisely as “selecting uniformly at random”. (We will discuss equally likely outcomes in more detail later.)\n\n\n\n\n\n\n\nExample 2.39 Recall Example 1.15. Suppose that the probability that a randomly selected U.S. household has a pet dog is 0.47, and that the probability that a randomly selected U.S. household has a pet cat is 0.25.\n\nDefine the sample space and two events of interest in words.\nRepresent these probabilities using proper notation.\nDonny Don’t says: “the probability that a randomly selected U.S. household has a pet dog OR a pet cat is \\(0.47 + 0.25=0.72\\).” Do you agree? What must be true for Donny to be correct? Explain.\nWhat is the largest possible value of the probability that a randomly selected U.S. household has a pet dog OR a pet cat? Describe the (unrealistic) situation in which this extreme case would occur.\nWhat is the smallest possible value of the probability that a randomly selected U.S. household has a pet dog OR a pet cat? Describe the (unrealistic) situation in which this extreme case would occur.\nDonny Don’t says: “I remember hearing once that in probability OR means add and AND means multiply. So the probability that a randomly selected U.S. household has a pet dog AND a pet cat is \\(0.47 \\times 0.25=0.1175\\).” Do you agree? Explain.\nSuppose that the probability that a randomly selected U.S. household has a pet dog AND a pet cat is \\(0.14\\). Compute the probability that a randomly selected U.S. household has a pet dog OR a pet cat.\nCompute and interpret \\(\\textrm{P}(C \\cap D^c)\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.39. \n\nThe sample space consists of U.S. households. Let \\(C\\) be the event that the household has a pet cat, and let \\(D\\) be the event that the household has a pet dog.\nLet \\(\\textrm{P}\\) be the probability measure corresponding to randomly selecting a U.S. household. The probability measure corresponds to however the random selection is done; though not specified, it’s assumed to be uniformly at random. Then \\(\\textrm{P}(C) = 0.25\\) and \\(\\textrm{P}(D) = 0.47\\).\nDonny would only be correct if the events \\(C\\) and \\(D\\) were disjoint, which would only be true if no households had both a pet cat and a pet dog. This is an unrealistic scenario so \\(\\textrm{P}(C \\cup D)\\) is less than 0.72.\nUsing the addition rule, \\(\\textrm{P}(C \\cup D) = \\textrm{P}(C) + \\textrm{P}(D) - \\textrm{P}(C \\cap D) = 0.25 + 0.47 - \\textrm{P}(C\\cap D).\\) So \\(\\textrm{P}(C\\cup D)\\) is the largest it can be when \\(\\textrm{P}(C \\cap D)\\) is the smallest it can be. The smallest \\(\\textrm{P}(C \\cap D)\\) can possibly30 be is 0, and hence the largest \\(\\textrm{P}(C\\cup D)\\) can be is 0.72, which would only be true if no households had both a pet cat and a pet dog.\n\\(\\textrm{P}(C \\cup D) = \\textrm{P}(C) + \\textrm{P}(D) - \\textrm{P}(C \\cap D) = 0.25 + 0.47 - \\textrm{P}(C\\cap D)\\). \\(\\textrm{P}(C\\cup D)\\) is the smallest it can be when \\(\\textrm{P}(C \\cap D)\\) is the largest it can be. The probability that the household has both a pet cat and a pet dog can not be larger than either of the two component probabilities; that is, by the subset rule, \\(\\textrm{P}(C\\cap D)\\le \\textrm{P}(C) = 0.25\\) and \\(\\textrm{P}(C\\cap D)\\le \\textrm{P}(D) = 0.47\\). The largest \\(\\textrm{P}(C \\cap D)\\) can be is 0.25, and hence the smallest \\(\\textrm{P}(C\\cup D)\\) can be is 0.47, which would only be true if every household that has a pet cat also has a pet dog.\nTell Donny to check the axioms of probability. There is no requirement that the probability of an intersection must be the product of the probabilities. The two previous parts show that \\(0\\le \\textrm{P}(C \\cap D) \\le 0.25\\), but without further information we can’t determine the value of \\(\\textrm{P}(C\\cap D)\\). We discussed this idea in Example 1.15, and we will explore probabilities of intersections in more detail later.\n\\(\\textrm{P}(C \\cup D) = \\textrm{P}(C) + \\textrm{P}(D) - \\textrm{P}(C \\cap D) = 0.25 + 0.47 - 0.14 = 0.58.\\) Notice that this is between the logical extremes of 0.47 and 0.72. Also notice that the actual \\(\\textrm{P}(C \\cap D)\\) is between the logical extremes of 0 and 0.25, but it is not equal to the product of 0.25 and 0.47. The moral is that we are not able to compute probabilities involving both events (\\(\\textrm{P}(C\\cup D)\\), \\(\\textrm{P}(C^c \\cap D\\))) based on the probability of each event alone.\nThe law of total probability implies that \\(\\textrm{P}(D) = \\textrm{P}(D \\cap C) + \\textrm{P}(D \\cap C^c)\\) so \\(\\textrm{P}(D \\cap C^c) = \\textrm{P}(D) - \\textrm{P}(D \\cap C) = 0.47 - 0.14 = 0.33\\). This might look complicated, but all it says is that we can add across and down in the two-way table. A household either has a cat or not (the two cases, \\(C, C^c\\)); if 14% of households have both a dog and a cat and 33% of households have a dog but no cat, then 47% of households have a dog.\n\n\n\n\n\nProbabilities involving multiple events, such as \\(\\textrm{P}(A \\cap B)\\) or \\(\\textrm{P}(X&gt;80, Y&lt;2)\\), are often called joint probabilities. Note that the axioms do not specify any direct requirements on probabilities of intersections. In particular, is not necessarily true that \\(\\textrm{P}(A\\cap B)\\) equals \\(\\textrm{P}(A)\\textrm{P}(B)\\). It is true that probabilities of intersections can be obtained by multiplying, but the product generally involves at least one conditional probability that reflects any association between the events involved. In general, joint probabilities (\\(\\textrm{P}(A \\cap B)\\)) can not be computed based on the individual probabilities (\\(\\textrm{P}(A)\\), \\(\\textrm{P}(B)\\)) alone. We will explore this topic in more depth later.\n\n\n2.4.5 Probability models\nA probability model (or probability space) puts all the objects we have seen so far in this chapter together in a model for the random phenomenon. Think of a probability model31 as the collection of all outcomes, events, and random variables associated with a random phenomenon along with the probabilities of all events of interest (and distributions of random variables) under the assumptions of the model.\nThere will be many probability measures that satisfy the logical consistency requirements of the probability axioms. Which one is most appropriate depends on the assumptions about the random phenomenon. We will study a variety of commonly used probability models throughout the book.\nPerhaps the concept of multiple potential probability measures is easier to understand in a subjective probability situation. For example, each model that is used to forecast the 2024-2025 NFL season corresponds to a probability measure which assigns probabilities to events like “the Eagles win the 2025 Superbowl”. Different sets of assumptions and models can assign different probabilities for the same events. As another example, the weather forecaster on one local news station might report that the probability of rain tomorrow is 0.6, while an online source might report it as 0.5. Each weather forecasting model corresponds to a different probability measure which encodes a set of assumptions about the random phenomenon.\nBefore moving on, we want to reiterate: Most random phenomenon do not involve equally likely outcomes or uniform probability measures. Even when the underlying outcomes are equally likely, the values of related random variables are usually not. Equally like outcomes or uniform probability measures are the simplest probability measures, and therefore are the ones we typically encounter first. But don’t let that fool you; most interesting probability problems involve non-equally likely outcomes or non-uniform probability measures.\nIt’s easy to get confused between things like events, random variables, and probabilities, and the symbols that represent them. But a strong understanding of these fundamental concepts will help you solve probability problems. Examples like the following do more than encourage proper use of notation. Explaining to Donny why he is wrong will help you better understand the objects that symbols represent, how they are different from one another, and how they connect to real-world contexts.\n\n\n\n\n\n\n\nExample 2.40 At various points in his homework, Donny Don’t writes the following. Explain to Donny why each of the following symbols is nonsense, both mathematically and intuitively using a simple example (like tomorrow’s weather). Try to guess what Donny intends to say, and help him write it properly. Below, \\(A\\) and \\(B\\) represent events, \\(X\\) and \\(Y\\) represent random variables.\n\n\\(\\textrm{P}(A = 0.5)\\)\n\\(\\textrm{P}(A + B)\\)\n\\(\\textrm{P}(A) \\cup \\textrm{P}(B)\\)\n\\(\\textrm{P}(X)\\)\n\\(\\textrm{P}(X = A)\\)\n\\(\\textrm{P}(X \\cap Y)\\)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.40. We’ll respond to Donny using tomorrow’s weather as an example, with \\(A\\) representing the event that it rains tomorrow, \\(X\\) tomorrow’s high temperature (degrees F), \\(B=\\{X&gt;80\\}\\) the event that tomorrow’s high temperature is above 80 degrees, and \\(Y\\) tomorrow’s rainfall (inches).\n\n\\(A\\) is a set and 0.5 is a number; it doesn’t make mathematical sense to equate them. It doesn’t make sense to say “it rains tomorrow equals 0.5”. Donny probably means “the probability that it rains tomorrow equals 0.5” which he should write as \\(\\textrm{P}(A) = 0.5\\).\n\\(A\\) and \\(B\\) are sets; it doesn’t make mathematical sense to add them. The symbol \\(A + B\\) would represent “it rains tomorrow plus tomorrow’s high temperature is above 80 degrees F,” where “plus” literally means addition. Donny might mean “the probability that (it rains tomorrow) or (tomorrow’s high temperature is above 80 degrees),” which he should write as \\(\\textrm{P}(A \\cup B)\\). Donny might have meant to write \\(\\textrm{P}(A) + \\textrm{P}(B)\\), which is valid expression since \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) are numbers. However, he should keep in mind that \\(\\textrm{P}(A) + \\textrm{P}(B)\\) is not necessarily a probability of anything; this sum could even be greater than one. In particular, since there are some rainy days with high temperatures above 80 degrees—that is, \\(A\\) and \\(B\\) are not disjoint—\\(\\textrm{P}(A) + \\textrm{P}(B)\\) is greater than \\(\\textrm{P}(A\\cup B)\\). Donny might also mean “the probability that (it rains tomorrow) and (tomorrow’s high temperature is above 80 degrees),” which he should write as \\(\\textrm{P}(A \\cap B)\\).\n\\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) are numbers; union is an operation on sets, and it doesn’t make mathematical sense to take a union of numbers. See the previous part for related discussion.\n\\(X\\) is a random variable, and probabilities are assigned to events. \\(P(X)\\) reads “the probability that tomorrow’s high temperature in degrees F”, a subject in need of a predicate; the phrase is missing any qualifying information that could define an event. We assign probabilities to things that might happen (events) like “tomorrow’s high temperature is above 80 degrees,” which has probability \\(\\textrm{P}(X &gt; 80)\\).\n\\(X\\) is a random variable (a function) and \\(A\\) is an event (a set), and it doesn’t make sense to equate these two different mathematical objects. It doesn’t make sense to say “tomorrow’s high temperature in degrees F equals the event that it rains tomorrow”. We’re not sure what Donny was thinking here.\n\\(X\\) and \\(Y\\) are random variables (functions) and intersection is an operation on sets. \\(X \\cap Y\\) is attempting to say “tomorrow’s high temperature in degrees F and the amount of rainfall in inches tomorrow”, but this is still missing qualifying information to define a valid event for which a probability can be assigned. We could say \\(\\textrm{P}(X &gt; 80, Y &lt; 2)\\) to represent “the probability that (tomorrow’s high temperature is greater than 80 degrees F) AND (the amount of rainfall tomorrow is less than 2 inches)”. (Remember,“\\(X &gt; 80, Y &lt; 2\\)” is short for the event \\(\\{X &gt; 80\\} \\cap \\{Y &lt; 2\\}\\).) If we want to say something like “we measure tomorrow’s high temperature in degrees F and the amount of rainfall in inches tomorrow” we would write \\((X, Y)\\).\n\n\n\n\n\n\n\n2.4.6 Exercises\n\nExercise 2.8 Consider the matching problem with \\(n=4\\): objects labeled 1, 2, 3, 4, are placed at random in spots labeled 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. Recall the sample space from Table 2.2. Let the random variable \\(X\\) count the number of objects that are put back in the correct spot; recall Table 2.9. Let \\(\\textrm{P}\\) denote the probability measure corresponding to the assumption that the objects are equally likely to be placed in any spot, so that the 24 possible placements are equally.\n\n\nCompute and interpret \\(\\textrm{P}(X=0)\\).\nCompute and interpret \\(\\textrm{P}(X \\ge 1)\\).\nLet \\(C_1\\) be the event that object 1 is put correctly in spot 1. Find \\(\\textrm{P}(C_1)\\).\nLet \\(C_2\\) be the event that object 2 is put correctly in spot 2. Find \\(\\textrm{P}(C_2)\\).\nDefine \\(C_3\\), and \\(C_4\\) similarly. Represent the event \\(\\{X \\ge 1\\}\\) in terms of \\(C_1, C_2, C_3, C_4\\).\nFind and interpret \\(\\textrm{P}(C_1\\cap C_2 \\cap C_3 \\cap C_4)\\).\nDonny Don’t says: \\(\\textrm{P}(C_1 \\cup C_2 \\cup C_3 \\cup C_4)\\) is equal to \\(\\textrm{P}(C_1)+\\textrm{P}(C_2)+\\textrm{P}(C_3)+\\textrm{P}(C_4)\\).” Explain to Donny his mistake.\nDonny Don’t says: “ok, the events are not disjoint so then by the general addition rule \\(\\textrm{P}(C_1 \\cup C_2 \\cup C_3 \\cup C_4)\\) is equal to \\(\\textrm{P}(C_1)+\\textrm{P}(C_2)+\\textrm{P}(C_3)+\\textrm{P}(C_4)-\\textrm{P}(C_1\\cap C_2 \\cap C_3 \\cap C_4)\\).” Explain to Donny his mistake.\n\n\nExercise 2.9 Consider the outcome of a sequence of 4 flips of a coin. Assume that the coin is fair so that all 16 possible outcomes are equally likely, and let \\(\\textrm{P}\\) be the corresponding probability measure. Let \\(X\\) be the number of heads flipped and let \\(Y=4-X\\).\n\nCompute \\(\\textrm{P}(X=1)\\).\nCompute \\(\\textrm{P}(X = x)\\) for each \\(x = 0, 1, 2, 3, 4\\).\nCompute \\(\\textrm{P}(Y=1)\\).\nCompute \\(\\textrm{P}(Y = y)\\) for each \\(y = 0, 1, 2, 3, 4\\).\nCompute \\(\\textrm{P}(X = Y)\\).\n\n\n\nExercise 2.10 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Suppose that each package is equally likely to contain any of the 3 prizes, regardless of the contents of other packages, so that there are 27 equally likely outcomes, and let \\(\\textrm{P}\\) be the corresponding probability measure.\n\nLet \\(A_1\\) be the event that prize 1 is obtained—that is, at least one of the packages contains prize 1—and define \\(A_2, A_3\\) similarly for prize 2, 3.\nLet \\(B_1\\) be the event that only prize 1 is obtained—that is, all three packages contain prize 1—and define \\(B_2, B_3\\) similarly for prize 2, 3.\n\n\nCompute \\(\\textrm{P}(A_1)\\)\nCompute \\(\\textrm{P}(B_1)\\)\nInterpret the values from parts 1 and 2 as long run relative frequencies.\nInterpret the values from parts 1 and 2 as relative likelihoods.\nCompute \\(\\textrm{P}(A_1 \\cap A_2 \\cap A_3)\\)\nCompute \\(\\textrm{P}(A_1 \\cup A_2 \\cup A_3)\\)\nCompute \\(\\textrm{P}(B_1 \\cap B_2 \\cap B_3)\\)\nCompute \\(\\textrm{P}(B_1 \\cup B_2 \\cup B_3)\\)\n\n\n\nExercise 2.11 The latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Suppose that each package is equally likely to contain any of the 3 prizes, regardless of the contents of other packages, so that there are 27 equally likely outcomes, and let \\(\\textrm{P}\\) be the corresponding probability measure.\nLet \\(X\\) be the number of distinct prizes obtained in these 3 packages. Let \\(Y\\) be the number of these 3 packages that contain prize 1.\nThe sample space consists of 27 outcomes, listed in the table below.\n\n\n\n\n111\n112\n113\n121\n122\n123\n131\n132\n133\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n211\n212\n213\n221\n222\n223\n231\n232\n233\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n311\n312\n313\n321\n322\n323\n331\n332\n333\n\n\n\\(X\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(Y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompute \\(\\textrm{P}(X = 1)\\).\nCompute \\(\\textrm{P}(X = 2)\\).\nCompute \\(\\textrm{P}(X = 3)\\).\nInterpret the values in parts 1 through 3 as long run relative frequencies.\nInterpret the values in parts 1 through 3 as relative likelihoods.\nCompute \\(\\textrm{P}(Y = y)\\) for each possible value \\(y\\).\nCompute \\(\\textrm{P}(X = 2, Y = 1)\\).\nCompute \\(\\textrm{P}(X = Y)\\).\n\n\n\nExercise 2.12 Katniss throws a dart at a circular dartboard with radius 1 foot. Suppose that the dart lands uniformly at random anywhere on the dartboard, and let \\(\\textrm{P}\\) be the corresponding probability measure.\n\nCompute \\(\\textrm{P}(A)\\), where \\(A\\) is the event that Katniss’s dart lands within 1 inch of the center of the dartboard.\nCompute \\(\\textrm{P}(B)\\), where \\(B\\) is the event that Katniss’s dart lands more than 1 inch but less than 2 inches away from the center of the dartboard.\nCompute \\(\\textrm{P}(E)\\), where \\(E\\) is the event that Katniss’s dart lands within 1 inch of the outside edge of the dartboard.\nInterpret the previous probabilities as long run relative frequencies.\nInterpret the previous probabilities as relative likelihoods.\n\n\n\nExercise 2.13 Katniss throws a dart at a circular dartboard with radius 1 foot. Suppose that the dart lands uniformly at random anywhere on the dartboard, and let \\(\\textrm{P}\\) be the corresponding probability measure.\nLet \\(X\\) be the distance (inches) from the location of the dart to the center of the dartboard.\n\nCompute \\(\\textrm{P}(X \\le 1)\\)\nCompute \\(\\textrm{P}(1 &lt; X &lt; 2)\\)\nCompute \\(\\textrm{P}(X &gt; 11)\\)\n\n\n\nExercise 2.14 Katniss throws a dart at a circular dartboard with radius 1 foot. Suppose that the dart lands uniformly at random anywhere on the dartboard, and let \\(\\textrm{P}\\) be the corresponding probability measure.\nLet \\(X\\) be the distance (inches) from the location of the dart to the center of the dartboard.\n\nCompute \\(\\textrm{P}(X \\le 0.1)\\)\nCompute \\(\\textrm{P}(X \\le 0.01)\\)\nCompute \\(\\textrm{P}(X = 0)\\)\nCompute \\(\\textrm{P}(X \\ge 11.9)\\)\nCompute \\(\\textrm{P}(X \\ge 11.99)\\)\nCompute \\(\\textrm{P}(X = 12)\\)\nWhich is more likely: the dart lands exactly in the center or the darts lands exactly on the edge? Discuss.\nWhich is more likely: the dart lands close to the center or the darts lands close to the edge? Discuss.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-dist-intro",
    "href": "language-probability.html#sec-dist-intro",
    "title": "2  The Language of Probability",
    "section": "2.5 Distributions of random variables (a brief introduction)",
    "text": "2.5 Distributions of random variables (a brief introduction)\nEven when outcomes of a random phenomenon are equally likely, values of related random variable are usually not. The probability distribution of a random variable describes the possible values that the random variable can take and their relative likelihoods or plausibilities. We will see several ways of summarizing and describing distributions throughout the book; this section only provides a brief introduction.\n\n\n\n\n\n\n\nExample 2.41 Roll a four-sided die twice; recall the sample space in Example 2.17 and Table 2.7. One choice of probability measure \\(\\textrm{P}\\) corresponds to assuming that the die is fair and that the 16 possible outcomes are equally likely. Let \\(X\\) be the sum of the two dice, and let \\(Y\\) be the larger of the two rolls (or the common value if both rolls are the same).\n\nCompute \\(\\textrm{P}(E_1)\\), where \\(E_1\\) is the event that the first roll lands on 1.\n\nCompute \\(\\textrm{P}(X = 6)\\).\nInterpret \\(\\textrm{P}(X = 6)\\) as a long run relative frequency.\nInterpret \\(\\textrm{P}(X = 6)\\) as a relative degree of likelihood. (Hint: compare to \\(\\textrm{P}(X \\neq 6)\\).)\nConstruct a table displaying \\(\\textrm{P}(X = x)\\) for each possible value \\(x\\) of \\(X\\), and sketch a corresponding plot.\nConstruct a table displaying \\(\\textrm{P}(Y = y)\\) for each possible value \\(y\\) of \\(Y\\), and sketch a corresponding plot.\nConstruct a table displaying \\(\\textrm{P}(X = x, Y= y)\\) for each possible \\((x, y)\\) pair, and sketch a corresponding plot.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.41. \n\nSince \\(\\textrm{P}\\) corresponds to equally likely outcomes, we simply need to count the number of outcomes that satisfy the event and divide by the total number of outcomes. There are 16 equally likely outcomes, of which 4 satisfy event \\(E_1\\). (Remember, the sample space corresponds to pairs of rolls, and there are 4 pairs for which the first roll is 1.) So \\(\\textrm{P}(E_1) = 4 / 16 = 1/4\\), which makes sense if we’re assuming the die is fair.\nThere are 16 equally likely outcomes, 3 of which satisfy the event that the sum is 6. So \\(\\textrm{P}(X = 6) = 3 / 16 = 0.1875\\).\nOver many pairs of rolls of a fair four-sided die, around 18.75% of pairs will yield a sum of 6.\n\\(\\textrm{P}(X\\neq 6) = 13/16 = 0.8125\\). The ratio of \\(\\textrm{P}(X \\neq 6)\\) to \\(\\textrm{P}(X = 6)\\) is \\(13/3 \\approx 4.3\\). If you roll a fair four-sided die twice, it is 4.3 times more likely for the sum to be something other than 6 than for it to be 6.\nThe possible values of \\(X\\) are \\(2, 3, 4, 5, 6, 7, 8\\). Find the probability of each value by counting the corresponding outcomes using Table 2.7. For example, \\(\\textrm{P}(X = 3) = \\textrm{P}(\\{(1, 2), (2, 1)\\}) = 2/16\\). See Table 2.14. Figure 2.16 displays an “impulse” plot with the possible values of \\(X\\) on the horizontal axis and the corresponding probabilities on the vertical axis.\nThe possible values of \\(Y\\) are \\(1, 2, 3, 4\\). See Table 2.15 and Figure 2.17 for probabilities. For example, \\(\\textrm{P}(Y = 3) = \\textrm{P}(\\{(1, 3), (2, 3), (3, 1), (3, 2), (3, 3)\\}) = 5/16\\).\nSimilar to the previous parts, we can first construct a table with each row corresponding to a possible \\((X, Y)\\) pair, and then find the probabilities of the corresponding outcomes. For example, there are two pairs of rolls that result in \\(X=4\\) and \\(Y=3\\)—\\((1, 3), (3,1)\\)—so \\(\\textrm{P}((X, Y) = (4, 3))=\\textrm{P}(X = 4, Y=3) = \\textrm{P}(\\{(1, 3), (3, 1)\\}) = 2/16\\). See Table 2.16 for probabilities. Table 2.17 reorganizes Table 2.16 into a two-way table with rows corresponding to possible values of \\(X\\) and columns corresponding to possible values of \\(Y\\). Figure 2.18 displays the distribution of \\((X, Y)\\) pairs in a 3d impulse plot, and Figure 2.19 displays the distribution in a “tile” plot where lighter colors represent larger probabilities.\n\n\n\n\n\n\n\n\n\nTable 2.14: The marginal distribution of \\(X\\), the sum of two rolls of a fair four-sided die.\n\n\n\n\n\n\nx\nP(X=x)\n\n\n\n\n2\n0.0625\n\n\n3\n0.1250\n\n\n4\n0.1875\n\n\n5\n0.2500\n\n\n6\n0.1875\n\n\n7\n0.1250\n\n\n8\n0.0625\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.16: The marginal distribution of \\(X\\), the sum of two rolls of a fair four-sided die.\n\n\n\n\n\n\n\n\n\nTable 2.15: The marginal distribution of \\(Y\\), the larger (or common value if a tie) of two rolls of a fair four-sided die.\n\n\n\n\n\n\ny\nP(Y=y)\n\n\n\n\n1\n0.0625\n\n\n2\n0.1875\n\n\n3\n0.3125\n\n\n4\n0.4375\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.17: The marginal distribution of \\(Y\\), the larger (or common value if a tie) of two rolls of a fair four-sided die.\n\n\n\n\n\n\n\n\n\nTable 2.16: Table representing the joint distribution of sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die\n\n\n\n\n\n\n(x, y)\nP(X = x, Y = y)\n\n\n\n\n(2, 1)\n0.0625\n\n\n(3, 2)\n0.1250\n\n\n(4, 2)\n0.0625\n\n\n(4, 3)\n0.1250\n\n\n(5, 3)\n0.1250\n\n\n(5, 4)\n0.1250\n\n\n(6, 3)\n0.0625\n\n\n(6, 4)\n0.1250\n\n\n(7, 4)\n0.1250\n\n\n(8, 4)\n0.0625\n\n\n\n\n\n\n\n\n\n\n\nTable 2.17: Two-way table representation of the joint distribution of \\(X\\) and \\(Y\\), the sum and the larger (or common value if a tie) of two rolls of a fair four-sided die. Possible values of \\(X\\) are in the leftmost column; possible values of \\(Y\\) are in the top row.\n\n\n\n\n\n\\(x\\) \\ \\(y\\)\n1\n2\n3\n4\n\n\n2\n1/16\n0\n0\n0\n\n\n3\n0\n2/16\n0\n0\n\n\n4\n0\n1/16\n2/16\n0\n\n\n5\n0\n0\n2/16\n2/16\n\n\n6\n0\n0\n1/16\n2/16\n\n\n7\n0\n0\n0\n2/16\n\n\n8\n0\n0\n0\n1/16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.18: 3D Impulse plot representing the joint distribution of the sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.19: Tile plot representing the joint distribution of the sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die.\n\n\n\n\n\nThe above tables and plots represent the joint and marginal distributions of the random variables \\(X\\) and \\(Y\\) in Example 2.41 according to the probability measure \\(\\textrm{P}\\), which reflects the assumption that the die is fair and the rolls are independent.\nTable 2.17, Table 2.16, Figure 2.18 and Figure 2.19 represent the joint distribution of the sum and larger of two rolls of a fair four-sided die.. The joint distribution of two random variables summarizes the possible pairs of values and their relative likelihoods or plausibilities.\nIn the context of multiple random variables, the distribution of any one of the random variables is called a marginal distribution. Table 2.14 and Figure 2.16 represent the marginal distribution of the sum and larger of two rolls of a fair four-sided die. Table 2.15 and Figure 2.17 represent the marginal distribution of the larger of two rolls of a fair four-sided die.\nIn Example 2.41, we can obtain the marginal distributions from the joint distribution by summing rows and columns: think of adding a total column (for \\(X\\)) and a total row (for \\(Y\\)) in the “margins” of the table. It is possible to obtain marginal distributions from a joint distribution. However, in general you cannot recover the joint distribution from the marginal distributions alone. Just because you know the row and column totals doesn’t mean you know all the values of the interior cells in the joint distribution table.\n\n\n\n\n\n\n\nExample 2.42 Continuing Example 2.41, suppose that instead of a fair die, the weighted die in Example 2.29 is rolled twice. Answer the following without doing any computations.\n\nAre the possible values of \\(X\\) the same as in Table 2.14? Is the distribution of \\(X\\) the same as in Table 2.14?\nAre the possible values of \\((X, Y)\\) the same as in Table 2.16? Is the joint distribution of \\((X, Y)\\) the same as in Table 2.16?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.42. In both parts, the possible values are the same. There are still 16 possible outcomes and the random variables are still measuring the same quantities as before. But the distributions are all different. With the weighted die some outcomes are more or less likely than others, and some values of the random variables are more or less likely than when the die is fair. For example, the probabilities of the events \\(\\{X = 8\\}\\), \\(\\{Y=4\\}\\), and \\(\\{X = 8, Y=4\\}\\) are larger with the weighted die than with the fair die, because each roll of the weighted die is more likely to result in a 4 than the fair die.\n\n\n\n\nDistributions of random variables depend on the underlying probability measure. Changing the probability measure can change distributions.\nIn Example 2.41, we first specified the probability space of 16 equally likely outcomes then derived the distribution. However, in many problems we often assume or identify distributions directly, without any mention of the underlying sample space or probability measure. Recall the brown bag analogy in Section 2.3.2. The probability space corresponds to the random selection of fruits to put in the bag. The random variable is weight. The distribution of weight can be obtained by randomly selecting fruits to put in the bag, weighing the bag, and then repeating this process many times to observe many weights. For example, maybe 10% of bags have weights less than 5 pounds, 75% of bags have weights less than 20 pounds, etc. We can observe the distribution of weights even if we don’t observe the actual fruits in the bag or fully specify the random phenomenon and its sample space.\nExample 2.41 involved two discrete random variables. We will introduce distributions of continuous random variables later.\n\n2.5.1 Interpretations of distributions\nDistributions can be thought of as collections of probabilities of events involving random variables. As for probabilities, we can interpret probability distributions of random variables as:\n\nlong run relative frequency distributions: what pattern of values would emerge if we repeated the random process many times and observed many values of the random variables?\n\nsubjective probability distributions: which potential values of these uncertain quantities are relatively more plausible than others?\n\nThe long run relative frequency interpretation is natural for Example 2.41. We can roll a pair of fair four-sided dice and measure the sum of the rolls and the larger of the rolls. If we repeat this process many times, we would expect about 6.25% of repetitions to result in a sum of 2, 12.5% of repetitions to result in a sum of 3, 6.25% of repetitions to result in a larger roll of 1, 18.75% of repetitions to result in a larger roll of 3, 6.25% of repetitions to result in both a sum of 2 and a larger roll of 1, 12.5% of repetitions to result in both a sum of 3 and a larger roll of 2, etc. If we summarize the results of many repetitions—which we will do in the next chapter—we would expect the patterns to look like those in the tables and plots in this section.\nIn other situations the subjective distribution interpretation is more natural. For example, the total number of points scored in the next Superbowl will be one and only one number, but since we don’t know what that number is we can treat it as a random variable. Treating the number of points as a random variable allows us to quantify our uncertainty about it through probability statements like “there is a 0.6 probability that at most 45 points will be scored in the next Superbowl”. A subjective probability distribution for the number of points describes which possible values are relatively more plausible than others.\nAs with probabilities, the mathematics of distributions work the same way regardless of which interpretation is used, so we will use the two interpretations interchangeably.\n\n\n2.5.2 Expected value\nThe distribution of a random variable specifies its possible values and the probability of any event that involves the random variable. It is also useful to summarize some key features of a distribution. Recall that in Section 1.7 we introduced the idea of a “probability-weighted average value”. We also saw how this value can be interpreted as a “long run average value”.\n\n\n\n\n\n\n\nExample 2.43 Continuing Example 2.41, recall the marginal distributions of \\(X\\) and \\(Y\\) from Table 2.14 and Table 2.15.\n\nCompute the probability-weighted average value of \\(X\\).\nInterpret the value from the previous part as a long run average value in context.\nCompute the probability-weighted average value of \\(Y\\).\nCompute the probability that \\(Y\\) is equal to the value from the previous part.\nIs the value from part 3 the value we would expect for \\(Y\\) when we roll the dice? If not, explain in what sense the value from part 3 is “expected”.\nSuppose that instead of rolling a fair die we rolled the weighted die from Example 2.29) represented by the spinner Figure 2.9 (b). How would the probability-weighted average values of \\(X\\) and \\(Y\\) for the weighted die relate to those for the fair die?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.43. \n\nMultiply each possible of \\(X\\) by its probability and sum \\[\n\\small{\n2\\times 0.0625 + 3 \\times 0.1250 + 4 \\times 0.1875 + 5 \\times 0.2500 + 6 \\times 0.1875 + 7 \\times 0.1250 + 8 \\times 0.0625 = 5\n}\n\\]\nWe can roll a pair of fair four-sided dice and measure the sum of the rolls. If we repeat this process many times and average the values of the sum, we would expect the average to be around 5.\nMultiply each possible of \\(Y\\) by its probability and sum \\[\n1\\times 0.0625 + 3 \\times 0.1875 + 5 \\times 0.3125 + 7 \\times 0.4375  = 3.125\n\\]\n\\(\\textrm{P}(Y = 3.125) = 0\\).\nIt’s not possible for the sum of two rolls of a fair four-sided die to be 3.125, so it’s certainly not expected. Over many pairs of rolls of a fair four-sided die, we would expect the average of the values of the larger roll in the pair to be around 3.125.\nThis weighted die is more likely to return large values than small values so we would expect the long run averages of \\(X\\) and \\(Y\\) to be greater with this weighted die than with the fair die.\n\n\n\n\n\nIn Example 2.43, 5 is the expected value of \\(X\\), denoted \\(\\textrm{E}(X)\\). Likewise, \\(\\textrm{E}(Y) = 3.125\\). As we discussed in Section 1.7 the term “expected value” is somewhat of a misnomer. The expected value of \\(X\\) is not necessarily the value of \\(X\\) we expect to see when the random phenomenon is observed, but rather the value of \\(X\\) we would expect to see on average in the long run over many observations of the random phenomenon.\nThe distribution of a random variable and hence its expected value depend on the probability measure. If the probability measure changes (e.g., from representing a fair die to a weighted die) then distributions and expected values of random variables can change.\nExample 2.43 involved two discrete random variables. We will introduce expected values of continuous random variables later.\nExpected value is just one feature of a distribution. We are also interested in other features, such as percentiles or the overall degree of variability. Usually there are multiple random variables of interest and we are interested in summarizing relationships between them. We will explore distributions of random variables and related concepts such as expected value, variance, and correlation in much more detail in the remaining chapters.\n\n\n2.5.3 Exercises\n\nExercise 2.15 Consider the matching problem with \\(n=4\\): objects labeled 1, 2, 3, 4, are placed at random in spots labeled 1, 2, 3, 4, with spot 1 the correct spot for object 1, etc. Recall the sample space from Table 2.2. Let the random variable \\(X\\) count the number of objects that are put back in the correct spot; recall Table 2.9. Let \\(\\textrm{P}\\) denote the probability measure corresponding to the assumption that the objects are equally likely to be placed in any spot, so that the 24 possible placements are equally.\n\n\nFind the distribution of \\(X\\) by creating an appropriate table and plot.\nFind the probability-weighted average value of \\(X\\).\nIs the value from part 2 the most likely value of \\(X\\)? Explain.\nIs the value from part 2 the value that we would “expect” to see for \\(X\\) in a single repetition of the phenomenon? Explain.\nExplain in what sense the value from part 2 is “expected”.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-cond",
    "href": "language-probability.html#sec-cond",
    "title": "2  The Language of Probability",
    "section": "2.6 Conditioning",
    "text": "2.6 Conditioning\nConditioning concerns how probabilities of events or distributions of random variables are influenced by information about the occurrence of events or the values of random variables. We discussed some ideas related to conditioning in Section 1.5. Now we will explore conditioning in more detail, introducing some of the notation and math.\n\n2.6.1 Conditional probability\nA probability quantifies the likelihood or degree of uncertainty of an event. A conditional probability revises this value to reflect any newly available information about the outcome of the underlying random phenomenon.\n\n\n\n\n\n\n\nExample 2.44 The probability32 that a randomly selected American adult (18+) uses Snapchat is 0.24.\n\nSuppose the randomly selected adult is age 18-29. Do you think the probability that a randomly selected adult who is age 18-29 uses Snapchat is 0.24? What if the adult is age 65+? Explain.\nThe probability33 that a randomly selected American adult is age 18-29 is 0.20. Is the probability that a randomly selected American adult both (1) is age 18-29, and (2) uses Snapchat equal to \\(0.20\\times 0.24\\)? Explain.\nWithout further information, provide a range of “logically possible” values for the probability in the previous part. (“Logically possible” means they satisfy the rules of probability, even though they might not be realistic in context.)\nSuppose that the probability that a randomly selected American adult both is age 18-29 and uses Snapchat is 0.13. Construct an appropriate two-way table.\nFind the probability that a randomly selected American adult who is age 18-29 uses Snapchat.\nHow can the probability in the previous part be written in terms of the probabilities provided earlier?\nFind the probability that a randomly selected American adult who uses Snapchat is age 18-29.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.44. \n\nThe value 0.24 represents adults of all ages (18+). We might expect Snapchat use to vary with age, with younger adults more likely to use Snapchat than older adults. We might expect the probability that a randomly selected adult who is age 18-29 uses Snapchat to be greater than 0.24, while the probability that a randomly selected adult who is age 65+ uses Snapchat to be less than 0.24.\nNo. This would only be true if the probability that a randomly selected adult who is age 18-29 uses Snapchat is 0.24. But as we mentioned in the previous part we expect this probability to be greater than 0.24.\nWe could make a table like in the following part and see what values produce valid tables. If \\(A\\) is the event that the selected adult is age 18-29, \\(C\\) is the event that the selected adult uses Snapchat, and \\(\\textrm{P}\\) corresponds to randomly selecting an American adult, then \\(\\textrm{P}(A) = 0.20\\) and \\(\\textrm{P}(C) = 0.24\\). By the subset rule \\(\\textrm{P}(A\\cap C)\\le \\min(\\textrm{P}(A), \\textrm{P}(C)) = 0.20\\). The largest \\(\\textrm{P}(A\\cap C)\\) can be is 0.20, which corresponds to all adults age 18-29 using Snapchat. The smallest \\(\\textrm{P}(A \\cap C)\\) can be is 0, which corresponds to no adults age 18-29 using Snapchat. The extremes are not realistic, but without knowing more information, we do not know where \\(\\textrm{P}(A\\cap C)\\) lies in \\(0\\le \\textrm{P}(A \\cap C) \\le 0.20\\).\n\nIf \\(\\textrm{P}(A \\cap C)= 0.13\\), then the two-way table of probabilities34 is\n\n\n\n\n\\(A\\)\n\\(A^c\\)\nTotal\n\n\n\n\n\\(C\\)\n0.13\n0.11\n0.24\n\n\n\\(C^c\\)\n0.07\n0.69\n0.76\n\n\nTotal\n0.20\n0.80\n1.00\n\n\n\n\\(\\frac{0.13}{0.20}=0.65\\) is the probability that a randomly selected American adult who is age 18-29 uses Snapchat. Imagine a group of 100 hypothetical adults; we would expect 20 to be age 18-29 of whom 13 use Snapchat, so 65% of adults age 18-29 use Snapchat.\n\\(0.65= \\frac{0.13}{0.20}=\\frac{\\textrm{P}(A\\cap C)}{\\textrm{P}(A)}\\). The probability that a randomly selected American adult who is age 18-29 uses Snapchat is the probability that an adult both uses Snapchat and is age 18-29 divided by the probability that an adult is age 18-29.\nThe probability that a randomly selected American adult who uses Snapchat is age 18-29 is \\(\\frac{\\textrm{P}(A\\cap C)}{\\textrm{P}(C)} = \\frac{0.13}{0.24} = 0.5417\\). Note that the numerator is the same as in the previous part but now the denominator is the probability that an adult uses Snapchat. Imagine a group of 100 hypothetical adults; we would expect 24 to use Snapchat of whom 13 are age 18-29, so 54.17% of adults who use Snapchat are age 18-29.\n\n\n\n\n\n\nDefinition 2.7 The conditional probability of event \\(A\\) given event \\(B\\), denoted \\(\\textrm{P}(A|B)\\), is defined as (provided35 \\(\\textrm{P}(B)&gt;0\\)):\n\n\\[\n\\textrm{P}(A|B) = \\frac{\\textrm{P}(A\\cap B)}{\\textrm{P}(B)}\n\\]\nThe conditional probability \\(\\textrm{P}(A|B)\\) represents the likelihood, plausibility, or degree of uncertainty of event \\(A\\) reflecting information that event \\(B\\) has occurred. The event to the left of the vertical bar, \\(A\\) in \\(\\textrm{P}(A|B)\\), is the event we are evaluating the probability of. The unconditional probability \\(\\textrm{P}(A)\\) is often called the prior probability (a.k.a., base rate) of \\(A\\) (prior to observing \\(B\\)). The event to the right of the vertical bar, \\(B\\) in \\(\\textrm{P}(A|B)\\), is the event being conditioned on—how does the probability of \\(A\\) change given that event \\(B\\) occurs? The conditional probability \\(\\textrm{P}(A|B)\\) is the posterior probability of \\(A\\) after observing \\(B\\). Read the vertical bar \\(|\\) in \\(\\textrm{P}(A | B)\\) as “given”.\nIn Example 2.44, \\(\\textrm{P}(C|A) = 0.65\\) is the conditional probability that an adult uses Snapchat given that they are age 18-29, and \\(\\textrm{P}(A|C) = 0.5417\\) is the conditional probability that an adult is age 18-29 given that they use Snapchat.\nAll of the ideas from Section 1.5 still apply. We’ll remind you of a few, using our new notation. Remember that, in general, knowing whether or not event \\(B\\) occurs influences the probability of event \\(A\\); that is, \\[\n\\text{In general, } \\textrm{P}(A|B) \\neq \\textrm{P}(A)\n\\] Also remember that order is essential in conditioning; that is, \\[\n\\text{In general, } \\textrm{P}(A|B) \\neq \\textrm{P}(B|A)\n\\] Lastly, remember to always ask “probability of what?” Thinking of a conditional probability as a fraction, the event being conditioned on identifies the total/baseline group which corresponds to the denominator.\n\n\n2.6.2 Joint, conditional, and marginal probabilities\nWhen dealing with multiple events, probabilities can be joint, conditional, or marginal. In the context of two events \\(A\\) and \\(B\\):\n\nJoint: unconditional probability involving both events, \\(\\textrm{P}(A \\cap B)\\).\nConditional: conditional probability of one event given the other, \\(\\textrm{P}(A | B)\\), \\(\\textrm{P}(B | A)\\).\nMarginal: unconditional probability of a single event \\(\\textrm{P}(A)\\), \\(\\textrm{P}(B)\\).\n\nThe relationship \\(\\textrm{P}(A|B) = \\textrm{P}(A\\cap B)/\\textrm{P}(B)\\) can be stated generically as \\[\n\\text{conditional} = \\frac{\\text{joint}}{\\text{marginal}}\n\\] We will see several versions of this general relationship in the remaining chapters.\nIn Example 2.44, we were provided the marginal probabilities (\\(\\textrm{P}(A) = 0.20\\), \\(\\textrm{P}(C) = 0.24\\)) and a joint probability (\\(\\textrm{P}(A \\cap C) = 0.13\\)) and we computed conditional probabilities (\\(\\textrm{P}(C|A) = 0.65\\), \\(\\textrm{P}(A|C) = 0.5417\\)). In many problems some conditional probabilities are provided or can be determined directly.\n\n\n\n\n\n\n\nExample 2.45 Continuing Example 2.44, suppose that\n\n65% of American adults age 18-29 use Snapchat\n24% of American adults age 30-49 use Snapchat\n12% of American adults age 50-64 use Snapchat\n2% of American adults age 65+ use Snapchat\n\nAlso suppose that\n\n20% of American adults are age 18-29\n33% of American adults are age 30-49\n25% of American adults are age 50-64\n22% of American adults are age 65+\n\n\nIf the probability measure \\(\\textrm{P}\\) corresponds to randomly selecting an American adult, write all the percentages above as probabilities using proper notation.\nCompute and identify with proper notation the probability that a randomly selected American adult is age 18-29 and uses Snapchat.\nCompute and identify with proper notation the probability that a randomly selected American adult is age 30-49 and does not use Snapchat.\nCompute an appropriate two-way table.\nCompute and identify with proper notation the probability that a randomly selected American adult uses Snapchat.\nCompute and identify with proper notation the probability that a randomly selected American adult is age 18-29 given that they use Snapchat.\nRepeat the previous part for each of the age groups. How do the conditional probabilities that the selected adult is in each group given that they use Snapchat compare to the prior probabilities?\nNow suppose the randomly selected adult does not use Snapchat. Compute the conditional probability that the selected adult is in age group. How do the conditional probabilities compare to the prior probabilities?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.45. \n\nLet \\(C\\) denote the event that the selected adult uses Snapchat, and let \\(A_1\\), \\(A_2\\), \\(A_3\\), \\(A_4\\) denote the events that the selected adult is in the age group 18-29, 30-49, 50-64, 65+, respectively. Then the marginal probabilities that the selected adult is in each age group are \\[\\begin{align*}\n\\textrm{P}(A_1) & = 0.20\\\\\n\\textrm{P}(A_2) & = 0.33\\\\\n\\textrm{P}(A_3) & = 0.25\\\\\n\\textrm{P}(A_4) & = 0.22\n\\end{align*}\\] The conditional probabilities that the selected adult uses Snapchat given that the adult is in each of the age groups are \\[\\begin{align*}\n\\textrm{P}(C|A_1) & = 0.65\\\\\n\\textrm{P}(C|A_2) & = 0.24\\\\\n\\textrm{P}(C|A_3) & = 0.12\\\\\n\\textrm{P}(C|A_4) & = 0.02\n\\end{align*}\\]\n\\(\\textrm{P}(C|A_1) = \\frac{\\textrm{P}(A_1 \\cap C)}{\\textrm{P}(A_1)}\\) so \\(\\textrm{P}(A_1 \\cap C) = \\textrm{P}(C|A_1)\\textrm{P}(A_1) = 0.65\\times 0.20 = 0.13\\) is the probability that a randomly selected American adult is age 18-29 and uses Snapchat. (This value was provided to us directly in Example 2.44.)\n\\(\\textrm{P}(C^c|A_2) = 1 - \\textrm{P}(C|A_2) = 1 - 0.24 = 0.76\\) is the probability that the selected adult does not use Snapchat given that they are in the 30-49 age group. Then \\(\\textrm{P}(A_2 \\cap C^c) = \\textrm{P}(C^c|A_2)\\textrm{P}(A_2) = 0.76 \\times 0.33 = 0.2508\\) is the probability that a randomly selected American adult is age 30-49 and does not use Snapchat.\nMultiply as in the previous parts to complete the table.\n\n\n\n\n\n\n\n\n\n\n\\(C\\) (uses Snapchat)\n\\(C^c\\) (does not use Snapchat)\nTotal\n\n\n\n\n\\(A_1\\) (age 18-29)\n0.1300\n0.0700\n0.2000\n\n\n\\(A_2\\) (age 30-49)\n0.0792\n0.2508\n0.3300\n\n\n\\(A_3\\) (age 50-64)\n0.0300\n0.2200\n0.2500\n\n\n\\(A_4\\) (age 65+)\n0.0044\n0.2156\n0.2200\n\n\nTotal\n0.2436\n0.7564\n1.0000\n\n\n\n\\(\\textrm{P}(C) = 0.2436\\) is the marginal probability36 that a randomly selected American adult uses Snapchat. We will discuss this value in further detail below.\n\\(\\textrm{P}(A_1|C) = \\frac{0.13}{0.2436} = 0.5337\\) is the conditional probability37 that a randomly selected American adult is age 18-29 given that they use Snapchat.\nCompute38 the conditional probabilities similar to the previous part \\[\\begin{align*}\n\\textrm{P}(A_1|C) & = \\frac{0.1300}{0.2436} = 0.5337\\\\\n\\textrm{P}(A_2|C) & = \\frac{0.0792}{0.2436} = 0.3251\\\\\n\\textrm{P}(A_3|C) & = \\frac{0.0300}{0.2436} = 0.1232\\\\\n\\textrm{P}(A_4|C) & = \\frac{0.0044}{0.2436} = 0.0181\n\\end{align*}\\] Given that the adult uses Snapchat, we see the probability shift towards the younger ages. For example, the posterior probability (0.5337) that the adult is age 18-29 given that they use Snapchat is much greater than the prior probability (0.20), while the posterior probability (0.0181) that the adult is age 65+ given that they use Snapchat is much less than the prior probability (0.22).\nCompute similar to the previous part \\[\\begin{align*}\n\\textrm{P}(A_1|C^c) & = \\frac{0.0700}{0.7564} = 0.0925\\\\\n\\textrm{P}(A_2|C^c) & = \\frac{0.2508}{0.7564} = 0.3316\\\\\n\\textrm{P}(A_3|C^c) & = \\frac{0.2200}{0.7564} = 0.2909\\\\\n\\textrm{P}(A_4|C^c) & = \\frac{0.2156}{0.7564} = 0.2850\n\\end{align*}\\] Given that the adult does not use Snapchat, we see the probability shift towards the older ages. For example, the posterior probability (0.0925) that the adult is age 18-29 given that they do not use Snapchat is less than the prior probability (0.20), while the posterior probability (0.2850) that the adult is age 65+ given that they do not use Snapchat is greater than the prior probability (0.22). However, the shift from prior to posterior given that the adult does not use Snapchat is less dramatic than given that the adult uses Snapchat. See Figure 2.20.\n\n\n\n\n\nA mosaic plot provides a nice visual of joint, marginal, and one-way conditional probabilities. The mosaic plot in Figure 2.20 (a) represents conditioning on age group. The vertical bars represent the conditional probabilities of using/not using Snapchat for each group. The widths of the vertical bars are scaled in proportion to the marginal probabilities for the age groups; the bar for 30-49 is a little wider than the others. The area of each rectangle represents a joint probability; the rectangle for “age 18-29 and uses Snapchat” represents 13% of the total area. The single vertical bar on the right displays the marginal probabilities of using/not using Snapchat.\nFigure 2.20 (b) represents conditioning on Snapchat use. Now the widths of the vertical bars represent the probabilities of using/not using Snapchat, the heights within the bars represent conditional probabilities of each age group given Snapchat use, and the single bar to the right represents the marginal probabilities of age group.\n\n\n\n\n\n\n\n\n\n\n\n(a) Conditioning on age group\n\n\n\n\n\n\n\n\n\n\n\n(b) Conditioning on Snapchat use\n\n\n\n\n\n\n\nFigure 2.20: Mosaic plots for Example 2.45\n\n\n\n\n\n2.6.3 Multiplication rule\nIn Example 2.45 we were given marginal probabilities of age groups and conditional probabilities of Snapchat use given age groups, and we computed joint probabilities. For example:\n\n20% of adults are age 18-29\n65% of adults age 18-29 use Snapchat\nSo 13% of adults are age 18-29 and use Snapchat, \\(0.13 = 0.20\\times 0.65\\).\n\nIn fraction terms,\n\\[\n\\scriptsize{\n\\frac{\\text{adults age 18-29 who use Snapchat}}{\\text{adults}} = \\left(\\frac{\\text{adults age 18-29}}{\\text{adults}}\\right)\\left(\\frac{\\text{adults age 18-29 who use Snapchat}}{\\text{adults age 18-29}}\\right)\n}\n\\]\nThis calculation is an application of the following multiplication rule which we have already applied intuitively in several examples.\n\nLemma 2.6 (Multiplication rule) The probability that two events \\(A\\) and \\(B\\) both occur is\n\n\\[\n\\begin{aligned}\n\\textrm{P}(A \\cap B) & = \\textrm{P}(A|B)\\textrm{P}(B)\\\\\n& = \\textrm{P}(B|A)\\textrm{P}(A)\n\\end{aligned}\n\\]\nThe multiplication rule is just a rearranging of the definition of the conditional probability of one event given another. The multiplication rule says that you should think “multiply” when you see “and”. However, be careful about what you are multiplying: to find a joint probability you need an unconditional probability and an appropriate conditional probability. You can condition either on \\(A\\) or on \\(B\\), provided you have the appropriate marginal probability; often, conditioning one way is easier than the other based on the available information. Be careful: the multiplication rule does not say that \\(\\textrm{P}(A\\cap B)\\) is equal to \\(\\textrm{P}(A)\\textrm{P}(B)\\).\nGenerically, the multiplication rule says \\[\n\\text{joint} = \\text{conditional}\\times\\text{marginal}\n\\] We will see several versions of this general relationship in the remaining chapters.\nThe multiplication rule is useful in situations where conditional probabilities are easier to obtain directly than joint probabilities.\n\n\n\n\n\n\n\nExample 2.46 A standard deck of playing cards has 52 cards, 13 cards (2 through 10, jack, king, queen, ace) in each of 4 suits (hearts, diamonds, clubs, spades). Shuffle a deck and deals cards one at a time without replacement.\n\nCompute the probability that the first card dealt is a heart.\nIf the first card dealt is a heart, determine the conditional probability that the second card is a heart.\nCompute the probability that the first two cards dealt are hearts.\nCompute the probability that the first two cards dealt are hearts and the third card dealt is a diamond.\nShuffle the deck and deal cards one at a time until an ace is dealt, and then stop. Compute the probability that more than 4 cards are dealt. (Hint: consider the first 4 cards dealt.)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.46. \n\nIf the cards are well shuffled, then any of the cards in the deck is equally likely to be the first card dealt. There are 13 hearts out of 52 cards in the deck, so the probability that the first card is a heart is 13/52 = 1/4 = 0.25.\nIf the first card dealt is a heart, there are 51 cards left in the deck, 12 of which are hearts (and all the remaining cards in the deck are equally likely to be the next one drawn). So the conditional probability that the second card is a heart given that the first card is a heart is 12/51 = 0.235.\nUse the multiplication rule: the probability the both cards are hearts is the product of the probability that the first card is a heart and the conditional probability that the second card is a heart given that the first card is a heart, (13/52)(12/51) = 0.0588. If we imagine 132600 repetitions (a convenient choice given these fractions), then we would expect the first card to be a heart in 33150=132600(13/52) repetitions, and among these 33150 repetitions we would expect the second card to be a heart in 7800=33150(12/51) repetitions, so the proportion of repetitions in which both cards are hearts is 7800/132600 = 0.0588.\nThe third card adds a third “stage” but the multiplication rule extends naturally. The probability the first two cards dealt are hearts and the third card dealt is a diamond is (13/52)(12/51)(13/50)= 0.0153, the product of:\n\n13/52, the probability that the first card is a heart,\n12/51, the conditional probability that the second card is a heart given that the first card is a heart, and\n13/50, the conditional probability that the third card is a diamond given that the first two cards are hearts. (If the first two cards are hearts, then there are 50 cards remaining in the deck, of which 13 are diamonds.) Continuing the simulation from the previous part, among the 7800 repetitions in which the first two cards are hearts, we would expect the third card will be a diamond in 2028 = 7800(13/50) repetitions, so the proportion of repetitions in which the first two cards are hearts and the third is a diamond is 2028/132600 = 0.0153.\n\nThe key is to recognize that in this scenario more than 4 cards are needed to obtain the first ace if and only if the first four cards dealt are not aces. The probability that the first 4 cards are not aces is \\((48/52)(47/51)(46/50)(45/49) = 0.719\\).\n\n\n\n\n\nThe multiplication rule extends naturally to more than two events (though the notation gets messy). For three events, we have\n\\[\n\\textrm{P}(A_1 \\cap A_2 \\cap A_3) = \\textrm{P}(A_1)\\textrm{P}(A_2|A_1)\\textrm{P}(A_3|A_1\\cap A_2)\n\\]\nAnd in general, \\[\n\\textrm{P}(A_1\\cap A_2 \\cap A_3 \\cap A_4 \\cap \\cdots) = \\textrm{P}(A_1)\\textrm{P}(A_2|A_1)\\textrm{P}(A_3|A_1\\cap A_2)\\textrm{P}(A_4|A_1\\cap A_2 \\cap A_4)\\cdots\n\\]\nThe multiplication rule is useful for computing probabilities of events that can be broken down into component “stages” where conditional probabilities at each stage are readily available. At each stage, condition on the information about all previous stages.\n\n\n\n\n\n\n\nExample 2.47 The birthday problem concerns the probability that at least two people in a group of \\(n\\) people have the same birthday39. Ignore multiple births and February 29 and assume that the other 365 days are all equally likely40.\n\nIf \\(n=30\\), what do you think the probability that at least two people share a birthday is: 0-20%, 20-40%, 40-60%, 60-80%, 80-100%? How large do you think \\(n\\) needs to be in order for the probability that at least two people share a birthday to be larger than 0.5? Just make your best guesses before proceeding to calculations.\nNow consider \\(n=3\\) people, labeled 1, 2, and 3. What is the probability that persons 1 and 2 have different birthdays?\nWhat is the probability that persons 1, 2, and 3 all have different birthdays given that persons 1 and 2 have different birthdays?\nWhat is the probability that persons 1, 2, and 3 all have different birthdays?\nWhen \\(n = 3\\), what is the probability that at least two people share a birthday?\nNow consider \\(n=4\\). What is the probability that 4 people all have different birthdays?\nWhen \\(n = 4\\), what is the probability that at least two people share a birthday?\nFor \\(n=30\\), compute the probability that none of the people have the same birthday.\nFor \\(n=30\\), compute the probability that at least two people have the same birthday.\nWrite a clearly worded sentence interpreting the probability in the previous part as a long run relative frequency.\nWhen \\(n=30\\), how much more likely than not is it for at least two people to have the same birthday?\nProvide an expression of the probability for a general \\(n\\) and find the smallest value of \\(n\\) for which the probability is over 0.5. (You can just try different values of \\(n\\).)\nWhen \\(n=100\\) the probability is about 0.9999997. If you are in a group of 100 people and no one shares your birthday, should you be surprised? Discuss.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.47. \n\nYour guesses are whatever they are. But many people who have never encountered this problem before say that the probability is 0-20%, and it takes \\(n\\) over at least 100 to get to a probability greater than 0.5.\nWhatever person 1’s birthday is, the probability that person 2 has the same birthday41 is 1/365, so the probability that person 2 has a different birthday than person 1 is 364/365.\nGiven that person 1 and person 2 are born on different days, the probability that person 3 is also born on a different day is 363/365. Notice the importance of the conditioning; if persons 1 and 2 share the same birthday, then the probability that person 3 is born on a different day is 364/365.\nUse the multiplication rule: \\((364/365)(363/365) = 0.992\\), the probability that all three are born on different days, is the product of the probability that persons 1 and 2 are born on different days, and the conditional probability that person 3 is also born on a different day given that the first two are.\nExactly one of the following must be true: (1) all 3 people are born on different days, or (2) at least two people share a birthday. Use the complement rule: when \\(n=3\\), the probability that at least two people share a birthday is \\(1-(364/365)(363/365) = 0.008\\).\nNow consider \\(n=4\\). In order for all 4 people to have different birthdays, the first three people must have different birthdays and the fourth also has to be different from theirs.\n\nThe probability that the first three people have different birthdays is \\((364/365)(363/365)\\) (from a previous part).\nGiven that the first three people have different birthdays, the conditional probability that the fourth person’s birthday is also different is 362/365. Notice the importance of the conditioning; if for example, persons 1 and 2 and 3 all shared the same birthday, then the probability that person 4 is born on a different day is 364/365.\nUsing the multiplication rule, the probability that the first three people have different birthdays and the fourth is also different from theirs is \\((364/365)(363/365)(362/365) = 0.983\\)\n\nExactly one of the following must be true: (1) all 4 people are born on different days, or (2) at least two people share a birthday. Use the complement rule: when \\(n=4\\), the probability that at least two people share a birthday is \\(1-(364/365)(363/365)(362/365) = 0.016\\).\nWe can use the method for \\(n=3\\) and \\(n=4\\). Imagine lining the 30 people up in some order. Let \\(A_2\\) be the event that the first two people have different birthdays, \\(A_3\\) be the event that the first three people have different birthdays, and so on, until \\(A_{30}\\), the event that all 30 people have different birthdays. Notice \\(A_{30}\\subseteq A_{29} \\subseteq \\cdots \\subseteq A_3 \\subseteq A_2\\), so \\(\\textrm{P}(A_{30}) = \\textrm{P}(A_2 \\cap A_3 \\cap \\cdots \\cap A_{30})\\).\n\nThe first person’s birthday can be any one of 365 days. In order for the second person’s birthday to be different, it needs to be on one of the remaining 364 days. So the probability that the second person’s birthday is different from the first is \\(\\textrm{P}(A_2)=\\frac{364}{365}\\).\nNow if the first two people have different birthdays, in order for the third person’s birthday to be different it must be on one of the remaining 363 days. So \\(\\textrm{P}(A_3|A_2) = \\frac{363}{365}\\). Notice that this is a conditional probability. (If the first two people had the same birthday, then the probability that the third person’s birthday is different would be \\(\\frac{364}{365}\\).)\nIf the first three people have different birthdays, in order for the fourth person’s birthday to be different it must be on one of the remaining 362 days. So \\(\\textrm{P}(A_4|A_2\\cap A_3) = \\frac{362}{365}\\).\nAnd so on. If the first 29 people have different birthdays, in order for the 30th person’s birthday to be different it must be on one of the remaining 365-29=336 days. Then using the multiplication rule \\[\\begin{align*}\n\\textrm{P}(A_{30}) & = \\textrm{P}(A_{2}\\cap A_3 \\cap \\cdots \\cap A_{30})\\\\\n& = \\textrm{P}(A_2)\\textrm{P}(A_3|A_2)\\textrm{P}(A_4|A_2\\cap A_3)\\textrm{P}(A_5|A_2\\cap A_3 \\cap A_4)\\cdots \\textrm{P}(A_{30}|A_2\\cap \\cdots \\cap A_{29})\\\\\n& = \\left(\\frac{364}{365}\\right)\\left(\\frac{363}{365}\\right)\\left(\\frac{362}{365}\\right)\\left(\\frac{361}{365}\\right)\\cdots \\left(\\frac{365-30 + 1}{365}\\right)\\approx 0.294\n\\end{align*}\\]\n\n\nBy the complement rule, the probability that at least two people have the same birthday is \\(1-0.294=0.706\\), since either (1) none of the people have the same birthday, or (2) at least two of the people have the same birthday.\nIn about 70% of groups of 30 people at least two people in the group will have the same birthday. For example, if Cal Poly classes all have 30 students, then in about 70% of your classes at least two people in the class will share a birthday.\n\\(0.706 / 0.294 = 2.4.\\) In a group of \\(n=30\\) people it is about 2.4 times more likely to have at least two people with the same birthday than not.\nFor a general \\(n\\), the probability that at least two people have the same birthday is \\[\n1 - \\left(\\frac{364}{365}\\right)\\left(\\frac{363}{365}\\right)\\left(\\frac{362}{365}\\right)\\left(\\frac{361}{365}\\right)\\cdots \\left(\\frac{365-n + 1}{365}\\right)\n\\] See Figure 2.21 which plots this probability as a function of \\(n\\). When \\(n=23\\) this probability is 0.507.\nMaybe, but not because of the 0.999997. 0.999997 is the probability that at least two people in the group of 100 share a birthday. It is NOT the probability that someone shares YOUR birthday. The probability that no one shares your birthday is about \\(0.76\\)—we’ll see how to compute this later—so it’s about 3.1 times more likely than not that someone in a group of 100 people shares your birthday.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.21: Probability of at least one birthday match as a function of the number of people in the room in Example 2.47. For 23 people, the probability of at least one birthday match is 0.507.\n\n\n\n\n\nThat only 23 people are needed to have a better than 50% chance of a birthday match is surprising to many people, because 23 doesn’t seem like a lot of people. But when determining if there is a birthday match, we need to consider every pair of people in the group. In a group of 23 people, there are \\(23(22)/2 = 253\\) different pairs of people, and each one of these pairs has a chance of sharing a birthday.\n\n\n2.6.4 Law of total probability\nThe law of total probability says that a marginal probability can be thought of as a weighted average of “case-by-case” conditional probabilities, where the weights are determined by the likelihood or plausibility of each case.\n\n\n\n\n\n\n\nExample 2.48 Continuing Example 2.45.\n\nDonny Don’t says: “The average of the probabilities of using Snapchat for each age group—0.65, 0.24, 0.12, and 0.02—is 0.2575. Why isn’t \\(\\textrm{P}(C)\\), the probability of using Snapchat equal to 0.2575 (instead of 0.2436)?” Can you answer Donny’s question? (Hint: consider an extreme case; for example, if everyone were age 18-29 what would \\(\\textrm{P}(C)\\) be?)\nShow how \\(\\textrm{P}(C) = 0.2436\\) can be written as a weighted average of the values 0.65, 0.24, 0.12, and 0.02.\nShow how \\(\\textrm{P}(A_1)\\) can be written as a weighted average—what probabilities are being averaged and what are they weights?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.48. \n\nIf all adults were age 18-29 then the overall probability of using Snapchat would be 0.65; if all adults were age 65+ the overall probability of using Snapchat would be 0.02. The overall probability of using Snapchat depends on the age group breakdown. The marginal probabilities of the age groups differ, partly because the age groups cover different numbers of ages.\nWe can write our two-way table calculation of \\(\\textrm{P}(C)\\) in Example 2.45 in formulas as \\[\\begin{align*}\n\\textrm{P}(C) & = \\textrm{P}(C \\cap A_1) + \\textrm{P}(C \\cap A_2) + \\textrm{P}(C \\cap A_3) + \\textrm{P}(C \\cap A_4)\\\\\n& = \\textrm{P}(C|A_1)\\textrm{P}(A_1) + \\textrm{P}(C|A_2)\\textrm{P}(A_2) + \\textrm{P}(C|A_3)\\textrm{P}(A_3) +\\textrm{P}(C|A_4)\\textrm{P}(A_4)\\\\\n& = 0.65\\times 0.20 + 0.24\\times 0.33 + 0.12 \\times 0.25 + 0.02\\times 0.22\\\\\n& = 0.2436\n\\end{align*}\\] The above shows that the overall probability of using Snapchat, \\(\\textrm{P}(C) = 0.2436\\), is a weighted average of the conditional probabilities of using Snapchat for each of the age groups—\\(\\textrm{P}(C|A_1) = 0.65\\), \\(\\textrm{P}(C|A_2) = 0.24\\), \\(\\textrm{P}(C|A_3) = 0.12\\), \\(\\textrm{P}(C|A_4) = 0.02\\)—where the weights are the marginal probabilities of the age groups, \\(\\textrm{P}(A_1) = 0.20\\), \\(\\textrm{P}(A_2) = 0.33\\), \\(\\textrm{P}(A_3) = 0.25\\), \\(\\textrm{P}(A_4) = 0.22\\).\nNow we break down the probability into two cases, using/not using Snapchat. \\[\\begin{align*}\n\\textrm{P}(A_1) & = \\textrm{P}(A_1\\cap C) + \\textrm{P}(A_1 \\cap C^c)\\\\\n& = \\textrm{P}(A_1 | C)\\textrm{P}(C) + \\textrm{P}(A_1 | C^c)\\textrm{P}(C^c)\\\\\n& = 0.5337\\times 0.2436 + 0.0925 \\times (1 - 0.2436)\\\\\n& = 0.20\n\\end{align*}\\] The above shows that the overall probability of being age 18-29, \\(\\textrm{P}(A_1) = 0.20\\), is a weighted average of the conditional probabilities of being age 18-29 for each Snapchat use case—\\(\\textrm{P}(A_1|C) = 0.5337\\), \\(\\textrm{P}(A_1|C^c) = 0.0925\\)—where the weights are the marginal probabilities of the Snapchat use cases, \\(\\textrm{P}(C) = 0.2436\\), \\(\\textrm{P}(C^c) = 1-0.2436 = 0.7564\\). Since the overall probability of not using Snapchat is about 3 times greater than the overall probability of using Snapchat, the conditional probability of being age 18-29 given the adult does not use Snapchat (0.0925) gets about 3 times more weight in the average than the conditional probability of being age 18-29 given the adult does uses Snapchat (0.5337). This is why the overall probability of being age 18-29 (0.20) is closer to 0.0925 than to 0.5337.\n\n\n\n\n\nThe previous example illustrates another version of the law of total probability.\n\nLemma 2.7 (Law of total probability) If \\(C_1, C_2, C_3\\ldots\\) are disjoint events with \\(C_1\\cup C_2 \\cup C_3\\cup \\cdots =\\Omega\\), then42\n\n\\[\\begin{align*}\n    \\textrm{P}(A) & = \\textrm{P}(A |C_1)\\textrm{P}(C_1) + \\textrm{P}(A | C_2)\\textrm{P}(C_2) + \\textrm{P}(A | C_3)\\textrm{P}(C_3) + \\cdots\n\\end{align*}\\]\nThe events \\(C_1, C_2, C_3, \\ldots\\), which represent the “cases”, form a partition of the sample space; each outcome \\(\\omega\\in\\Omega\\) lies in exactly one of the \\(C_i\\). The law of total probability says that we can interpret the unconditional probability \\(\\textrm{P}(A)\\) as a probability-weighted average of the case-by-case conditional probabilities \\(\\textrm{P}(A|C_i)\\) where the weights \\(\\textrm{P}(C_i)\\) represent the probability of encountering each case.\nFor an illustration of the law of total probability, consider the mosaic plots in Figure 2.20. In Figure 2.20 (a), the heights of the orange bars for each age group correspond to the conditional probabilities of using Snapchat given age group (0.65, 0.24, 0.12, 0.02). The widths of these bars are scaled in proportion to the marginal probabilities of the age groups; the width of the bar for age 30-49 is 1.65 (0.33/0.20) times wider than the width for age 18-29. The height of the orange part of the single vertical bar on the right represents the marginal probability of using Snapchat (0.2436), and this is the weighted average of the heights of the the other orange bars (the conditional probabilities of using Snapchat given the age groups), with the weights given by the widths of the other bars (the marginal probabilities of the age groups).\nThe influence of the weighting is even more apparent in the mosaic plot in Figure 2.20 (b). Since the marginal probability of not using Snapchat is greater than the marginal probability of using Snapchat, the marginal probabilities of the age groups are closer to those for the conditional probabilities of the age groups given the adult does not use Snapchat than those given that the adult uses Snapchat.\nConditioning and using the law of probability is an effective strategy in solving many problems, even when the problem doesn’t seem to involve conditioning. For example, when a problem involves iterations or steps it is often useful to condition on the result of the first step.\n\n\n\n\n\n\n\nExample 2.49 You and your friend are playing the “lookaway challenge”.\nThe game consists of possibly multiple rounds. In the first round, you point in one of four directions: up, down, left or right. At the exact same time, your friend also looks in one of those four directions. If your friend looks in the same direction you’re pointing, you win! Otherwise, you switch roles and the game continues to the next round—now your friend points in a direction and you try to look away. As long as no one wins, you keep switching off who points and who looks. The game ends, and the current “pointer” wins, whenever the “looker” looks in the same direction as the pointer.\nSuppose that each player is equally likely to point/look in each of the four directions, independently from round to round. What is the probability that you, starting as the pointer, win the game?\n\nWhy might you expect the probability to not be equal to 0.5?\nIf you start as the pointer, what is the probability that you win in the first round?\nIf \\(p\\) denotes the probability that the player who starts as the pointer wins the game, what is the probability that the player who starts as the looker wins the game? (Note: \\(p\\) is the probability that the person who starts as pointer wins the whole game, not just the first round.)\nLet \\(A\\) be the event that the person who starts as the pointer wins the game, and \\(B\\) be the event that the person who starts as the pointer wins in the first round. What is \\(\\textrm{P}(A|B)\\)?\nFind a simple expression for \\(\\textrm{P}(A | B^c)\\) in terms of \\(p\\). The key is to consider this question: if the player who starts as the pointer does not win in the first round, how does the game behave from that point forward?\nCondition on the result of the first round and set up an equation to solve for \\(p\\).\nInterpret the probability from the previous part as a long run relative frequency.\nHow much more likely is the player who starts as the pointer to win than the player who starts as the looker?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.49. \n\nThe player who starts as the pointer has the advantage of going first; that player can win the game in the first round, but cannot lose the game in the first round. So we might expect the player who starts as the pointer to be more likely to win than the player who starts as the looker.\n1/4. Whichever direction the pointer points, the probability that the looker looks in the same direction is 1/4.Alternatively, if we represent an outcome in the first round as a pair (point, look) then there are 16 possible equally likely outcomes, of which 4 represent pointing and looking in the same direction.\n\\(1-p\\), since the game keeps going until someone wins.\n\\(\\textrm{P}(A|B)=1\\) since if the person who starts as the pointer wins the first round then they win the game.\nThe key is to recognize that if the person who starts as the pointer does not win in the first round, it is like the game starts over with the roles reversed. That is, the player who originally started as the pointer, having not won the first round, is now starting as the looker, and the probability that the player who starts as the looker wins the game is \\(1-p\\). That is, \\(\\textrm{P}(A|B^c) = 1-p\\).\nHere is where we use conditioning and the law of total probability. We condition on what happens in the first round: either the person who starts as the pointer wins the first round and the game ends (event \\(B\\)), or the person who starts as the pointer does not win the the first round and the game continues with the other player becoming the pointer for the next round (event \\(B^c\\)). By the law of total probability \\[\n\\textrm{P}(A) = \\textrm{P}(A|B)\\textrm{P}(B) + \\textrm{P}(A|B^c)\\textrm{P}(B^c)\n\\] From previous parts \\(\\textrm{P}(A)=p\\), \\(\\textrm{P}(B)=1/4\\), \\(\\textrm{P}(B^c)=3/4\\), \\(\\textrm{P}(A|B) = 1\\), and \\(\\textrm{P}(A|B^c)=1-p\\). Therefore \\[\np = (1)(1/4)+ (1-p)(3/4)\n\\] Solve to find \\(p=4/7= 0.571\\).\nOver many games of the lookaway challenge, the player who starts as the pointer wins about 57.1% of games.\nThe player who starts as the pointer is about \\((4/7)/(3/7) = 4/3= 1.33\\) times more likely to win the game than the player who starts as the looker.\n\n\n\n\n\nThe game in Example 2.49 could potentially last any number of rounds (1, 2, 3, …) However, the law of total probability allowed us to take advantage of the iterative nature of the game, and consider only one round rather than enumerating all the possibilities of what might happen over many potential rounds.\n\n\n2.6.5 Conditioning is “slicing and renormalizing”\n\n\n\n\n\n\n\nExample 2.50 Continuing Example 2.45.\n\nHow many times more likely is it for an American adult to be a Snapchat user and age 18-29 than to be:\n\na Snapchat user and age 30-49?\na Snapchat user and age 50-64?\na Snapchat user and age 65+?\n\nHow many times more likely is it for an American adult who uses Snapchat to be age 18-29 than to be:\n\nage 30-49?\nage 50-64?\nage 65+?\n\nWhat do you notice about the answers to the two previous parts?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.50. \n\nUse the joint probabilities we computed in Example 2.45; see the “uses Snapchat” column of the two-way table in the solution to part 4. The joint probability that an American adult is a Snapchat user and age 18-29 is:\n\n\\(\\frac{0.1300}{0.0792} = 1.64\\) times greater than the joint probability that an American adult is a Snapchat user and age 30-49\n\\(\\frac{0.1300}{0.0300} = 4.33\\) times greater than the joint probability that an American adult is a Snapchat user and age 50-64\n\\(\\frac{0.1300}{0.0044} = 29.55\\) times greater than the joint probability that an American adult is a Snapchat user and age 65+\n\nUse the conditional probabilities we computed in Example 2.45; see the solution to part 7. The conditional probability that an American adult is age 18-29 given that they use Snapchat is:\n\n\\(\\frac{0.5337}{0.3251} = \\frac{0.1300/0.2436}{0.0792/0.2436} = 1.64\\) times greater than the conditional probability that an American adult is age 30-49 given that they use Snapchat.\n\\(\\frac{0.5337}{0.1232} = \\frac{0.1300/0.2436}{0.0300/0.2436}= 4.33\\) times greater than the conditional probability that an American adult is age 50-64 given that they use Snapchat.\n\\(\\frac{0.5337}{0.0181} = \\frac{0.1300/0.2436}{0.0044/0.2436} = 29.55\\) times greater than The conditional probability that an American adult is age 65+ given that they use Snapchat.\n\nThe ratios are the same43! Conditioning on using Snapchat zooms in on the “slice” of adults who use Snapchat in the two-way table of joint probabilities. The ratios within this slice are determined by the joint probabilities for adults, as in part 1. The conditional probabilities given Snapchat use that we used to compute ratios in part 2 are simply rescaled versions of the joint probabilities for the “use Snapchat slice”; rescaled so that the slice represents 100% of the probability given that the adult uses Snapchat.\n\n\n\n\n\nThe process of conditioning can be thought of as “slicing and renormalizing”.\n\nExtract the “slice” corresponding to the event being conditioned on (and discard the rest). For example, a slice might correspond to a particular row or column of a two-way table, or a section of a plot.\n\n“Renormalize” the values in the slice so that corresponding probabilities add up to 1.\n\nSlicing determines shape; renormalizing determines scale. Slicing determines relative probabilities; renormalizing just makes sure they add up to 1.\nConsider the mosaic plot in Figure 2.20 (b), where the areas of rectangles represent joint probabilities. The areas of the rectangles in the “uses Snapchat” column represent the joint probabilities we used in part 1 of Example 2.45. Imagine taking the rectangles in this column and unstacking them to make a bar plot with heights determined by the joint probabilities of being in each age group and using Snapchat, as in Figure 2.22 (a). The “slice” determines the shape of the bar plot: The bar for age 18-29 is 1.64 times higher than the bar for age 30-49, 4.33 times higher than the bar for age 50-64, and 29.55 times higher than the bar for age 65+.\nSumming the joint probabilities in Figure 2.22 (a) over the age groups yields 0.2436, the marginal probability that an adult uses Snapchat. Given that the adult uses Snapchat, we want the conditional probabilities of the age groups to sum to 1. Thus we “renormalize” the joint probabilities on the vertical axis—by dividing each by 0.2436—so that they sum to 1 to obtain the conditional probabilities of each age group given that the adult uses Snapchat, displayed in Figure 2.22 (b). Renormalizing only changes the absolute scale of the plot; compare the values on the vertical axes in Figure 2.22, which correspond to joint probabilities on the left and conditional probabilities on the right. Both plots have the same relative shape: the bar for age 18-29 is 1.64 times higher than the bar for age 30-49, 4.33 times higher than the bar for age 50-64, and 29.55 times higher than the bar for age 65+.\n\n\n\n\n\n\n\n\n\n\n\n(a) Joint probability of each age group and Snapchat use for the uses Snapchat slice\n\n\n\n\n\n\n\n\n\n\n\n(b) Renormalized, conditional probability of each age group given that the adult uses Snapchat.\n\n\n\n\n\n\n\nFigure 2.22: Illustration of slicing and renormalizing for Example 2.50\n\n\n\n\n\n\n\n\n\n\nExample 2.51 Each of the three Venn diagrams below represents a sample space with 16 equally likely outcomes. Let \\(A\\) be the yellow / event, \\(B\\) the blue \\ event, and their intersection \\(A\\cap B\\) the green \\(\\times\\) event. Suppose that areas represent probabilities, so that for example \\(\\textrm{P}(A) = 4/16\\).\nFind \\(\\textrm{P}(A|B)\\) for each of the scenarios. Be sure to indicate what represents the “slice” in each scenario.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.23: Three sample spaces with 16 equally outcomes\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.51. In each case we’re conditioning on event \\(B\\), so the slice represents the 4 blue outcomes. Imagine zooming in on the blue (including green) area of each plot: remove the slice with the 4 blue outcomes (and erase the rest) and then magnify (renormalize) the slice so that it is the size of the original rectangle.\n\nLeft: \\(\\textrm{P}(A|B)=0\\). After conditioning on \\(B\\), there are now 4 equally likely outcomes, of which none satisfy \\(A\\).\nMiddle: \\(\\textrm{P}(A|B) = 2/4=1/2\\). After conditioning on \\(B\\), there are now 4 equally likely outcomes, of which 2 satisfy \\(A\\). The green part represents 1/2 of the area of the blue slice.\nRight: \\(\\textrm{P}(A|B) = 1/4\\). After conditioning on \\(B\\), there are now 4 equally likely outcomes, of which 1 satisfies \\(A\\). The green part represents 1/4 of the area of the blue slice.\n\n\n\n\n\nWe will see that “slicing and renormalizing” is a helpful way to conceptualize conditioning, especially when dealing with conditional distributions of random variables.\n\n\n2.6.6 Bayes rule\nBayes’ rule describes how to update uncertainty in light of new information, evidence, or data. We’ll introduce it in the context of two-way tables.\n\n\n\n\n\n\n\nExample 2.52 A recent survey of American adults asked: “Based on what you have heard or read, which of the following two statements best describes the scientific method?”\n\n70% selected “The scientific method produces findings meant to be continually tested and updated over time”. (We’ll call this the “iterative” opinion.)\n14% selected “The scientific method identifies unchanging core principles and truths”. (We’ll call this the “unchanging” opinion).\n16% were not sure which of the two statements was best.\n\nHow does the response to this question change based on education level? Suppose education level is classified as: high school or less (HS), some college but no Bachelor’s degree (college), Bachelor’s degree (Bachelor’s), or postgraduate degree (postgraduate). The education breakdown is\n\nAmong those who agree with “iterative”: 31.3% HS, 27.6% college, 22.9% Bachelor’s, and 18.2% postgraduate.\nAmong those who agree with “unchanging”: 38.6% HS, 31.4% college, 19.7% Bachelor’s, and 10.3% postgraduate.\nAmong those “not sure”: 57.3% HS, 27.2% college, 9.7% Bachelor’s, and 5.8% postgraduate\n\n\nUse the information to construct an appropriate two-way table.\nOverall what percentage of adults have a postgraduate degree? How is this related to the values 18.2%, 10.3%, and 5.8%?\nWhat percent of those with a postgraduate degree agree that the scientific method is “iterative”? How is this related to the values provided?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.52. \n\nSuppose there are 100000 hypothetical American adults. Of these 100000, \\(100000\\times 0.7 = 70000\\) agree with the “iterative” statement. Of the 70000 who agree with the “iterative” statement, \\(70000\\times 0.182 = 12740\\) also have a postgraduate degree. Continue in this way to complete Table 2.18\nOverall 15.11% of adults have a postgraduate degree (15110/100000 in the table). The overall percentage is a weighted average of the three percentages; 18.2% gets the most weight in the average because the “iterative” statement has the highest percentage of people that agree with it compared to “unchanging” and “not sure”. \\[\n0.1511 = (0.70)(0.182) + (0.14)(0.103) + (0.16)(0.058)  \n\\]\nOf the 15110 who have a postgraduate degree 12740 agree with the “iterative” statement, and \\(12740/15110 = 0.843\\). 84.3% of those with a graduate degree agree that the scientific method is “iterative”. The value 0.843 is equal to the product of (1) 0.70, the overall proportion who agree with the “iterative” statement, and (2) 0.182, the proportion of those who agree with the “iterative” statement that have a postgraduate degree; divided by 0.1511, the overall proportion who have a postgraduate degree. \\[\n0.843 = \\frac{0.182 \\times 0.70}{0.1511}\n\\]\n\n\n\n\n\n\n\n\n\nTable 2.18: Two-way table for Example 2.52\n\n\n\n\n\n\nhypothesis\nHS\nCollege\nBachelors\nPostgrad\nTotal\n\n\n\n\niterative\n21910\n19320\n16030\n12740\n70000\n\n\nunchanging\n5404\n4396\n2758\n1442\n14000\n\n\nnot sure\n9168\n4352\n1552\n928\n16000\n\n\nTotal\n36482\n28068\n20340\n15110\n100000\n\n\n\n\n\n\n\n\n\nLemma 2.8 (Bayes rule for events) Bayes’ rule for events44 specifies how a prior probability \\(P(H)\\) of event \\(H\\) is updated in response to the evidence \\(E\\) to obtain the posterior probability \\(P(H|E)\\). \\[\nP(H|E) = \\frac{P(E|H)P(H)}{P(E)}\n\\]\n\n\nEvent \\(H\\) represents a particular hypothesis45 (or model or case)\nEvent \\(E\\) represents observed evidence (or data or information)\n\\(P(H)\\) is the unconditional or prior probability of \\(H\\) (prior to observing evidence \\(E\\))\n\\(P(H|E)\\) is the conditional or posterior probability of \\(H\\) after observing evidence \\(E\\).\n\\(P(E|H)\\) is the likelihood of evidence \\(E\\) given hypothesis (or model or case) \\(H\\)\n\n\n\n\n\n\n\n\nExample 2.53 Continuing Example 2.52. Randomly select an American adult.\n\nConsider the conditional probability that a randomly selected American adult agrees that the scientific method is “iterative” given that they have a postgraduate degree. Identify the hypothesis, prior probability, evidence, likelihood, and posterior probability, and use Bayes’ rule to compute the posterior probability.\nCompute the conditional probability that a randomly selected American adult with a postgraduate degree agrees that the scientific method is “unchanging”.\nCompute the conditional probability that a randomly selected American adult with a postgraduate degree is not sure about which statement is best.\nHow many times more likely is it for an American adult to have a postgraduate degree and agree with the “iterative” statement than to have a postgraduate degree and agree with the “unchanging” statement?\nHow many times more likely is it for an American adult with a postgraduate degree to agree with the “iterative” statement than to agree with the “unchanging” statement?\nWhat do you notice about the answers to the two previous parts?\nHow many times more likely is it for an American adult to agree with the “iterative” statement than to agree with the “unchanging” statement?\nHow many times more likely is it for an American adult to have a postgraduate degree when the adult agrees with the “iterative” statement than when the adult agree with the “unchanging” statement?\nHow many times more likely is it for an American adult with a postgraduate degree to agree with the “iterative” statement than to agree with the “unchanging” statement?\nHow are the values in the three previous parts related?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.53. \n\nThis is essentially the same question as the last part of Example 2.52, just with different terminology.\n\nThe hypothesis is \\(H_1\\), the event that the randomly selected adult agrees with the “iterative” statement.\nThe prior probability is \\(\\textrm{P}(H_1) = 0.70\\), the overall or unconditional probability that a randomly selected American adult agrees with the “iterative” statement.\nThe given “evidence” \\(E\\) is the event that the randomly selected adult has a postgraduate degree. The marginal probability of the evidence is \\(\\textrm{P}(E)=0.1511\\), which can be obtained by the law of total probability as in Example 2.52.\nThe likelihood is \\(\\textrm{P}(E | H_1) = 0.182\\), the conditional probability that the adult has a postgraduate degree (the evidence) given that the adult agrees with the “iterative” statement (the hypothesis).\nThe posterior probability is \\(\\textrm{P}(H_1 |E)=0.843\\), the conditional probability that a randomly selected American adult agrees that the scientific method is “iterative” given that they have a postgraduate degree. By Bayes rule \\[\n\\textrm{P}(H_1 | E) = \\frac{\\textrm{P}(E | H_1) \\textrm{P}(H_1)}{\\textrm{P}(E)} = \\frac{0.182 \\times 0.70}{0.1511} = 0.843\n\\]\n\nLet \\(H_2\\) be the event that the randomly selected adult agrees with the “unchanging” statement; the prior probability is \\(\\textrm{P}(H_2) = 0.14\\). The evidence \\(E\\) is still “postgraduate degree” but now the likelihood of this evidence is \\(\\textrm{P}(E | H_2) = 0.103\\) under the “unchanging” hypothesis. The conditional probability that a randomly selected adult with a postgraduate degree agrees that the scientific method is “unchanging” is \\[\n\\textrm{P}(H_2 | E) = \\frac{\\textrm{P}(E | H_2) \\textrm{P}(H_2)}{\\textrm{P}(E)} = \\frac{0.103 \\times 0.14}{0.1511} = 0.095\n\\]\nLet \\(H_3\\) be the event that the randomly selected adult is “not sure”; the prior probability is \\(\\textrm{P}(H_3) = 0.16\\). The evidence \\(E\\) is still “postgraduate degree” but now the likelihood of this evidence is \\(\\textrm{P}(E | H_3) = 0.058\\) under the “not sure” hypothesis. The conditional probability that a randomly selected adult with a postgraduate degree is “not sure” is \\[\n\\textrm{P}(H_3 | E) = \\frac{\\textrm{P}(E | H_3) \\textrm{P}(H_3)}{\\textrm{P}(E)} = \\frac{0.058 \\times 0.16}{0.1511} = 0.061\n\\]\nThe probability that an American adult has a postgraduate degree and agrees with the “iterative” statement is \\(\\textrm{P}(E \\cap H_1) = \\textrm{P}(E|H_1)\\textrm{P}(H_1) = 0.182\\times 0.70 = 0.1274\\). The probability that an American adult has a postgraduate degree and agrees with the “unchanging” statement is \\(\\textrm{P}(E \\cap H_2) = \\textrm{P}(E|H_2)\\textrm{P}(H_2) = 0.103\\times 0.14 = 0.01442\\). Since \\[\n\\frac{\\textrm{P}(E \\cap H_1)}{\\textrm{P}(E \\cap H_2)} = \\frac{0.182\\times 0.70}{0.103\\times 0.14} = \\frac{0.1274}{0.01442} = 8.835\n\\] an American adult is 8.835 times more likely to have a postgraduate degree and agree with the “iterative” statement than to have a postgraduate degree and agree with the “unchanging” statement.\nThe conditional probability that an American adult with a postgraduate degree agrees with the “iterative” statement is \\(\\textrm{P}(H_1 | E) = \\textrm{P}(E|H_1)\\textrm{P}(H_1)/\\textrm{P}(E) = 0.182\\times 0.70/0.1511 = 0.843\\). The conditional probability that an American adult with a postgraduate degree agrees with the “unchanging” statement is \\(\\textrm{P}(H_2|E) = \\textrm{P}(E|H_2)\\textrm{P}(H_2)/\\textrm{P}(E) = 0.103\\times 0.14/0.1511 = 0.09543\\). Since \\[\n\\frac{\\textrm{P}(H_1 | E)}{\\textrm{P}(H_2 | E)} = \\frac{0.182\\times 0.70/0.1511}{0.103\\times 0.14/0.1511} = \\frac{0.84315}{0.09543} = 8.835\n\\] an American adult with a postgraduate degree is 8.835 times more likely to agree with the “iterative” statement than to agree with the “unchanging” statement.\nThe ratios are the same! Conditioning on having a postgraduate degree just “slices” out the Americans who have a postgraduate degree. The ratios are determined by the overall probabilities for Americans. The conditional probabilities, given postgraduate degree, simply rescale the probabilities for Americans who have a postgraduate degree to add up to 1 (by dividing by 0.1511).\nThis is a ratio of prior probabilities: 0.70 / 0.14 = 5. An American adult is 5 times more likely to agree with the “iterative” statement than to agree with the “unchanging” statement.\nThis is a ratio of likelihoods: 0.182 / 0.103 = 1.767. An American adult is 1.767 times more likely to have a postgraduate degree when the adult agrees with the iterative statement than when the adult agree with the unchanging statement.\nThis is a ratio of posterior probabilities: 0.8432 / 0.0954 = 8.835. An American adult with a postgraduate degree is 8.835 times more likely to agree with the “iterative” statement than to agree with the “unchanging” statement.\nThe ratio of the posterior probabilities is equal to the product of the ratio of the prior probabilities and the ratio of the likelihoods: \\(8.835 = 5 \\times 1.767\\). The posterior is proportional to the product of prior and likelihood.\n\n\n\n\n\nBayes rule is often used when there are multiple hypotheses or cases. Suppose \\(H_1,H_2, \\ldots\\) is a series of distinct hypotheses which together account for all possibilities, and \\(E\\) is any event (evidence). Then Bayes’ rule implies that the posterior probability of any particular hypothesis \\(H_j\\) satisfies \\[\n\\textrm{P}(H_j |E) = \\frac{\\textrm{P}(E|H_j)\\textrm{P}(H_j)}{\\textrm{P}(E)}\n\\]\nThe marginal probability of the evidence, \\(\\textrm{P}(E)\\), in the denominator can be calculated using the law of total probability \\[\n\\textrm{P}(E) = \\textrm{P}(E|H_1) \\textrm{P}(H_1) + \\textrm{P}(E|H_2) \\textrm{P}(H_2) + \\textrm{P}(E|H_3) \\textrm{P}(H_3) + \\cdots\n\\] Since \\(\\textrm{P}(E)\\) is the sum of the terms \\(\\textrm{P}(E|H_j)\\textrm{P}(H_j)\\) over all the hypotheses, Bayes rule implies that \\(\\textrm{P}(H_j |E)\\) is proportional to46 \\(\\textrm{P}(E|H_j)\\textrm{P}(H_j)\\) \\[\\begin{align*}\n\\textrm{P}(H_j |E) & = \\frac{\\textrm{P}(E|H_j)\\textrm{P}(H_j)}{\\textrm{P}(E)}\\\\\n\\textrm{P}(H_j |E) & \\propto \\textrm{P}(E|H_j)\\textrm{P}(H_j)\n\\end{align*}\\]\nIn short, Bayes’ rule says that a posterior probability of a hypothesis is proportional to the product of the prior probability of the hypothesis and the likelihood of the evidence if the hypothesis were true.\n\\[\n\\textbf{posterior} \\propto \\textbf{prior} \\times \\textbf{likelihood}\n\\]\nBayes rule calculations are often organized in a Bayes’ table like Table 2.19 which illustrates “posterior is proportional to likelihood times prior”. The table has one row for each hypothesis and columns for\n\nprior probability: column sum is 1\nlikelihood of the evidence given each hypothesis\n\nlikelihood depends on the evidence; if the evidence changes, the likelihood column changes\nthe sum of the likelihood column is a meaningless number and can be any value\n\nproduct of prior and likelihood: column sum is the marginal probability of the evidence\nposterior probability: column sum is 1\n\n\n\n\n\nTable 2.19: Bayes table representation of the posterior probabilities of each opinion about the scientific method (the hypotheses) given a postgraduate degree (the evidence) in Example 2.53\n\n\n\n\n\n\nhypothesis\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\niterative\n0.70\n0.182\n0.1274\n0.8432\n\n\nunchanging\n0.14\n0.103\n0.0144\n0.0954\n\n\nnot sure\n0.16\n0.058\n0.0093\n0.0614\n\n\nTotal\n1.00\n0.343\n0.1511\n1.0000\n\n\n\n\n\n\n\n\nThe likelihood column in a Bayes table depends on the evidence. In Table 2.19 the evidence is that the American has a postgraduate degree; the likelihood column contains the probability of the same event, \\(E\\) = “the American has a postgraduate degree”, under each of the distinct hypotheses:\n\n\\(\\textrm{P}(E |H_1) = 0.182\\), given the American agrees with the “iterative” statement\n\\(\\textrm{P}(E |H_2) = 0.103\\), given the American agrees with the “unchanging” statement\n\\(\\textrm{P}(E |H_3) = 0.058\\), given the American is “not sure”\n\nSince each of these probabilities is computed under a different case, these values do not need to add up to anything in particular. The sum of the likelihoods is meaningless.\nThe “product” column contains the product of the values in the prior and likelihood columns. In Table 2.19 the product of prior and likelihood for “iterative” (0.1274) is 8.835 (0.1274/0.0144) times higher than the product of prior and likelihood for “unchanging” (0.0144). Therefore, Bayes rule implies that the conditional probability that an American with a postgraduate degree agrees with “iterative” should be 8.835 times higher than the conditional probability that an American with a postgraduate degree agrees with “unchanging”. Similarly, the conditional probability that an American with a postgraduate degree agrees with “iterative” should be \\(0.1274 / 0.0093 = 13.73\\) times higher than the conditional probability that an American with a postgraduate degree is “not sure”, and the conditional probability that an American with a postgraduate degree agrees with “unchanging” should be \\(0.0144 / 0.0093 = 1.55\\) times higher than the conditional probability that an American with a postgraduate degree is “not sure”. The last column just translates these relative relationships into probabilities that sum to 1.\nThe sum of the “product” column is \\(\\textrm{P}(E)\\), the marginal probability of the evidence or “average likelihood”. The sum of the product column represents the result of the law of total probability calculation. However, for the purposes of determining the posterior probabilities, it isn’t really important what \\(P(E)\\) is. Rather, it is the ratio of the values in the “product” column that determine the posterior probabilities. \\(\\textrm{P}(E)\\) is whatever it needs to be to ensure that the posterior probabilities sum to 1 while maintaining the proper ratios.\nBayes rule is just another application of conditioning as “slicing and renormalizing”.\n\nExtract the “slice” corresponding to the event being conditioned on (and discard the rest). For example, a slice might correspond to a particular row or column of a two-way table.\n\n“Renormalize” the values in the slice so that corresponding probabilities add up to 1.\n\nIn Bayes rule, the product of prior and likelihood determines the shape of the slice. Slicing determines relative probabilities; renormalizing just makes sure they “add up” to 1 while maintaining the proper ratios.\n\n\n\n\n\n\n\nExample 2.54 Continuing Example 2.52. Randomly select an American adult. Now suppose we want to compute the posterior probabilities for an American adult’s perception of the scientific method given that the randomly selected American adult has some college but no Bachelor’s degree (“College”).\n\nBefore computing, make an educated guess for the posterior probabilities. In particular, will the changes from prior to posterior be more or less extreme given the American has some college but no Bachelor’s degree than when given the American has a postgraduate degree? Why?\nConstruct a Bayes table and compute the posterior probabilities. Compare to the posterior probabilities given postgraduate degree from the previous examples.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.54. \n\nWe start with the same prior probabilities as before: 0.70 for iterative, 0.14 for unchanging, 0.16 for not sure. Now the evidence is that the American has some college but no Bachelor’s degree. The likelihood of the evidence (“college”) is 0.276 under the iterative hypothesis, 0.314 under the unchanging hypothesis, and 0.272 under the not sure hypothesis. The likelihood of the evidence does not change as much across the different hypotheses when the evidence is “college” than when the evidence was “postgraduate degree”. Therefore, the changes from prior to posterior should be less extreme when the evidence is “college” than when the evidence was “postgraduate degree”. Furthermore, since the likelihood doesn’t vary much across hypotheses when the evidence is “college” we expect the posterior probabilities to be close to the prior probabilities.\nSee Table 2.20 As expected, the posterior probabilities are closer to the prior probabilities when the evidence is “college” than when the evidence is “postgraduate degree”.\n\n\n\n\n\n\n\n\n\nTable 2.20: Bayes table representation of the posterior probabilities of each opinion about the scientific method (the hypotheses) given a college degree (the evidence) in Example 2.54\n\n\n\n\n\n\nhypothesis\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\niterative\n0.70\n0.276\n0.1932\n0.6883\n\n\nunchanging\n0.14\n0.314\n0.0440\n0.1566\n\n\nnot sure\n0.16\n0.272\n0.0435\n0.1551\n\n\nTotal\n1.00\n0.862\n0.2807\n1.0000\n\n\n\n\n\n\n\n\nLike the scientific method, applying Bayes rule is often an iterative process.\n\n\n\n\n\n\n\nExample 2.55 Suppose that you are presented with six boxes, labeled 0, 1, 2, \\(\\ldots\\), 5, each containing five marbles. Box 0 contains 0 green and 5 gold marbles, box 1 contains 1 green and 4 gold, and so on with box \\(i\\) containing \\(i\\) green and \\(5-i\\) gold. One of the boxes is chosen uniformly at random (perhaps by rolling a fair six-sided die), and then you will randomly select marbles from that box, without replacement. Based on the colors of the marbles selected, you will update the probabilities of which box had been chosen.\n\nSuppose that a single marble is selected and it is green. Which box do you think is the most likely to have been chosen? Make a guess for the posterior probabilities for each box. Then construct a Bayes table to compute the posterior probabilities. How do they compare to the prior probabilities?\nNow suppose a second marble is selected from the same box, without replacement, and its color is gold. Which box do you think is the most likely to have been chosen given these two marbles? Make a guess for the posterior probabilities for each box. Then construct a Bayes table to compute the posterior probabilities, using the posterior probabilities from the previous part after the selection of the green marble as the new prior probabilities before seeing the gold marble.\nNow construct a Bayes table corresponding to the original prior probabilities (1/6 each) and the combined evidence that the first ball selected was green and the second was gold. How do the posterior probabilities compare to the previous part?\nIn the previous part, the first ball selected was green and the second was gold. Suppose you only knew that in a sample of two marbles, 1 was green and 1 was gold. That is, you didn’t know which was first or second. How would the previous part change? Should knowing the order matter? Construct the Bayes table and compute the posterior probabilities, and compare to the previous part.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.55. \n\nSince the prior probability is the same for each box, the posterior probability will be greatest for the box for which the likelihood of selecting a green marble (the evidence) is greatest, i.e., box 5 which has a likelihood of drawing a green marble of 1. See Table 2.21. The likelihood column provides the probability of drawing a green marble from each of the boxes, which is \\(i/5\\) for box \\(i\\). (The likelihood of drawing a green marble is 0 for box 0, so box 0 will have a posterior probability of 0.) Since the prior is “flat” the posterior probabilities are proportional to the likelihoods.\nThe posterior probabilities above quantify our uncertainty about the box after observing a single randomly selected marble is green. These probabilities serve as the prior probabilities before drawing any additional marbles. After drawing a green marble without replacement, each box has 4 marbles and 1 less green marble than before, and the likelihood of observing a second marble which is gold is computed for each of the 4-marble boxes. For example, after drawing a green marble, box 2 now contains 1 green marble and 3 gold marbles, so the likelihood of drawing a gold marble from box 2 is 3/4. (The likelihood for box 0 is technically undefined because the probability of drawing a green marble first from box 0 is 0. But since the prior probability for box 0 is 0, the posterior probability for box 0 will be 0 regardless of the likelihood.) See Table 2.22. Since we have observed green and gold in equal proportion in our sample, the posterior probabilities are highest for the boxes with closest to equal proportions of green and gold (box 2 and box 3).\nIn the previous part we updated the posterior probabilities after the first marble and again after selecting the second. What if we start with equally likely prior probabilities and only update the posterior probabilities after selecting both marbles? The likelihood now represents the probability of drawing a green and then a gold marble, without replacement, from each of the boxes. For example, for box 2, the probability of drawing a green marble first is 2/5 and the conditional probability of then drawing a gold marble is 3/4, so the probability of drawing green and then gold is (2/5)(3/4) = 0.3. See Table 2.23. Notice that the posterior probabilities are the same as in the previous part! It doesn’t matter if we sequentially update our probabilities after each draw as in the previous part, or only once after the entire sample is drawn. The posterior probabilities are the same either way.\nWhat if we know the sample contains 1 green and 1 gold marble, but we don’t know which was drawn first? It seems that knowing the order shouldn’t matter in terms of our posterior probabilities. Technically, the likelihood does change since there are two ways to get a sample with 1 green and 1 gold: green followed by gold or gold followed by green. Therefore, each likelihood will be two times larger than in the previous part. For example, for box 2, the probability of green then gold is (2/5)(3/4) and the probability of gold then green is (3/5)(2/4), so the probability of 1 green and 1 gold is (2/5)(3/4) + (3/4)(2/5) = 2(0.3). However, the ratios of the likelihoods have not changed; since each likelihood is twice as large as it was in the previous part, the likelihood from this part is proportional to the likelihood from the previous part. Therefore, since the prior probabilities are the same as in the previous part and the likelihoods are proportionally the same as in the previous part, the posterior probabilities will also be the same as in the previous part. See Table 2.24.\n\n\n\n\n\n\n\n\n\nTable 2.21: Bayes table given a single green marble in Example 2.55\n\n\n\n\n\n\nGreen\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\n0\n0.1667\n0.0\n0.0000\n0.0000\n\n\n1\n0.1667\n0.2\n0.0333\n0.0667\n\n\n2\n0.1667\n0.4\n0.0667\n0.1333\n\n\n3\n0.1667\n0.6\n0.1000\n0.2000\n\n\n4\n0.1667\n0.8\n0.1333\n0.2667\n\n\n5\n0.1667\n1.0\n0.1667\n0.3333\n\n\nsum\n1.0000\nNA\n0.5000\n1.0000\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2.22: Bayes table given the second marble is gold in Example 2.55, using the posterior given a single green marble as the prior\n\n\n\n\n\n\nGreen\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\n0\n0.0000\n1.00\n0.0000\n0.0\n\n\n1\n0.0667\n1.00\n0.0667\n0.2\n\n\n2\n0.1333\n0.75\n0.1000\n0.3\n\n\n3\n0.2000\n0.50\n0.1000\n0.3\n\n\n4\n0.2667\n0.25\n0.0667\n0.2\n\n\n5\n0.3333\n0.00\n0.0000\n0.0\n\n\nsum\n1.0000\nNA\n0.3333\n1.0\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2.23: Bayes table given one green then one gold marble in Example 2.55\n\n\n\n\n\n\nGreen\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\n0\n0.1667\n0.0\n0.0000\n0.0\n\n\n1\n0.1667\n0.2\n0.0333\n0.2\n\n\n2\n0.1667\n0.3\n0.0500\n0.3\n\n\n3\n0.1667\n0.3\n0.0500\n0.3\n\n\n4\n0.1667\n0.2\n0.0333\n0.2\n\n\n5\n0.1667\n0.0\n0.0000\n0.0\n\n\nsum\n1.0000\nNA\n0.1667\n1.0\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2.24: Bayes table given one green and one gold marble in Example 2.55\n\n\n\n\n\n\nGreen\nprior\nlikelihood\nproduct\nposterior\n\n\n\n\n0\n0.1667\n0.0\n0.0000\n0.0\n\n\n1\n0.1667\n0.4\n0.0667\n0.2\n\n\n2\n0.1667\n0.6\n0.1000\n0.3\n\n\n3\n0.1667\n0.6\n0.1000\n0.3\n\n\n4\n0.1667\n0.4\n0.0667\n0.2\n\n\n5\n0.1667\n0.0\n0.0000\n0.0\n\n\nsum\n1.0000\nNA\n0.3333\n1.0\n\n\n\n\n\n\n\n\nLike the scientific method, Bayesian analysis is often an iterative process. Posterior probabilities are updated after observing some information or data. These probabilities can then be used as prior probabilities before observing new data. Posterior probabilities can be sequentially updated as new data becomes available, with the posterior probabilities after the previous stage serving as the prior probabilities for the next stage. The final posterior probabilities only depend upon the cumulative data. It doesn’t matter if we sequentially update the posterior after each new piece of data or only once after all the data is available; the final posterior probabilities will be the same either way. Also, the final posterior probabilities are not impacted by the order in which the data are observed.\n\n\n2.6.7 Conditional probabilities are probabilities\nConditioning on an event \\(E\\) can be viewed as a change in the probability measure47 on \\(\\Omega\\), from \\(\\textrm{P}(\\cdot)\\) to \\(\\textrm{P}(\\cdot|E)\\). That is, the original probability measure \\(\\textrm{P}(\\cdot)\\) assigns probability \\(\\textrm{P}(A)\\), a number, to event \\(A\\), while the conditional probability measure \\(\\textrm{P}(\\cdot |E)\\) assigns probability \\(\\textrm{P}(A|E)\\), a possibly different number, to event \\(A\\). Switching to \\(\\textrm{P}(\\cdot |E)\\) resembles the following.\n\nOutcomes48 in \\(E^c\\) are assigned probability 0 under \\(\\textrm{P}(\\cdot|E)\\). If \\(A\\) consists only of outcomes not in \\(E\\), i.e., if \\(A\\subseteq E^c\\), then \\(\\textrm{P}(A\\cap E)=0\\) so \\(\\textrm{P}(A|E)=0\\).\nThe probabilities of outcomes in \\(E\\) are rescaled so that they comprise 100% of the probability conditional on \\(E\\), i.e. so that \\(\\textrm{P}(E|E)=1\\). This is the effect of dividing by \\(\\textrm{P}(E)\\). For example, if \\(A, B\\subseteq E\\) and \\(\\textrm{P}(A)=2\\textrm{P}(B)\\), then also \\(\\textrm{P}(A|E)=2\\textrm{P}(B|E)\\). That is, if event \\(A\\) is twice as likely as event \\(B\\) according to \\(\\textrm{P}(\\cdot)\\), then the same will be true according to \\(\\textrm{P}(\\cdot|E)\\) provided that the probabilities of none of the outcomes satisfying the events has been zeroed out due to conditioning on \\(E\\).\n\nConditional probabilities are probabilities. Given an event \\(E\\), the function \\(\\textrm{P}(\\cdot|E)\\) defines a valid probability measure. Analogous versions of probability rules hold for conditional probabilities, just condition on event \\(E\\) everywhere.\n\n\\(0 \\le \\textrm{P}(A|E) \\le 1\\) for any event \\(A\\).\n\\(\\textrm{P}(\\Omega|E)=1\\). Moreover, \\(\\textrm{P}(E|E) = 1\\).\nIf events \\(A_1, A_2, \\ldots\\) are disjoint (i.e. \\(A_i \\cap A_j = \\emptyset, i\\neq j\\)) then \\[\n\\textrm{P}(A_1 \\cup A_2 \\cup \\cdots |E) = \\textrm{P}(A_1|E) + \\textrm{P}(A_2|E) + \\cdots\n\\]\n\\(\\textrm{P}(A^c|E) = 1-\\textrm{P}(A|E)\\). (Be careful! Do not confuse \\(\\textrm{P}(A^c|E)\\) with \\(\\textrm{P}(A|E^c)\\).)\n\\(\\textrm{P}(A|E) = \\textrm{P}(A |C_1\\cap E)\\textrm{P}(C_1| E) + \\textrm{P}(A | C_2\\cap E)\\textrm{P}(C_2|E) + \\textrm{P}(A | C_3\\cap E)\\textrm{P}(C_3|E) + \\cdots\\)\n\nAll probabilities are conditional on some information. The probability measure \\(\\textrm{P}\\) assigns probabilities that reflect all assumptions and information about the random phenomenon. When new information becomes available we revise our probabilities. The probability measure \\(\\textrm{P}(\\cdot |E)\\) assigns probabilities that reflect all assumptions and information about the random phenomenon, including the information that event \\(E\\) occurs. Our revised probabilities must still satisfy the logical consistency conditions required by the probability axioms, so \\(\\textrm{P}(\\cdot |E)\\) must be a valid probability measure.\nLike probabilities, conditional probabilities can be interpreted as long run relative frequencies or subjective probabilities. Imagine repeating the random phenomenon a large number of times. The unconditional probability \\(\\textrm{P}(A)\\) can be interpreted as the proportion of repetitions where event \\(A\\) occurs. The conditional probability \\(\\textrm{P}(A|E)\\) can be interpreted as the proportion of repetitions on which event \\(E\\) occurs where event \\(A\\) occurs. From the subjective viewpoint, \\(\\textrm{P}(A)\\) represents the relative plausibility of event \\(A\\), while \\(\\textrm{P}(A|E)\\) represents the relative plausibility of event \\(A\\) given that event \\(E\\) occurs.\n\n\n2.6.8 Conditional distributions (a brief introduction)\nThe probability distribution of a random variable describes the possible values that the random variable can take and the relative likelihoods or plausibilities of these values. A conditional distribution revises this description to reflect newly available information.\n\n\n\n\n\n\n\nExample 2.56 Continuing Example 2.41. Roll a fair four-sided die twice and let \\(X\\) be the sum of the two rolls, and let \\(Y\\) be the larger of the two rolls. We have previously found the joint and marginal distributions of \\(X\\) and \\(Y\\), displayed in Table 2.25; marginal probabilities of \\(X\\) values are in the “Total” column, and marginal probabilities of \\(Y\\) values are in the “Total” row.\n\nCompute and interpret in context \\(\\textrm{P}(X=6|Y=4)\\).\nInterpret \\(\\textrm{P}(X=6|Y=4)\\) as a long run relative frequency.\nConstruct a table and plot to represent the conditional distribution of \\(X\\) given \\(Y=4\\) by “slicing and renormalizing”.\nInterpret the the conditional distribution of \\(X\\) given \\(Y=4\\) as a long run relative frequency distribution.\nConstruct a table and plot to represent the conditional distribution of \\(X\\) given \\(Y=3\\).\nConstruct a table and plot to represent the conditional distribution of \\(X\\) given \\(Y=2\\).\nConstruct a table and plot to represent the conditional distribution of \\(X\\) given \\(Y=1\\).\nCompute and interpret \\(\\textrm{P}(Y=4|X=6)\\).\nConstruct a table and plot to represent the distribution of \\(Y\\) given \\(X=6\\).\nConstruct a table and plot to represent the distribution of \\(Y\\) given \\(X=5\\).\nConstruct a table and plot to represent the distribution of \\(Y\\) given \\(X=4\\).\n\n\n\n\n\n\n\n\nTable 2.25: Two-way table representation of joint and marginal distributions of \\(X\\) and \\(Y\\), the sum and the larger (or common value if a tie) of two rolls of a fair four-sided die. Possible values of \\(X\\) are in the leftmost column; possible values of \\(Y\\) are in the top row.\n\n\n\n\n\n\\((x, y)\\)\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\nTotal\n\n\n2\n1/16\n0\n0\n0\n1/16\n\n\n3\n0\n2/16\n0\n0\n2/16\n\n\n4\n0\n1/16\n2/16\n0\n3/16\n\n\n5\n0\n0\n2/16\n2/16\n4/16\n\n\n6\n0\n0\n1/16\n2/16\n3/16\n\n\n7\n0\n0\n0\n2/16\n2/16\n\n\n8\n0\n0\n0\n1/16\n1/16\n\n\nTotal\n1/16\n3/16\n5/16\n7/16\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.56. \n\nRemember that \\(\\{X=6\\}\\) and \\(\\{Y=4\\}\\) are events, so we use the definition of conditional probability for events. \\[\n\\textrm{P}(X = 6 | Y = 4) =\\frac{\\textrm{P}(X = 6, Y = 4)}{\\textrm{P}(Y=4)} = \\frac{2/16}{7/16} = 2/7 =0.286\n\\] The conditional probability that the sum of the rolls is 6 given that the larger roll is 4 is 2/7.\nWe can roll a pair of fair four-sided dice and measure the sum and larger of the rolls. If we repeat this process many times then we would expect the sum to be 6 on 28.6% of the repetitions for which the larger roll is 4. That is, among pairs of rolls of a fair four-sided die that result in a larger roll of 4, the sum of the rolls is 6 in 28.6% of these pairs.\nWe could find \\(\\textrm{P}(X= x|Y=4)\\) as in the previous part for each of the possible values of \\(x\\). We can also slice the column of the joint distribution table corresponding to \\(Y=4\\), and then renormalize. If \\(Y = 4\\) then \\(X\\) is either 5, 6, 7, or 8; \\(Y\\) is equally likely to be 5, 6, or 7, and each of those values is twice as likely as 8. That is, the joint probabilities in the \\(Y=4\\) column (slice) are in a 2:2:2:1 ratio for the values 5, 6, 7, 8, and renormalizing yields probabilities of 2/7, 2/7, 2/7, 1/7. The table below displays the conditional distribution of \\(X\\) given \\(Y=4\\). Note well that this is a distribution of values of \\(X\\).\n\n\n\n\\(x\\)\n\\(\\textrm{P}(X = x|Y = 4)\\)\n\n\n\n\n5\n2/7\n\n\n6\n2/7\n\n\n7\n2/7\n\n\n8\n1/7\n\n\n\nWe can roll a pair of fair four-sided dice and measure the sum and larger of the rolls. If we repeat this process many times then among only the repetitions for which the larger roll is 4 we would expect the sum to be 5 on 28.6%, 6 on 28.6%, 7 on 28.6%, and 8 on 14.3% of these repetitions.\nSlice the column of the joint distribution table corresponding to \\(Y=3,\\) and then renormalize. Given \\(Y=3,\\) \\(X\\) is equally likely to be either 4 or 5, and each of those values is twice as likely as 6. Note that changing the condition from \\(\\{Y=4\\}\\) to \\(\\{Y=3\\}\\) changes the possible values of \\(X\\), along with their probabilities.\n\n\n\n\\(x\\)\n\\(\\textrm{P}(X = x | Y = 3)\\)\n\n\n\n\n4\n2/5\n\n\n5\n2/5\n\n\n6\n1/5\n\n\n\nSlice the column of the joint distribution table corresponding to \\(Y=2,\\) and then renormalize. Given \\(Y=2,\\) \\(X\\) is twice as likely to be 3 than 4.\n\n\n\n\\(x\\)\n\\(\\textrm{P}(X = x | Y = 2)\\)\n\n\n\n\n3\n2/3\n\n\n4\n1/3\n\n\n\nGiven \\(Y=1,\\) \\(X\\) is equal to 2 with probability 1: \\(\\textrm{P}(X = 2 | Y = 1)=1\\).\nRemember that \\(\\textrm{P}(X = 6 | Y = 4)\\) and \\(\\textrm{P}(Y = 4 | X = 6)\\) measure different probabilities. \\[\n\\textrm{P}(Y = 4 | X = 6) =\\frac{\\textrm{P}(X = 6, Y = 4)}{\\textrm{P}(X=6)} = \\frac{2/16}{3/16} = 2/3 =0.667\n\\] The conditional probability that the larger roll is 4 given that the sum of the rolls is 6 given is 2/3.\nWe could find \\(\\textrm{P}(Y=y|X = 6)\\) for each possible value of \\(Y\\) as in the previous part. We can also slice the row of the joint distribution table corresponding to \\(X=6\\), and then renormalize. If \\(X = 6\\) then \\(Y\\) is either 3 or 4, and \\(Y\\) is twice as likely to be 4 than 3. The table below represents the conditional distribution of \\(Y\\) given \\(X = 6\\). Note that this is a distribution of values of \\(Y\\).\n\n\n\n\\(y\\)\n\\(\\textrm{P}(Y = y | X = 6)\\)\n\n\n\n\n3\n1/3\n\n\n4\n2/3\n\n\n\nSlice the row of the joint distribution table corresponding to \\(X=5\\), and then renormalize. If \\(X=5\\) then \\(Y\\) is equally likely to be 3 or 4.\n\n\n\n\\(y\\)\n\\(\\textrm{P}(Y = y | X = 5)\\)\n\n\n\n\n3\n1/2\n\n\n4\n1/2\n\n\n\nSlice the row of the joint distribution table corresponding to \\(X=4\\), and then renormalize. If \\(X=4\\) then \\(Y\\) is twice as likely to be 3 than 2. Note that changing the condition from \\(\\{X=5\\}\\) to \\(\\{X=4\\}\\) changes the possible values of \\(Y\\), along with their probabilities.\n\n\n\n\\(y\\)\n\\(\\textrm{P}(Y = y | X = 5)\\)\n\n\n\n\n2\n1/3\n\n\n3\n2/3\n\n\n\n\n\n\n\n\nThe conditional distribution of \\(Y\\) given \\(X=x\\) is the distribution of \\(Y\\) values over only those outcomes for which \\(X=x\\). It is a distribution on values of \\(Y\\) only; treat \\(x\\) as a fixed constant when conditioning on the event \\(\\{X=x\\}\\).\nConditional distributions can be obtained from a joint distribution by slicing and renormalizing. The conditional distribution of \\(Y\\) given \\(X=x\\), where \\(x\\) represents a particular number, can be thought of as:\n\nthe slice of the joint distribution corresponding to \\(X=x\\), a distribution on values of \\(Y\\) alone with \\(X=x\\) fixed\nrenormalized so that the slice accounts for 100% of the probability over the possible values of \\(Y\\)\n\nThe shape of the conditional distribution of \\(Y\\) given \\(X=x\\) is determined by the shape of the slice of the joint distribution over values of \\(Y\\) for the fixed \\(x\\).\nFor example, consider the joint distribution of \\(X\\) and \\(Y\\) in Example 2.56, depicted in Figure 2.18. To find the conditional distribution of \\(X\\) given \\(Y=4\\), remove the slice corresponding to \\(y=4\\) in Figure 2.18, and then renormalize to obtain the plot in the bottom right of Figure 2.24.\nFor each fixed \\(x\\), the conditional distribution of \\(Y\\) given \\(X=x\\) is a different distribution on values of the random variable \\(Y\\). There is not one “conditional distribution of \\(Y\\) given \\(X\\)”, but rather a family of conditional distributions of \\(Y\\) given different values of \\(X\\). In Example 2.56, Figure 2.25 depicts the conditional distribution of \\(Y\\) given \\(X=x\\) for each value \\(x\\) of \\(X\\), and Figure 2.24 depicts the conditional distribution of \\(X\\) given \\(Y=y\\) for each value \\(y\\) of \\(Y\\). Notice how each conditional distribution corresponds to a renormalized slice of the joint distribution depicted in Figure 2.18. We can also think of conditioning as slicing (and renormalizing) the joint distribution depicted in the tile plot in Figure 2.19, just remember that color represents probability in the tile plot.\n\n\n\n\n\n\n\n\nFigure 2.24: Impulse plots representing the family of conditional distributions of \\(X\\) given \\(Y\\) in Example 2.56. Each plot represents a conditional distribution of \\(X\\) given \\(Y=y\\) for a particular value of \\(y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.25: Impulse plots representing the family of conditional distributions of \\(Y\\) given \\(X\\) in Example 2.56). Each plot represents a conditional distribution of \\(Y\\) given \\(X=x\\) for a particular value of \\(x\\)\n\n\n\n\n\nWe can also depict families of conditional distributions in mosaic plots; see Figure 2.26. A mosaic plot represents a family of conditional distributions where color represents the possible values of one variable and area represents probability.\n\n\n\n\n\n\nWarning\n\n\n\nBe careful to distinguish between mosaic plots (like Figure 2.26) and tile plots (like Figure 2.19). A tile plot represents a joint distribution and color represents probability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Conditional distributions of \\(Y\\) given each value of \\(X\\); color represents values of \\(Y\\).\n\n\n\n\n\n\n\n\n\n\n\n(b) Conditional distributions of \\(X\\) given each value of \\(Y\\); color represents values of \\(X\\).\n\n\n\n\n\n\n\nFigure 2.26: Mosaic plots for Example 2.56, where \\(X\\) is the sum and \\(Y\\) is the max of two rolls of a fair four-sided die.\n\n\n\n\n\n\n\n\n\n\nExample 2.57 Continuing Example 2.56.\n\nCompute the probability-weighted average value of \\(X\\) given \\(Y=4\\).\nInterpret the value from the previous part as a long run average value in context.\nWithout doing any calculations, determine if the probability-weighted average value of \\(X\\) given \\(Y=3\\) is greater than, less than, or equal to the value from part 1.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.57. \n\nMultiply each possible of \\(X\\) by its conditional probability given \\(Y=4\\) and sum \\[\n\\small{\n5 \\times 2/7 + 6 \\times 2/7 + 7 \\times 2/7 + 8 \\times 1/7 = 44/7 = 6.286\n}\n\\]\nWe can roll a pair of fair four-sided dice and measure the sum and larger of the rolls. If we repeat this process many times and average the values of the sum for repetitions with a larger roll of 4 we would expect the average to be around 6.286.\nThe probability-weighted average value of \\(X\\) given \\(Y=3\\) is less than the probability-weighted average value of \\(X\\) given \\(Y=4\\) is greater than. Compare the conditional distributions; \\(X\\) tends to be larger if \\(Y=4\\) than if \\(Y=3\\).\n\n\n\n\n\nEach conditional distribution is a distribution, so we can summarize its characteristics, such as expected value. The value in part 1 of Example 2.57 is the conditional expected value of \\(X\\) given \\(Y=4\\), denoted \\(\\textrm{E}(X|Y=4)\\). The conditional expected value of \\(Y\\) given \\(X=x\\) represents the long run average of values of \\(Y\\) over only \\((X, Y)\\) pairs with \\(X=x\\). Since each value of \\(x\\) typically corresponds to a different conditional distribution of \\(Y\\) given \\(X=x\\), the conditional expected value will typically be a function of \\(x\\).\nWe will explore conditioning in more detail throughout the book, including conditional distributions when continuous random variables are involved. We will also see how to use conditioning as a problem-solving tool.\n\n\n2.6.9 Exercises\n\nExercise 2.16 Each question on a multiple choice test has four options. You know with certainty the correct answers to 70% of the questions. For 20% of the questions, you can eliminate two of the incorrect choices with certainty, but you guess at random among the remaining two options. For the remaining 10% of questions, you have no idea and guess one of the four options at random.\nRandomly select a question from this test. What is the probability that you answer the question correctly?\n\nConstruct an appropriate twoway table and use it to find the probability of interest.\nFor any given question on the exam, your probability of answering it correctly is either 1, 0.5, or 0.25, depending on if you know it, can eliminate two choices, or are just guessing. How does your probability of correcting answering a randomly selected question relate to these three values? Which value — 1, 0.5, or 0.25 —is the overall probability closest to, and why?\n\n\n\n\nExercise 2.17 Imagine a light that flashes every few seconds49. The light randomly flashes green with probability 0.75 and red with probability 0.25, independently from flash to flash.\n\nWrite down a sequence of G’s (for green) and R’s (for red) to predict the colors for the next 40 flashes of this light. Before you read on, please take a minute to think about how you would generate such a sequence yourself.\nMost people produce a sequence that has 30 G’s and 10 R’s, or close to those proportions, because they are trying to generate a sequence for which each outcome has a 75% chance for G and a 25% chance for R. That is, they use a strategy in which they predict G with probability 0.75, and R with probability 0.25. How well does this strategy do? Compute the probability of correctly predicting any single item in the sequence using this strategy.\nDescribe a better strategy. (Hint: can you find a strategy for which the probability of correctly predicting any single flash is 0.75?)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#sec-independence",
    "href": "language-probability.html#sec-independence",
    "title": "2  The Language of Probability",
    "section": "2.7 Independence",
    "text": "2.7 Independence\nWe revise probabilities of events and distributions of random variables when new information becomes available. In this section we investigate situations where conditioning on information does not change probabilities or distributions.\n\n2.7.1 Independence of two events\nIn general, the conditional probability of event \\(A\\) given some other event \\(B\\) is usually different from the unconditional probability of \\(A\\); that is, in general \\(\\textrm{P}(A | B) \\neq \\textrm{P}(A)\\). Knowledge of the occurrence of event \\(B\\) typically influences the probability of event \\(A\\), and vice versa. If so, we say that events \\(A\\) and \\(B\\) are dependent.\nHowever, in some situations knowledge of the occurrence of one event does not influence the probability of another. For example, if a coin is flipped twice then knowing that the first flip landed on heads does not change the probability that the second flips lands on heads. In such situations we say the events are independent.\n\n\n\n\n\n\n\nExample 2.58 Consider the following hypothetical data.\n\n\n\n\n\n\n\n\n\n\nDemocrat (\\(D\\))\nNot Democrat (\\(D^c\\))\nTotal\n\n\n\n\nLoves puppies (\\(L\\))\n180\n270\n450\n\n\nDoes not love puppies (\\(L^c\\))\n20\n30\n50\n\n\nTotal\n200\n300\n500\n\n\n\nSuppose a person is selected uniformly at random from this group. Let \\(L\\) be the event that the selected person loves puppies and let \\(D\\) be the event that the selected person is a Democrat.\n\nCompute and interpret \\(\\textrm{P}(L)\\).\nCompute and interpret \\(\\textrm{P}(L|D)\\).\nCompute and interpret \\(\\textrm{P}(L|D^c)\\).\nWhat do you notice about \\(\\textrm{P}(L)\\), \\(\\textrm{P}(L|D)\\), and \\(\\textrm{P}(L|D^c)\\)?\nCompute and interpret \\(\\textrm{P}(D)\\).\nCompute and interpret \\(\\textrm{P}(D|L)\\).\nCompute and interpret \\(\\textrm{P}(D|L^c)\\).\nWhat do you notice about \\(\\textrm{P}(D)\\), \\(\\textrm{P}(D|L)\\), and \\(\\textrm{P}(D|L^c)\\)?\nCompute and interpret \\(\\textrm{P}(D \\cap L)\\).\nWhat is the relationship between \\(\\textrm{P}(D \\cap L\\)) and \\(\\textrm{P}(D)\\) and \\(\\textrm{P}(L)\\)?\nWhen randomly selecting a person from this particular group, would you say that events \\(D\\) and \\(L\\) are independent? Why?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.58. \n\nThe probability that the randomly selected person loves puppies is \\(\\textrm{P}(L)=450/500=0.9\\).\nThe conditional probability that the randomly selected person loves puppies given that the person is a Democrat is \\(\\textrm{P}(L|D)=180/200=0.9\\).\nThe conditional probability that the randomly selected person loves puppies given that the person is not a Democrat is \\(\\textrm{P}(L|D^c)=270/300=0.9\\).\n\\(\\textrm{P}(L)=\\textrm{P}(L|D)=\\textrm{P}(L|D^c)=0.9\\). Regardless of whether or not the person is a Democrat the probability that they love puppies is 0.9, the overall probability that a person loves puppies.\nThe probability that the randomly selected person is a Democrat is \\(\\textrm{P}(D)=200/500=0.4\\).\nThe conditional probability that the randomly selected person is a Democrat given that the person loves puppies is \\(\\textrm{P}(D|L)=180/450=0.4\\).\nThe conditional probability that the randomly selected person is a Democrat given that the person does not love puppies is \\(\\textrm{P}(D|L^c)=20/50=0.4\\).\n\\(\\textrm{P}(D)=\\textrm{P}(D|L)=\\textrm{P}(D|L^c)=0.4\\). Regardless of whether or not the person loves puppies the probability that the person is a Democrat is 0.4, the overall probability that a person is a Democrat.\nThe probability that the randomly selected person is a Democrat and loves puppies is \\(\\textrm{P}(D \\cap L)=180/500=0.36\\).\n\\(\\textrm{P}(D \\cap L) = 0.36 = (0.4)(0.9)=\\textrm{P}(D)\\textrm{P}(L)\\). In this case, the joint probability is a product of the marginal probabilities.\nYes, the events \\(D\\) and \\(L\\) are independent. Knowing whether or not the person is a Democrat does not change the probability that the person loves puppies, and vice versa.\n\n\n\n\n\n\nDefinition 2.8 For a probability space with probability measure \\(\\textrm{P}\\), two events \\(A\\) and \\(B\\) are50 independent if \\(\\textrm{P}(A \\cap B) = \\textrm{P}(A)\\textrm{P}(B)\\).\n\nIn general, the multiplication rule says \\[\\begin{align*}\n\\textrm{P}(A \\cap B) & = \\textrm{P}(A|B)\\textrm{P}(B)\\\\\n\\text{Joint} & = \\text{Conditional}\\times\\text{Marginal}\n\\end{align*}\\] For independent events, the multiplication rule simplifies \\[\\begin{align*}\n\\text{If $A$ and $B$ are independent then } && \\textrm{P}(A \\cap B) & = \\textrm{P}(A)\\textrm{P}(B)\\\\\n\\text{If independent then } && \\text{Joint} & = \\text{Product of Marginals}\n\\end{align*}\\]\n\n\n2.7.2 Interpreting independence\nIntuitively, events \\(A\\) and \\(B\\) are independent if the knowing whether or not one occurs does not change the probability of the other. The following lemma51 formalizes this idea.\n\nLemma 2.9 (Equivalent conditions for independence of two events) For a probability space with probability measure \\(\\textrm{P}\\) the following statements are equivalent52 for events \\(A\\) and \\(B\\) (with \\(0&lt;\\textrm{P}(A)&lt;1\\) and \\(0&lt;\\textrm{P}(B)&lt;1\\)).\n\n\\[\\begin{align*}\n\\text{$A$ and $B$} & \\text{ are independent} & &\\\\\n\\textrm{P}(A \\cap B) & = \\textrm{P}(A)\\textrm{P}(B) & & \\\\\n\\textrm{P}(A|B) & = \\textrm{P}(A) & & \\\\\n\\textrm{P}(A|B) & = \\textrm{P}(A|B^c) & & \\\\\n\\textrm{P}(B|A) & = \\textrm{P}(B) & & \\\\\n\\textrm{P}(B|A) & = \\textrm{P}(B|A^c) & &\\\\\n\\textrm{P}(A^c \\cap B) & = \\textrm{P}(A^c)\\textrm{P}(B) & & \\text{that is, $A^c$ and $B$ are independent}\\\\\n\\textrm{P}(A \\cap B^c) & = \\textrm{P}(A)\\textrm{P}(B^c) & & \\text{that is, $A$ and $B^c$ are independent}\\\\\n\\textrm{P}(A^c \\cap B^c) & = \\textrm{P}(A^c)\\textrm{P}(B^c) & & \\text{that is, $A^c$ and $B^c$ are independent}\n\\end{align*}\\]\n\n\n\n\n\n\n\nExample 2.59 Figure 2.27 displays four mosaic plots, each representing probabilities corresponding to two events \\(A\\) and \\(B\\). Which of the mosaic plots represent independent events?\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.27: Four different mosaic plots for two events \\(A\\) and \\(B\\). Example 2.59 discusses which plots represent independent events.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.59. The bottom two plots represent independent events. In these situations \\(\\textrm{P}(B|A) = \\textrm{P}(B|A^c) = \\textrm{P}(B)\\).\n\n\n\n\n\n\n\n\n\n\n\nExample 2.60 Continuing Example 2.51. In which of the three scenarios represented in ?fig-venn-conditional are events \\(A\\) and \\(B\\) independent? Try your intuition first, and then determine which scenarios represent independence by computing and comparing appropriate probabilities.\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.60. We can check any one of the conditions for independence in Lemma 2.9. We’ll compute and compare \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(A |B)\\) for each scenario. In each case, \\(\\textrm{P}(A)=4/16\\). Condition on event \\(B\\) by zooming in on the blue slice, and see if \\(\\textrm{P}(A|B)\\) is the same as \\(\\textrm{P}(A)\\).\n\nLeft: \\(\\textrm{P}(A|B)=0\\neq 4/16 = \\textrm{P}(A)\\). Therefore, events \\(A\\) and \\(B\\) are not independent.\nMiddle: \\(\\textrm{P}(A|B) = 2/4\\neq 4/16 = \\textrm{P}(A)\\). Therefore, events \\(A\\) and \\(B\\) are not independent.\nRight: \\(\\textrm{P}(A|B) = 1/4= 4/16 = \\textrm{P}(A)\\). Therefore, events \\(A\\) and \\(B\\) are independent. The ratio of yellow to total is the same as the ratio of the yellow (green) part of blue to blue. If we zoom into the blue part of the picture (slice) and then resize it to the size of the original picture (renormalize), then the yellow (green) part takes up 1/4 of the area just as the yellow part did in the original picture.\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nDo not confuse “disjoint” with “independent”. Disjoint means two events do not “overlap”. Independence means two events “overlap in just the right way”. You can pretty much forget “disjoint” exists; you will naturally apply the addition rule for disjoint events correctly without even thinking about it. Independence is much more important and useful, but also requires more care.\n\n\n\n\n\n\n\n\n\nExample 2.61 Roll two fair four-sided dice, one green and one gold. There are 16 total possible outcomes (roll on green, roll on gold), all equally likely. Consider the event \\(E=\\{\\text{the green die lands on 1}\\}\\). Answer the following questions by computing and comparing appropriate probabilities.\n\nConsider \\(A=\\{\\text{the gold die lands on 4}\\}\\). Are \\(A\\) and \\(E\\) independent?\nConsider \\(B=\\{\\text{the sum of the dice is 3}\\}\\). Are \\(B\\) and \\(E\\) independent?\nConsider \\(C=\\{\\text{the sum of the dice is 5}\\}\\). Are \\(C\\) and \\(E\\) independent?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.61. \\(\\textrm{P}(E)=4/16=1/4\\) since there 4 out of 16 equally likely outcomes satisfy event \\(E\\): \\(E=\\{(1, 1), (1, 2), (1, 3), (1, 4)\\}\\).\n\nThere are 4 outcomes which satisfy event \\(A=\\{(1, 4), (2, 4), (3, 4), (4, 4)\\}\\), all equally likely, only one, (1, 4), of which also satisfies event \\(E\\). \\(\\textrm{P}(E|A) = 1/4 = 4/16 = \\textrm{P}(E)\\), so events \\(A\\) and \\(E\\) are independent. Intuitively, the ratio of the \\(E\\) part of \\(A\\) to \\(A\\) is equal to the ratio of \\(E\\) to the sample space.\nThere is only 1 outcome which satisfies event \\(B=\\{(1, 1)\\}\\) and it also satisfies event \\(E\\). \\(\\textrm{P}(E|B) = 1 \\neq 4/16 = \\textrm{P}(E)\\), so events \\(A\\) and \\(E\\) are not independent. If you know the sum of the dice is 2, then the green die must have landed on 1.\nThere are 4 outcomes which satisfy event \\(C=\\{(1, 4), (2, 3), (3, 2), (4, 1)\\}\\), all equally likely, only one, (1, 4), of which also satisfies event \\(E\\). \\(\\textrm{P}(E|C) = 1/4 = 4/16 = \\textrm{P}(E)\\), so events \\(C\\) and \\(E\\) are independent. The ratio of the \\(E\\) part of \\(C\\) to \\(C\\) is the ratio of \\(E\\) to the sample space.\n\n\n\n\n\nIndependence concerns whether or not the occurrence of one event affects the probability of the other. Conditioning involves slicing and renormalizing; independence concerns whether the renormalized slice matches the original picture. Given two events it is not always obvious whether or not they are independent. When there is any doubt, be sure to check directly if one of the equivalent conditions for independence is true (that is, the directly compute the left side and right side and see if they’re equal).\n\n\n2.7.3 Independence is an assumption\nIndependence is often a reasonable assumption based on the physical properties of the random phenomenon. But remember that it is an assumption, which might or might not match reality.\n\n\n\n\n\n\n\nExample 2.62 You have just been elected president (congratulations!) and you need to choose one of four people to sing the national anthem at your inauguration: Alicia, Ariana, Beyonce, or Billie. You write their names on some cards—each name on possibly a different number of cards—shuffle the cards, and draw one. Let \\(A\\) be the event that either Alicia or Ariana is selected, and \\(B\\) be the event that either Alicia or Beyonce is selected.\nThe following questions ask you to specify probability models satisfying different conditions. You can specify the model by identifying how many cards each person’s name is written on. For each model, find the probabilities of \\(A\\), \\(B\\), and \\(A\\cap B\\), and verify whether or not events \\(A\\) and \\(B\\) are independent according to the model.\n\nSpecify a probability model according to which the events \\(A\\) and \\(B\\) are independent.\nSpecify a different probability model according to which the events \\(A\\) and \\(B\\) are independent.\nSpecify a probability model according to which the events \\(A\\) and \\(B\\) are not independent.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.62. Note that \\(A \\cap B\\) is the event that Alicia is selected.\n\nWrite each person’s name on exactly one card, so the 4 outcomes are equally likely. Let \\(\\textrm{P}\\) represent this probability measure. Then \\(\\textrm{P}(A \\cap B) = 1/4 = (2/4)(2/4)=\\textrm{P}(A)\\textrm{P}(B)\\), so \\(A\\) and \\(B\\) are independent.\n\nThe previous part involves a situation where \\((1/2)(1/2)=1/4=(2/4)(2/4)\\). We try to construct a situation where \\((1/3)(1/3)=1/9=(3/9)(3/9)\\). Suppose there are 9 cards, with Alicia on 1, Ariana and Beyonce on 2 each, and Billie on 4.\n\n\n\nOutcome\nAlicia\nAriana\nBeyonce\nBillie\n\n\n\n\nNumber of cards\n1\n2\n2\n4\n\n\nProbability\n1/9\n2/9\n2/9\n4/9\n\n\n\nLet \\(\\textrm{Q}\\) represent this probability measure. Then \\(\\textrm{Q}(A \\cap B) = 1/9 = (3/9)(3/9)=\\textrm{Q}(A)\\textrm{Q}(B)\\), so events \\(A\\) and \\(B\\) are independent. Elaborating,\n\nThere are 3 cards that satisfy \\(A\\) and 6 that don’t so \\(A\\) is 3/6 = 1/2 as likely to occur than not.\nIf \\(B\\) occurs, then it’s either Alicia (satisfies \\(A\\), 1 card) or Beyonce (does not satisfy \\(A\\), 2 cards), so given that \\(B\\) occurs then \\(A\\) is 1/2 times as likely to occur than not.\nIf \\(B\\) does not occur, then it’s either Ariana (satifies \\(A\\), 2 cards) or Billie (does not satisfy \\(A\\), 4 cards), so given that \\(B\\) does not occur then \\(A\\) is 2/4 = 1/2 times as likely to occur than not.\n\nKnowing whether or not \\(B\\) occurs doesn’t change the chance of \\(A\\) occurring, so \\(A\\) and \\(B\\) are independent according to this probability model.\nIndependence requires probabilities to overlap in just the right way. Aside from equally likely situations, if we blindly write down numbers that sum to 1 we will probably not luck into a probability measure where the events are independent. For example,\n\n\n\nOutcome\nAlicia\nAriana\nBeyonce\nBillie\n\n\n\n\nNumber of cards\n1\n2\n3\n4\n\n\nProbability\n0.1\n0.2\n0.3\n0.4\n\n\n\nLet \\(\\tilde{\\textrm{Q}}\\) represent this probability measure. Then \\(\\tilde{\\textrm{Q}}(A \\cap B) = 0.1 \\neq (0.3)(0.4)=\\tilde{\\textrm{Q}}(A)\\tilde{\\textrm{Q}}(B)\\), so events \\(A\\) and \\(B\\) are not independent. Elaborating,\n\nThere are 3 cards that satisfy \\(A\\) and 7 that don’t so \\(A\\) is 3/7 as likely to occur than not.\nIf \\(B\\) occurs, then it’s either Alicia (satisfies \\(A\\), 1 card) or Beyonce (does not satisfy \\(A\\), 3 cards), so given that \\(B\\) occurs then \\(A\\) is 1/3 times as likely to occur than not.\nIf \\(B\\) does not occur, then it’s either Ariana (satifies \\(A\\), 2 cards) or Billie (does not satisfy \\(A\\), 4 cards), so given that \\(B\\) does not occur then \\(A\\) is 2/4 = 1/2 times as likely to occur than not.\n\nKnowing whether or not \\(B\\) occurs changes the chance of \\(A\\) occurring, so \\(A\\) and \\(B\\) are not independent according to this probability model.\n\n\n\n\n\nRemember, independence is a statement about probabilities, not outcomes themselves. Given two events it is not always obvious whether or not they are independent.\nIndependence is determined by the probability measure. Events that are independent under one probability measure might not be independent under another. The probability measure represents all the assumptions about the random phenomenon. We often incorporate independence assumptions when specifying the probability measure. However, whether or not independence is a valid assumption depends on the underlying random phenomenon.\nBe sure to make a distinction between assumption and observation. For example, flip a coin some number of times. It might be reasonable to assume the coin is fair and flips are independent. In this case, the probability that the next flip lands on heads is 1/2 regardless of what you observed on the previous flips. However, if you flip a coin twenty times and it lands on heads each time, this might cast doubt on your assumption that the coin is fair.\n\n\n2.7.4 Independence of multiple events\n\n\n\n\n\n\n\nExample 2.63 Flip a fair coin twice. Let\n\n\\(A\\) be the event that the first flip lands on heads\n\\(B\\) be the event that the second flip lands on heads,\n\\(C\\) be the event that both flips land on the same side.\n\n\nAre the two events \\(A\\) and \\(B\\) independent?\nAre the two events \\(A\\) and \\(C\\) independent?\nAre the two events \\(B\\) and \\(C\\) independent?\nAre the three events \\(A\\), \\(B\\), and \\(C\\) independent?\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.63. There are four equally likely outcomes \\(\\{HH, HT, TH, TT\\}\\).\n\n\\(A = \\{HH, HT\\}\\), so \\(\\textrm{P}(A) = 2/4\\)\n\\(B = \\{HH, TH\\}\\), so \\(\\textrm{P}(B) = 2/4\\)\n\\(C = \\{HH, TT\\}\\), so \\(\\textrm{P}(C) = 2/4\\)\n\n\nYes, events \\(A\\) and \\(B\\) are independent. \\(A\\cap B=\\{HH\\}\\), \\(\\textrm{P}(A\\cap B)=1/4\\), and \\(\\textrm{P}(A\\cap B)=\\textrm{P}(A)\\textrm{P}(B)\\).\nYes, events \\(A\\) and \\(C\\) are independent. \\(A\\cap C=\\{HH\\}\\), \\(\\textrm{P}(A\\cap C)=1/4\\), and \\(\\textrm{P}(A\\cap C)=\\textrm{P}(A)\\textrm{P}(C)\\).\nYes, events \\(B\\) and \\(C\\) are independent. \\(B\\cap C=\\{HH\\}\\), \\(\\textrm{P}(B\\cap C)=1/4\\), and \\(\\textrm{P}(B\\cap C)=\\textrm{P}(B)\\textrm{P}(C)\\).\nNo, even though each pair of events is independent, the collection of the three events is not. If \\(A\\) and \\(B\\) occur then we know event \\(C\\) occurs. That is, \\(\\textrm{P}(C|A \\cap B)=1\\) but \\(\\textrm{P}(C) = 1/2\\).\n\n\n\n\n\nEvents \\(A_1, A_2, A_3, \\ldots\\) are independent if:\n\nany pair of events \\(A_i, A_j, (i \\neq j)\\) satisfies \\(\\textrm{P}(A_i\\cap A_j)=\\textrm{P}(A_i)\\textrm{P}(A_j)\\),\nand any triple of events \\(A_i, A_j, A_k\\) (distinct \\(i,j,k\\)) satisfies \\(\\textrm{P}(A_i\\cap A_j\\cap A_k)=\\textrm{P}(A_i)\\textrm{P}(A_j)\\textrm{P}(A_k)\\),\nand any quadruple of events \\(A_i, A_j, A_k, A_\\ell\\) (distinct \\(i,j,k,\\ell\\)) satisfies \\(\\textrm{P}(A_i\\cap A_j\\cap A_k \\cap A_\\ell)=\\textrm{P}(A_i)\\textrm{P}(A_j)\\textrm{P}(A_k)\\textrm{P}(A_\\ell)\\),\nand so on.\n\nIntuitively, a collection of events is independent if knowing whether or not any combination of the events in the collection occur does not change the probability of any other event in the collection.\nIn particular, three events \\(A\\), \\(B\\), \\(C\\) are independent if and only if all of the following are true \\[\n\\scriptsize{\n\\textrm{P}(A\\cap B) = \\textrm{P}(A)\\textrm{P}(B), \\quad  \\textrm{P}(A\\cap C) = \\textrm{P}(A)\\textrm{P}(C),\\quad  \\textrm{P}(B\\cap C) = \\textrm{P}(B)\\textrm{P}(C),\\quad \\textrm{P}(A\\cap B\\cap C) = \\textrm{P}(A)\\textrm{P}(B)\\textrm{P}(C)\n}\n\\]\nEquivalently, it can be shown that three events \\(A\\), \\(B\\), \\(C\\) are independent if and only if all of the following53 are true.\n\\[\\begin{align*}\n& \\textrm{P}(A| B) = \\textrm{P}(A), \\quad \\textrm{P}(A| C) = \\textrm{P}(A), \\quad \\textrm{P}(B|A) = \\textrm{P}(B), \\quad \\textrm{P}(B| C) = \\textrm{P}(B), \\quad \\textrm{P}(C|A) = \\textrm{P}(C),\\\\\n& \\textrm{P}(C|B) = \\textrm{P}(C), \\quad\n\\textrm{P}(A| B\\cap C) = \\textrm{P}(A), \\quad \\textrm{P}(B|A\\cap C) = \\textrm{P}(B), \\quad \\textrm{P}(C|A\\cap B) = \\textrm{P}(C)\n\\end{align*}\\]\n\n\n2.7.5 Independence of random variables\nWe have focused on independence of events, but random variables can also be independent.\n\n\n\n\n\n\n\nExample 2.64 Continuing Example 2.56. Let \\(U_1\\) be the result of the first roll.\n\nAre the events \\(\\{U_1 = 1\\}\\) and \\(\\{X = 5\\}\\) independent?\nDo you think the random variables \\(U_1\\) and \\(X\\) are independent? Support your answer by computing and comparing appropriate probabilities.\nSuggest a random variable in this context—not \\(X\\) or \\(Y\\)—that is independent of \\(U_1\\).\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.64. \n\nYes the events \\(\\{U_1 = 1\\}\\) and \\(\\{X = 5\\}\\). See the solution to part 3 of Example 2.61).\nIntuitively, \\(U_1\\) and \\(X\\) are not independent. But remember that independence is a statement about probabilities, so we need to compare appropriate probabilities. For example, \\(\\textrm{P}(X = 8 | U_1 = 1) = 0\\) but \\(\\textrm{P}(X = 8) = 1/16\\). Knowing that \\(U_1=1\\) changes the distribution of \\(X\\).\nIf \\(U_2\\) is the result of the second roll, then intuitively \\(U_1\\) and \\(U_2\\) are independent. \\(U_2\\) is equally likely to be 1, 2, 3, or 4, regardless of the value of \\(U_1\\).\n\n\n\n\n\nTwo random variables are independent if any event involving one of the random variables is independent of any event involving the other. Roughly, two random variables are independent if knowing the value of one does not change the distribution of the other. See Figure 2.28) for mosaic plots illustrating two independent discrete random variables (not in the dice context); notice that the conditional distribution of \\(X\\) is the same for each value of \\(Y\\), and vice versa.\n\n\n\n\n\n\n\n\n\n\n\n(a) Conditioning on values of \\(X\\); color represents values of \\(Y\\).\n\n\n\n\n\n\n\n\n\n\n\n(b) Conditioning on values of \\(Y\\); color represents values of \\(X\\)\n\n\n\n\n\n\n\nFigure 2.28: Mosaic plots for two independent discrete random variables \\(X\\) and \\(Y\\).\n\n\n\n\n\n2.7.6 Using independence\nRemember the general multiplication rule involves successive conditional probabilities \\[\n\\textrm{P}(A_1\\cap A_2 \\cap A_3 \\cap A_4 \\cap \\cdots) = \\textrm{P}(A_1)\\textrm{P}(A_2|A_1)\\textrm{P}(A_3|A_1\\cap A_2)\\textrm{P}(A_4|A_1\\cap A_2 \\cap A_4)\\cdots\n\\] In problems with complicated relationships, determining joint and conditional probabilities can be difficult.\nBut when events are independent, the multiplication rule simplifies greatly. \\[\n\\textrm{P}(A_1 \\cap A_2 \\cap A_3 \\cap \\cdots) = \\textrm{P}(A_1)\\textrm{P}(A_2)\\textrm{P}(A_3)\\cdots \\quad \\text{if $A_1, A_2, A_3, \\ldots are independent}\n\\]\nWhen a problem involves independence, you will want to take advantage of it. Work with “and” events whenever possible in order to use the multiplication rule. For example, for problems involving “at least one” (an “or” event) take the complement to obtain “none” (an “and” event).\n\n\n\n\n\n\n\nExercise 2.18 A certain system consists of four identical components. Suppose that the probability that any particular component fails is 0.1, and failures of the components occur independently of each other. Find the probability that the system fails if:\n\nThe components are connected in parallel: the system fails only if all of the components fail.\nThe components are connected in series: the system fails whenever at least one of the components fails.\nDonny Don’t says the answer to the previous part is \\(0.1 + 0.1 + 0.1 + 0.1 = 0.4\\). Explain the error in Donny’s reasoning.\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.65. Let \\(F\\) be the event the system fails, and \\(F_i\\) the event that component \\(i\\) fails.\n\nIf the components are connected in parallel, \\(F=F_1 \\cap F_2 \\cap F_3 \\cap F_4\\). \\[\\begin{align*}\n\\textrm{P}(F) & = \\textrm{P}(F_1\\cap F_2\\cap F_3 \\cap F_4) & & \\\\\n& = \\textrm{P}(F_1)\\textrm{P}(F_2)\\textrm{P}( F_3)\\textrm{P}(F_4) & & \\text{independence}\\\\\n& = (0.1)(0.1)(0.1)(0.1) = 0.0001\n\\end{align*}\\]\n“At least one fails” is an “or” event: \\(F= F_1 \\cup F_2 \\cup F_3 \\cup F_4\\). With independence you want “and” events. Use the complement rule \\[\\begin{align*}\n\\textrm{P}(F) & = \\textrm{P}(\\text{at least one fails}) & & \\\\\n& = 1 - \\textrm{P}(\\text{none fails})\\ & & \\\\\n& = 1 - \\textrm{P}(F_1^c\\cap F_2^c \\cap F_3^c\\cap F_4^c) & & \\\\\n& = 1 - \\textrm{P}(F_1^c)\\textrm{P}(F_2^c)\\textrm{P}( F_3^c)\\textrm{P}(F_4^c) & & \\text{independence}\\\\\n& = 1-(0.9)(0.9)(0.9)(0.9) = 0.3439\n\\end{align*}\\]\nDonny is assuming that the component failures are disjoint, but that’s not true since multiple components could fail. Simply adding the probabilities double counts outcomes where multiple components fail. Don’t confuse “disjoint” and “independent”. It is almost always better to work with “and” events and multiplying rather than “or” events.\n\n\n\n\n\nThe complement rule is often useful in probability problems that involve finding “the probability of at least one…,” which on the surface involves unions (OR). It usually more convenient to use the complement rule and compute “the probability of at least one…” as one minus “the probability of none…”; the latter probability involves intersections (AND). Don’t forget to actually use the complement rule to get back to the original probability of interest!\n\n\n\n\n\n\nWarning\n\n\n\nWhen using the complement rule, subtracting a computed probability from 1 seems like a small computational step, but it’s an important one. Getting 90% correct on a test is very different than getting 10% correct! Unfortunately, the complement rule step is often overlooked when doing probability calculations. It’s a good idea to ask yourself if the probability you are computing should be greater than or less than 50%. If your computed value seems to be on the wrong side of 50%, check your calculations to see if you have forgotten (or misapplied) the complement rule.\n\n\n\n\n\n\n\n\n\nExample 2.65 In the Powerball lottery, a player picks five different whole numbers between 1 and 69, and another whole number between 1 and 26 that is called the Powerball.\nIn the drawing, the 5 numbers are drawn without replacement from a “hopper” with balls labeled 1 through 69, but the Powerball is drawn from a separate hopper with balls labeled 1 through 26. The player wins the jackpot if both the first 5 numbers match those drawn, in any order, and the Powerball is a match. Under this set up, there are 292,201,338 possible winning numbers.\n\nWhat is the probability the next winning number is 6-7-16-23-26, plus the Powerball number, 4.\nWhat is the probability the next winning number is 1-2-3-4-5, plus the Powerball number, 6.\nThe Powerball drawing happens twice a week. Suppose you play the same Powerball number, twice a week, every week for over 50 years. Let’s say you purchase a ticket for 6000 drawings in total. What is the probability that you win at least once?\nInstead of playing for 50 years, you decide only to play one lottery, but you buy 6000 tickets, each with a different Powerball number. What is the probability that at least one of your tickets wins? How does this compare to the previous part? Why?\nEach ticket costs 2 dollars, but the jackpot changes from drawing to drawing. Suppose you buy 6000 tickets for a single drawing. How large does the jackpot need to be for your “expected” profit to be positive? To be $100,000? (We’re ignoring inflation, taxes, transaction costs, and any changes in the rules.)\n\n\n\n\n\n\n\n\n\n\n\nSolution (click to expand)\n\n\n\n\n\n\nSolution 2.66. \n\nEach of the possible winning numbers is equally likely, so the probability is \\(1/292,201,338\\approx 3\\times 10^{-9}\\). See Example 1.22 and the discussion following it.\nEach of the possible winning numbers is equally likely. Remember, don’t confuse a general event with a specific outcome; see Example 1.22.\nThe probability that you lose in any single drawing is \\((1-1/292201338)\\). The drawings are independent so the probability that you lose all 6000 is \\((1-1/292201338)^{6000}\\). The probability that you win at least once is \\(1 - (1-1/292201338)^{6000}\\approx 0.00002\\). If many people each play 6000 drawings, about 2 in every 100,000 people win will at least once.\nIf you play 6000 different numbers, the events that each different number wins are disjoint. So the probability you win at least once is \\(6000/292201338\\approx 0.00002\\). This is about the same as the probability in the previous part. When you play 6000 different independent drawings, there is a possibility that you win multiple times, so the events of winning in each different drawing are not disjoint. But the probability of winning multiple lotteries is so small that it’s negligible. The probability of winning any single drawing is about 1 in 300 million. The probability of winning twice in any two drawings is about 1 in 85 quadrillion.\nYou pay $12,000 in total. Let \\(w\\) be the value of the jackpot. You win either 0 or \\(w\\) so your “expected” profit is \\(w(6000/292201338)-12000\\). But this not what you expect in a single repetition. Rather, it is the profit you would expect to see on average in the long run. You probably won’t be buying 6000 tickets for a large number of drawings, so your long run average isn’t really relevant. In any case, we must have \\(w&gt;584,402,676\\) for the expected profit to be positive. Sometimes, but not often, the jackpot does get this high; even so, this just guarantees that your expected profit is positive. In order for your expected long run average profit to be greater than just $100,000, the jackpot must be over 5 billion dollars, and the largest jackpot ever was 1.6 billion. The moral: there are better things to do with $12,000 dollars.\n\n\n\n\n\n\n\n2.7.7 Exercises\n\nExercise 2.19 A very large petri dish starts with a single microorganism. After one minute, the microorganism either splits into two with probability \\(s\\), or dies. All subsequent microorganisms behave in the same way — splitting into two or dying after each minute — independently of each other.\n\nIf \\(s=3/4\\), what is the probability that the population eventually goes extinct? (Hint: condition on the first step.)\nCompute the probability that the population eventually goes extinct as a function of \\(s\\). For what values of \\(s\\) is the extinction probability 1?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#chapter-exercises",
    "href": "language-probability.html#chapter-exercises",
    "title": "2  The Language of Probability",
    "section": "2.8 Chapter exercises",
    "text": "2.8 Chapter exercises",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability.html#footnotes",
    "href": "language-probability.html#footnotes",
    "title": "2  The Language of Probability",
    "section": "",
    "text": "Why four-sided? Simply to make the number of possibilities a little more manageable. Rolling a four-sided die twice yields 16 possible pairs, while rolling a six-sided die yields 36 possible pairs.↩︎\nThere is no one set of universally agreed on notation, but \\(\\Omega\\) is commonly used. It is also common practice to use uppercase and lowercase letters to denote different objects, like \\(\\Omega\\) versus \\(\\omega\\).↩︎\nWe could have written the sample space as the Cartesian product \\(\\Omega = \\{1, 2, 3, 4\\} \\times\\{1, 2, 3, 4\\}\\), where the first \\(\\{1, 2, 3, 4\\}\\) set in the product represents the result of the first roll (and similarly for the second). But this Cartesian product still represents a single set of ordered pairs, and it is that single set which is the sample space corresponding to outcomes of the pair of rolls.↩︎\nWhy have we started with [0, 1] and not some other continuous interval? Because probabilities take values in \\([0, 1]\\). We will see why this is useful in more detail later.↩︎\nMathematically we can write the sample space as \\([0,60]\\times [0,60]=[0,60]^2\\), the Cartesian product \\(\\{(x, y): x \\in [0, 60], y \\in [0, 60]\\}\\), the set of ordered pairs whose components take values in \\([0, 60]\\).↩︎\nWe could also try \\([0, m]\\) where \\(m\\) is some large dollar amount providing an upper bound on the maximum possible salary. But we would need to be sure that \\(m\\) is large enough so that all possible outcomes are in the sample space \\([0, m]\\). Without knowing this bound in advance, it is convenient to just choose the unbounded interval \\([0, \\infty)\\). There is really no harm in making the sample space bigger than it needs to be, but you can run into problems if you make it too small.↩︎\nMathematically this sample space can be written as \\(\\Omega=\\{1, 2, 3\\}^\\infty\\).↩︎\na.k.a., jimmies↩︎\nTechnically, \\(\\mathcal{F}\\) is a \\(\\sigma\\)-field of subsets of \\(\\Omega\\): \\(\\mathcal{F}\\) contains \\(\\Omega\\) and is closed under countably many elementary set operations (complements, unions, intersections). This requirement ensures that if \\(A\\) and \\(B\\) are “events of interest”, then so are \\(A\\cup B\\), \\(A\\cap B\\), and \\(A^c\\). While this level of technical detail is not needed, we prefer to introduce the idea of a “collection of events” now since a probability measure is a function whose input is an event (set) rather than an outcome (point).↩︎\nA \\(d\\)-dimensional random vector \\(V\\) maps sample space outcomes to \\(d\\)-dimensional vectors, \\(V:\\Omega \\mapsto \\mathbb{R}^d\\). The output of a random vector is a vector (or tuple) of numbers.↩︎\nThroughout, we use \\(g\\) to denote a generic function, and reserve \\(f\\) to represent a probability density function (which we will encounter later). Likewise, we represent a generic function argument (or “dummy variable”) with \\(u\\), since \\(x\\) is often used to represent possible values of a random variable \\(X\\). In the context of a random variable, \\(x\\) typically represents the output of the function \\(X\\) rather than the input (which is a sample space outcome \\(\\omega\\).)↩︎\nIn Example 2.17 sample space outcomes are pairs of rolls. If we denote a generic outcome as \\(\\omega = (\\omega_1, \\omega_2)\\) then \\(X(\\omega) = X((\\omega_1, \\omega_2)) = \\omega_1 + \\omega_1\\). Similarly, \\(Y(\\omega) = Y((\\omega_1, \\omega_2)) = \\max(\\omega_1, \\omega_2)\\). But we don’t need this level of technical detail; defining \\(X\\) and \\(Y\\) in words is sufficient.↩︎\n\\(Y(\\omega) = g(X(\\omega))\\) so \\(Y\\) maps \\(\\Omega\\) to \\(\\mathbb{R}\\) via the composition of the functions \\(g\\) and \\(X\\); that is, \\(Y=g\\circ X\\) where \\((g\\circ X):\\Omega\\mapsto \\mathbb{R}\\)↩︎\nOrange you glad I didn’t say banana?↩︎\nSee the inclusion-exclusion principle↩︎\nAnd \\(\\{X = 3\\}\\) itself is short for \\(\\{\\omega\\in\\Omega:X(\\omega) = x\\}\\).↩︎\nA probability measure is a set function; its input is a set and its output is a number.↩︎\nIt’s the number of events that must be countable. The events themselves can be uncountable sets like intervals.↩︎\nThat the probability of each outcome must be 1/4 when there are four equally likely outcomes follows from the axioms, by writing \\(\\{1, 2, 3, 4\\} = \\{1\\}\\cup\\{2\\}\\cup \\{3\\}\\cup \\{4\\}\\), a union of disjoint sets, and applying countable additivity and \\(\\textrm{P}(\\Omega)=1\\). But we don’t need this level of technical detail; our intuition tells us the probability of each four equally likely outcomes is 1/4.↩︎\nProbabilities are always defined for events (sets). When we say loosely “the probability of an outcome \\(\\omega\\)” we really mean the probability of the event \\(\\{\\omega\\}\\) consisting of the single outcome \\(\\omega\\). In this example \\(\\textrm{P}(\\{1\\})=\\textrm{P}(\\{2\\})=\\textrm{P}(\\{3\\})=\\textrm{P}(\\{4\\})=1/4\\).↩︎\n\\(\\Omega = \\{1, 2, 3\\} \\cup \\{4\\}\\), a union of disjoint events, so \\(1 = \\textrm{Q}(\\Omega) = \\textrm{Q}(\\{1, 2, 3\\}) + \\textrm{Q}(\\{4\\})\\).↩︎\nBecause he’s solo.↩︎\nIt doesn’t really matter if we round or truncate to the nearest minute, but we’re truncating so we don’t treat 0 differently than the other values (technically only times in the first 30 seconds, not minute, round to 0).↩︎\nThis is one reason why probabilities are defined directly for events and not outcomes.↩︎\nProof. Since \\(\\Omega = A \\cup A^c\\) and \\(A\\) and \\(A^c\\) are disjoint the axioms imply that \\(1=\\textrm{P}(\\Omega) = \\textrm{P}(A \\cup A^c) = \\textrm{P}(A) + \\textrm{P}(A^c)\\).↩︎\nProof. If \\(A \\subseteq B\\) then \\(B = A \\cup (B \\cap A^c)\\). Since \\(A\\) and \\((B \\cap A^c)\\) are disjoint, \\(\\textrm{P}(B) = \\textrm{P}(A) + \\textrm{P}(B \\cap A^c) \\ge \\textrm{P}(A)\\).↩︎\nThe proof is easiest to see by considering a picture like the one in Figure 2.8).↩︎\nSee the inclusion-exclusion principle.↩︎\n\\(A = A\\cap \\Omega = A\\cap(C_1 \\cup C_2 \\cup \\cdots) = (A\\cap C_1)\\cup(A\\cap C_2)\\cup \\cdots\\). The \\(A\\cap C_i\\)’s are disjoint since the \\(C_i\\)’s are, and the result follows from countable additivity.↩︎\nIn this example it is logically possible for \\(\\textrm{P}(C \\cap D)\\) to be 0, but that’s not always true. For example, if \\(\\textrm{P}(A) = 0.9\\) and \\(\\textrm{P}(B) = 0.8\\), then \\(\\textrm{P}(A \\cap B)\\) must be at least 0.7 so that \\(\\textrm{P}(A \\cup B)\\le 1\\).↩︎\nA probability space is usually defined as a triple \\((\\Omega, \\mathcal{F}, \\textrm{P})\\), where \\(\\Omega\\) is the sample space, \\(\\mathcal{F}\\) is a \\(\\sigma\\)-field of subsets of \\(\\Omega\\) representing the collection of events of interest, and \\(\\textrm{P}\\) is a probability measure. Given that many events of interest involve random variables, we also include random variables in the model.↩︎\nThe values in this problem are based on a April, 2021 report by the Pew Research Center.↩︎\nBased on data from the U.S. Census Bureau↩︎\nWe generally encourage you to use two-way tables of whole number counts, but we’re using probabilities here to motivate the definition of conditional probability.↩︎\nWe have seen that “equals to” events involving continuous random variables have probability 0. We will discuss some issues related to conditioning on the value of a continuous random variable later.↩︎\nThe value only differs from the 0.24 in Example 2.45 due to rounding.↩︎\nThe value only differs from the 0.5417 in Example 2.45 due to rounding.↩︎\nIn computing these probabilities we have unconsciously applied “Bayes rule”, which we will discuss in more detail later.↩︎\nYou should really check about this birthday problem demo from The Pudding.↩︎\nWhich isn’t quite true. However, a non-uniform distribution of birthdays only increases the probability that at least two people have the same birthday. To see that, think of an extreme case like if everyone were born in September.↩︎\nSometimes students mistake this for \\((1/365)^2\\), but \\((1/365)^2\\) would be the probability that person 1 and person 2 both have a particular birthday, like the probability that both are born on January 1. There are \\(365^2\\) possible (person 1, person 2) birthday pairs, of which 365 — (Jan 1, Jan 1), (Jan 2, Jan 2), etc — result in the same birthday, so the probability of sharing a birthday is \\(365/365^2 = 1/365\\).↩︎\nProof: start with Lemma 2.5 and use the multiplication rule to write \\(\\textrm{P}(A \\cap C_1)=\\textrm{P}(A|C_1)\\textrm{P}(C_1)\\), etc.↩︎\nThey should be exactly the same; any differences are due to rounding.↩︎\nThis section only covers Bayes’ rule for events. We’ll see Bayes’ rule for distributions of random variables later. But the ideas are analogous.↩︎\nWe’re using “hypothesis” in the sense of a general scientific hypothesis, not necessarily a statistical null or alternative hypothesis.↩︎\nThe symbol \\(\\propto\\) means “is proportional to”.↩︎\nConditioning on event \\(E\\) can also be viewed as a restiction of the sample sample from \\(\\Omega\\) to \\(E\\). However, we prefer to keep the sample space as \\(\\Omega\\) and only view conditioning as a change in probability measure. In this way, we can consider conditioning on various events as representing different probability measures all defined for the same collection of events corresponding to the same sample space.↩︎\nRemember: probabilities are assigned to events, so we are speaking loosely when we say probabilities of outcomes.↩︎\nThanks to Allan Rossman for this example.↩︎\nTechnically, we should say “\\(\\textrm{P}\\)-independent”; see Section 2.7.3↩︎\nThe proof follows from the definitions of independence and conditional probability and properties of a probability measure. For example, \\(\\textrm{P}(A) = \\textrm{P}(A\\cap B) + \\textrm{P}(A \\cap B^c)\\) so \\(\\textrm{P}(A \\cap B^c) = \\textrm{P}(A) - \\textrm{P}(A \\cap B)\\). If \\(A\\) and \\(B\\) are independent then \\(\\textrm{P}(A \\cap B^c) = \\textrm{P}(A) - \\textrm{P}(A)\\textrm{P}(B) = \\textrm{P}(A)(1-\\textrm{P}(B)) = \\textrm{P}(A)\\textrm{P}(B^c)\\), so \\(A\\) and \\(B^c\\) are independent.↩︎\nThat is, if one statement is true then they all are true; if one statement is false, then they all are false.↩︎\nSome of these conditions are redundant. For example, \\(\\textrm{P}(A|B)=\\textrm{P}(A)\\) if and only if \\(\\textrm{P}(B|A)=\\textrm{P}(B)\\) so technically only one of those conditions needs to be verified.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Language of Probability</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html",
    "href": "language-probability-exercises.html",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "",
    "text": "3.1 Solution to Exercise 2.2\nTable 3.1: Sample space for Exercise 2.2\n\n\n\n\n\n\nbox1\nbox2\nbox3\nX\nY\n\n\n\n\n1\n1\n1\n1\n3\n\n\n2\n1\n1\n2\n2\n\n\n3\n1\n1\n2\n2\n\n\n1\n2\n1\n2\n2\n\n\n2\n2\n1\n2\n1\n\n\n3\n2\n1\n3\n1\n\n\n1\n3\n1\n2\n2\n\n\n2\n3\n1\n3\n1\n\n\n3\n3\n1\n2\n1\n\n\n1\n1\n2\n2\n2\n\n\n2\n1\n2\n2\n1\n\n\n3\n1\n2\n3\n1\n\n\n1\n2\n2\n2\n1\n\n\n2\n2\n2\n1\n0\n\n\n3\n2\n2\n2\n0\n\n\n1\n3\n2\n3\n1\n\n\n2\n3\n2\n2\n0\n\n\n3\n3\n2\n2\n0\n\n\n1\n1\n3\n2\n2\n\n\n2\n1\n3\n3\n1\n\n\n3\n1\n3\n2\n1\n\n\n1\n2\n3\n3\n1\n\n\n2\n2\n3\n2\n0\n\n\n3\n2\n3\n2\n0\n\n\n1\n3\n3\n2\n1\n\n\n2\n3\n3\n2\n0\n\n\n3\n3\n3\n1\n0",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-collector4-outcome",
    "href": "language-probability-exercises.html#solution-to-exr-collector4-outcome",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "",
    "text": "There are 3 possible prizes in each of 3 boxes, so there are \\(3^3 = 27\\) possible outcomes.\nSee Table 3.1 (ignore \\(X\\) and \\(Y\\) columns for now); there are 27 rows, each row for a different possible outcome.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-event-collector3",
    "href": "language-probability-exercises.html#solution-to-exr-event-collector3",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.2 Solution to Exercise 2.3",
    "text": "3.2 Solution to Exercise 2.3\nSee the sample space \\(\\Omega\\) of 27 possible outcomes in Table 3.1.\n\n\\(A_1^c = \\{222, 223, 232, 322, 233, 323, 332, 333\\}\\) is the event that none of the boxes contain prize 1, so \\(A_1\\) consists of the \\(27-8 = 19\\) other outcomes.\n\\(B_1 = \\{111\\}\\)\n\\(A_1 \\cap A_2 \\cap A_3 = \\{123, 132, 213, 231, 312, 321\\}\\) is the event that at least one of each prize is obtained (that is, a complete set of prizes)\n\\(A_1 \\cup A_2 \\cup A_3 = \\Omega\\), the set of all possible outcomes; you have to get at least 1 of one of the prizes.\n\\(B_1 \\cap B_2 \\cap B_3=\\emptyset\\); you can’t get only prize 1 and only prize 2\n\\(B_1 \\cup B_2 \\cup B_3 = \\{111, 222, 333\\}\\) is the event you only obtain one of the prizes (in every box)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-event-dartboard",
    "href": "language-probability-exercises.html#solution-to-exr-event-dartboard",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.3 Solution to Exercise 2.4",
    "text": "3.3 Solution to Exercise 2.4\nSee Figure 3.1\n\nFigure 3.1 (a): \\(A\\), Katniss’s dart lands within 1 inch of the center of the dartboard.\nFigure 3.1 (b): \\(B\\), Katniss’s dart lands more than 1 inch but less than 2 inches away from the center of the dartboard.\nFigure 3.1 (c): \\(E\\), Katniss’s dart lands within 1 inch of the outside edge of the dartboard.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Within 1 inch of center\n\n\n\n\n\n\n\n\n\n\n\n(b) More than 1 but less than 2 inches from center\n\n\n\n\n\n\n\n\n\n\n\n(c) Within 1 inch of edge\n\n\n\n\n\n\n\nFigure 3.1: Events in Exercise 2.4",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-rv-collector3",
    "href": "language-probability-exercises.html#solution-to-exr-rv-collector3",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.4 Solution to Exercise 2.6",
    "text": "3.4 Solution to Exercise 2.6\n\nSee Table 3.1\nThe possible values of \\(X\\) are \\(\\{1, 2, 3\\}\\)\nThe possible values of \\(Y\\) are \\(\\{0, 1, 2, 3\\}\\)\nThe possible \\((X, Y)\\) pairs are \\(\\{(1, 0), (1, 3), (2, 0), (2, 1) (2, 2), (3, 1)\\}\\), In particular, the following pairs are NOT possible: \\((1, 1), (1, 2), (2, 3), (3, 0), (3, 2), (3, 3)\\)\n\\(\\{X = 1\\} = \\{111, 222, 333\\}\\) is the event that only one distinct prize is obtained (that is, you get the same prize in every box)\n\\(\\{X=2\\}\\) is the event you get two distinct prizes, which consists of 18 putcomes. It’s easier to write \\(\\{X = 2\\}^c = \\{111, 222, 333, 123, 132, 213, 231, 312, 321\\}\\).\n\\(\\{X = 3\\} = \\{123, 132, 213, 231, 312, 321\\}\\) is the event that you get all 3 prizes; that is, the event that you get the complete set\n\\(\\{Y = 0\\}=\\{222, 223, 232, 322, 233, 323, 332, 333\\}\\) is the event that none of the boxes contain prize 1\n\\(\\{Y = 1\\}=\\{122, 123, 132, 133, 212, 213, 312, 313, 221, 231, 321, 331\\}\\) is the event that exactly one of the boxes contains prize 1\n\\(\\{Y = 2\\}=\\{112, 113, 121, 131, 211, 311\\}\\) is the event that exactly two of the boxes contain prize 1.\n\\(\\{Y = 3\\}=\\{111\\}\\) is the event that all three of the boxes contain prize 1.\n\\(\\{X = 2, Y = 1\\} = \\{122, 133, 212, 313, 221, 331\\}\\) is the event that one box contains prize one and the other two boxes contain either both prize 2 or both prize 3.\n\\(\\{X = Y\\} = \\{112, 113, 121, 131, 211, 311\\}\\) is the event that the number of boxes that contain prize 1 is equal to the number of distinct prizes obtained (in this case it only happens if both \\(X\\) and \\(Y\\) equal 2)\nLet \\(I_1\\) be the indicator random variable that prize 1 is obtained (in at least one of the three packages). Identify and intepret \\(\\{I_1 = 0\\}\\).\n\\(X = I_1+ I_2+ I_3\\)\nLabel the boxes instead of the prizes. Let \\(J_1\\) be the indicator random variable that box 1 contains prize 1, \\(J_2\\) that box 2 contains prize 1, and \\(J_3\\) that box 3 contains prize 1. Then \\(Y = J_1+ J_2+ J_3\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-rv-dartboard",
    "href": "language-probability-exercises.html#solution-to-exr-rv-dartboard",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.5 Solution to Exercise 2.7",
    "text": "3.5 Solution to Exercise 2.7\n\nFigure 3.1 (a): \\(\\{X \\le 1\\}\\), Katniss’s dart lands within 1 inch of the center of the dartboard.\nFigure 3.1 (b): \\(\\{1 &lt; X &lt; 2\\}\\), Katniss’s dart lands more than 1 inch but less than 2 inches away from the center of the dartboard.\nFigure 3.1 (c): \\(\\{X &gt; 11\\}\\), Katniss’s dart lands within 1 inch of the outside edge of the dartboard.\n\\(\\{X = 0\\}\\), the event that the dart hits exactly in the center, is just the single point in the center\n\\(\\{X = 1\\}\\), the event that the dart hits exactly 1 inch from the center, is the circle with radius 1 inch (the outside egde of the shaded region in Figure 3.1 (a))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-probspace-collector3-a",
    "href": "language-probability-exercises.html#solution-to-exr-probspace-collector3-a",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.6 Solution to Exercise 2.10",
    "text": "3.6 Solution to Exercise 2.10\nThe latest series of collectible Lego Minifigures contains 3 different Minifigure prizes (labeled 1, 2, 3). Each package contains a single unknown prize. Suppose we only buy 3 packages and we consider as our sample space outcome the results of just these 3 packages (prize in package 1, prize in package 2, prize in package 3). For example, 323 (or (3, 2, 3)) represents prize 3 in the first package, prize 2 in the second package, prize 3 in the third package. Suppose that each package is equally likely to contain any of the 3 prizes, regardless of the contents of other packages, so that there are 27 equally likely outcomes, and let \\(\\textrm{P}\\) be the corresponding probability measure.\n\nLet \\(A_1\\) be the event that prize 1 is obtained—that is, at least one of the packages contains prize 1—and define \\(A_2, A_3\\) similarly for prize 2, 3.\nLet \\(B_1\\) be the event that only prize 1 is obtained—that is, all three packages contain prize 1—and define \\(B_2, B_3\\) similarly for prize 2, 3.\n\n\nCompute \\(\\textrm{P}(A_1)\\)\nCompute \\(\\textrm{P}(B_1)\\)\nInterpret the values from parts 1 and 2 as long run relative frequencies.\nInterpret the values from parts 1 and 2 as relative likelihoods.\nCompute \\(\\textrm{P}(A_1 \\cap A_2 \\cap A_3)\\)\nCompute \\(\\textrm{P}(A_1 \\cup A_2 \\cup A_3)\\)\nCompute \\(\\textrm{P}(B_1 \\cap B_2 \\cap B_3)\\)\nCompute \\(\\textrm{P}(B_1 \\cup B_2 \\cup B_3)\\)\n\\(A_1^c = \\{222, 223, 232, 322, 233, 323, 332, 333\\}\\) is the event that none of the boxes contain prize 1, so \\(A_1\\) consists of the \\(27-8 = 19\\) other outcomes. Since the outcomes are equally likely, \\(\\text{P}(A_1) = 18/27=0.667\\).\nThere is only one outcome that satisfies \\(B_1\\) so \\(\\text{P}(B_1) = 1/27 = 0.037\\).\nOver many sets of 3 boxes, about 66.7% of sets of 3 boxes will contain at least one prize 1, and about 3.7% of sets of 3 boxes will contain only prize 1.\nIt is 18 times more likely to obtain at least one prize 1 than it is to obtain only prize 1. Also, it is 2 times more likely to obtain at least one prize 1 than to not obtain it (18/9), and it is 26 times less likely to obtain only prize 1 than it is to obtain any other collection of prizes.\n\\(A_1 \\cap A_2 \\cap A_3 = \\{123, 132, 213, 231, 312, 321\\}\\) is the event that at least one of each prize is obtained (that is, a complete set of prizes) so \\(\\textrm{P}(A_1 \\cap A_2 \\cap A_3) = 6/27 = 0.222\\)\n\\(A_1 \\cup A_2 \\cup A_3 = \\Omega\\), the set of all possible outcomes; you have to get at least 1 of one of the prizes so \\(\\textrm{P}(A_1 \\cup A_2 \\cup A_3) = 1\\)\n\\(B_1 \\cap B_2 \\cap B_3=\\emptyset\\); you can’t get only prize 1 and only prize 2, so \\(\\textrm{P}(B_1 \\cap B_2 \\cap B_3) = 0\\)\n\\(B_1 \\cup B_2 \\cup B_3 = \\{111, 222, 333\\}\\) is the event you only obtain one of the prizes (in every box), so \\(\\textrm{P}(B_1 \\cup B_2 \\cup B_3) = 3/27 = 0.111\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-probspace-dartboard-b",
    "href": "language-probability-exercises.html#solution-to-exr-probspace-dartboard-b",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.7 Solution to Exercise 2.13",
    "text": "3.7 Solution to Exercise 2.13\nSince the dart lands uniformly at random anywhere on the dartboard, probabilities are computed as the ratio between the area corresponding to the event of interest divided by the area of the total dartboard (\\(12^2\\pi\\))\nSee Figure 3.1. Find the area of the shaded pieces by subtracting areas of circles.\n\n\\(\\text{P}(X \\le 1) = \\frac{1^2\\pi}{12^2\\pi} = 1/144 = 0.00694\\)\n\\(\\text{P}(1 &lt; X &lt; 2) = \\frac{2^2\\pi - 1^2\\pi}{12^2\\pi} = 3/144 = 0.021\\)\n\\(\\text{P}(X &gt; 11) = 1 - \\frac{11^2\\pi}{12^2\\pi} = 1 - (11/12)^2 = 0.160\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-probspace-dartboard-c",
    "href": "language-probability-exercises.html#solution-to-exr-probspace-dartboard-c",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.8 Solution to Exercise 2.14",
    "text": "3.8 Solution to Exercise 2.14\nSince the dart lands uniformly at random anywhere on the dartboard, probabilities are computed as the ratio between the area corresponding to the event of interest divided by the area of the total dartboard (\\(12^2\\pi\\))\nFind the area of the events of interest by finding areas of corresponding circles and subtracting as needed.\n\n\\(\\textrm{P}(X \\le 0.1) = \\frac{0.1^2\\pi}{12^2\\pi} = (0.1/12)^2 = 0.0000694\\)\n\\(\\textrm{P}(X \\le 0.01) = \\frac{0.01^2\\pi}{12^2\\pi} = (0.01/12)^2 = 0.000000694\\)\n\\(\\textrm{P}(X = 0) = 0\\), the single point has no area\n\\(\\textrm{P}(X \\ge 11.9) = 1 - \\frac{11.9^2\\pi}{12^2\\pi} = 1 - (11.9/12)^2 = 0.0166\\)\n\\(\\textrm{P}(X \\ge 11.99) = 1 - \\frac{11.99^2\\pi}{12^2\\pi} = 1 - (11.99/12)^2 = 0.00166\\)\n\\(\\textrm{P}(X = 12) = 0\\), the circle representing the outside edge has no area\nWell, both of these events—the dart lands exactly in the center and the darts lands exactly on the edge—have 0 probability. However for practical purposes we would never be interested in probabilities like \\(\\textrm{P}(X = 0.000000000\\ldots)\\) or \\(\\textrm{P}(X = 12.000000000\\ldots)\\) with infinite precision.\nHowever we define “close to”—within 1 inch or within 0.1 inch or within 0.01 inch, etc—the dart is more likely to land close to the edge than close to the center.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-ltp-multiple-choice",
    "href": "language-probability-exercises.html#solution-to-exr-ltp-multiple-choice",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.9 Solution to Exercise 2.16",
    "text": "3.9 Solution to Exercise 2.16\n\nSuppose there are 1000 questions on the test. (That’s a long test! But remember, 1000 is just a convenient round number.) We can classify each question by its type (know, eliminate, guess) and whether we answer it correctly or not. The probability that we answer a question correctly is 1 given that we know it, 0.5 given that we can eliminate two choices, or 0.25 given that we guess randomly.\n\n\n\n\nKnow\nEliminate\nGuess\nTotal\n\n\n\n\nCorrect\n700\n100\n25\n825\n\n\nIncorrect\n0\n100\n75\n175\n\n\nTotal\n700\n200\n100\n1000\n\n\n\nThe probability that we answer a randomly selected question correctly is 825/1000 = 0.825.\nThe overall probability of answering a question correctly is closer to 1 than 0.5 or 0.25. To construct the table and obtain the value 0.825, we basically did the following calculation\n\\[\n0.825 = (1)(0.7) + (0.5)(0.2) + (0.25)(0.1)\n\\]\nWe see that the overall probability, 0.825, is a weighted average of the case-by-case probabilities 1, 0.5, and 0.25, where 1 gets the most weight in the average because there is a higher percentage of questions that we know.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-ltp-rats",
    "href": "language-probability-exercises.html#solution-to-exr-ltp-rats",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.10 Solution to Exercise 2.17",
    "text": "3.10 Solution to Exercise 2.17\n\nMost people produce a sequence that has 30 G’s and 10 R’s, or close to those proportions, because they are trying to generate a sequence for which each outcome has a 75% chance for G and a 25% chance for R. That is, they use a strategy in which they predict G with probability 0.75, and R with probability 0.25.\nThere are two cases: the true flash is either green (with probability 0.75) or red (with probability 0.25). Given that the flash is green, your probability of correctly predicting it is 0.75 (because your probability of guessing “G” is 0.75). Given that the flash is red, your probability of correctly predicting it is 0.25 (because your probability of guessing “R” is 0.25). Use the law of total probability to find the probability that your prediction is correct: \\((0.75)(0.75) + (0.25)(0.25) = 0.625\\).\nJust pick G every time! Picking green every time has a 0.75 probability of correctly predicting any flash. When events are independent, trying to guess the pattern doesn’t help.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#solution-to-exr-branching-extinction",
    "href": "language-probability-exercises.html#solution-to-exr-branching-extinction",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "3.11 Solution to Exercise 2.19",
    "text": "3.11 Solution to Exercise 2.19\n\nLet \\(D\\) be the probability that the original microorganism dies after the first minute; \\(\\textrm{P}(D) = 1/4\\). Condition on the first “step” and use the law of total probability \\[\np = \\textrm{P}(E) = \\textrm{P}(E|D)\\textrm{P}(D) + \\textrm{P}(E|D^c)\\textrm{P}(D^c) = (1)(1/4) + \\textrm{P}(E|D^c)(3/4)\n\\] \\(\\textrm{P}(E|D) = 1\\) since if the first microorganism dies the population goes extinct immediately.\nThe key is to find an expression for \\(\\textrm{P}(E|D^c)\\) in terms of \\(p\\). If the first microorganism does not die (\\(D^c\\)) there are 2 microorganisms at the start of the second minute; let’s call them Marge and Homer. In order for the population to go extinct, we need Marge and all her descendants to go extinct, and the same for Homer. But Marge is just a single microorganism, so the probability that her line eventually goes extinct is \\(p\\); similarly the probability that Homer’s line goes extinct is \\(p\\). Since all microorganisms behave independently, the probability that both Marge and Homer’s lines eventually go extinct is \\((p)(p)=p^2\\). That is, \\(\\textrm{P}(E | D^c) = p^2\\).\nPlugging into the equation above yields \\[\np = (1)(1/4) + p^2(3/4)\n\\]\nSolve (quadratic formula) this equation to get1 \\(p= 1/3\\). The probability that the population eventually goes extinct is 1/3. This microorganism population is 2 times more likely to survive forever than to go extinct!\nThe process is the same as the above, with 3/4 replaced by \\(s\\) \\[\np = (1)(1-s) + p^2s\n\\] Solving gives two solutions, 1 and \\(1/s - 1\\). However, if \\(s&lt;1/2\\) then \\(1/s - 1 &gt; 1\\), which is not a valid probability. Therefore the probability of eventual extinction is 1 if \\(s \\le 1/2\\), and \\(1/s - 1&lt;1\\) if \\(s &gt; 1/2\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "language-probability-exercises.html#footnotes",
    "href": "language-probability-exercises.html#footnotes",
    "title": "3  Chapter 2 Exercise Solutions",
    "section": "",
    "text": "Technically, there are two solutions, 1 and \\(1/3\\). There are some technical justifications that can be made to show that the extinction probability is the smaller of the two solutions, but this is beyond our scope.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 2 Exercise Solutions</span>"
    ]
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "(APPENDIX) Appendix",
    "section": "",
    "text": "TBA",
    "crumbs": [
      "(APPENDIX) Appendix"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aldous, David. 2023. “Forty Thousand Coin Tosses Yield Ambiguous\nEvidence for Dynamical Bias.” 2023. https://www.stat.berkeley.edu/~aldous/Real-World/coin_tosses.html.\n\n\nBarclay, Scott, Rex Brown, Clinton III, Cameron Peterson, and Lawrence\nPhillips. 1977. “Handbook for Decision Analysis,”\nSeptember, 284.\n\n\nBartoš, František, Alexandra Sarafoglou, Henrik R. Godmann, Amir\nSahrani, David Klein Leunk, Pierre Y. Gui, David Voss, et al. 2024.\n“Fair Coins Tend to Land on the Same Side They Started: Evidence\nfrom 350,757 Flips.” https://arxiv.org/abs/2310.04153.\n\n\nDavid, F. N. 1955. “Studies in the History of Probability and\nStatistics i. Dicing and Gaming (a Note on the History of\nProbability).” Biometrika 42 (1/2): 1–15. http://www.jstor.org/stable/2333419.\n\n\nDiaconis, Persi, Susan Holmes, and Richard Montgomery. 2007.\n“Dynamical Bias in the Coin Toss.” SIAM Review 49\n(2): 211–35. http://www.jstor.org/stable/20453950.\n\n\nDiaconis, Persi, and Brian Skrms. 2018. Ten Great Ideas about\nChance. Princeton University Press. http://www.jstor.org/stable/j.ctvc77m33.\n\n\nGilovich, Thomas D., Robert P. Vallone, and Amos Tversky. 1985.\n“The Hot Hand in Basketball: On the Misperception of Random\nSequences.” Cognitive Psychology 17 (3): 295–314.\nhttps://doi.org/https://doi.org/10.1016/0010-0285(85)90010-6.\n\n\nKahneman, Daniel. 2012. Thinking, Fast and Slow. London:\nPenguin.\n\n\nMiller, Joshua B., and Adam Sanjurjo. 2018a. “Surprised by the Hot\nHand Fallacy? A Truth in the Law of Small Numbers.”\nEconometrica 86 (6): 2019–47. https://doi.org/10.3982/ECTA14943.\n\n\n———. 2018b. “A Cold Shower for the Hot Hand Fallacy: Robust\nEvidence That Belief in the Hot Hand Is Justified.” OSF\nPreprints. https://doi.org/10.31219/osf.io/pj79r.\n\n\n———. 2018c. “Is It a Fallacy to Believe in the Hot Hand in the NBA\nThree-Point Contest?” OSF Preprints. https://doi.org/10.31219/osf.io/dmksp.\n\n\nMurray, Daniel B., and Scott W. Teare. 1993. “Probability of a\nTossed Coin Landing on Edge.” Phys. Rev. E 48 (October):\n2547–52. https://doi.org/10.1103/PhysRevE.48.2547.\n\n\nRoss, Kevin, and Dennis L. Sun. 2019. “Symbulate: Simulation in\nthe Language of Probability.” Journal of Statistics\nEducation 27 (1): 12–28. https://doi.org/10.1080/10691898.2019.1600387.\n\n\nTversky, Amos, and Daniel Kahneman. 1982. “Judgments of and by\nRepresentativeness.” In Judgment Under Uncertainty:\nHeuristics and Biases, edited by Daniel Kahneman, Paul Slovic, and\nAmosEditors Tversky, 84–98. Cambridge University Press. https://doi.org/10.1017/CBO9780511809477.007.",
    "crumbs": [
      "References"
    ]
  }
]